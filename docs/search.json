[
  {
    "objectID": "00_about.html",
    "href": "00_about.html",
    "title": "Material de apoio à disciplinas",
    "section": "",
    "text": "Esta página contém os materiais de apoio em linguagem R das disciplinas ministradas pelo Prof. Tiago Olivoto no Departamento de Fitotecnia do Centro de Ciências Agrárias da Universidade Federal de Santa Catarina\n\nInstalação dos softwares\nPara reprodução dos exemplos deste material, os softwares R e RStudio são necessários\n\n\n  \n\n\n\n\n\n Download do R\n Download do RStudio\n\n\nProfessor\n\n\n\n\n\n\nNote\n\n\n\nTécnico Agrícola pela Escola Estadual de Educação Básica Viadutos (2008), Engenheiro agrônomo pela Universidade do Oeste de Santa Catarina (2014), Mestre em Agronomia: Agricultura e Ambiente pela Universidade Federal de Santa Maria (2017) e Doutor em Agronomia com ênfase em Melhoramento Genético Vegetal e Experimentação Agrícola pela Universidade Federal de Santa Maria (2020). Atualmente é Professor Adjunto A1 do Departamento de Fitotecnia da Universidade Federal de Santa Catarina (UFSC), atuando na área de Melhoramento Genético Vegetal e Experimentação Agrícola. Exerce atividades relacionadas ao planejamento, condução e avaliação de experimentos com culturas anuais, com ênfase no desenvolvimento e aperfeiçoamento de métodos estatístico-experimentais para avaliação de ensaios multi-ambientes em melhoramento genético de plantas. Em seu Currículo, os termos mais frequentes na contextualização da produção científica são: análise de ensaios multi-ambientes, índices multivariados, intervalo de confiança para correlação, planejamento de experimentos, seleção indireta, interação genótipo-vs-ambiente, modelos mistos e parâmetros genéticos. É membro atuante da International Biometric Society (IBS) e integrante da comissão de Jovens Pesquisadores da Região Brasileira da Sociedade Internacional de Biometria, RBras, (JP-RBras) representando os estados do RS, SC e PR. Atua também como revisor ad hoc em revistas científicas nacionais e internacionais. Tem experiência com os softwares Gênes, GEA-R, R, SAS e SPSS. Vem desenvolvendo os pacotes para software R metan, voltado para a checagem, manipulação, análise e apresentação de dados de ensaios multi-ambientes e pliman voltado para a análise de imagens de plantas.\n\n\n\n\n\n\n\n\n\nPacotes úteis\nPara reprodução dos exemplos deste repositório é sugerido instalar os seguintes pacotes. Para saber como instalar pacotes no R, visite este vídeo!\n\nlibrary(tidyverse)  # manipulação de dados\nlibrary(metan)      # estatísticas descritivas/gráficos\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA\n\n\n\nLicença\nEste conteúdo está licenciado com uma Licença Creative Commons - Atribuição-NãoComercial-CompartilhaIgual 4.0 Internacional. O resumo legível da licença afirma que você tem o direito de:\n\nCompartilhar — copie e redistribua o material em qualquer meio ou formato.\nAdaptar — remixar, transformar e construir sobre o material\nAtribuir — Você deve dar o crédito apropriado, fornecer um link para a licença e indicar se foram feitas alterações. Você deve fazê-lo sob quaisquer circunstâncias razoáveis, mas de forma alguma sugerindo que o licenciante endossa você ou seu uso.\n\nEsta licença e válida sob os seguintes termos:\n\nNão comercial (NC) — Você não pode usar o material para fins comerciais.\nShare Alike (SA) — Se você remixar, transformar ou desenvolver o material, deverá distribuir suas contribuições sob a mesma licença do original.\nSem restrições adicionais — Você não pode aplicar termos legais ou medidas tecnológicas que restrinjam legalmente outras pessoas de fazer qualquer coisa que a licença permita.\n\n\n\nSelo DC\n\nO selo selo Democratizando Conhecimento (DC) é uma ideia criada pelo Prof. Ben Dêivid. O selo é compatível com a licença Creative Commons CC BY NC SA 4.0 e é utilizado aqui para garantir que o acesso de todo esse material seja livre, gratuíto e de código aberto. Meu principal objetivo com isso é democratizar o uso e aplicação do R nas Ciências Agrárias.\n\n\nVisite-nos!\n\n\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html",
    "href": "FIT5306/FIT5306_00_ABOUT.html",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "",
    "text": "Bem-vindo ao material de apoio da disciplina FIT5306 (Bioestatística e Experimentação Agrícola)! Esta página contém os dados e scripts R necessários para aplicação prática dos conteúdos vistos na disciplina."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#regressão",
    "href": "FIT5306/FIT5306_00_ABOUT.html#regressão",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Regressão",
    "text": "Regressão\n\nREG_DATA: dados sem repetição (hipotéticos) do RG observados em diferentes doses de Nitrogênio.\nREG_ANALISE: Análise de regressão linear de primeiro grau dos dados REG_DATA.\nREG_DEL_DATA: dados com repetições do rendimento de grãos observados em diferentes doses de Nitrogênio.\nREG_DEL_ANALISE: Análise de regressão dos dados REG_DEL_DATA.\nREG_PRATICA: dados referente a uma amostra de tamanho n = 11, na qual se aplicou CO2 em diferentes concentrações em folhas de trigo (X). A quantidade de C02 absorvida (Y) em cm3 / dm2 / hora foi avaliada. Esse exemplo foi apresentado por Ferreira (2009)[^1].\nREG_PRATICA_ANALISE: Análise de regressão dos dados REG_PRATICA."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#correlação",
    "href": "FIT5306/FIT5306_00_ABOUT.html#correlação",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Correlação",
    "text": "Correlação\n\nCOR_DATA_DENSIDADE: Dois métodos de mensurar a densidade média da madeira (g /cm\\(^3\\)) em Eucalyptus grandis foram aplicados a uma amostra de n = 13 árvores. O primeiro método (X) é determinado utilizando um paquímetro e uma sonda Pressler de 0,5 cm na região da árvore determinada no diâmetro à altura do peito (DAP). A segunda, variável (Y) também foi mensurada no DAP utilizando cortes transversais no tronco. Esse exemplo foi apresentado por Ferreira (2009)[^1].\nCORRELACAO_DATA: dados de altura de planta (AP) e altura da espiga (AE) observados em 10 plantas de milho.\nCORRELACAO_ANALISE: Análise de correlação para os dados CORRELACAO_DATA."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#experimentos-unifatoriais",
    "href": "FIT5306/FIT5306_00_ABOUT.html#experimentos-unifatoriais",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Experimentos unifatoriais",
    "text": "Experimentos unifatoriais\n\n\n\n\n\n\nNote\n\n\n\nOs dados COBERTURA_N_MASSA e COBERTURA_N_SOJA foram obtidos em um trabalho conduzido em grupo no Centro Universitário Unideau, tendo como participantes os alunos Bernardo Pinheiro Busatta, Tiago Jonatan Fochesatto, Diogo Andre Ody, Gustavo Peretti e Paulo Sérgio Trevisol.\n\n\n\nCOBERTURA_N_MASSA: dados de um experimento bifatorial com dois níveis de nitrogênio (com e sem) e quatro níveis de plantas de cobertura (aveia preta, centeio, triticale e pousio), conduzido em um DBC com quatro repetições. Foram avaliados a matéria verde (MV) e matéria seca (MS) das plantas, bem como a matéria seca de raiz (MSR).\nCOBERTURA_N_SOJA: Com os mesmos tratamentos apresentados em COBERTURA_N_MASSA, o experimento avaliou caracteres morfológicos e o rendimento de grãos de soja cultivada na resteva das respectivas coberturas de solo. Foram avaliados o número de legumes por planta (NL), número de grãos por legume (NGL), massa de mil grãos (MMG) e o rendimento de grãos (RG).\nDIC-DBC: dados de área foliar (AF) e matéria seca de planta (MST) de plantas de chicória avaliadas em diferentes níveis de radiação solar (50%, 70% e 100%). O experimento foi conduzido em delineamento de blocos completos casualizados, com quatro repetições.\nEFEITOS: Os efeitos de tratamento e erro (delineamento inteiramente casualizado) para os dados da planilha DIC-DBC.\nDIC-DBC-ANOVA: análise de variância nos delineamentos DIC e DBC, para efeitos de comparação, dos dados da planilha DIC-DBC.\nQUALI: Dados do rendimento de grãos (RG) de 10 híbridos de milho avaliados em um delineamento de blocos completos casualizados, com quatro repetições.\nQUANTI_LINEAR: Dados do rendimento de grãos (RG) de um híbrido de milho sob diferentes doses de nitrogênio, avaliados em um delineamento de blocos completos casualizados, com quatro repetições. O conjunto apresenta um comportamento linear.\nQUANTI_LINEAR: Dados do rendimento de grãos (RG) de um híbrido de milho sob diferentes doses de nitrogênio, avaliados em um delineamento de blocos completos casualizados, com quatro repetições. O conjunto apresenta um comportamento linear.\nQUANTI_QUADRÁTICA: Dados do rendimento de grãos (RG) de um híbrido de milho sob diferentes doses de nitrogênio, avaliados em um delineamento de blocos completos casualizados, com quatro repetições. O conjunto apresenta um comportamento quadrático.\nmaize: Dados de um ensaio multi-ambientes onde 13 híbridos de milho foram avaliados em quatro localidades, sendo que em cada localidade um delineamento de blocos completos casualizados com três repetições foi utilizado. São apresentados dados de sete caracteres quantitativos avaliados em cinco plantas aleatoriamente escolhidas em cada parcela."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#experimentos-bifatoriais",
    "href": "FIT5306/FIT5306_00_ABOUT.html#experimentos-bifatoriais",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Experimentos bifatoriais",
    "text": "Experimentos bifatoriais\nAs seguintes planilhas contém dados de experimentos bifatoriais com diferentes combinações de fatores qualitativos e quantitativos na presença de interação significativa e não significativa. Em todos os exemplos, é utilizado o delineamento de blocos completos casualizados.\n\nFAT1_SI: Fator 1 qualitativo (fontes de nitrogênio), com três níveis; Fator 2 qualitativo (híbridos), com três níveis, com interação significativa.\nFAT1_CI: Fator 1 qualitativo (dias de avaliação), com três níveis; Fator 2 qualitativo (radiação solar), com três níveis, sem interação significativa.\nFAT1_C2I1: Fator 1 Qualitativo (enxofre), com dois níveis; Fator 2 qualitativo (parcelamento de N), com três níveis, com interação significativa.\nFAT2_SI: Fator 1 qualitativo (híbridos), com dois níveis; Fator 2 quantitativo (doses de N), com cinco níveis, sem interação significativa.\nFAT2_CI: Fator 1 qualitativo (híbridos), com dois níveis; Fator 2 quantitativo (doses de N), com cinco níveis, com interação significativa.\nFAT3: Fator 1 quantitativo (doses de N), com quatro níveis; Fator 2 quantitativo (doses de K), com cinco níveis, com interação significativa.\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html",
    "href": "FIT5306/FIT5306_01_DESC.html",
    "title": "1. Estatística Descritiva",
    "section": "",
    "text": "library(tidyverse)\nlibrary(metan)"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#média",
    "href": "FIT5306/FIT5306_01_DESC.html#média",
    "title": "1. Estatística Descritiva",
    "section": "Média",
    "text": "Média\n\nMédia aritmética\nSeja uma amostra \\(X_1\\), \\(X_2\\), \\(X_n\\), de uma população \\(X_1\\), \\(X_2\\), \\(X_N\\) de tamanho \\(n\\) e \\(N\\), definimos a média aritmética por\n\\[\n\\mu  = \\frac{\\displaystyle\\sum_{i=1}^{N}X_i}{N}, \\quad \\textrm{(População)}\n\\]\n\\[\n\\bar{X} = \\frac{\\displaystyle\\sum_{i=1}^{n}X_i}{n}. \\quad \\textrm{(Amostra)}\n\\]\nConsidere a altura (em cm) de cinco plantas de milho, armazenada no objeto altura. Para calcular a média aritmética destas alturas, utilziamos a função mean().\n\naltura <- c(245, 250, 269, 280, 262)\nmean(altura)\n\n[1] 261.2\n\n\n\n\nMédia geométrica\nA média geométrica (\\(m_g\\)) entre um conjunto de n dados é a n-ésima raíz do produto desses dados.\n\\[\nm_g = \\sqrt[n]{\\prod\\limits_{i = 1}^n {{x_i}} }\n\\]\n\n\nMédia harmônica\nA média harmônica (\\(m_h\\)) é definida como sendo o inverso da média aritmética dos inversos, representada como segue\n\\[\nm_h = \\frac{n}{{\\sum\\limits_{i = 1}^n {\\frac{1}{{{x_i}}}} }}\n\\]\nA escolha pelo uso da média harmônica para representação da média de um conjunto está ligada a situações que envolvem grandezas inversamente proporcionais, por exemplo a velocidade média.\n\n\n\n\n\n\nExemplo de aplicação\n\n\n\nUm carro percorre um percurso de mesma distância duas vezes. No primeira, ele faz o percurso com uma velocidade V1 = 80 km/h. No segunda, ele realiza o mesmo percurso com velocidade de V2 = 120 km/h. Pede-se: qual foi a velocidade média dos dois percursos?\nIntuitivamente (e erroneamente) computaríamos a média aritmética (\\((80 + 120) / 2 = 100\\)). Note que a distância é a mesma, para os dois percursos, o que muda é a velocidade e, consequentemente, o tempo. A resolução correta do problema é a seguinte:\nSejam,\n\\(d\\), a distância do percurso \\(v_1\\), a velocidade média do percurso \\(t_i\\), o tempo de viagem do percurso\nEntão, temos que \\(d = v_1t_1=v_2t_2\\). Se \\(v\\) é a velocidad média nos dois trajetos, então \\(2d=v(t_1+t_2)\\), ou \\(2d=v(d/v_1+d/v_2)\\). Moral da história: a velocidade média no percurso todo é a média harmônica das velocidades dos dois percursos:\n\\[\nm_h = \\frac{2}{{{\\frac{1}{{{80}}} + \\frac{1}{{{120}}}} }} = 96\n\\]\n\n\nNo R base, não existe uma função específica para a média harmônica. Pode-se utilizar, então, a função hmean() do pacote metan2.\n\nlibrary(metan)\nhmean(c(80, 120))\n\n[1] 96"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#mediana",
    "href": "FIT5306/FIT5306_01_DESC.html#mediana",
    "title": "1. Estatística Descritiva",
    "section": "Mediana",
    "text": "Mediana\nA mediana é calculada com a função median().\n\naltura <- c(245, 250, 269, 280, 262)\n\n# Média\n(media <- mean(altura))\n\n[1] 261.2\n\n# Mediana\n# Ordenar os dados\nsort(altura)\n\n[1] 245 250 262 269 280\n\n# Calcular a mediana\n(mediana <- median(altura))\n\n[1] 262"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#amplitude",
    "href": "FIT5306/FIT5306_01_DESC.html#amplitude",
    "title": "1. Estatística Descritiva",
    "section": "Amplitude",
    "text": "Amplitude\nA primeira medida de dispersão que definiremos é a amplitude ou amplitude total, denotada por \\(A_p = X_{(max)} - X_{(min)}\\), onde \\(X_{(max)}\\) e \\(X_{(min)}\\) são os valores máximos e mínimos do conjunto de dados, respectivamente. Os valores extremos podem ser encontrados com a função range().\n\n(extremos <- range(altura))\n\n[1] 245 280\n\n(amplitude <- extremos[2] - extremos[1])\n\n[1] 35"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#desvios-médios",
    "href": "FIT5306/FIT5306_01_DESC.html#desvios-médios",
    "title": "1. Estatística Descritiva",
    "section": "Desvios médios",
    "text": "Desvios médios\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(X_n\\), de uma população \\(X_1\\), \\(X_2\\), \\(X_N\\) de tamanho \\(n\\) e \\(N\\), a soma dos desvios é dada por\n\\[\nDM  = \\sum_{i = 1}^{n} \\left(X_i - \\bar{X} \\right)\n\\]\nPara calcularmos os desvios, basta utilizar o operador - no R.\n\n(desvios <- altura - media)\n\n[1] -16.2 -11.2   7.8  18.8   0.8\n\n\nPara expressar estes desvios, vamos construir um gráfico utilizando o pacote ggplot2.\n\ndf <- data.frame(pessoa = paste(\"Planta\", 1:5),\n                 altura = altura,\n                 altura_media = media,\n                 desvio = desvios)\n\nggplot(df, aes(x = altura, y = pessoa)) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  geom_segment(aes(x = media,\n                   xend = altura,\n                   y = pessoa,\n                   yend = pessoa)) +\n  geom_vline(xintercept = media, linetype = 2, color = \"red\") +\n  geom_text(aes(x = altura, y = pessoa, label = round(desvio, digits = 3),\n                hjust = ifelse(desvio < 0, 1.5, -0.5))) +\n  scale_x_continuous(limits = c(230, 300)) + \n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"Altura da planta (cm)\",\n       y = \"Planta\")\n\n\n\n\nA expressão anterior resulta em\n\\[\nDM  = \\sum_{i = 1}^{n} \\left(X_i - \\bar{X} \\right) = 0\n\\]\n\nsum(desvios) |> round()\n\n[1] 0\n\n\nIsso significa que essa medida não traz ganho algum a descrição dos dados, porque os desvios positivos anulam-se com os desvios negativos no somatório. Para isso, podemos contornar essa situação inserindo uma função modular nessa medida anterior, e criar o módulo do desvio. Assim, o desvio médio é dado por:\n\\[\nS_{|\\bar{X}|} = \\frac{\\sum_{i = 1}^{n} \\left|X_i - \\bar{X} \\right|}{n}\n\\]\n\n# soma dos desvios em módulo\n(somadesv <- desvios |> abs() |> sum())\n\n[1] 54.8\n\n# desvio médio\nsomadesv / 5\n\n[1] 10.96"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#variância",
    "href": "FIT5306/FIT5306_01_DESC.html#variância",
    "title": "1. Estatística Descritiva",
    "section": "Variância",
    "text": "Variância\nUtilizando uma função quadrática na medida surge uma outra medida de variabilidade que é a soma de quadrados. A soma de quadrados apresenta uma outra informação interessante que é penalizar as observações quanto mais estiver distante do valor central. Assim, quando elevamos ao quadrado um alto desvio, esse valor se torna maior ainda, mas quando elevamos ao quadrado um desvio pequeno, esse valor não cresce tanto. Com isso, conseguimos compreender quais os dados que estão mais dispersos em torno da média. Ao dividir a soma de quadrados por \\(n-1\\) temos o estimador da variância amostral (\\(S^2\\)), dado por:\n\\[\nS^2 = \\frac{\\sum_{i = 1}^{n} \\left(X_i - \\bar X_i \\right)^2}{n-1}\n\\]\n\n# Desvios ao quadrado\n(desvq <- desvios ^ 2)\n\n[1] 262.44 125.44  60.84 353.44   0.64\n\n# soma dos desvios ao quadrado\n(somadesvq <- sum(desvq))\n\n[1] 802.8\n\n# divisão por n - 1\n(var_altura <- somadesvq / 4)\n\n[1] 200.7\n\n\nAnteriormente, vimos o passo a passo para o cálculo da variância amostral. No R, a função var() pode ser utilizada para este fim.\n\nvar(altura)\n\n[1] 200.7"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#desvio-padrão",
    "href": "FIT5306/FIT5306_01_DESC.html#desvio-padrão",
    "title": "1. Estatística Descritiva",
    "section": "Desvio padrão",
    "text": "Desvio padrão\nA variância, como medida de dispersão, apresenta sua unidade ao quadrado da unidade da variável em estudo. Em outras palavras, que se tivermos usando uma variável na escala de centímetros (ex., algura), a dispersão dada pela variância estará na escala de área (cm\\(^2\\)). Isso se torna difícil a percepção de dispersão quando observamos os dados. Para contornar isso, utilizamos o desvio padrão, que é a raíz quadrada da variância, dado por\n\\[\nS = \\sqrt{S^2}\n\\]\nPara o exemplo acima, computamos o desvio padrão extraíndo a raíz de var_altura, ou, como para a variância, utilizando uma função específica do R para isso: sd() (de standard deviation).\n\n(desv_altura <- sqrt(var_altura))\n\n[1] 14.16686\n\n# utilizando a função sd()\nsd(altura)\n\n[1] 14.16686"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#coeficiente-de-variação",
    "href": "FIT5306/FIT5306_01_DESC.html#coeficiente-de-variação",
    "title": "1. Estatística Descritiva",
    "section": "Coeficiente de variação",
    "text": "Coeficiente de variação\nAs medidas de variabilidade tais como a variância e desvio padrão, são conhecidas como medidas de dispersão absoluta. Isto significa que elas serão diretamente influenciadas pela magnitude da variável. Vamos tomar como motivação, os valores em altura, tomados em cm. Consideremos que estes dados são transformados para metros, por tanto, cada observação será dividida por 100. Observe abaixo o resultado do desvio padrão da mesma variável, mas com escala diferente.\n\n(altura_m <- altura / 100)\n\n[1] 2.45 2.50 2.69 2.80 2.62\n\n(desv_altura_m <- sd(altura_m))\n\n[1] 0.1416686\n\n\nPara contornar este problema, podemos utilizar uma medida relativa de variabilidade chamada de Coeficiente de Variação (CV). Este pode ser usada para comparar a variabilidade entre quaisquer grupo de dados, independentemente da sua escala. O coeficiente de variação é definido por:\n\\[\nCV = \\frac{S}{\\bar{X}} \\times 100\n\\]\n\n# coeficiente de variação da variável em centímetros\n(cv_altura <- desv_altura / media * 100)\n\n[1] 5.423761\n\n# coeficiente de variação da variável em metros\n(cv_altura2 <- desv_altura_m / mean(altura_m) * 100)\n\n[1] 5.423761\n\n\nNão existe no R base uma função para computar o coeficiente de variação, então vamos criá-la utilizando a abordagem function().\n\nCV <- function(dados){\n  if(!class(dados) == \"numeric\"){\n    stop(\"Os dados precisam ser numéricos\")\n  } #Indica que os dados devem ser numéricos\n  media <- mean(dados)\n  sd <- sd(dados)\n  CV <- (sd/media) * 100\n  return(CV) # Valor que será retornado pela função\n}\n\nCV(altura)\n\n[1] 5.423761"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#erro-padrão-da-média",
    "href": "FIT5306/FIT5306_01_DESC.html#erro-padrão-da-média",
    "title": "1. Estatística Descritiva",
    "section": "Erro padrão da média",
    "text": "Erro padrão da média\nO erro padrão da média é a estimativa do desvio padrão de sua distribuição amostral. O desvio padrão visto anteriormente reflete a variabilidade de cada observação em torno da média amostral. Já o erro padrão da média, representa a variabilidade de cada média amostral de todas amostra possíveis, em relação a média populacional. Sua estimativa é dada por:\n\\[\nS_{\\bar{X}}  = \\frac{S}{\\sqrt{n}}\n\\]\nÉ fácil observar que à medida que \\(n \\to N\\), isto é, à medida que\n\\(n\\) aumenta, a média amostral (\\(\\bar X\\)) tende a média populacional (\\(\\mu\\)). Isso significa que a média amostral é mais precisa porque se aproxima cada vez mais da média populacional. Para os dados em altura, o erro padrão da média é calculado com:\n\n(epm <- desv_altura / sqrt(5))\n\n[1] 6.335614"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#exemplo-da-altura-de-planta",
    "href": "FIT5306/FIT5306_01_DESC.html#exemplo-da-altura-de-planta",
    "title": "1. Estatística Descritiva",
    "section": "Exemplo da altura de planta",
    "text": "Exemplo da altura de planta\nPara calcular todas as estatísticas de uma só vez, podemos usar desc_stat() do pacote metan. Esta função pode ser usada para calcular medidas de tendência central, posição e dispersão. Por padrão (stats = \"main\"), sete estatísticas (coeficiente de variação, máximo, média, mediana, mínimo, desvio padrão da amostra, erro padrão e intervalo de confiança da média) são calculadas. Outros valores permitidos são \"all\" para mostrar todas as estatísticas, \"robust\" para mostrar estatísticas robustas, \"quantile\" para mostrar estatísticas quantílicas ou escolher uma (ou mais) estatísticas usando um vetor separado por vírgula com os nomes das estatísticas, por exemplo, stats = c(\"mean, cv\"). Também podemos usar hist = TRUE para criar um histograma para cada variável. Para mais detalhes consulte este material.\n\nlibrary(metan)\ndesc_stat(altura, stats = \"all\") |> as.data.frame()\n\n  variable av.dev    ci.t    ci.z     cv    gmean    hmean iqr    kurt     mad\n1      val  10.96 17.5905 12.4176 5.4238 260.8937 260.5887  19 -1.3829 17.7912\n  max  mean median min n n.valid n.missing n.unique      ps  q2.5 q25 q75 q97.5\n1 280 261.2    262 245 5       5         0        5 14.0741 245.5 250 269 278.9\n  range  sd.amo  sd.pop     se   skew  sum sum.dev ave.dev sum.sq.dev var.amo\n1    35 14.1669 12.6712 6.3356 0.2144 1306    54.8   10.96      802.8   200.7\n  var.pop\n1  160.56\n\n# estatísticas vistas neste material\ndesc_stat(altura,\n          stats = c(\"mean, median, range, ave.dev, var.amo, sd.amo, cv, se\")) |> \n  as.data.frame()\n\n  variable  mean median range ave.dev var.amo  sd.amo     cv     se\n1      val 261.2    262    35   10.96   200.7 14.1669 5.4238 6.3356"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#exemplo-com-os-dados-coletados-em-aula",
    "href": "FIT5306/FIT5306_01_DESC.html#exemplo-com-os-dados-coletados-em-aula",
    "title": "1. Estatística Descritiva",
    "section": "Exemplo com os dados coletados em aula",
    "text": "Exemplo com os dados coletados em aula\nNeste exemplo, mostro como as estatísticas descritivas para os dados coletados em aula podem ser calculadas utilizando o pacote metan. Os dados são importados diretamente da planilha armazenada no drive, utilizando a função import() do pacote rio.\n\nlibrary(rio)\n\n# link dos dados\nlink <- \"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=0\"\n\n# função para importar os dados\ndf <- \n  import(link, dec = \",\") |> \n  as_character(1:2) \n\n# estrutura dos dados \nstr(df)\n\n'data.frame':   21 obs. of  4 variables:\n $ ramo       : chr  \"Ramo 1\" \"Ramo 1\" \"Ramo 1\" \"Ramo 1\" ...\n $ observacao : chr  \"1\" \"2\" \"3\" \"4\" ...\n $ comprimento: num  16 15 16.5 16 15 13 16.5 16 14 15 ...\n $ largura    : num  6 6 7.5 7 6.5 5 6 6 5.9 6.5 ...\n\n# primeiras linhas\nhead(df)\n\n    ramo observacao comprimento largura\n1 Ramo 1          1        16.0     6.0\n2 Ramo 1          2        15.0     6.0\n3 Ramo 1          3        16.5     7.5\n4 Ramo 1          4        16.0     7.0\n5 Ramo 1          5        15.0     6.5\n6 Ramo 1          6        13.0     5.0\n\n\nOs dados foram organziados de maneira que cada fator/variável estivessem em uma coluna. Isto possibilita o cálculo das estatísticas para cada nível destes fatores. As duas variáveis quantitativas contínuas são: comprimento (o comprimento da folha em cm); e largura(largura da folha em mm).\n\nEstatísticas gerais\nPara saber as estatísticas descritivas gerais vamos utilizar a função desc_stat9). Por padrão, a função calcula as estatísticas descritivas para todas as variáveis numéricas do conjunto de dados. Sendo assim, não há necessidade de informar qual variável analisar.\n\nstats = c(\"mean, median, range, ave.dev, var.amo, sd.amo, cv, se, n\")\ndf |> \n  desc_stat(stats = stats)\n\n# A tibble: 2 × 10\n  variable     mean median range ave.dev var.amo sd.amo    cv    se     n\n  <chr>       <dbl>  <dbl> <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 comprimento 13.2    14.2   9     2.37     8.21   2.86  21.6 0.625    21\n2 largura      5.67    6     3.7   0.969    1.24   1.12  19.7 0.243    21\n\n\n\n\nEstatísticas por ramo\nPara obter as estatística para cada ramo, basta vamos utilizar a função group_by() para agrupar por ramo. Com isso, as estatísticas serão calculadas separadamente para ramo 1 e ramo 2.\n\ndf |> \n  group_by(ramo) |> \n  desc_stat(stats = stats)\n\n# A tibble: 4 × 11\n  ramo   variable     mean median range ave.dev var.amo sd.amo    cv    se     n\n  <chr>  <chr>       <dbl>  <dbl> <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 Ramo 1 comprimento 13.5    15     9     2.46     8.92   2.99  22.1 0.771    15\n2 Ramo 1 largura      5.59    6     3.7   0.941    1.24   1.12  19.9 0.288    15\n3 Ramo 2 comprimento 12.6    13.8   6.1   2.24     7.09   2.66  21.2 1.09      6\n4 Ramo 2 largura      5.87    6.5   2.8   1.01     1.43   1.19  20.4 0.488     6\n\n\n\n\nBoxplot (descritiva e teste t)\n\nlibrary(ggstatsplot)\n\nWarning: package 'ggstatsplot' was built under R version 4.2.1\n\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\nggbetweenstats(df,\n               x = ramo,\n               y = comprimento,\n               plot.type = \"box\",\n               ylab = \"rendimento\")"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html",
    "href": "FIT5306/FIT5306_02_FREQ.html",
    "title": "2. Distribuição de frequências",
    "section": "",
    "text": "Uma forma de lidar com grandes conjuntos de dados e identificar informações relevantes é agrupar estes dados. O agrupamento é feito em tabelas, denominadas de distribuições de frequências. A construção de distribuição de frequências é geralmente realizada de forma distinta para variáveis discretas (distribuição por pontos) e contínuas (distribuição por classes ou intervalos).\nNeste exemplo, vamos utilizar os dados coletados do comprimento, diâmetro e cor de grão de café."
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#representação-tabular",
    "href": "FIT5306/FIT5306_02_FREQ.html#representação-tabular",
    "title": "2. Distribuição de frequências",
    "section": "Representação tabular",
    "text": "Representação tabular\nPode-se criar facilmente esta tabela de frequência combinando as funções count() e mutate() do pacote dplyr (parte do tidyverse).\n\ntab_feq <- \n  df %>%\n  count(cor_grao) |>\n  mutate(abs_freq = n,\n         abs_freq_ac = cumsum(abs_freq),\n         rel_freq = abs_freq / sum(abs_freq),\n         rel_freq_ac = cumsum(rel_freq))\n\nknitr::kable(tab_feq)\n\n\n\n\ncor_grao\nn\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\namarelo\n6\n6\n6\n0.2142857\n0.2142857\n\n\nverde\n15\n15\n21\n0.5357143\n0.7500000\n\n\nvermelho\n7\n7\n28\n0.2500000\n1.0000000"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#representação-gráfica",
    "href": "FIT5306/FIT5306_02_FREQ.html#representação-gráfica",
    "title": "2. Distribuição de frequências",
    "section": "Representação gráfica",
    "text": "Representação gráfica\nPara apresentar estes dados graficamente, pode-se construir um gráfico de barras, mostrando a contagem em cada classe.\n\nggplot(df, aes(cor_grao)) + \n  geom_histogram(stat=\"count\") +\n  scale_y_continuous(breaks = 0:15) + \n  labs(x = \"Cor do grão\",\n       y = \"Número de observações\") +\n  theme(panel.grid.minor = element_blank())\n\nWarning: Ignoring unknown parameters: binwidth, bins, pad"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#apresentação-tabular",
    "href": "FIT5306/FIT5306_02_FREQ.html#apresentação-tabular",
    "title": "2. Distribuição de frequências",
    "section": "Apresentação tabular",
    "text": "Apresentação tabular\n\nfrequencias <- freq_table(df, comp_grao)\nknitr::kable(frequencias$freqs)\n\n\n\n\n\n\n\n\n\n\n\nclass\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\n8.229 |— 9.952\n2\n2\n0.071\n0.071\n\n\n9.952 |— 11.675\n5\n7\n0.179\n0.250\n\n\n11.675 |— 13.398\n10\n17\n0.357\n0.607\n\n\n13.398 |— 15.121\n8\n25\n0.286\n0.893\n\n\n15.121 |—| 16.844\n3\n28\n0.107\n1.000\n\n\nTotal\n28\n28\n1.000\n1.000"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#apresentação-gráfica",
    "href": "FIT5306/FIT5306_02_FREQ.html#apresentação-gráfica",
    "title": "2. Distribuição de frequências",
    "section": "Apresentação gráfica",
    "text": "Apresentação gráfica\n\nfreq_hist(frequencias)"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#cor-do-grão-do-café",
    "href": "FIT5306/FIT5306_02_FREQ.html#cor-do-grão-do-café",
    "title": "2. Distribuição de frequências",
    "section": "Cor do grão do café",
    "text": "Cor do grão do café\n\ndf_cor_grao <- import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=1550268554\",\n                      dec = \",\")\n\nfreq_cafe <- freq_table(df_cor_grao, var = cor)\nknitr::kable(freq_cafe$freqs)\n\n\n\n\ncor\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\namarelo\n6\n6\n0.25\n0.25\n\n\nverde\n18\n24\n0.75\n1.00\n\n\nTotal\n24\n24\n1.00\n1.00\n\n\n\n\n# criar um histograma\nfreq_hist(freq_cafe)"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#comprimento-da-folha-do-café",
    "href": "FIT5306/FIT5306_02_FREQ.html#comprimento-da-folha-do-café",
    "title": "2. Distribuição de frequências",
    "section": "Comprimento da folha do café",
    "text": "Comprimento da folha do café\n\ncomp_folha <- import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=0\",\n                    dec = \",\")\n\n# Tabela\ndist_comprimento <- freq_table(comp_folha, var = comprimento)\nknitr::kable(dist_comprimento$freqs)\n\n\n\n\n\n\n\n\n\n\n\nclass\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\n6.375 |— 8.625\n2\n2\n0.095\n0.095\n\n\n8.625 |— 10.875\n3\n5\n0.143\n0.238\n\n\n10.875 |— 13.125\n3\n8\n0.143\n0.381\n\n\n13.125 |— 15.375\n8\n16\n0.381\n0.762\n\n\n15.375 |—| 17.625\n5\n21\n0.238\n1.000\n\n\nTotal\n21\n21\n1.000\n1.000\n\n\n\n\n# Gráfico\nfreq_hist(dist_comprimento)"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html",
    "title": "3. Distribuições discretas",
    "section": "",
    "text": "Um modelo probabilístico é um modelo em que, à priori, não é possível definir um resultado particular. Este modelo é especificado por meio de uma distribuição de probabilidade. Geralmente, modelos probabilísticos são utilizados quando se tem um grande número de variáveis influenciando o resultado e estas variáveis não podem ser controladas. Como exemplo, pode-se citar a observação da germinação de uma semente, o lançamento de um dado, onde tenta-se prever o número da face que irá sair, etc."
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#um-exemplo-simples",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#um-exemplo-simples",
    "title": "3. Distribuições discretas",
    "section": "Um exemplo simples",
    "text": "Um exemplo simples\nConsideremos a variável aleatória discreta X como o sexo de um bezerro nascido. Denotando sucesso (1 = fêmea) e fracasso (2 = macho), a probabilidade de sucesso é \\(p = 0,5\\) e a de fracasso \\(q = 1 - q = 0,5\\). Assim, considerando o parto de uma vaca, há 50% de chance de nascimento de uma terneira.\n\nlibrary(DiagrammeR)\nmermaid(\"\n   graph TB\n    Start -->|0,5|A(1)\n    Start -->|0,5|B(0)\n\")\n\n\n\n\n\nConsiderando duas vacas prenhas, com a mesma probabilidade de nascimento de fêmeas, temos então o seguinte cenário.\n\nmermaid(\"\n   graph TB\n    Start --> |0,5|A(1)\n    Start --> |0,5|B(0)\n    A --> |0,5|C(1)\n    A --> |0,5|D(0)\n    B --> |0,5|E(1)\n    B --> |0,5|F(0)\n    C --> G(11 = pp)\n    D --> H(10 = pq)\n    E --> I(01 = qp)\n    F --> J(00 = qq)\n\")\n\n\n\n\n\nAssim, as probabilidades associadas ao número de nascimentos de bezzeras são dadas por\n\nNenhuma bezerra\n\n\\[\nP(X = 0) = \\left( \\begin{array}{l}2\\\\0\\end{array} \\right) \\times {0,5^0} \\times {0,5^{2 - 0}} = 0,25\n\\]\n\nUma bezerra\n\n\\[\nP(X = 1) = \\left( \\begin{array}{l}2\\\\1\\end{array} \\right) \\times {0,5^1} \\times {0,5^{2 - 1}} = 0,50\n\\]\n\nDuas bezerras\n\n\\[\nP(X = 2) = \\left( \\begin{array}{l}2\\\\2\\end{array} \\right) \\times {0,5^2} \\times {0,5^{2 - 2}} = 0,25\n\\]\nNo software R, a probabilidade de sucesso de um evento para uma variável que segue uma distribuição binomial é computada com a função dbinom().\n\nargs(dbinom)\n\nfunction (x, size, prob, log = FALSE) \nNULL\n\n\n\nx é o vetor de quantiles (sucesso);\nsize é o número de experimentos (repetições);\nprob é a probabilidade de sucesso em cada experimento aleatório.\n\n\nlibrary(tibble)\n\nWarning: package 'tibble' was built under R version 4.2.1\n\ndata.frame(nbez = 0:2,\n           prob = dbinom(0:2, size = 2, prob = 0.5))\n\n  nbez prob\n1    0 0.25\n2    1 0.50\n3    2 0.25\n\n\nA mesma lógica é utilizada para uma situação onde três vacas estão prenhas. Assim, \\(n = 3\\), gera o seguinte cenário.\n\nmermaid(\"\n   graph TB\n    Start --> |0,5|A(1)\n    Start --> |0,5|B(0)\n    A --> |0,5|C(1)\n    A --> |0,5|D(0)\n    B --> |0,5|E(1)\n    B --> |0,5|F(0)\n    C --> |0,5|G(1)\n    C --> |0,5|H(0)\n    D --> |0,5|I(1)\n    D --> |0,5|J(0)\n    E --> |0,5|K(1)\n    E --> |0,5|L(0)\n    F --> |0,5|M(1)\n    F --> |0,5|N(0)\n    G --> O(111 = ppp)\n    H --> P(110 = ppq)\n    I --> Q(101 = pqp)\n    J --> R(100 = pqq)\n    K --> S(011 = qpp)\n    L --> T(010 = qpq)\n    M --> U(001 = qqp)\n    N --> V(000 = qqq)\n\")\n\n\n\n\n\n\ndata.frame(n_femeas = 0:3,\n           prob = dbinom(0:3, size = 3, prob = 0.5))\n\n  n_femeas  prob\n1        0 0.125\n2        1 0.375\n3        2 0.375\n4        3 0.125"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-bezerro",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-bezerro",
    "title": "3. Distribuições discretas",
    "section": "Exercício bezerro",
    "text": "Exercício bezerro\nUm produtor possui quatro vacas prenhas de monta natural. Como está cursando a disciplina de Bioestatística, ele gostaria de calcular probabilidades associadas ao nascimento de bezerras fêmeas.\n\nlibrary(tibble)\nbezerros <- \n  tibble(nbez = 0:4,\n         prob = dbinom(x = 0:4, size = 4, prob = 0.5),\n         prob_ac = cumsum(prob),\n         prob_ac_inv = rev(prob_ac))\nbezerros\n\n# A tibble: 5 × 4\n   nbez   prob prob_ac prob_ac_inv\n  <int>  <dbl>   <dbl>       <dbl>\n1     0 0.0625  0.0625      1     \n2     1 0.25    0.313       0.938 \n3     2 0.375   0.688       0.688 \n4     3 0.25    0.938       0.313 \n5     4 0.0625  1           0.0625\n\n# Gráfico da distribuição\nlibrary(tidyverse)\nggplot(bezerros, aes(nbez, prob))+\n  geom_bar(stat = \"identity\",\n           col = \"black\",\n           size = 0,\n           fill = \"cyan\")+\n  labs(x = \"Número de bezerros fêmeas\",\n       y = \"Probabilidade\")+\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0))) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-questões-prova",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-questões-prova",
    "title": "3. Distribuições discretas",
    "section": "Exercício questões prova",
    "text": "Exercício questões prova\nConsidere uma prova de estatística com peso 10 contendo 10 questões, cada uma com 5 alternativas. Apenas 1 é correta. Se o aluno tirar uma nota inferior a 4, o aluno está reprovado. Notas entre 4 e 7 fazem com que o aluno fique em exame. Se a nota for superior a 7 o aluno passa. Como João não prestou atenção nas aulas de estatística, ele decidiu “chutar” todas as questões. Calcule as probabilidades que se pede.\n\nProbabilidade de não acertar nenhuma questão\n\ndbinom(x = 0, size = 10, prob = 0.2)\n\n[1] 0.1073742\n\n\n\n\nProbabilidade de ser reprovado\nJoão será reprovado caso acerte menos que quatro questões. Logo, a soma as probabilidades de acertar 0, 1, 2 e 3 questões é esta probabilidade.\n\ndbinom(x = 0:3, size = 10, prob = 0.2) %>% sum()\n\n[1] 0.8791261\n\n\n\n\nProbabilidade de ficar em exame\nJoão ficará em exame caso acerte entre 4 e 7 questões. Logo, a probabilidade de ficar em exame será a soma das probabilidades individuais destes números de questões.\n\ndbinom(x = 4:7, size = 10, prob = 0.2) %>% sum()\n\n[1] 0.120796\n\n\n\n\nPasse na prova\nJoão somente passará na prova, caso acerte mais que sete questões. Valendo-se da propriedade da soma das probabilidades, a probabilidade de João passar na prova é data tanto somando-se as probabilidades de acertar 8, 9 e 10 questões, quanto subtraindo a unidade da probabilidade da soma de acerto de até 7 questões.\n\ndbinom(x = 8:10, size = 10, prob = 0.2) %>% sum()\n\n[1] 7.79264e-05\n\n1 - dbinom(0:7, size = 10, prob = 0.2) |> sum()\n\n[1] 7.79264e-05\n\n\n\n\nGabarite a prova\nA probabilidade de acerto de 10 questões é dada pela probabilidade pontual de exatamente 10 sucessos em 10 tentativas.\n\ndbinom(x = 10, size = 10, prob = 0.2)\n\n[1] 1.024e-07\n\n\n\n\nMostrar código\nprova <- \n  tibble(nques = 0:10,\n         prob = dbinom(x = 0:10, size = 10, prob = 0.2),\n         prob_ac = cumsum(prob))\n\n\nggplot(prova, aes(nques, prob, label = round(prob, 4)))+\n  geom_bar(stat = \"identity\",\n           col = \"black\",\n           fill = \"cyan\")+\n  scale_x_continuous(breaks = c(0:10))+\n  labs(x = \"Número de questões\",\n       y = \"Probabilidade\")+\n  ggtitle(label = \"Probabilidade de acerto em uma prova de 10 questões\",\n          subtitle = \"Cada questão tem 5 alternativas, apenas 1 é correta\")+\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1)))+\n  geom_text(vjust = -1) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\nMostrar código\n# distribuição acumulada\n\nggplot(prova, aes(nques, prob_ac))+\n  geom_path(color = \"red\", size = 1)+\n  labs(x = \"Número de questões\",\n       y = \"Probabilidade acumulada\")+\n  ggtitle(label = \"Probabilidade acumulada de acertar 10 questões 'chutando' todas\",\n          subtitle = \"Cada questão tem 5 alternativas, apenas 1 é correta\")+\n  scale_x_continuous(breaks = c(0:10)) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-germinação-de-sementes",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-germinação-de-sementes",
    "title": "3. Distribuições discretas",
    "section": "Exercício germinação de sementes",
    "text": "Exercício germinação de sementes\nUma empresa produtora de sementes de moranga vende pacotes com 20 sementes cada. O percentual de germinação destas sementes é de 92%. A empresa garante que pacotes que contém menos de 18 sementes germinadas são indenizados na metade do valor de venda. Se você comprou um pacote de sementes desta empresa a probabilidade de ser indenizado é de:\n\ndbinom(0:17, size = 20, prob = 0.92) |> sum()\n\n[1] 0.2120538"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-nascimento-de-bezerros",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-nascimento-de-bezerros",
    "title": "3. Distribuições discretas",
    "section": "Exercício nascimento de bezerros",
    "text": "Exercício nascimento de bezerros\n\nA inseminação artificial (IA) é uma das biotecnias da reprodução bovina mais importante e utilizada visando o melhoramento genético do rebanho. O uso de sêmem sexado é uma tecnologia em que os espermatozoides que vão resultar na escolha do sexo que o criador deseja, são separados daqueles que resultariam em machos após a fecundação do óvulo. Ou seja, ao final do processo obtêm-se uma paleta de sêmen com predominância de espermatozoides “fêmeas” ou “Machos”, dependendo da escolha. Portanto, a sexagem de espermatozoides permite maximizar a produção animal, possibilitando maior progresso genético entre as gerações1.\n\nConsidere um lote de 120 vacas inseminadas com sêmem sexado que contenha a probabilidade de 85% de nascimento de fêmeas. Assumindo um nascimento por fêmea, calcule a probabilidade de:\n\nTodos os bezerros nascidos sejam fêmeas\nNeste caso, a probabilidade é dada pela probabilidade pontual de 120 nascimentos de fêmeas.\n\ndbinom(x = 120, size = 120, prob = 0.85)\n\n[1] 3.390557e-09\n\n\n\n\nPelo menos 90% dos bezerros nascidos sejam fêmeas\nNeste caso, precisaríamos de, pelo menos, 108 (120 \\(\\times\\) 0,9) bezerros fêmeas. Então, a probabilidade dessa ocorrência é \\(P(X \\>= 108) = P(X = 109) + P(X = 109) + ... + P(X = 120)\\)\n\nx <- \n  data.frame(nascimentos = 108:120) |> \n  mutate(prob = dbinom(nascimentos, size = 120, prob = 0.85),\n         acum = cumsum(prob))\nx\n\n   nascimentos         prob       acum\n1          108 3.260600e-02 0.03260600\n2          109 2.034136e-02 0.05294736\n3          110 1.152677e-02 0.06447412\n4          111 5.884537e-03 0.07035866\n5          112 2.679566e-03 0.07303823\n6          113 1.074988e-03 0.07411322\n7          114 3.740456e-04 0.07448726\n8          115 1.105874e-04 0.07459785\n9          116 2.701129e-05 0.07462486\n10         117 5.232956e-06 0.07463009\n11         118 7.539004e-07 0.07463085\n12         119 7.180004e-08 0.07463092\n13         120 3.390557e-09 0.07463092\n\n\n\n\nMulta por ineficiência\nO vendedor do sêmen se comprometeu em pagar uma multa de R$10,00 para cada bezerro macho nascido se a taxa de parição de fêmeas fosse menor que 75%. Qual a probabilidade do produtor receber alguma indenização?\nO produtor somente será indenizado se nascerem 89 ou menos bezerras. Assim, a probabilidade é dada pela soma das probabilidades individuais de 0 até 89\n\ndbinom(x = 0:89, size = 120, prob = 0.85) |> sum()\n\n[1] 0.001409492\n\n\nAbaixo, é possível identificar a distribuição de probabilidade para o exemplo dado.\n\n\nMostrar código\nbezerros <- \n  tibble(nbez = 0:120,\n         prob = dbinom(x = 0:120, size = 120, prob = 0.85),\n         prob_ac = cumsum(prob))\n\n\n# Gráfico da distribuição\nggplot(bezerros, aes(nbez, prob))+\n  geom_bar(stat = \"identity\",\n           col = \"black\",\n           size = 0.05,\n           fill = \"cyan\")+\n  labs(x = \"Número de bezerros fêmeas\",\n       y = \"Probabilidade\") +\n  ggtitle(label = \"Probabilidade de nascimento de terneiras em 120 partos\",\n          subtitle = \"Sêmen com 85% de probabilidade de nascimento de terneiras\")+\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1)))+\n  scale_x_continuous(breaks = seq(0, 120, 20))\n\n\n\n\n\nMostrar código\n# distribuição acumulada\n\nggplot(bezerros, aes(nbez, prob_ac))+\n  geom_path(color = \"red\", size = 1)+\n  labs(x = \"Número de fêmeas\",\n       y = \"Probabilidade acumulada\")+\n  ggtitle(label = \"Probabilidade acumulada de nascimento de fêmeas\",\n          subtitle = \"Sêmem sexado com 85% de chance de nascimento de fêmeas\")+\n  # scale_x_continuous(breaks = c(0:10)) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_04_DIST_CONT.html",
    "href": "FIT5306/FIT5306_04_DIST_CONT.html",
    "title": "4. Distribuições Contínuas",
    "section": "",
    "text": "A distribuição normal é um modelo bastante útil na estatística, pois sua função densidade de probabilidade (FDP) está associada ao fato de que aproxima de forma bastante satisfatória as curvas de frequências observadas quando se mensura diversas variáveis biológicas (ex., altura, massa, comprimento, etc). Como exemplo, vamos ver a distribuição da massa de mil grãos de híbridos de milho, disponíveis no conjunto de dados data_ge do pacote metan. Neste exemplo, a linha vermelha representa a distribuição normal.\n\n\nMostrar script\nlibrary(tidyverse)\nlibrary(metan)\n\n# tema personalizado\nmy_theme <- \n  theme_gray(base_size = 14) +\n  theme(panel.grid.minor = element_blank())\n# define o tema para todos os gráficos\ntheme_set(my_theme)\n\n\nggplot(data_ge2, aes(TKW)) + \n  geom_histogram(aes(y = ..density..),\n                 bins = 15) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                color = \"red\",\n                size = 1,\n                args = list(\n                  mean = mean(data_ge2$TKW),\n                  sd = sd(data_ge2$TKW)\n                ))\n\n\n\n\n\nVamos ver a distribuição dos valores do comprimento da folha de café, mensurado na primeira aula de bioestatística.\n\n\nMostrar script\nlibrary(rio)\n# link dos dados\nlink <- \"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=1453191616\"\n\n# função para importar os dados\ndf <-  \n  import(link, dec = \",\") |> \n  filter(tipo == \"Folha\")\n\nggplot(df, aes(comprimento)) + \n  geom_histogram(aes(y = ..density..),\n                 bins = 10) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                color = \"red\",\n                size = 1,\n                args = list(\n                  mean = mean(df$comprimento),\n                  sd = sd(df$comprimento)\n                ))\n\n\n\n\n\n\n\nA distribuição normal possui dois parâmetros:\n\n\\(\\mu\\), sendo a média;\n\\(\\sigma\\), sendo o desvio padrão.\n\nEstes parâmetros definem a posição e a dispersão do conjunto de dados. Assim, se X se distribui de forma normal e contínua (variável contínua) de \\(-\\infty < x <+\\infty\\), a área total sob a curva do modelo é 1.\nO modelo da função normal possui a seguinte Função Densidade de Probabilidade:\n\\[\n{f}(x) = \\frac{1}{{\\sqrt {2\\pi {\\sigma ^2}} }}{e^{ - \\frac{{{{(x - \\mu )}^2}}}{{2{\\sigma ^2}}}}}-\\infty< x < \\infty\n\\]\nNo exemplo abaixo, é apresentado a distribuição de uma variável aleatória contínua (X) com \\(\\mu = 20\\), e \\(\\sigma = 2\\). Assim, dizemos que \\(X \\sim N(\\mu,\\sigma)\\), ou seja, segue uma distribuição normal com média \\(\\mu = 20\\) e desvio padrão \\(\\sigma = 2\\).\n\n\nMostrar script\nggplot() +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                color = \"red\",\n                size = 1,\n                xlim = c(10, 30),\n                args = list(\n                  mean = 20,\n                  sd = 2\n                )) +\n  labs(y = bquote(f(x)~~\"densidades\"),\n       x = \"x\")\n\n\n\n\n\nAbaixo, pode-se observar a distribuição de variáveis aleatórias contínuas com diferentes valores de parâmetros. No gráfico à esquerda, fixa-se a média e varia-se o desvio padrão. No exemplo central, fixa-se o desvio padrão e varia-se a média. No exemplo à direita, varia-se os dois parâmetros.\n\n\nMostrar código\nget_norm <- function(mu, sd, col = \"blue\"){\n  stat_function(fun=dnorm,\n                geom = \"line\",\n                size = 1,\n                col=col,\n                args = c(mean=mu,sd=sd))\n}\n\np1 <- \n  ggplot(data.frame(x=c(0,30)),aes(x=x)) +\n  get_norm(10, 1) +\n  get_norm(10, 2, \"green\") +\n  get_norm(10, 4, \"red\")\n\np2 <- \n  ggplot(data.frame(x=c(0,30)),aes(x=x)) +\n  get_norm(6, 2) +\n  get_norm(10, 2, \"green\") +\n  get_norm(14, 2, \"red\")\n\np3 <- \n  ggplot(data.frame(x=c(0,30)),aes(x=x)) +\n  get_norm(6, 1) +\n  get_norm(10, 2, \"green\") +\n  get_norm(14, 4, \"red\")\n\narrange_ggplot(p1, p2, p3)\n\n\n\n\n\n\n\n\nA probabilidade estatística de um valor estar no intervalo \\(x_1,x_2\\) é dada pela soma da área abaixo da curva contida no intervalo entre estes dois pontos. Tal área pode ser obtida conforme segue:\n\\[\nP\\left(x_{1}\\le X \\le  x_{2}\\right)=\\int_{x_{1}}^{x_{2}} \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}} d x\n\\]\nConsidere como exemplo, a altura de planta em uma lavoura de milho que segue uma distribuição normal com média 2 e desvio padrão de 0,2. Pergunda-se: qual é a probabilidade de, ao entrar aleatoriamente nesta lavoura ser encontrada uma planta que mede de 1,75 m a 2 m?\n\nSOLUÇÃO: Para resolver este problema, precisamos encontrar a área sombreada na figura abaixo.\n\n\n\nMostrar script\nme <- 2\nsdd <- 0.2\n\nargs <- \n  list(mean = me,\n       sd = sdd)\n\nggplot() +\n  scale_x_continuous(limits = c(1, 3),\n                     breaks = seq(1, 3, by = 0.25)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(1.75, 2),\n                args = args)+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                size = 1,\n                args = args)+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Altura da planta (m)\",\n       y = \"Probabilidade\")\n\n\n\n\n\nPara calcular esta probabilidade, precisamos encontrar a probabilidade associada a cada quantil, utilizando a função pnorm(). Esta função retorna por padrão a probabilidade \\(PX \\\\le x\\). Assim, ao se diminuir a probabilidade de encontrar uma planta com 2 m da probabilidade de encontrar uma planta com até 1,75 m, resolvemos o problema.\n\n# P[X<= 2.0]\n(p2 <- pnorm(q = 2, mean = 2, sd = 0.2))\n\n[1] 0.5\n\n# P[X<= 1.75]\n(p175 <- pnorm(q = 1.75, mean = 2, sd = 0.2))\n\n[1] 0.1056498\n\np2 - p175\n\n[1] 0.3943502\n\n\n\n\n\nO cálculo da integral da distribuição Normal pode ser aproximado pelo método geométrico por soma de retângulos (Ou Soma de Riemann). Este método possibilita calcular a integral definida em dois pontos (ex., \\(x_1\\) e \\(x_2\\)), considerando uma variável com distribuição normal. Assim, a soma das áreas dos retângulos sob a curva da distribuição normal resultarão na probabilidade estatística de um valor estar no intervalo \\(x_1,x_2\\).\n\n\nMostrar script\n##### N = 20\nn <- 20\np <- 0.5\nx <- seq(0, n, 1)\npx <- dbinom(x, n, p)\ndf2 <- data.frame(x, px)\n\n\n# Aproximação\nmedia <- n*p # media\ndesvp <- sqrt(n*p*(1-p)) # desvio padrao\n\nggplot(df2, aes(x = x, y = px)) + \n  geom_bar(stat = \"identity\",\n           width = 1, \n           color = \"black\",\n           size = 0.01,\n           fill = \"salmon\") + \n  scale_y_continuous(expand = c(0.01, 0)) + \n  xlab(\"x\") + \n  ylab(\"px e fx\") +\n  stat_function(aes(x=x),\n                fun=dnorm,\n                geom = \"line\",\n                size=1,\n                col=\"green\",\n                args = c(mean = media, sd = desvp))\n\n\n\n\n\nNo método geométrico, a função f(x) corresponderá a altura de cada retângulo. A base do retângulo (\\(\\Delta\\)), será dada por:\n\\[\n\\Delta=\\frac{x_2-x_1}{n}\n\\]\nonde n representa o número de retângulos no intervalo. Ao multiplicar a altura do retângulo pela sua base, temos a área de cada retângulo. Ao somarmos todas as n áreas, teremos a aproximação da probabilidade. Logo, é fácil notar que quanto maior o valor de n melhor será a aproximação do valor calculado pela integral.\nA função abaixo pode ser utilizada para aproximar a integral da função da distribuição Normal. A função mnorm é a Função Densidade de Probabilidade e é aplicada dentro da função int_norm para encontrar a altura de cada retângulo. Por padrão, 50000 retângulos são utilizados.\n\n# função normal, f(x)\nmnorm <- function(x, m, dp){\n  (1/(dp * sqrt(2 * pi) )) * exp(-((x - m)^2)/(2 * dp ^ 2))\n}\n# integral definida em dois pontos\n# (método geométrico por soma de retângulos)\nint_norm <- function(x1, x2, me, dp, n = 50000){\n  # cria uma sequência com n retangulos de x1 a x2\n  x <- seq(x1, x2, length.out = n)\n  # acha a base da área\n  barea <- (x2 - x1)/n\n  # encontra a altura\n  altrect <- mnorm(x, me, dp)\n  # multiplica a altura pela base e soma\n  sum(altrect * barea)\n}\n\nAbaixo, a função int_norm() é usada para aproximar a probabilidade obtida anteriormente com a função pnorm().\n\nx1 <- 1.75 # x_0\nx2 <- 2    # x_1\nm <- 2     # média\ndp <- 0.2  # desvio padrão\n\n# método geométrico\n(aprox <- int_norm(x1, x2, m, dp))\n\n[1] 0.3943496\n\n(fun_pnorm <- p2 - p175)\n\n[1] 0.3943502\n\nfun_pnorm - aprox\n\n[1] 6.171243e-07\n\n\nNota-se que com 50000 retângulos, a aproximação da probabilidade pelo método geométrico apresentou diferença somente na quinta casa após a vírgula, demonstrando uma aproximação satisfatória. Vejamos o impacto do número de retângulos nesta aproximação. Para isso, vamos criar um gráfico para mostrar como esta aproximação vai melhorando com o aumento no número de retângulos. No exemplo, é simulado de 1 até 200 (apenas para fins didáticos). A linha vermelha horizontal representa a probabilidade compudata com a função pnorm().\n\nx <- NULL\nfor (i in 1:200) {\n  x[i] <- int_norm(x1, x2, m, dp, i)\n}\ndf <- \n  data.frame(x = 1:200,\n             prob = x)\n\nggplot(df, aes(x, prob)) +\n  geom_line() +\n  geom_hline(yintercept = p2 - p175,\n             color = \"red\") +\n  labs(x = \"Números de retângulos\",\n       y = \"Probabilidade aproximada\")\n\n\n\n\n\n\n\nA distribuição Normal Padrão é nada mais que uma distribuição normal com média e desvio padrão fixos (\\(\\mu = 0; \\sigma = 1\\)). Uma vez que estes parâmetros são fixos, sempre que desejamos calcular uma probabilidade pode-se recorrer a uma tabela, onde valores de probabilidade já foram previamente calculados para essa única distribuição.\nPara isso, precisamos definir uma nova variável aleatória Z, chamada de variável aleatória normal padronizada, dada pela função linear Z.\n\\[\nZ = \\frac{X- \\mu}{\\sigma}\n\\]\nOnde X é uma variável aleatória com distribuição normal com média \\(\\mu\\) e \\(\\sigma \\> 0\\).\nComo exemplo, vamos simular uma variável aleatória (X) com \\(n = 300\\) tal que \\(X \\sim N(\\mu = 20; \\sigma = 3)\\).\n\nset.seed(1) # assegura a reprodutibilidade\nX <- round(rnorm(n = 300 , mean = 20, sd = 3), digits = 1)\nhist(X)\n\n\n\n(mu <- mean(X))\n\n[1] 20.102\n\n(sdx <- sd(X))\n\n[1] 2.892973\n\n\nPodemos criar uma função para criar a nova variável Z com base em um vetor numérico da variável original. Neste caso, a chamei de get_z().\n\nget_z <- function(x){\n  (x - mean(x)) / sd(x)\n}\n# obtém o valor Z de X\nZ <- get_z(X)\nhist(Z)\n\n\n\n\nOs valores de Z podem ser interpretados como o número de desvios padrão afastados da média, em uma distribuição normal padrão.\n\n\nMostrar script\nggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"cyan\",\n                xlim = c(-3, 3),\n                alpha = 1) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"green\",\n                xlim = c(-2, 2),\n                alpha = 1) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"salmon\",\n                xlim = c(-1, 1),\n                alpha = 1) +\n  \n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-4, 4), breaks = c(seq(-5, 5, 1))) +\n  scale_y_continuous(expand = expansion(mult = c(0, .5)),\n                     breaks = NULL) +\n  labs(x = \"Z\",\n       y = \"\")+\n  theme_gray(base_size = 16) +\n  theme(panel.grid = element_blank(),\n        panel.background = element_rect(fill = NA))\n\n\n\n\n\nDesta forma, uma tabela contendo a área sobre a curva desta distribuição de Z pode ser utilizada.\n\n\n\n\n\nA primeira decimal da variável Z encontra-se na linha e a segunda decimal na coluna. Como exemplo, a probabilidade de Z ser menor ou igual a -1 é de 0,15866.\n\n# valor exato\npnorm(-1)\n\n[1] 0.1586553\n\n\n\n\n\n\n\n\nNote\n\n\n\nRetomando o exemplo: Considere como exemplo, a altura de planta em uma lavoura de milho. Esta variável segue uma distribuição normal com média 2 e desvio padrão de 0,2. Pergunda-se: qual é a probabilidade de, ao entrar aleatoriamente nesta lavoura ser encontrada uma planta que mede de 1,75 m a 2 m? Neste caso, utilizando a normal padrão, a resolução é dada por:\n\n\n\nme <- 2 # média \nsdd <- 0.2 # desvio padrão\nval1 <- 1.75 # primeiro quantil do intervalo\nval2 <- 2 # segundo quantil do intervalo\n(Z1 <- (val1 - me) / sdd) # Z associado ao primeiro quantil\n\n[1] -1.25\n\n(Z2 <- (val2 - me) / sdd) # Z associado ao segundo quantil\n\n[1] 0\n\n(prob1 <- pnorm(Z1)) # P(Z <= -1,25)\n\n[1] 0.1056498\n\n(prob2 <- pnorm(Z2)) # P(z <= 0)\n\n[1] 0.5\n\nprob2 - prob1 # P(-1,25 <= Z <= 0)\n\n[1] 0.3943502\n\n\nNo exemplo, a área da parte sombreada (probabilidade) é de 0,39455.\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(1.2, 2.8)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(1.75, 2),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                )) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original (altura em m)\", y = \"Probabilidade\")\n\npadrao <-\n  ggplot() +\n  scale_x_continuous(limits = c(-4, 4)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z1, Z2))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\n\n\nA série histórica das vendas de uma determinada fórmula de adubo seguem uma distribuição normal com média 25.000 t e desvio padrão de 2.600 t. Se a empresa fabricante decidir fabricar 30000 toneladas deste adubo para suprir a demanda da safra atual, qual é a probabilidade de que ela não possa atender todas as vendas por estar com a produção esgotada?\n\nR = 0,0272\n\nSOLUÇÃO: encontrar a probabilidade de vender mais que 30000 t.\n\n\nMostrar script\nme <- 25000\nsdd <- 2600\nval <- 30000\n(Z <- (val - me) / sdd)\n\n\n[1] 1.923077\n\n\nMostrar script\n(prob <- 1 - pnorm(Z))\n\n\n[1] 0.0272352\n\n\nMostrar script\n# gráfico da normal padrão\nnormal <-\n  ggplot() +\n  xlim(c(15900, 34100)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(30000, 34100),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                )) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                )) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável original\")\n\n# gráfico da variável original\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z, 3.5)) +\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"; Prob área sombreada:\", round(prob, 4)))\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\n\nO gerente da empresa que João trabalha resolveu premiar seus vendedores mais eficientes (5%) na venda de insumos. Um levantamento das vendas individuais anuais mostrou que a venda de adubo segue uma distribuição normal com média 240.000 t. e desvio padrão 30.000 t. Qual o volume de vendas mínimo que João deve realizar para ser premiado?\n\n\n(R = 289.346)\n\nRESOLUÇÃO: encontrar o valor de Z associado aos 5% que mais vendem Z = 1.6448 Valor da variável original associado ao Z = 289.346\n\n\nMostrar script\n# quantil associado aos 5% que mais vendem\n(Z <- qnorm(0.95))\n\n\n[1] 1.644854\n\n\nMostrar script\nme <- 240000\nsdd <- 30000\n\n# volume mínimo de vendas\n(vendas <- Z * sdd + me)\n\n\n[1] 289345.6\n\n\nMostrar script\n# gráfico da variável original\noriginal <-\n  ggplot() +\n  xlim(c(135000, 345000)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(vendas, 360000),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável original\")\n\n# gráfico da normal padrão\npadrao <-\n  ggplot() +\n  xlim(c(-3.5, 3.5)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z, 3.5))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição de Z\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"; Prob área sombreada:\", round(prob, 4)))\n\n\nScale for 'x' is already present. Adding another scale for 'x', which will\nreplace the existing scale.\n\n\nMostrar script\narrange_ggplot(original, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nUma variável aleatória X segue uma distribuição normal com média 100 e desvio padrão 10. Calcule a probabilidade de x estar entre 90 e 110.\n\nR: 0.6826895\n\nRESOLUÇÃO: encontrar os valores de Z associado a 90 e 100, encontrando a área sobre a curva entre estes dois valores.\n\n\nMostrar script\nme <- 100\nsdd <- 10\nval1 <- 90\nval2 <- 110\n(Z1 <- (val1 - me) / sdd)\n\n\n[1] -1\n\n\nMostrar script\n(Z2 <- (val2 - me) / sdd)\n\n\n[1] 1\n\n\nMostrar script\n# probabilidade dos valores estarem a 1 desvio padrão para mais ou menos\npnorm(Z2) - pnorm(Z1)\n\n\n[1] 0.6826895\n\n\nMostrar script\nargs <- list(\n  mean = 100,\n  sd = 10\n)\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(60, 140),\n                     breaks = seq(60, 140, 10)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(90, 110),\n                args = args) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = args) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável original\")\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z1, Z2)) +\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-4, 4), breaks = c(seq(-4, 4, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\",\n       y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\")\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nSe X~N(10, 2), calcule (9 < X < 12)\n\nR: 0,53\n\nRESOLUÇÃO: calcular a probabilidade x ser maior que 9 e menor que 12\n\n\nMostrar script\nme <- 10\nsdd <- 2\nval1 <- 9\nval2 <- 12\nZ1 <- (val1 - me) / sdd\nZ2 <- (val2 - me) / sdd\n(prob <- pnorm(Z2) - pnorm(Z1))\n\n\n[1] 0.5328072\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits =  c(3, 17),\n                     breaks = 3:17) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(val1, val2),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável original\")\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z1, Z2))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Z1:\", round(Z1, 4), \"  Z2:\", round(Z2, 4), \"; Prob área sombreada:\", round(prob, 4)))\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nSe X tem uma distribuição normal com média 100 e desvio padrão 10, determine:\n\nP(X < 115)\n\n\nR: 0,9333\n\nRESOLUÇÃO: Encontrar a probabilidade associada ao valor de Z associado a 115\n\n\nMostrar script\nme <- 100\nsdd <- 10\nval <- 115\n(Z <- (val - me) / sdd)\n\n\n[1] 1.5\n\n\nMostrar script\n(prob <- pnorm(Z))\n\n\n[1] 0.9331928\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(65,  135)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(65, val),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável original\")\n\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(-3.5, Z))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"\\nProb área sombreada:\", round(prob, 4)))\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\nP(X > 80)\n\n\nR: 0,9772\n\nRESOLUÇÃO: calcular a probabilidade x ser maior que 80, ou seja \\(1 - P(X \\le 80\\)).\n\n\nMostrar script\nme <- 100\nsdd <- 10\nval <- 80\n(Z <- (val - me) / sdd)\n\n\n[1] -2\n\n\nMostrar script\n(prob <- 1 - pnorm(Z))\n\n\n[1] 0.9772499\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(65,  135)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(80, 140),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\",\n       y = \"Probabilidade\")\n\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z, 4))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\nP(X > 100)\n\n\nR: 0,5\n\nRESOLUÇÃO: calcular a probabilidade x ser maior que 50, ou seja \\(1 - P(X \\le 50\\)).\n\n\nMostrar script\nme <- 100\nsdd <- 10\nval <- 100\n(Z <- (val - me) / sdd)\n\n\n[1] 0\n\n\nMostrar script\n(prob <- 1 - pnorm(Z))\n\n\n[1] 0.5\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(65,  135)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(100, 140),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\",\n       y = \"Probabilidade\")\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z, 4))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nA alturas de 10000 alunos de um colégio têm distribuição aproximadamente normal com média de 170 cm e desvio padrão de 5 cm. Qual o número esperado de alunos com altura superior a 1,65 m?\n\nR = 8413 alunos (0,8413 * 10000)\n\nRESOLUÇÃO: calcular a probabilidade de alunos com mais de 165 cm, logo achando o número de alunos.\n\n\nMostrar script\nn <- 10000\nme <- 170\nsdd <- 5\nval <- 165\nZ <- (val - me) / sdd\n(prob <- 1 - pnorm(Z))\n\n\n[1] 0.8413447\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(152.5,  187.5),\n                     breaks = seq(150, 190, by = 5)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(val, 187.5),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Altura do aluno\",\n       y = \"Probabilidade\")\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z, 3.5))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5),\n                     breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\",\n       y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"\\nProb área sombreada:\", round(prob, 4)))\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nUma ensacadora de adubos está regulada para que o peso em cada saco seja de 50 Kg com desvio padrão de 5 Kg. Admitindo-se que a distribuição é aproximadamente normal, qual a percentagem de sacos em que o peso de adubo é inferior a 45 Kg?\n\nR (0,1587)\n\nRESOLUÇÃO: encontrar a probabilidade de achar sacos com menos que 45 Kg.\n\n\nMostrar script\nme <- 50\nsdd <- 5\nval <- 45\n(Z <- (val - me) / sdd)\n\n\n[1] -1\n\n\nMostrar script\n(prob <- pnorm(Z))\n\n\n[1] 0.1586553\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(32.5,  67.5),\n                     breaks = seq(30, 70, by = 5)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(32.5, val),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                size = 1,\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Peso do saco de adubo\",\n       y = \"Probabilidade\")\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(-3.5, Z))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"\\nProb área sombreada:\", round(prob, 4)))\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nUm lote de frangos com 14.000 frangos apresenta média de peso de 3,0 Kg e desvio padrão de 0,2 Kg. Assumindo que o peso deste lote segue uma distribuição aproximadamente normal, quantos são os frangos que pesam mais que 3300 g?\n\nR = ~ 935 (0,0668072 * 14000)\n\nRESOLUÇÃO: encontrar Z e achar a probabilidade de o peso ser maior que Z.\n\n\nMostrar script\nme <- 3\nsdd <- 0.2\nval <- 3.3\n(Z <- (val - me) / sdd)\n\n\n[1] 1.5\n\n\nMostrar script\n(prob <- 1 - pnorm(Z))\n\n\n[1] 0.0668072\n\n\nMostrar script\nround(prob * 14000)\n\n\n[1] 935\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(2.3, 3.7),\n                     breaks = seq(2, 4, by = 0.5)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(val, 4),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Peso do frango (kg)\", y = \"probabilidade\")\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z, 3.5))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5),\n                     breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"\\nProb área sombreada:\", round(prob, 4)))\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nEm uma fazenda de criação de coelhos, um lote com 300 coelhos tem média que segue uma distribuição normal com média de 3,5 Kg com desvio padrão de 250 g. Coelhos com peso de até 3.7 Kg são vendidos a R$ 15,00 o Kg. Coelhos com peso acima de 3,7 Kg são vendidos a R$ 20,00 o Kg. Quantos coelhos serão vendidos ao maior valor de venda?\n\nR (~ 63 coelhos; 0.2119 * 300)\n\nRESOLUÇÃO encontrar o número de coelhos que pesem mais que 3.7 Kg. No gráfico abaixo, a cor vermelha representa a probabilidade de coelhos com menos de 3.7 Kg e a cor azul a probabilidade de encontrar coelhos com mais de 3.7 Kg.\n\n\nMostrar script\nme <- 3.5\nsdd <- 0.25\nval <- 3.7\n(Z <- (val - me) / sdd)\n\n\n[1] 0.8\n\n\nMostrar script\n(prob <- 1 - pnorm(Z))\n\n\n[1] 0.2118554\n\n\nMostrar script\n# número de coelhos\nround(prob * 300)\n\n\n[1] 64\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(2.625,  4.375)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"blue\",\n                xlim = c(val, 4.375),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"red\",\n                xlim = c(2.625, val),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Peso do coelho\")\n\npadrao <-\nggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"blue\",\n                xlim = c(Z, 3.5))+\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"red\",\n                xlim = c(-3.5, Z))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"\\nProb área azul:\", round(prob, 4)))\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\n\nUm lote gado de corte com 3000 cabeças apresenta 430 Kg de peso vivo por cabeça em média com desvio padrão de 65 Kg e se sabe que segue uma distribuição normal. Na venda deste lote, animais com até 320 Kg são abatidos em um abatedouro A. Por outro lado, animais com peso maior que 320 e menor que 520 Kg são abatidos no abatedouro B. Animais com peso superior a 520 Kg são abatidos no abatedouro C. Considerando estes dados, responda:\n\na. O número de animais abatidos nos 3 batedouros: 3000\nb. O número de animais abatidos no abatedouro A:\nc. O número de animais abatidos no abatedouro B:\nd. O número de animais abatidos no abatedouro C:\n\nRESOLUÇÃO: encontrar a probabilidade do peso (X) assumir P(X<320), P(320 < X < 520) e P(X > 520).\n\n\n\nMostrar script\nme <- 430\nsdd <- 65\nval1 <- 320\nval2 <- 520\n(Z1 <- (val1 - me) / sdd)\n\n\n[1] -1.692308\n\n\nMostrar script\n(Z2 <- (val2 - me) / sdd)\n\n\n[1] 1.384615\n\n\nMostrar script\n# Abatedouro A\n(prob1 <- pnorm(Z1))\n\n\n[1] 0.04529366\n\n\nMostrar script\n(n1 <- round(prob1*3000))\n\n\n[1] 136\n\n\nMostrar script\n# Abateroudo B\n(prob2 <- pnorm(Z2) - prob1)\n\n\n[1] 0.8716213\n\n\nMostrar script\n(n2 <- round(prob2*3000))\n\n\n[1] 2615\n\n\nMostrar script\n# Abatedouro C\n(prob3 <- 1 - sum(prob1, prob2))\n\n\n[1] 0.08308505\n\n\nMostrar script\n(n3 <- round(prob3*3000))\n\n\n[1] 249\n\n\nMostrar script\n# checar se a soma das probabilidades deu 1\nsum(prob1, prob2, prob3)\n\n\n[1] 1\n\n\nMostrar script\n# checar se o total de animais deu 3000\nn1 + n2 + n3\n\n\n[1] 3000\n\n\nMostrar script\n# gráfico\nnormal <-\n  ggplot() +\n  xlim(c(202.5,  657.5)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(202.5, val1),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"green\",\n                xlim = c(val1, val2),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"red\",\n                xlim = c(val2, 657.5),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável \")\n\npadrao <-\n  ggplot() +\n  xlim(c(-3.5, 3.5)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(-3.5, Z1))+\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"green\",\n                xlim = c(Z1, Z2))+\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"red\",\n                xlim = c(Z2, 3.5))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  annotate(\"text\", x = -3, y = 0.11, label = \"Abatedouro A\") +\n  annotate(\"segment\",\n           x = -3,\n           y = 0.1,\n           xend = -2.2,\n           yend = 0.01,\n           arrow=arrow()) +\n  annotate(\"text\", x = -3, y = 0.31, label = \"Abatedouro B\") +\n  annotate(\"segment\",\n           x = -3,\n           y = 0.3,\n           xend = 0,\n           yend = 0.15,\n           arrow=arrow()) +\n  annotate(\"text\", x = 3, y = 0.11, label = \"Abatedouro C\") +\n  annotate(\"segment\",\n           x = 3,\n           y = 0.1,\n           xend = 2,\n           yend = 0.01,\n           arrow=arrow())\n\n\nScale for 'x' is already present. Adding another scale for 'x', which will\nreplace the existing scale.\n\n\nMostrar script\narrange_ggplot(normal, padrao)\n\n\n\n\n\n\n\n\nUm agricultor possui uma área de plantio de eucalipto com 2,5 ha e uma densidade de 1500 plantas por ha. O diâmetro a altura do peito (DAP) segue uma distribuição normal, com média de 22 cm e variância de 16 cm\\(^2\\). O produtor recebeu uma proposta de compra das toras que segue a seguinte condição.\n\nSe as toras apresentarem até 17 cm de DAP, a madeira é destinada para produção de maravalha, com preço por tora de R\\$ 28,00.\nSe as toras apresentarem DAP maior do que 17 cm, a madeira é destinada para produção de tábuas, com preço por tora de R\\$ 46,00.\n\nConsiderando o exposto, calcule:\na) O valor estimado de venda de toras para maravalha\n\nPara encontrar este número, precisamos saber quantas árvores com esta medida são esperadas. Para isso, precisamos encontrar a probabilidade de ocorrência de árvores com até 18 cm de DAP e multiplicar essa probabilidade pelo total de árvores.\n\n\\[\nZ = \\frac{17 - 22}{4} = -1,25\n\\]\n\n\nMostrar script\nggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"cyan\",\n                xlim = c(-3, -1.25)) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                xlim = c(-3, 3)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(y = \"\", x = \"Z\")\n\n\n\n\n\nMostrar script\n# probabilidade\n(p17 <- pnorm(17, mean = 22, sd = 4))\n\n\n[1] 0.1056498\n\n\nMostrar script\n# número de toras\n(n <- round(p17 * (1500 * 2.5)))\n\n\n[1] 396\n\n\nMostrar script\n# valor das toras\nn * 28\n\n\n[1] 11088\n\n\nb) o valor estimado de venda de toras para fabricação de tábua\n\nPara encontrar este número, precisamos saber quantas árvores com com mais de 18 cm se espera. A probabilidade de árvores com mais de 18 cm (P) é dada por\n\n\\[\nZ = P(X > 1,25) = 1 - P(\\le 1,25)\n\\]\n\\[\nP(X > 1,25) = 1 - 0,1056\n\\]\n\\[\nP(X > 1,25) = 0,8943\n\\]\n\n\nMostrar script\nggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"cyan\",\n                xlim = c(-1.25, 3)) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                xlim = c(-3, 3)) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(y = \"\", x = \"Z\")\n\n\n\n\n\nMostrar script\n# probabilidade\n(p_mais18 <- 1 - pnorm(17, mean = 22, sd = 4))\n\n\n[1] 0.8943502\n\n\nMostrar script\n# número de toras\n(n2 <- round(p_mais18 * (1500 * 2.5)))\n\n\n[1] 3354\n\n\nMostrar script\n# valor das toras\nn2 * 46\n\n\n[1] 154284\n\n\nc) O DAP que somente 5 % das toras ultrapassará\n\nEste valor é o quantil da distribuição no valor acumulado de 0.95. Precisamos, primeiramente, encontrar a probabilidade de \\(P(Z \\> z)\\):\n\n\\[\nP(Z\\>z) = 1 - P(Z≤z)\n\\]\n\\[\nP(Z\\>z) = 1 - 0,95\n\\]\n\\[\nP(Z\\>z) = 0,05\n\\]\nO valor de 0,95 é encontrado no quantil ~1,65 (Z) da distribuição normal padrão (tabela). Para saber o valor exato, podemos utilizar a função qnorm().\n\nqnorm(0.95)\n\n[1] 1.644854\n\n\n\n\nMostrar script\nggplot() +\n  scale_x_continuous(limits = c(-3, 3),\n                     breaks = 1.644) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"cyan\",\n                xlim = c(1.644, 3)) +\n  stat_function(fun = dnorm,\n                geom = \"line\") +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  labs(y = \"\", x = \"Z\") +\n    annotate(\"segment\",\n           x = 2.1,\n           y = 0.1,\n           xend = 2,\n           yend = 0.02,\n           arrow=arrow()) +\n  annotate(\"text\",\n           x = 2.1, y = 0.11,\n           label = \"Área = 0,05\")\n\n\n\n\n\nDe posse do valor de Z, basta realizar uma inversão da fórmula de padronização para encontrar o valor de x.\n\\[\nZ = (x -- \\mu)/\\sigma\\\\\n\\]\n\\[\n1,644 = (x -- 22)/4\\\\\n\\]\n\\[\n1,644\\times4 = x -- 22\\\\\n\\]\n\\[\n6,576 = x -- 22\\\\\n\\]\n\\[\nx = 22 + 6,576\n\\]\n\\[\nx = 28,576\n\\]\nEntão, o peso DAP que somente 5% das toras ultrapassará é de ~28,6 cm."
  },
  {
    "objectID": "FIT5306/FIT5306_04_DIST_CONT.html#intervalo-de-confiança",
    "href": "FIT5306/FIT5306_04_DIST_CONT.html#intervalo-de-confiança",
    "title": "4. Distribuições Contínuas",
    "section": "Intervalo de confiança",
    "text": "Intervalo de confiança\nA estimação por pontos (ex., média) não nos fornece a ideia da margem de erro cometida ao estimar um determinado parâmetro. Por isso, para verificar se uma dada hipótese \\(H_0\\) (de igualdade) é ou não verdadeira, deve-se utilizar intervalos de confiança ou testes de hipóteses. A construção destes intervalos, e as particularidades dos testes de hipóteses para amostras independentes e dependentes, serão discutidos a seguir. Recomendo como literatura o livro Estatística Básica^analdata-2 escrito pelo Prof. Daniel Furtado Ferreira.\nO intervalo de confiança de uma média amostral assumindo uma taxa de erro \\(\\alpha\\) é dado por:\n\\[\nP\\left[ {\\bar X - {t_{\\alpha /2}}\\frac{S}{{\\sqrt n }} \\le \\mu  \\le \\bar X + {t_{\\alpha /2}}\\frac{S}{{\\sqrt n }}} \\right] = 1 - \\alpha\n\\]\nNa expressão acima, \\(\\bar X\\) é a média, \\(S\\) é o desvio padrão e \\(-t\\_{\\\\alpha /2}\\) e \\(+t\\_{\\\\alpha /2}\\) são os quantis inferior e superior, respectivamente, da distribuição t de Student. O intervalo acima indica que o valor do parâmetro (\\(\\mu\\)) tem \\(1 - \\\\alpha\\) de chance de estar contido no intervalo.\n\nExemplo 1 (altura da turma)\nComo exemplo de motivação, vamos utilizar os dados referentes a altura (em cm) dos alunos da disciplina de Bioestatística e Experimentação Agrícola, mensurada em sala de aula. A amostra é composta por 20 observações.\n\nlibrary(rio)\ndf_altura <- \n  import(\"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=1992833755\") |> \n  as_character(Pessoa)\n\ndf_altura\n\n   Pessoa Altura\n1       1    176\n2       2    164\n3       3    159\n4       4    163\n5       5    173\n6       6    161\n7       7    177\n8       8    179\n9       9    168\n10     10    172\n11     11    178\n12     12    170\n13     13    174\n14     14    169\n15     15    175\n16     16    169\n17     17    187\n18     18    181\n19     19    186\n20     20    171\n\n\nComo n = 20, o grau liberdade para encontrar o quantil da distribuição t é 19. O quantil associado a este Grau Liberdade, considerando \\(\\alpha = 0,05\\) é encontrado na tabela da distribuição t. Nesta tabela, o valor de\n\n\n\n\n\nTamém podemos encontrar este quantil utilizando a função qt(). No próximo código, o quantil (2.5% e 97.5%), a média e o desvio padrão são calculados. Note que\n\n(quantil_t <- qt(c(0.025, 0.975), df = 19))\n\n[1] -2.093024  2.093024\n\n(media <- mean(df_altura$Altura))\n\n[1] 172.6\n\n(desvpad <- sd(df_altura$Altura))\n\n[1] 7.639234\n\n\nDe posse destas informações, podemos calcular o intervalo de confiança (limite inferior, LI e limite superior, LS)\n\\[\nLI = 172,6 - 2,093 \\times \\frac{{7,64}}{{\\sqrt {20} }} = 169,02\n\\]\n\\[\nLs = 172,6 + 2,093 \\times \\frac{{7,64}}{{\\sqrt {20} }} = 176,17\n\\]\nPara facilitar nossos próximos exemplos, vamos criar uma função para computar o intervalo de confiança 95%.\n\nget_ci_t <- function(media, dp, n){\n  quantil_t <- qt(0.975, n - 1)\n  semi_amp <- quantil_t * dp / sqrt(n)\n  message(\n    \"[\", round(media - semi_amp, 3), \" ; \", round(media + semi_amp, 3), \"]\"\n  )\n  return(semi_amp)\n}\nget_ci_t(168, sqrt(67.404), 20)\n\n[164.158 ; 171.842]\n\n\n[1] 3.842395\n\n\n\n\nMostrar script\ndf <- tibble(\n  media = media,\n  desvpad = desvpad,\n  LI = media - get_ci_t(media, desvpad, 20),\n  LS = media + get_ci_t(media, desvpad, 20)\n)\n\n\n[169.025 ; 176.175]\n[169.025 ; 176.175]\n\n\nMostrar script\ndf\n\n\n# A tibble: 1 × 4\n  media desvpad    LI    LS\n  <dbl>   <dbl> <dbl> <dbl>\n1  173.    7.64  169.  176.\n\n\nMostrar script\n# criar o gráfico com os intervalos\nggplot(df, aes(x = media, y = \"\")) +\n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS),\n                width = 0.1) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  scale_x_continuous(breaks = seq(169, 177, by = 1)) +\n  labs(x = \"Altura do aluno (cm)\",\n       y = \"\")\n\n\n\n\n\nA função t.test() pode também ser utilizada para calcular o intervalo de confiança de 95% quando se tem apenas uma amostra.\n\nic <- t.test(df_altura$Altura)\nic$conf.int\n\n[1] 169.0247 176.1753\nattr(,\"conf.level\")\n[1] 0.95\n\n\n\n\nExemplo 2 (peso de frango)\nConsidere um aviário com 15000 frangos. O criador realizou a amostragem de 25 frangos aleatoriamente para realizar uma estimativa da média do peso do lote visando a programação para abate. Após analisar as pesagens coletadas, o produtor encontrou uma média de 2,83 Kg e um desvio padrão de 0,27 Kg. Pergunta-se: Qual o intervalo de 95% para a média estimada?\n\n\nMostrar script\ndf3 <- tibble(\n  media = 2.83,\n  desvpad = 0.27,\n  LI = media - get_ci_t(media, desvpad, n = 25),\n  LS = media + get_ci_t(media, desvpad, n = 25)\n)\n\n\n[2.719 ; 2.941]\n[2.719 ; 2.941]\n\n\nMostrar script\nggplot(df3, aes(x = media, y = \"\")) +\n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS),\n                width = 0.1) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  labs(x = \"Peso médio do frango\",\n       y = \"\")\n\n\n\n\n\n\n\nVariação no desvio padrão\nAbaixo, são simuladas 4 amostras de n = 20 com médias igual a 10 e desvios padrões variantes. Note como o intervalo de confiança é menor a medida em que o desvio padrão é mais baixo.\n\n\nMostrar script\ndf4 <- tibble(\n  amostra = paste0(1:4),\n  media = c(10, 10, 10, 10),\n  desvpad = c(1, 4, 6, 8),\n  LI = media - get_ci_t(media, desvpad, n = 20),\n  LS = media + get_ci_t(media, desvpad, n = 20),\n  lab = paste0(\"dp: \", desvpad)\n)\n\n\n[9.5328.1287.1926.256 ; 10.46811.87212.80813.744]\n[9.5328.1287.1926.256 ; 10.46811.87212.80813.744]\n\n\nMostrar script\ndf4\n\n\n# A tibble: 4 × 6\n  amostra media desvpad    LI    LS lab  \n  <chr>   <dbl>   <dbl> <dbl> <dbl> <chr>\n1 1          10       1  9.53  10.5 dp: 1\n2 2          10       4  8.13  11.9 dp: 4\n3 3          10       6  7.19  12.8 dp: 6\n4 4          10       8  6.26  13.7 dp: 8\n\n\nMostrar script\n# criar o gráfico com os intervalos\nggplot(df4, aes(x = media, y = amostra)) +\n  geom_vline(xintercept = 10, linetype = 2) + \n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS),\n                width = 0.1) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  scale_x_continuous(breaks = seq(169, 177, by = 1)) +\n  geom_text(aes(label = lab),\n            vjust = -1,\n            hjust = 2) +\n  labs(x = \"Variável hipotética\",\n       y = \"Amostra\")\n\n\n\n\n\n\n\nVariação no tamanho da amostra\n\n\nMostrar script\ndf_t <- tibble(\n  dist = \"t\",\n  n = seq(2, 30, length.out = 200),\n  media = 10,\n  desvpad = 2,\n  UL = media + get_ci_t(media, desvpad, n = n),\n  LL = media - get_ci_t(media, desvpad, n = n)\n)\n\n\n[-7.969-3.041-0.1791.6462.8923.7894.4614.9835.3985.7376.0186.2556.4586.6336.7876.9237.0447.1527.257.3397.427.4947.5637.6267.6847.7397.797.8387.8837.9257.9658.0028.0388.0728.1048.1358.1648.1928.2188.2448.2688.2918.3148.3368.3568.3768.3968.4148.4338.458.4678.4838.4998.5148.5298.5448.5588.5718.5848.5978.618.6228.6348.6458.6578.6688.6798.6898.6998.7098.7198.7298.7388.7478.7568.7658.7738.7828.798.7988.8068.8148.8218.8298.8368.8438.858.8578.8648.8718.8778.8848.898.8968.9028.9088.9148.928.9268.9318.9378.9438.9488.9538.9588.9648.9698.9748.9798.9838.9888.9938.9989.0029.0079.0119.0169.029.0249.0289.0339.0379.0419.0459.0499.0539.0579.069.0649.0689.0729.0759.0799.0829.0869.0899.0939.0969.19.1039.1069.119.1139.1169.1199.1229.1259.1289.1319.1349.1379.149.1439.1469.1499.1529.1549.1579.169.1639.1659.1689.1719.1739.1769.1789.1819.1839.1869.1889.1919.1939.1969.1989.29.2039.2059.2079.219.2129.2149.2169.2189.2219.2239.2259.2279.2299.2319.2339.2359.2379.2399.2419.2439.2459.2479.2499.2519.253 ; 27.96923.04120.17918.35417.10816.21115.53915.01714.60214.26313.98213.74513.54213.36713.21313.07712.95612.84812.7512.66112.5812.50612.43712.37412.31612.26112.2112.16212.11712.07512.03511.99811.96211.92811.89611.86511.83611.80811.78211.75611.73211.70911.68611.66411.64411.62411.60411.58611.56711.5511.53311.51711.50111.48611.47111.45611.44211.42911.41611.40311.3911.37811.36611.35511.34311.33211.32111.31111.30111.29111.28111.27111.26211.25311.24411.23511.22711.21811.2111.20211.19411.18611.17911.17111.16411.15711.1511.14311.13611.12911.12311.11611.1111.10411.09811.09211.08611.0811.07411.06911.06311.05711.05211.04711.04211.03611.03111.02611.02111.01711.01211.00711.00210.99810.99310.98910.98410.9810.97610.97210.96710.96310.95910.95510.95110.94710.94310.9410.93610.93210.92810.92510.92110.91810.91410.91110.90710.90410.910.89710.89410.8910.88710.88410.88110.87810.87510.87210.86910.86610.86310.8610.85710.85410.85110.84810.84610.84310.8410.83710.83510.83210.82910.82710.82410.82210.81910.81710.81410.81210.80910.80710.80410.80210.810.79710.79510.79310.7910.78810.78610.78410.78210.77910.77710.77510.77310.77110.76910.76710.76510.76310.76110.75910.75710.75510.75310.75110.74910.747]\n[-7.969-3.041-0.1791.6462.8923.7894.4614.9835.3985.7376.0186.2556.4586.6336.7876.9237.0447.1527.257.3397.427.4947.5637.6267.6847.7397.797.8387.8837.9257.9658.0028.0388.0728.1048.1358.1648.1928.2188.2448.2688.2918.3148.3368.3568.3768.3968.4148.4338.458.4678.4838.4998.5148.5298.5448.5588.5718.5848.5978.618.6228.6348.6458.6578.6688.6798.6898.6998.7098.7198.7298.7388.7478.7568.7658.7738.7828.798.7988.8068.8148.8218.8298.8368.8438.858.8578.8648.8718.8778.8848.898.8968.9028.9088.9148.928.9268.9318.9378.9438.9488.9538.9588.9648.9698.9748.9798.9838.9888.9938.9989.0029.0079.0119.0169.029.0249.0289.0339.0379.0419.0459.0499.0539.0579.069.0649.0689.0729.0759.0799.0829.0869.0899.0939.0969.19.1039.1069.119.1139.1169.1199.1229.1259.1289.1319.1349.1379.149.1439.1469.1499.1529.1549.1579.169.1639.1659.1689.1719.1739.1769.1789.1819.1839.1869.1889.1919.1939.1969.1989.29.2039.2059.2079.219.2129.2149.2169.2189.2219.2239.2259.2279.2299.2319.2339.2359.2379.2399.2419.2439.2459.2479.2499.2519.253 ; 27.96923.04120.17918.35417.10816.21115.53915.01714.60214.26313.98213.74513.54213.36713.21313.07712.95612.84812.7512.66112.5812.50612.43712.37412.31612.26112.2112.16212.11712.07512.03511.99811.96211.92811.89611.86511.83611.80811.78211.75611.73211.70911.68611.66411.64411.62411.60411.58611.56711.5511.53311.51711.50111.48611.47111.45611.44211.42911.41611.40311.3911.37811.36611.35511.34311.33211.32111.31111.30111.29111.28111.27111.26211.25311.24411.23511.22711.21811.2111.20211.19411.18611.17911.17111.16411.15711.1511.14311.13611.12911.12311.11611.1111.10411.09811.09211.08611.0811.07411.06911.06311.05711.05211.04711.04211.03611.03111.02611.02111.01711.01211.00711.00210.99810.99310.98910.98410.9810.97610.97210.96710.96310.95910.95510.95110.94710.94310.9410.93610.93210.92810.92510.92110.91810.91410.91110.90710.90410.910.89710.89410.8910.88710.88410.88110.87810.87510.87210.86910.86610.86310.8610.85710.85410.85110.84810.84610.84310.8410.83710.83510.83210.82910.82710.82410.82210.81910.81710.81410.81210.80910.80710.80410.80210.810.79710.79510.79310.7910.78810.78610.78410.78210.77910.77710.77510.77310.77110.76910.76710.76510.76310.76110.75910.75710.75510.75310.75110.74910.747]\n\n\nMostrar script\ndf_n <- tibble(\n  dist = \"normal\",\n  n = seq(2, 30, length.out = 200),\n  media = 10,\n  desvpad = 2,\n  UL = media + qnorm(0.975) * desvpad / sqrt(n),\n  LL = media - qnorm(0.975) * desvpad / sqrt(n)\n)\ndf_dists <- rbind(df_t, df_n)\n\n# criar o gráfico com os intervalos\nggplot(df_dists, aes(color = dist)) +\n  geom_line(aes(x = n, y = LL), size = 1) +\n  geom_line(aes(x = n, y = UL), size = 1) +\n  scale_x_continuous(breaks = seq(2, 30, by = 2)) +\n  labs(x = \"Tamanho da amostra\",\n       y = \"Intervalo de confiança (95%)\") +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_04_DIST_CONT.html#testes-de-hipóteses",
    "href": "FIT5306/FIT5306_04_DIST_CONT.html#testes-de-hipóteses",
    "title": "4. Distribuições Contínuas",
    "section": "Testes de hipóteses",
    "text": "Testes de hipóteses\nOs testes de hipóteses são utilizados para determinar quais resultados de um estudo científico podem levar à rejeição da hipótese nula (\\(H_0\\)) a um nível de significância pré–estabelecido. Os testes de hipóteses aqui demonstrados tem como objetivo:\n1) verificar se determinada amostra difrere ou não de zero (\\({H_0}:\\mu = 0\\)) 2) Verificar se duas amostras independentes são ou não iguais (\\({H_0}:{\\mu _1} = {\\mu _2}\\)). 2) Verificar se duas amostras dependentes possuem desvios iguais a zero (\\({H_0}:d_i = 0\\)).\n\nTeste de hipótese para uma amostra\nNo caso de uma amostra, a estatística teste (t calculado) é dada por\n\\[\n{t_{c(\\alpha; \\nu)}} = \\frac{{\\bar Y - \\mu }}{{\\frac{{{S_Y}}}{{\\sqrt n }}}}\n\\]\nOnde \\(\\alpha\\) é a probabilidade de erro, \\(\\nu\\) é o grau de liberdade (nº de amostras menos 1), \\(\\bar Y\\) é a média da amostra, \\(S_y\\) é o desvio padrão da amostra e \\(n\\) é o número de amostras.\nVamos retornar ao exemplo da altura da turma. A média da amostragem é de 172,6 cm. Digamos que a altura média dos alunos da UFSC é de 165 cm. Pode-se dizer que a estimativa da altura da turma de Bioestatística a 165 cm, considerando uma taxa de erro de 5%?\nPrimeiramente, define-se as hipóteses;\n\\[\n{H_0}:172,6 = 165\n\\]\n\\[\nH_1:172,6 \\ne 165\n\\]\n\naltura <- df_altura$Altura\n(dp <- sd(altura))\n\n[1] 7.639234\n\n(media <- mean(altura))\n\n[1] 172.6\n\n(n <- length(altura))\n\n[1] 20\n\n(t_tab <- qt(0.975, df = n - 1))\n\n[1] 2.093024\n\n\n\\[\n{t_c} = \\frac{{172,6 - 165}}{{\\frac{{7,63}}{{\\sqrt {20} }}}}\n\\]\n\\[\n{t_c} = 4,455\n\\]\nComo o t calculado (4,455) é maior que o t tabelado (2,09), rejeita-se a hipótese nula e afirma-se que a estimativa da média da altura da turma difere de 165 cm. Este mesmo teste pode ser realizado com a função t.test().\n\n# t tabelado\nt.test(altura, mu = 165)\n\n\n    One Sample t-test\n\ndata:  altura\nt = 4.4492, df = 19, p-value = 0.0002752\nalternative hypothesis: true mean is not equal to 165\n95 percent confidence interval:\n 169.0247 176.1753\nsample estimates:\nmean of x \n    172.6 \n\n\n\n\nTeste de hipóteses para amostras independentes\nNeste tipo de teste de hipótese, o objetivo é comparar se a estimativa da média de um grupo “A” difere estatisticamente da estimativa da média de um grupo “B”. Utilizaremos como amostras os dados do diâmetro dos grãos obtidas na primeira aula, onde deseja-se comparar se o diâmetro entre os grupos “vermelho” e “verde” difere estatisticamente.\n\n\nMostrar script\ndf_grao <- \n  import(\"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=1716920199\",\n         dec = \",\")\n\n#gráfico\nggplot(df_grao, aes(DIAM_GRAO, fill = COR_GRAO)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_manual(values = c(\"green\", \"red\")) +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())\n\n\n\n\n\nNeste caso, a estatística do teste é dada por\n\\[\n{t_c} = \\frac{{\\left( {{{\\bar x}_1} - {{\\bar x}_2}} \\right)}}{{\\sqrt {S_p^2\\left( {\\frac{1}{{{n_1}}} + \\frac{1}{{{n_2}}}} \\right)} }}\n\\]\nOnde\n\\[\nS_p^2 = \\frac{{\\left( {{n_1} - 1} \\right)S_{{x_1}}^2 + \\left( {{n_2} - 1} \\right)S_{{x_2}}^2}}{{{n_1} + {n_2} - 2}}\n\\]\nOnde \\(\\bar x_1\\), \\(n_1\\) e \\(S^2\\_{x_1}\\) são a média, o tamanho da amostra e a variância para a amostra 1; \\(\\bar x_2\\), \\(n_2\\) e \\(S^2\\_{x_2}\\) são a média, o tamanho da amostra e a variância para a amostra 2. Vamos calcular estas estatísticas para os dados em questão. A estatística de teste é então comparada com o t tabelado com 26 (13 + 15 - 2) Graus Liberdade.\n\ndf_grao |> \n  desc_stat(DIAM_GRAO,\n            by = COR_GRAO,\n            stats = c(\"n, mean, sd.amo\")) |> \n  as.data.frame()\n\n  COR_GRAO  variable  n    mean sd.amo\n1    verde DIAM_GRAO 15  8.8200 1.0105\n2 vermelho DIAM_GRAO 13 10.8177 1.0617\n\n(t_tab <- qt(0.975, df = 26))\n\n[1] 2.055529\n\n\nCom base nos valores obtidos, a estatística t é obtida com:\n\\[\nS_p^2 = \\frac{{\\left( {13 - 1} \\right)1,{{06}^2} + \\left( {15 - 1} \\right)1,{{01}^2}}}{{13 + 15 - 2}}\n\\]\n\\[\nS_p^2 = 1,067\n\\]\n\\[\n{t_c} = \\frac{{\\left( {10,81 - 8,82} \\right)}}{{\\sqrt {1,067\\left( {\\frac{1}{{13}} + \\frac{1}{{15}}} \\right)} }}\n\\]\n\\[\n{t_c} = 5,084\n\\]\nComo \\(5,084 > 2,055\\), rejeita-se a hipótese \\(H_0\\) e conclui-se que as médias dos dois grupos são estatisticamente distintas. Usando a função t.test(), este teste de hipótese é realizado com:\n\nvermelho <- \n  df_grao |> \n  subset(COR_GRAO == \"vermelho\") |>\n  pull(DIAM_GRAO)\n\nverde <- \n  df_grao |> \n  subset(COR_GRAO == \"verde\") |>\n  pull(DIAM_GRAO)\n\n# testa se as amostras difrem entre si\nt.test(vermelho, verde, var.equal = TRUE) \n\n\n    Two Sample t-test\n\ndata:  vermelho and verde\nt = 5.0962, df = 26, p-value = 2.608e-05\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.191932 2.803452\nsample estimates:\nmean of x mean of y \n 10.81769   8.82000 \n\n\nO pacote ggstatplot pode ser utilizado para confecionar gráficos que incluem teste de hipóteses.\n\n\nMostrar script\nlibrary(ggstatsplot)\n\nggbetweenstats(df_grao, \n               x = COR_GRAO,\n               y = DIAM_GRAO,\n               plot.type = \"box\",\n               bf.message = FALSE,\n               var.equal = TRUE)\n\n\n\n\n\n\n\nTeste de hipóteses para amostras dependentes\nAs formas de comparação discutidas acima consideram as amostras como sendo independentes entre si. Em certas ocasiões, um mesmo indivíduo de uma amostra é medido ao longo do tempo ou avaliado antes ou depois da aplicação de um determinado tratamento.\nAssim, nessas ocasiões, é possível avaliar se a diferença média das observações é estatisticamente igual a zero ou não. Se esta diferença for estatisticamente diferente de zero, pode-se afirmar que tal tratamento possui efeito significativo.\nA estatística do teste t para amostras pareadas é dada por\n\\[\n{t_c} = \\frac{{\\bar D}}{{\\frac{{{S_D}}}{{\\sqrt n }}}} \\sim {t_{\\left( {\\alpha ,\\nu } \\right)}}\n\\]\nOnde \\(\\bar D\\) é a média das diferenças e \\(S_D\\) é o desvio padrão das diferenças.\n\nA fim de determinar a eficiência de um medicamento antitérmico, a temperatura corporal (em graus Celsius) de 7 indivíduos foi medida. Em seguida, foi administrado o medicamento e após uma hora a temperatura foi medida novamente.\n\n\npaired <- \n  import(\"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=1507821405\",\n         dec = \",\")\npaired\n\n  INDIVIDUO ANTES DEPOIS DIFERENCA\n1         1  37.5   36.8      -0.7\n2         2  36.0   35.4      -0.6\n3         3  39.0   37.6      -1.4\n4         4  38.0   37.2      -0.8\n5         5  37.8   36.9      -0.9\n6         6  38.5   37.7      -0.8\n7         7  39.3   38.0      -1.3\n\n(mean_dif <- mean(paired$DIFERENCA))\n\n[1] -0.9285714\n\n(dp_dif <- sd(paired$DIFERENCA))\n\n[1] 0.3039424\n\n(n <- length(paired$DIFERENCA))\n\n[1] 7\n\n\nA estatística de teste é dada por:\n\\[\n{t_c} = \\frac{{-0.928 - 0}}{{\\frac{{0,3039}}{{\\sqrt {7} }}}}\n\\]\n\\[\nt_c = -8,079\n\\]\n\nantes <- paired$ANTES\ndepois <- paired$DEPOIS\nt.test(depois, antes, paired = TRUE, var.equal = TRUE)\n\n\n    Paired t-test\n\ndata:  depois and antes\nt = -8.083, df = 6, p-value = 0.0001921\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -1.2096712 -0.6474716\nsample estimates:\nmean difference \n     -0.9285714 \n\n\nNote que o mesmo resultado é obtido ao se realizar um teste para uma amostra utilizando a diferença calculada.\n\nt.test(paired$DIFERENCA, var.equal = TRUE)\n\n\n    One Sample t-test\n\ndata:  paired$DIFERENCA\nt = -8.083, df = 6, p-value = 0.0001921\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.2096712 -0.6474716\nsample estimates:\n mean of x \n-0.9285714"
  },
  {
    "objectID": "FIT5306/FIT5306_04_DIST_CONT.html#exercícios-distribuição-t",
    "href": "FIT5306/FIT5306_04_DIST_CONT.html#exercícios-distribuição-t",
    "title": "4. Distribuições Contínuas",
    "section": "Exercícios distribuição t",
    "text": "Exercícios distribuição t\n\nQuestão 1\nUm experimento visando comparar dois híbridos de milho (H1 e H2) obteve dados da massa de grãos (MGRA) e número de grãos (NGRA) por espiga, apresentados abaixo.\n\ndf <- import(\"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=1657403926\",\n             dec = \",\")\ndf\n\n   HIBRIDO MGRA NGRA\n1       H1  219  570\n2       H1  280  665\n3       H1  224  627\n4       H1  243  644\n5       H1  289  734\n6       H1  203  541\n7       H1  148  409\n8       H1  246  652\n9       H1  129  384\n10      H1  246  709\n11      H2  226  529\n12      H2  208  531\n13      H2  132  339\n14      H2  125  295\n15      H2  224  533\n16      H2  113  498\n17      H2  122  497\n18      H2  114  521\n19      H2  119  640\n20      H2   61  196\n\n# encontrando o desvio padrão e a média\ndf |> \n  desc_stat(MGRA, NGRA,\n            by = HIBRIDO, \n            stats = c(\"mean, sd.amo, n\")) |> \n  as.data.frame()\n\n  HIBRIDO variable  mean   sd.amo  n\n1      H1     MGRA 222.7  51.5753 10\n2      H1     NGRA 593.5 118.5685 10\n3      H2     MGRA 144.4  55.3598 10\n4      H2     NGRA 457.9 135.6396 10\n\n\nAssumindo que as variáveis MGRA e NGRA seguem uma distribuição normal, utilize um teste t para testar a hipótese de diferença das médias destas variáveis entre os dois híbridos. Após a obtenção dos resultados, realize a interpretação para cada variável.\n\nVariável MGRA\n\n\\[\n{t_c} = \\frac{{\\left( {{{\\bar x}_1} - {{\\bar x}_2}} \\right)}}{{\\sqrt {S_p^2\\left( {\\frac{1}{{{n_1}}} + \\frac{1}{{{n_2}}}} \\right)} }}\n\\]\n\\[\nS_p^2 = \\frac{{\\left( {10 - 1} \\right)51,575^2 + \\left( {10 - 1} \\right)55,359^2}}{{10 + 10 - 2}}\n\\]\n\\[\n2862,299\n\\]\n\\[\n{t_c} = \\frac{{\\left( {{222,7} - {144,4}} \\right)}}{{\\sqrt {2862,299\\left( {\\frac{1}{{10}} + \\frac{1}{{10}}} \\right)} }}\n\\]\n\\[\nt_c = 3,2725\n\\]\nA aplicação no software R, é dada no seguinte exemplo\n\n\nMostrar script\nt.test(MGRA ~ HIBRIDO, data = df, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  MGRA by HIBRIDO\nt = 3.2725, df = 18, p-value = 0.00423\nalternative hypothesis: true difference in means between group H1 and group H2 is not equal to 0\n95 percent confidence interval:\n  28.03252 128.56748\nsample estimates:\nmean in group H1 mean in group H2 \n           222.7            144.4 \n\n\nMostrar script\nlibrary(ggstatsplot)\nggbetweenstats(df,\n               x = HIBRIDO,\n               y = MGRA,\n               plot.type = \"box\",\n               bf.message = FALSE,\n               var.equal = TRUE)\n\n\n\n\n\n\nVariável NGRA\n\n\\[\nS_p^2 = \\frac{{\\left( {10 - 1} \\right)118,5685^2 + \\left( {10 - 1} \\right)135,6396^2}}{{10 + 10 - 2}}\n\\]\n\\[\n16228,29\n\\]\n\\[\n{t_c} = \\frac{{\\left( {{593,5} - {457,9}} \\right)}}{{\\sqrt {16228,29\\left( {\\frac{1}{{10}} + \\frac{1}{{10}}} \\right)}}}\n\\]\n\\[\nt_c = 2,38\n\\]\n\n\nMostrar script\nt.test(NGRA ~ HIBRIDO, data = df, var.equal = TRUE)\n\n\n\n    Two Sample t-test\n\ndata:  NGRA by HIBRIDO\nt = 2.3802, df = 18, p-value = 0.02856\nalternative hypothesis: true difference in means between group H1 and group H2 is not equal to 0\n95 percent confidence interval:\n  15.90901 255.29099\nsample estimates:\nmean in group H1 mean in group H2 \n           593.5            457.9 \n\n\nMostrar script\nggbetweenstats(df,\n               x = HIBRIDO,\n               y = NGRA,\n               plot.type = \"box\",\n               bf.message = FALSE,\n               var.equal = TRUE)\n\n\n\n\n\nO valor de t tabelado para 5% de erro e grau liberdade de 18 é 2,10.\n\nqt(0.975, df = 18)\n\n[1] 2.100922\n\n\nConsiderando os resultados do teste de hipótese, rejeita-se a hipótese nula para as duas variáveis e afirma-se que as médias dos dois híbridos para MGRA e NGRA por espiga são diferentes.\n\n\nQuestão 2\nNos últimos anos, o melhoramento ganhou ferramentas que aumentam a eficiência no desenvolvimento de novas cultivares. Dentre essas, pode-se citar a genotipagem por meio do mapeamento genético e marcadores moleculares, gerando uma infinidade de informações genéticas. No entanto, mesmo com o avanço exponencial desse ramo da ciência, há ainda uma enorme necessidade de obtenção de dados fenotípicos confiáveis 2.\nTécnicas que utilizam visão computacional e análise de imagens possibilitam ganho de tempo e, principalmente recursos durante as etapas do melhoramento. Com tais análises, é possível obter grande quantidade de dados em pouco tempo. No entanto, é necessário que tais medidas sejam acuradas, ou seja, representem fidedignamente os valores reais observados. Para validar a obtenção de medidas de comprimento e largura de folhas via imagens, medidas de comprimento e largura de 15 folhas foram obtidas utilizando duas técnicas. A primeira, utilizando análises de imagens no pacote R pliman e a segunda por meio do auxílio de uma régua. Os dados coletados são encontrados a seguir.\n\nlibrary(rio)\nlibrary(metan)\nlibrary(tidyverse)\n\ndf <- import(\"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=2115165499\",\n             dec = \",\")\ndf\n\n   folha metodo comprimento largura\n1      1  regua       16.50    6.40\n2      2  regua       16.00    4.70\n3      3  regua       12.50    3.40\n4      4  regua       10.00    4.20\n5      5  regua        7.60    3.40\n6      6  regua        6.80    3.20\n7      7  regua       14.10    6.80\n8      8  regua        9.90    4.80\n9      9  regua        9.70    4.30\n10    10  regua        6.50    2.60\n11    11  regua        5.70    2.50\n12     1   foto       15.64    6.66\n13     2   foto       15.40    4.55\n14     3   foto       12.29    3.38\n15     4   foto        9.71    4.16\n16     5   foto        7.66    3.41\n17     6   foto        6.67    3.17\n18     7   foto       14.55    6.90\n19     8   foto       10.22    4.98\n20     9   foto        9.96    4.46\n21    10   foto        6.61    2.72\n22    11   foto        5.94    2.54\n\n\nConsiderando que as medidas (régua e foto) foram obtidas no mesmo indivíduo, utilize um teste t pareado para testar, a 5% de probabilidade de erro, se o método de mensuração por imagem difere do método manual (por régua) para as variáveis em questão.\n\n# variável comprimento da folha\n# ex\n\ncomp_foto <- df |> subset(metodo == \"foto\") |> pull(comprimento)\ncomp_foto\n\n [1] 15.64 15.40 12.29  9.71  7.66  6.67 14.55 10.22  9.96  6.61  5.94\n\ncomp_regua <- df |> subset(metodo == \"regua\") |> pull(comprimento)\ncomp_regua\n\n [1] 16.5 16.0 12.5 10.0  7.6  6.8 14.1  9.9  9.7  6.5  5.7\n\n# calcula a diferença\ndif <- comp_foto - comp_regua\ndif\n\n [1] -0.86 -0.60 -0.21 -0.29  0.06 -0.13  0.45  0.32  0.26  0.11  0.24\n\n# realiza um teste t com a diferença\n\nt.test(dif)\n\n\n    One Sample t-test\n\ndata:  dif\nt = -0.48217, df = 10, p-value = 0.6401\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.3321539  0.2139721\nsample estimates:\n  mean of x \n-0.05909091 \n\n# mesma coisa informando as duas médias com 'paired = TRUE'\nt.test(comprimento ~ metodo, data = df, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  comprimento by metodo\nt = -0.48217, df = 10, p-value = 0.6401\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3321539  0.2139721\nsample estimates:\nmean difference \n    -0.05909091 \n\n# variável largura da folha\nt.test(largura ~ metodo, data = df, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  largura by metodo\nt = 1.5996, df = 10, p-value = 0.1408\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.02250533  0.13705079\nsample estimates:\nmean difference \n     0.05727273 \n\n\n\n\nQuestão 3\nUm Engenheiro Florestal realizou mensurações do Diâmetro a Altura do Peito em duas áreas plantadas de eucalipto. Ambas as áreas possuem 05 anos de idade, mas se encontram em diferentes tipos de solo. Após coletar os dados, os seguintes valores foram obtidos:\n\n\n\nParâmetro\nÁrea 1\nÁrea 2\n\n\n\n\n\\(\\bar X (cm)\\)\n11,5\n13,6\n\n\nS (cm)\n3\n5\n\n\nn (contagem)\n23\n31\n\n\n\nCom base nessas informações, calcule o intervalo de confiança de 95% para as médias do DAP da área 1 e área 2 e, com base nos intervalos, justifique se a média do DAP das duas áreas pode ser considerada estatisticamente diferente.\n\ndf <- tibble(\n  area = c(\"Área 1\", \"Área 2\"),\n  media = c(11.5, 13.6),\n  desvpad = c(3, 5),\n  n = c(20, 31),\n  LI = media - get_ci_t(media, desvpad, n),\n  LS = media + get_ci_t(media, desvpad, n)\n)\n\n[10.09611.766 ; 12.90415.434]\n[10.09611.766 ; 12.90415.434]\n\ndf\n\n# A tibble: 2 × 6\n  area   media desvpad     n    LI    LS\n  <chr>  <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 Área 1  11.5       3    20  10.1  12.9\n2 Área 2  13.6       5    31  11.8  15.4\n\n# criar o gráfico com os intervalos\nggplot(df, aes(x = media, y = area)) +\n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS),\n                width = 0.1) +\n  geom_point(size = 3) +\n  labs(x = \"Diâmetro a Altura do Peito (cm)\",\n       y = \"\")\n\n\n\n\nConsiderando que os intervalos de confiança se cruzam, pode-se afirmar que as médias não diferem estatisticamente. Vamos testar esta hipótese utilizando um teste t?. Neste caso, o t calculado é comparado com o t tabelado a 52 (23 + 31 - 2) graus liberdade.\n\nqt(0.975, df = 52)\n\n[1] 2.006647\n\n\n\\[\n{t_c} = \\frac{{11,5 - 13,6}}{{\\sqrt {\\frac{{\\left( {20 - 1} \\right){3^2} + \\left( {31 - 1} \\right){5^2}}}{{20 + 31 - 2}} \\times \\left( {\\frac{1}{{20}} + \\frac{1}{{31}}} \\right)} }}\n\\]\n\\[\n{t_c} = 1,688\n\\]\nComo o t calculado foi menor que o tabelado, não rejeita-se a hipótese nula de diferença entre as médias, assumindo-se que as médias são estatisticamente iguais.\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html",
    "title": "5. Visualização de dados",
    "section": "",
    "text": "Para reprodução destes exemplos, os seguintes pacotes precisam ser instalados do github\n\n# pacotes para criação de mapas (github)\nremotes::install_github(\"ropensci/rnaturalearthhires\")\nremotes::install_github(\"ricardo-bion/ggradar\")\nremotes::install_github(\"ricardo-bion/ggradar\")\n\nAntes de carregar, verifique se o pacote está instalado.\n\nlibrary(tidyverse)\nlibrary(metan)   \nlibrary(rio)\nlibrary(ggridges)\nlibrary(rnaturalearth)\nlibrary(ggradar)\nlibrary(lubridate)\nlibrary(geobr)"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#grãos-de-café",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#grãos-de-café",
    "title": "5. Visualização de dados",
    "section": "Grãos de café",
    "text": "Grãos de café\nOs dados contidos na aba graos do arquivo Atividade caracteres qualitativos e quantitativos serão utilizados. Este arquivo contém dados do comprimento e largura de grãos e folhas de café, amostrados na primeira aula de Bioestatística da turma 2022/01. Para carregar estes dados, utilizamos o seguinte comando.\n\nurl <- \"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=2073179916\"\ndf <- \n  import(url, dec = \",\") |> \n  as_factor(1:3)\nhead(df)\n\n    grupo individuo      cor comprimento largura\n1 Grupo 1         1 vermelho       13.49   16.61\n2 Grupo 1         2 vermelho       11.08   14.23\n3 Grupo 1         3 vermelho       13.35   15.93\n4 Grupo 1         4 vermelho        9.87   14.10\n5 Grupo 1         5    verde       11.61   16.11\n6 Grupo 1         6    verde        9.86   13.87"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação-meteorológica",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação-meteorológica",
    "title": "5. Visualização de dados",
    "section": "Dados da estação meteorológica",
    "text": "Dados da estação meteorológica\n\nurl2 <- \"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=764890920\"\ndf_estacao <-  \n  import(url2, setclass = \"tbl\", dec = \",\") |> \n  as_character(1:4) |> \n  mutate(dia = dmy(dia))\nhead(df_estacao)\n\n# A tibble: 6 × 14\n  dia        d     m     hora   prec  tmax  tmed  tmin urmax urmed urmin dirvent\n  <date>     <chr> <chr> <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 2022-01-01 1     1     00:00     0  21.2  20.6  20.2   100  99.5  99.0     0  \n2 2022-01-01 1     1     01:00     0  20.5  19.8  19.4   100  99.9  99.6     0  \n3 2022-01-01 1     1     02:00     0  19.7  19.4  19     100 100    99.9     0  \n4 2022-01-01 1     1     03:00     0  20.0  19.2  18.7   100 100   100       0  \n5 2022-01-01 1     1     04:00     0  20.5  20.2  19.8   100 100   100       0  \n6 2022-01-01 1     1     05:00     0  20.7  20.2  19.9   100 100   100      79.8\n# … with 2 more variables: velvent <dbl>, rajada <dbl>"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#o-pacote-ggplot2",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#o-pacote-ggplot2",
    "title": "5. Visualização de dados",
    "section": "O pacote ggplot2",
    "text": "O pacote ggplot2\nO ggplot2 é um pacote R para produção de gráficos que diferentemente da maioria dos outros pacotes, apresenta uma profunda gramática baseada no livro The grammar of graphics (Wilkinson 2005)1. Os gráficos originados em ggplot2 são baseados em camadas, e cada gráfico tem três componentes chave: data, os dados de onde o gráfico será criado; aes() (aesthetic mappings), que controla o mapeamento estético e as propriedades visuais do gráfico; e ao menos uma camada que irá descrever como cada observação será renderizada. Camadas são usualmente criadas utilizando uma função geom_()."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#meu-primeiro-gráfico-em-ggplot2",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#meu-primeiro-gráfico-em-ggplot2",
    "title": "5. Visualização de dados",
    "section": "Meu primeiro gráfico em ggplot2",
    "text": "Meu primeiro gráfico em ggplot2\nA seguir, vamos discutir os aspcetos básicos para a construção de gráficos utilizando o pacote ggplot2. A função arrange_ggplot() do pacote metan foi utilizada aqui para organizar os gráficos em forma de painéis."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#as-camadas-de-um-gráfico-ggplot2",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#as-camadas-de-um-gráfico-ggplot2",
    "title": "5. Visualização de dados",
    "section": "As camadas de um gráfico ggplot2",
    "text": "As camadas de um gráfico ggplot2\nNo ggplot2, os gráficos são construídos camada por camada (ou, layers, em inglês). Neste exemplo, vamos confeccionar um gráfico mostrando a distribuição do comprimento da folha (eixo x) e largura da folha (eixo y).\n\nggplot(df, aes(comprimento, largura)) +\n  geom_point()\n\n\n\n\nGráfico de dispersão (x e y) padrão.\n\n\n\np1 <- \n  ggplot(df, aes(x = comprimento, y = largura)) +\n  geom_point()\np1\n\n\n\n\nGráfico de dispersão (x e y) padrão.\n\n\n\n\nEste comando criou um gráfico e armazenou no objeto p1, que será plotado posteriormente. Observe que o primeiro argumento da função é o data frame onde nossos dados foram armazenados. A função aes() descreve como as variáveis são mapeadas (neste caso comprimento no eixo x e largura no eixo y). A função geom_point() definiu que a forma geométrica a ser utilizada é baseada em pontos, gerando, assim, um gráfico de dispersão. Isto é tudo que precisa ser feito para a confecção de um gráfico simples."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#aesthetics-estética",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#aesthetics-estética",
    "title": "5. Visualização de dados",
    "section": "Aesthetics (estética)",
    "text": "Aesthetics (estética)\n\n“O maior valor de uma imagem é quando ela nos obriga a perceber o que nunca esperamos ver.” — John Tukey\n\nAlterar a estética dos gráficos ggplot2 é uma tarefa relativamente simples. No gráfico anterior, os valores do comprimento e largura foram plotados sem nenhum tipo de mapeamento estético. Digamos que marcadores com diferentes cores para cada nível do fator cor poderia nos ajudar a compreender melhor o padrão presente em nossos dados. Vamos confeccionar este gráfico.\n\np2 <- \n  ggplot(df, aes(x = comprimento,\n                 y = largura,\n                 colour = cor)) +\n  geom_point()\np2\n\n\n\n\n\n\n\n\nAo incluirmos colour = cor dentro da função aes, dizemos ao ggplot que os pontos devem ser mapeados esteticamente (neste caso utilizando cores) para cada nível do fator cor presente em nossos dados. Digamos que em vez de utilizar diferentes cores, a cor do grão do café deveria ser representada por diferentes tipos de marcadores (quadrados, triângulo, etc.) Neste caso, o argumento colour = cor é substituído por shape = cor.\n\np3 <- \n  ggplot(df, aes(x = comprimento, y = largura, shape = cor, color = cor)) +\n  geom_point()\n\n# organizar os gráficos\narrange_ggplot(p1, p2, p3,\n               ncol = 3,\n               tag_levels = list(c(\"p1\", \"p2\", \"p3\")))\n\n\n\n\nGráfico de dispersão padrão (p1) e com pontos mapeados por cores (p2) e marcadores (p3) para cada nível do fator ‘cor’."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#salvar-gráficos",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#salvar-gráficos",
    "title": "5. Visualização de dados",
    "section": "Salvar gráficos",
    "text": "Salvar gráficos\nA função ggsave() é uma função conveniente para salvar um gráfico. O padrão é salvar a última plotagem exibida, usando o tamanho do dispositivo gráfico atual. Também é possível informar a altura (height) e largura (width). Ele também adivinha o tipo de dispositivo gráfico da extensão. No seguinte exemplo, o gráfico acima é salvo no diretório de trabalho atual com o nome pontos.png, com 5 polegadas de altura e 10 de largura.\n\nggsave(\"pontos.png\",\n       height = 5,\n       width = 10)"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#facet-facetas",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#facet-facetas",
    "title": "5. Visualização de dados",
    "section": "Facet (facetas)",
    "text": "Facet (facetas)\nMapeando os diferentes níveis de cor para diferentes cores, incluímos em um único gráfico os dados de todos osgrupos. Mas, e se nosso objetivo fosse realizar um gráfico para cada grupo? O ggplot2 tem uma poderosa ferramenta para isto: as funções facet_. Ao utilizar estas funções, o conjunto de dados é subdividido e um gráfico é construído para cada um destes subconjuntos. Vamos ver como elas podem nos ajudar em nosso problema.\n\nfac1 <- \n  ggplot(df, aes(x = comprimento,\n                 y = largura,\n                 color = cor)) +\n  geom_point() +\n  facet_wrap(~ grupo)\nfac1\n\n\n\n\nUm painel para cada nível da variável grupo.\n\n\n\n\nNeste exemplo, um gráfico completamente diferente do anterior é gerado com apenas uma simples adição: incluímos uma nova função, facet_wrap(~ grupo). Neste caso, informamos que um gráfico deveria ser realizado para cada grupo."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#theme-temas",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#theme-temas",
    "title": "5. Visualização de dados",
    "section": "Theme (temas)",
    "text": "Theme (temas)\nCada gráfico criado com a função ggplot() tem um tema padrão. Tema, aqui, é toda propriedade relacionada ao aspecto visual do gráfico, que não foi definida na função aes() e que pode ser modificada utilizando a função theme() (veja ?theme). O ggplot2 já conta com alguns temas personalizados para facilitar nosso trabalho. Considerando o exemplo anterior, vamos utilizar a função theme_bw() (preto e branco) e a função theme() para modificar as propriedades visuais do gráfico.\n\nfac2 <- \n  ggplot(df, aes(x = comprimento, y = largura, color = cor)) +\n  geom_point() +\n  facet_wrap(~ grupo) +\n  theme_light() +\n  theme(panel.grid.minor = element_blank(), # remove as linhas do corpo do gráfico\n        # sem bordas entre os painéis\n        panel.spacing = unit(0, \"cm\"),\n        # legenda abaixo do gráfico\n        legend.position = \"bottom\",\n        # modifica o texto dos eixos\n        axis.text = element_text(size = 12, colour = \"black\"),\n        # cor dos marcadores\n        axis.ticks = element_line(colour = \"black\"),\n        # tamanho dos marcadores\n        axis.ticks.length = unit(.2, \"cm\"), \n        #cor da borda\n        panel.border = element_rect(colour = \"black\", fill = NA, size = 0.5))+\n  # título dos eixos\n  labs(x = \"Comprimento do grão (mm)\", # título do eixo x\n       y = \"Largura do grão (mm)\", # título do eixo y\n       color = \"\") # título da legenda\n\narrange_ggplot(fac1, fac2,\n               ncol = 1,\n               tag_levels = list(c(\"f1\", \"f2\")))\n\n\n\n\nGráfico de dispersão considerando a confecção de um gráfico para cada nível de um fator(f1) e modificações na propriedades do tema de um gráfico ggplot2 (f2)\n\n\n\n\nOs argumentos inseridos dentro das função theme() modificaram a aparência do nosso gráfico. Inúmeros outros argumentos são disponíveis, fazendo com que os gráficos originados sejam completamente personalizáveis. Digamos que precisamos confeccionar diversos gráficos e gostaríamos de manter o mesmo tema do gráfico acima. Seria exaustivo e desinteressante informar cada vez estes argumentos para cada gráfico, não? Felizmente, outra poderosa ferramenta proporcionada pelo ggplot2 é a possibilidade de confeccionarmos nossos próprios temas. Para isto, vamos executar o seguinte comando para criar um tema personalizado (my_theme()). Este tema pode então ser aplicado como uma camada adicional a cada gráfico que confecionarmos. Para evitar a necessidade da inclusão deste tema em cada gráfico gerado, iremos definir este tema como padrão utilizando a função theme_set().\n\nmy_theme <- function () {\n  theme_light() %+replace% # permite que os valores informados possam ser sobescritos\n    theme(axis.ticks.length = unit(.2, \"cm\"),\n          axis.text = element_text(size = 12, colour = \"black\"),\n          axis.title = element_text(size = 12, colour = \"black\"),\n          axis.ticks = element_line(colour = \"black\"),\n          panel.border = element_rect(colour = \"black\", fill = NA, size = 0.5),\n          panel.grid.minor =  element_blank())\n}\ntheme_set(my_theme())"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#geoms-geometria",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#geoms-geometria",
    "title": "5. Visualização de dados",
    "section": "Geoms (geometria)",
    "text": "Geoms (geometria)\nAs funções geom_ definem qual forma geométrica será utilizada para a visualização dos dados no gráfico. Até agora, utilizamos a função geom_point()para construir gráficos de dispersão. Basicamente, qualquer outro tipo de gráfico pode ser criado dependendo da função geom_ utilizada. Dentre as diversas disponíveis no pacote ggplot2 as funções geom_ mais utilizadas são:\n\ngeom_abline(): para retas definidas por um intercepto e uma inclinação;\ngeom_hline(): para retas horizontais definidas por um intercept y;\ngeom_vline(): para retas verticais definidas por um intercept x;\ngeom_boxplot(): para boxplots;\ngeom_histogram(): para histogramas de frequência;\ngeom_smooth(): ajusta uma função para o conjunto de dados e mostra uma banda de confiança;\ngeom_density(): para densidades;\ngeom_area(): para áreas;\ngeom_bar(): para barras;\ngeom_errorbar() para barras de erro;\n\nDeste ponto em diante, vamos confeccionar alguns exemplos utilizando algumas destas funções (ou combinações destas funções) incluindo argumentos de mapeamento de estética e temas vistos até agora.\n\nLinhas horizontais, verticais e diagonais\nTrês importantes geometrias são apresentadas a seguir:\n\ngeom_hline() adiciona uma linha horizontal definida por um intercepto em y\ngeom_vline() adiciona uma linha vertical definida por um intercepto em x.\ngeom_abline() adiciona uma linha diagonal definida por um intercepto e uma inclinação.\n\n\ng1 <- \n  ggplot(df, aes(comprimento, largura)) +\n  geom_point()\n\n\n# adiciona linhas horizontais e verticais\ng2 <- \n  g1 +\n  geom_hline(yintercept = mean(df$largura), color = \"blue\") +\n  geom_vline(xintercept = mean(df$comprimento), color = \"red\")\n\narrange_ggplot(g1, g2,\n               ncol = 1,\n               tag_levels = list(c(\"g1\", \"g2\")))\n\n\n\n\n\n\nGráficos do tipo boxplot\n\nbox1 <- \n  ggplot(df, aes(grupo, comprimento)) +\n  geom_boxplot()\n\nbox2 <- \n  ggplot(df, aes(grupo, comprimento)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.1, color = \"salmon\")\n\nbox3 <- \n  ggplot(df, aes(grupo, comprimento, fill = cor)) +\n  geom_boxplot(width = 0.3) + \n  labs(x = \"Grupo\",\n       y = \"Comprimento do grão (mm)\") +\n  theme(legend.position = \"bottom\") +\n  scale_fill_manual(values = c(\"green\", \"red\"))\n\narrange_ggplot((box1 + box2) / box3,\n               tag_levels = list(c(\"b1\", \"b2\", \"b3\")))\n\n\n\n\nGráfico do tipo boxplot combinando mapeamentos estéticos.\n\n\n\n\nCinco estatísticas são mostradas neste boxplot. A mediana (linha horizontal), as caixas inferior e superior (primeiro e terceiro quartil (percentis 25 e 75, respectivamente)). A linha vertical superior se estende da caixa até o maior valor, não maior que $1,5 $ (onde IQR é a amplitude interquartílica). A linha vertical inferior se estende da caixa até o menor valor, de no máximo, $1,5 $. Dados além das linhas horizontais podem ser considerados outliers.\n\n\nGráficos do tipo histograma\nNeste exemplo, utilizaremos os dados de temperatura mínima da estação meteorológica, disponível no data frame df_estacao. O primeiro histograma (p1) mostra os dados gerais desde 01/01/2022. No segundo, um histograma é gerado para cada mês.\n\nh1 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_histogram()\n\nh2 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_histogram(color = \"black\",\n                 fill = \"skyblue\") +\n  facet_wrap(~m) +\n  labs(x = \"Temperatura mínima\",\n       y = \"Horas\")\n\narrange_ggplot(h1, h2,\n               widths = c(1, 1.4),\n               tag_levels = list(c(\"h1\", \"h2\")))\n\n\n\n\nGráfico do tipo histograma\n\n\n\n\nNo histograma (h2), a linha vermelha representa a estimativa da função de probabilidade normal. Para isto, a escala do eixo y foi mudada de contagem para densidade.\n\n\nGráficos de Densidade\nOs gráficos de densidade, têm a mesma interpretação que histogramas, no então são esteticamente mais atraente. Os primeiros dois exemplos nada mais são que a versão densidade dos histogramas apresentados anteriormente.\nNo terceiro exemplo (d3), eu mostro como é possível construir um gráfico de densidade ridges. Gráficos ridges são gráficos de linha parcialmente sobrepostos que criam a impressão de uma cordilheira. Eles podem ser bastante úteis para visualizar mudanças nas distribuições ao longo do tempo ou espaço2.\n\nd1 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_density()\n\nd2 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_density(color = \"black\",\n               fill = \"skyblue\") +\n  facet_wrap(~m) +\n  labs(x = \"Temperatura média (ºC)\",\n       y = \"Horas\")\n\nd3 <- \n  ggplot(df_estacao, aes(x = tmed, y = m, fill = stat(x))) +\n  geom_density_ridges_gradient() +\n  scale_fill_viridis_c() +\n  labs(x = \"Temperatura média (ºC)\",\n       y = \"Meses do ano\",\n       fill = \"Temperatura\\nmédia (ºC)\")\n\n# agrupa os gráficos\narrange_ggplot((d1 + d2) / d3,\n               tag_levels = list(c(\"d1\", \"d2\", \"d3\")))\n\n\n\n\nGráfico do tipo densidade\n\n\n\n\n\n\nGráficos de linhas\nO seguinte exemplo mostra a temperatura mínima, média e máxima ao longo dos dias desde 01/01/2022.\nPrimeiro, é preciso obter as temperaturas mínimas, máximas e médias de cada dia. Fazemos isso com a função summarise().\n\nclima_max_min <-\n  df_estacao %>%\n  group_by(dia) %>% \n  summarise(max = max(tmax),\n            min = min(tmin),\n            mean = mean(tmed),\n            precip = sum(prec)) %>% \n  pivot_longer(-dia)\nclima_max_min\n\n# A tibble: 628 × 3\n   dia        name   value\n   <date>     <chr>  <dbl>\n 1 2022-01-01 max     28.7\n 2 2022-01-01 min     18  \n 3 2022-01-01 mean    24.0\n 4 2022-01-01 precip   0  \n 5 2022-01-02 max     31.8\n 6 2022-01-02 min     23.4\n 7 2022-01-02 mean    27.1\n 8 2022-01-02 precip   0  \n 9 2022-01-03 max     32.4\n10 2022-01-03 min     24.3\n# … with 618 more rows\n\n\n\n# realiza um subset para remover a precipitação\ndf_temp <-  \n  clima_max_min |>  \n  subset(name != \"precip\")\n\n# faz o gráfico de linhas\nggplot(df_temp, aes(dia, value, color = name)) +\n  geom_point() + \n  geom_line() + \n  scale_color_manual(values = c(\"red\", \"green\", \"blue\"),\n                     labels = c(\"Temperatura máxima (ºC)\",\n                                \"Temperatura média (ºC)\",\n                                \"Temperatura mínima (ºC)\"),\n                     guide = \"legend\") + \n  scale_x_date(date_breaks = \"3 week\", # marcação a cada duas semanas\n               date_labels = \"%d/%m/%y\") + # formato dd/mm/aa\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + \n  labs(title = \"Temperaturas máximas, médias e mínimas em 2022\",\n       subtitle = \"Estação - Fazenda Ressacada\",\n       caption = \"Elaboração: Prof. Olivoto\",\n       x = \"Dia do ano\",\n       y = \"Temperatura (ºC)\",\n       color = NULL) # remove o título da legenda\n\n\n\n\n\n\nGráficos do tipo barra\nNo seguinte exemplo, os dados do comprimento do grão de café disponíveis em df são utilizados.\n\nbar1 <- \n  ggplot(df, aes(x = grupo, y = comprimento)) +\n  geom_bar(stat = \"summary\", fun = \"mean\")\n\nbar2 <- \n  ggplot(df, aes(x = grupo, y = comprimento, fill = cor)) +\n  stat_summary(fun = mean,\n               geom = \"bar\",\n               col = \"black\",\n               width = 0.8,\n               position = position_dodge(0.8)) + \n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.2,\n               position = position_dodge(0.8))\n\n\narrange_ggplot(bar1, bar2,\n               widths = c(0.6, 1.2),\n               tag_levels = list(c(\"bar1\", \"bar2\")))\n\n\n\n\nGráfico do tipo barras, com mapeamento estético e barras de erro.\n\n\n\n\nA afirmação de que um gráfico ggplot2 é feito em camadas fica mais evidente aqui. No gráfico bar1, as barras representam as médias geral do comprimento para cada grupo. No segundo gráfico, ao usar fill = cor informamos que as barras devem ser coloridas para cada nível do fator cor. A função stat_summary(), é vista pela primeira vez aqui, foi utilizada no segundo gráfico para substituir a função geom_bar(). Com isto, foi possível incluir as médias (fun = mean e geom = \"bar), bem como as barras de erro (fun.data = mean_se e geom = \"errorbar\").\nUtilizando a função plot_factbars() do pacote metan, um gráfico semelhante pode ser criado com as funções plot_bars() e plot_factbars()\n\nmetan1 <- \n  plot_bars(df,\n            x = grupo,\n            y = comprimento)\nmetan2 <- \n  plot_factbars(df, # dados\n                grupo, cor, # dois fatores\n                resp = comprimento) # eixo y\n\narrange_ggplot(metan1, metan2,\n               widths = c(0.6, 1.2),\n               tag_levels = list(c(\"metan1\", \"metan2\")))"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação",
    "title": "5. Visualização de dados",
    "section": "Dados da estação",
    "text": "Dados da estação\n\nGráfico da precipitação e temperatura\n\ndf_prec <- \n  clima_max_min |> \n  pivot_wider(names_from = \"name\",\n              values_from = \"value\")\n\nggplot() +\n  geom_bar(df_prec,\n           mapping = aes(x = dia, y = precip * 30 / 100),\n           stat = \"identity\",\n           fill = \"skyblue\") +\n  geom_line(df_prec,\n            mapping = aes(x = dia, y = max, colour = \"red\"),\n            size = 1) +\n  geom_line(df_prec, \n            mapping = aes(x = dia, y = min, colour = \"blue\"),\n            size = 1) +\n  scale_x_date(date_breaks = \"15 days\", date_labels =  \"%d/%m\",\n               expand = expansion(c(0, 0)))+\n  scale_y_continuous(name = expression(\"Temperatura (\"~degree~\"C)\"),\n                     sec.axis = sec_axis(~ . * 100 / 30 , name = \"Precipitação (mm)\")) +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  scale_color_identity(breaks = c(\"red\", \"blue\"),\n                       labels = c(\"Temperatura máxima (ºC)\",\n                                  \"Temperatura mínima (ºC)\"),\n                       guide = \"legend\") +\n  labs(x = \"Dia do ano\")\n\n\n\n\nTemperaturas máximas e mínimas e precipitação observada ao longo dos dias.\n\n\n\n\n\n\nVelocidade média do vento\n\n\nvento_long <-\n  df_estacao %>%\n  select(m, hora, velvent) %>% \n  pivot_longer(-c(m, hora))\nhead(vento_long)\n## # A tibble: 6 × 4\n##   m     hora  name    value\n##   <chr> <chr> <chr>   <dbl>\n## 1 1     00:00 velvent  0   \n## 2 1     01:00 velvent  0   \n## 3 1     02:00 velvent  0   \n## 4 1     03:00 velvent  0   \n## 5 1     04:00 velvent  0   \n## 6 1     05:00 velvent  0.33\n\n\n\n# confeccionar gráfico\nggplot(vento_long, aes(m, value, color = name, group = name )) +\n  stat_summary(geom = \"point\", \n               fun = mean) +\n  stat_summary(geom = \"line\") + \n  stat_summary(geom = \"errorbar\", width = 0.1) +\n  scale_color_manual(values = c(\"red\", \"blue\"),\n                     labels = c(\"Rajada (m/s)\",\n                                \"Velocidade do vento (m/s)\"),\n                     guide = \"legend\") +\n  theme(panel.grid.minor = element_blank(),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 12)) + \n  labs(title = \"Velocidade média mensal do vento em 2022\",\n       subtitle = \"Estação UFSC - Ressacada\",\n       caption = \"Elaboração: Prof. Tiago Olivoto\",\n       x = \"Mês do ano\",\n       y = \"Velocidade (m/s)\")\n\n\n\n\n\n\nDireção do vento\n\n# cria uma tabela de frequência transformando a variável quantitativa direção do vento\n# em uma qualitativa \nfreq <- \n  cut(df_estacao$dirvent, breaks = seq(0, 360, by = 45)) |> \n  table() |> \n  as.data.frame() %>% \n  set_names(\"Direção\", \"Dias\") %>% \n  mutate(Direção = paste0(seq(0, 315, by = 45)),\n         Percent = Dias / 3428 * 100) %>% \n  remove_cols(Dias)\nfreq\n##   Direção   Percent\n## 1       0 13.273046\n## 2      45  8.401400\n## 3      90 10.239207\n## 4     135 17.648775\n## 5     180 13.593932\n## 6     225  6.446908\n## 7     270  5.513419\n## 8     315 24.883314\n\n\n# criar um radar plot para mostrar a direção predominante\n# do vento\nggradar(freq %>% transpose_df(),\n        values.radar = c(\"0%\",  \"25.8%\"),\n        grid.max = max(freq$Percent))"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#mapas",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#mapas",
    "title": "5. Visualização de dados",
    "section": "Mapas",
    "text": "Mapas\n\nMapa da américa do sul e Brasil\nO pacote rnaturalearth é uma excelente ferramenta para manter e facilitar a interação com os dados do mapa Natural Earth. Para produção de mapas com o ggplot2, os seguintes pacotes são necessários.\n\n# américa do sul\nlibrary(rnaturalearth)\nlibrary(tidyverse)\nsam <-\n  ne_countries(continent = \"south america\",\n               returnclass = \"sf\",\n               scale = 50)\n\np1 <- \n  ggplot() +\n  geom_sf(data = sam, fill = \"white\") +\n  theme_light() +\n  xlim(c(-90, -35))\n\n# plotar o brasil e destacar santa catarina\nbrazil <- \n  ne_states(country = \"brazil\", returnclass = \"sf\") |> \n  mutate(scat = ifelse(postal == \"SC\", \"SC\", \"Outros\"))\n\np2 <- \n  p1 + \n  geom_sf(data = brazil, aes(fill = scat))\np2\n\n\n\n\n\n\nMapa do Brasil e SC, com municípios\n\nsc <- \n  read_municipality(code_muni = \"SC\",\n                    simplified = FALSE,\n                    showProgress = FALSE) |> \n  mutate(floripa = ifelse(name_muni == \"Florianópolis\",\n                          \"Florianópolis\",\n                          \"Outro\"))\n\nUsing year 2010\n\np3 <-\n  p1 + \n  geom_sf(data = brazil) +\n  geom_sf(data = sc, aes(fill = floripa)) +\n  xlim(c(-55, -47)) +\n  ylim(c(-30, -25)) +\n  labs(title = \"Mapa do brasil destacando o estado de SC\",\n       caption = \"Produzido com os pkgs geobr e rnaturalearth\",\n       fill = \"\") +\n  theme(legend.position = \"bottom\")\n\nScale for 'x' is already present. Adding another scale for 'x', which will\nreplace the existing scale.\n\np3"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#motivação",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#motivação",
    "title": "5. Visualização de dados",
    "section": "Motivação",
    "text": "Motivação\nA densidade de fluxo de fótons fotossintéticos (PPFD) em níveis subótimos ou superótimos pode modificar o acúmulo de biomassa, composição bromatológica e aparência das culturas. Para isso, Olivoto et al. (2018)3 investigaram o efeito de níveis de radiação no crescimento da chicória (Cichorium endivia L. var. latifolia). Os dados disponíveis na aba FAT_CI (https://docs.google.com/spreadsheets/d/1vpVGdIkggRxmdnwrkllHbVA0TIHN85UK/edit#gid=2056145155) são relativos a duas variáveis, à saber, matéria seca total (MST) e área foliar (AF) de plantas de chicória cultivadas em diferentes níveis de sombreamento (50, 70, e 100), e avaliados aos 21, 28 e 35 dias após o plantio.\n\nConsiderando o link disponível, importe os dados para o software R, salvando-os em um objeto chamado df (preste atenção com o separador decimal!).\n\n\nlibrary(rio)\nlibrary(tidyverse)\nlibrary(metan)\nurl <- \"https://docs.google.com/spreadsheets/d/1vpVGdIkggRxmdnwrkllHbVA0TIHN85UK/edit#gid=2056145155\"\ndf <-  import(url, dec = \",\")\n\nPara lapidar os conhecimentos na construção de gráficos, utilize o pacote ggplot24 e metan5 para solução dos seguintes problemas."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#problema-1---associação-entre-variáveis",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#problema-1---associação-entre-variáveis",
    "title": "5. Visualização de dados",
    "section": "Problema 1 - Associação entre variáveis",
    "text": "Problema 1 - Associação entre variáveis\n\nConsiderando os dados, construa um gráfico de dispersão com a variável AF no eixo x e a variável MST no eixo y, salve o gráfico em um objeto chamado p1.\n\n\np1 <- \n  ggplot(df, aes(AF, MST)) +\n  geom_point()\n\n\nPara melhor compreender a distribuição dos pontos, realize o mapeamento da variável DAP com diferentes cores.\nAltere a legenda do eixo x e y para ‘Área foliar (cm2)’ e ‘Matéria seca (g)’, respectivamente.\nAplique um tema de sua preferência ao tema utilizando qualquer tema definido por theme_*()6.\nArmazene o gráfico em um objeto chamado p2.\n\n\np2 <- \n  ggplot(df, aes(AF, MST, color = DAP)) +\n  geom_point() +\n  labs(x = \"Área foliar (cm2)\",\n       y = \"Matéria seca (g)\")\n\n\nOrganize os gráficos p1 e p2 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p1, p2)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à associação entre AF e MST.\n\n\nA área foliar e a matéria seca estão positivamente relacionadas, ou seja, há a tendêncida de que o aumento na área foliar venha acompanhado do aumento na matéria seca. No segundo gráfico, é possível identificar que os maiores valores de matéria seca e área foliar foram observados nos 35DAP, e o menores, aos 21DAP.\n\n\nSalve os gráficos em um arquivo chamado dispersão.png, com 3 polegadas de altura e 8 de largura\n\n\nggsave(\"dispersão.png\", width = 8, height = 3)"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#problema-2---variação-dos-dados",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#problema-2---variação-dos-dados",
    "title": "5. Visualização de dados",
    "section": "Problema 2 - Variação dos dados",
    "text": "Problema 2 - Variação dos dados\n\nConfeccione um gráfico do tipo boxplot contendo a variável DAP no eixo x e MST no eixo y. Salve o gráfico em um objeto chamado p3.\n\n\np3 <- \n  ggplot(df, aes(DAP, MST)) +\n  geom_boxplot()\n\n\nPara fazer inferências sobre o fator sombreamento, construa um boxplot semelhante, mas agora mapeando a variável SOM com diferentes cores de preenchimento do boxplot. * Inclua uma linha horizontal que represente a média geral da matéria seca.\nSalve o gráfico em um objeto chamado p4.\n\n\np4 <- \n  ggplot(df, aes(DAP, MST, fill = SOM)) +\n  geom_boxplot() +\n  geom_hline(yintercept = mean(df$MST))\n\n\nOrganize os gráficos p3 e p4 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p3, p4)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à variação da matéria seca total entre os diferentes níveis de radiação dentro de cada dia após o plantio.\n\n\nAos 21DAP foi observada a menor variação entre os níveis de SOM. Aos 28DAP, a diferença entre os níveis de SOM foi mais evidente, onde plantas crescendo em 100R apresentaram um valor mediano de MST maior, mas também a maior variação entre as repetições (comprimento da caixa). Aos 35DAP, a diferença entre as radiações torna-se mais evidente. Também, pode-se observar que as variações entre as repetições do 100R e 50R foram menores se comparado aos 28DAP (menor comprimento da caixa).\n\n\nSalve os boxplots em um arquivo chamado boxplot.png.\n\n\nggsave(\"boxplot.png\")"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#problema-3---médias",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#problema-3---médias",
    "title": "5. Visualização de dados",
    "section": "Problema 3 - Médias",
    "text": "Problema 3 - Médias\n\nConfeccione um gráfico de barras mostrando a média da variável AF no eixo y para cada dia após o plantio (DAP) no eixo x.\nDefina os limites do eixo y de 0 até 6000.\nSalve o gráfico em um objeto chamado p5.\n\n\nDica: a função plot_bars() do pacote metan pode ser útil.\n\n\np5 <- \n  plot_bars(df,\n            x = DAP,\n            y = AF,\n            y.lim = c(0, 6000))\n\n# versão ggplot2\np5.2 <- \n  ggplot(df, aes(DAP, AF)) +\n  geom_bar(stat = \"summary\") +\n  ylim(c(0, 6000))\n\n\nAssumindo que as médias da AF precisam ser apresentadas para cada combinação de DAP e SOM, mapeie a variável SOM com diferentes cores de preenchimento no gráfico de barras.\nMude os títulos dos eixos x e y para “Dias após o plantio (DAP)” e “Área foliar (cm2)”, respectivamente.\nDefina os limites do eixo y de 0 até 6000.\nArmazene o gráfico em um objeto chamado p6.\nOrganize os gráficos p5 e p6 em um único painel\nSalve os gráficos de barra em uma imagem chamada barras.png.\n\n\nDica: a função plot_factbars() do pacote metan pode ser útil.\n\n\np6 <- \n  plot_factbars(df, DAP, SOM,\n                resp = AF,\n                y.lim = c(0, 6000),\n                xlab = \"Dias após o plantio (DAP)\",\n                ylab = \"Área foliar (cm2)\")\n\n# versão ggplot2\np6.2 <- \n  ggplot(df, aes(DAP, AF, fill = SOM)) +\n  geom_bar(stat = \"summary\",\n           fun = \"mean\",\n           width = 0.7,\n           position = position_dodge()) +\n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.2,\n               position = position_dodge( width = 0.7)) +\n  labs(x = \"Dias após o plantio (DAP)\",\n       y = \"Área foliar (cm2)\") +\n  ylim(c(0, 6000))\n\n\nOrganize os gráficos p5 e p6 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p5, p6)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à área foliar nos diferentes níveis de radiação ao longo dos dias após o plantio.\n\n\nA média da área foliar foi mais semelhante entre os níveis de radiação aos 21DAP. Considerando o erro padrão da média como uma medida de significância, pode-se afirmar que aos 21DAP as médias do 50R e 70R foram estatisticamente iguais. Aos 35DAP, a área foliar das plantas crescendo com 50% de radiação foi menor que àquelas crescendo em pleno sol (100R) e com 70% de radiação (70R).\n\n\nSalve os boxplots em um arquivo chamado barras.png.\n\n\nggsave(\"barras.png\")"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html",
    "title": "6. Amostragem",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.1\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n\n\nWarning: package 'tibble' was built under R version 4.2.1\n\n\nWarning: package 'dplyr' was built under R version 4.2.1\n\n\nWarning: package 'stringr' was built under R version 4.2.1\n\n\nWarning: package 'forcats' was built under R version 4.2.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(rio)\ndf <- import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=1590128876\")\ndf\n\n   id                                 aluno crm altura\n1   1                Aline Kliauga Ferrante  xx     NA\n2   2                     André Cuneo Sagaz  xy     NA\n3   3              Beatriz Haensel Teixeira  xx     NA\n4   4                        Bruna Waltrich  xx    156\n5   5       Carlos Eduardo Forcelini Assoni  xy     NA\n6   6              Daniel Schmechel Affeldt  xy    169\n7   7                Danielli Zangalli Kern  xx    169\n8   8                 Felipe Ricci Westphal  xy     NA\n9   9                 Gabriel Loche Lopasso  xy    188\n10 10                   Gabriel Sbardelotto  xy     NA\n11 11                 Gabriela Araujo Catto  xx    162\n12 12            Guilherme Antonio Ferreira  xy    173\n13 13         Helena dos Santos Vanderlinde  xx    180\n14 14               Isabela Martins Ghizoni  xx    166\n15 15        João Pedro dos Santos Angulski  xy     NA\n16 16          Joao Pedro Lantyer Marcelino  xy    190\n17 17                    João Vitor Germano  xy    166\n18 18           João Vitor Zeferino Madeira  xy    168\n19 19         José Eduardo Pimentel e Silva  xy    169\n20 20        Juliana Eduarda Oliveira Gomes  xx    165\n21 21        Kamilly Vitoria Siqueira Tonet  xx    164\n22 22                  Leticia Herbert Post  xx     NA\n23 23                   Lucas Lopes Ribeiro  xy    175\n24 24                    Lucas Paz Claudino  xy    178\n25 25               Lucas Sodre de Oliveira  xy    174\n26 26                Luis Bortoluzzi Sobral  xy     NA\n27 27                   Luiz Paulo da Silva  xy     NA\n28 28              Magalhães Antonio Saxico  xy     NA\n29 29          Maria Eduarda Wendt Coutinho  xx    170\n30 30         Maria Laura Faustino Monteiro  xx    164\n31 31               Mateus Zunino Espindola  xy     NA\n32 32             Matheus de Oliveira Mussi  xy     NA\n33 33 Natacha Micheline de Oliveira da Rosa  xx     NA\n34 34           Pierre Marcel Bruno Boisson  xy     NA\n35 35          Rafaela Rodrigues dos Santos  xx    158\n36 36              Renan Guilherme da Silva  xy    179\n37 37                        Tassie Turcato  xx    165\n38 38         Thalita Maria Gomes Rodrigues  xx    163\n39 39        Wanessa Pedrinha do Nascimento  xx    177\n40 40                 Wesley Castilhos Drun  xy     NA\n41 41                      Wilson Rosa Neto  xy    173\nA função sample_random() retirada do pacote metan pode ser utilizada para amostrar n linhas aleatoriamente do conjunto de dados data. Utilizando prop, uma proporção dos dados é amostrada. Este último é útil ao realizar amostragens estratificadas informando o argumento by, onde cada estrato possui diferentes tamanhos de amostra."
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#aplicação",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#aplicação",
    "title": "6. Amostragem",
    "section": "Aplicação",
    "text": "Aplicação\nVamos considerar uma variável x, distribuida normalmente com média \\(\\bar X = 10\\) e desvio padrão \\(S = 2\\), avaliada em população com N = 10.\n\nset.seed(1)\nN <- 10\ndf2 <- data.frame(id = 1:N,\n                  x = rnorm(n = N, mean = 10, sd = 2))\ndf2\n\n   id         x\n1   1  8.747092\n2   2 10.367287\n3   3  8.328743\n4   4 13.190562\n5   5 10.659016\n6   6  8.359063\n7   7 10.974858\n8   8 11.476649\n9   9 11.151563\n10 10  9.389223\n\n\nConsiderando uma amostragem com n = 3, as 120 amostras possíveis são\n\nn <- 3\namostras <- combn(N, n) |> t()\namostras |> head()\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    1    2    4\n[3,]    1    2    5\n[4,]    1    2    6\n[5,]    1    2    7\n[6,]    1    2    8\n\namostras |> tail()\n\n       [,1] [,2] [,3]\n[115,]    6    8   10\n[116,]    6    9   10\n[117,]    7    8    9\n[118,]    7    8   10\n[119,]    7    9   10\n[120,]    8    9   10"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#abordagem-paralela",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#abordagem-paralela",
    "title": "6. Amostragem",
    "section": "Abordagem paralela",
    "text": "Abordagem paralela\nQuando o número de amostras cresce bastante, a abordagem for-loop não é computacionalmente eficiente. Assim, uma abordagem utilizando sapply() é mais eficiente. Quando paraleliza-se a função, a eficiência aumenta mais ainda.\n\n# criando uma função para obter a média de um id\nget_mean <- function(df, var, amostras, id){\n  individ <- amostras[id,]\n  mean(df[[var]][individ])\n}\n\n\nN <- 30\nn <- 5\ndf2 <- data.frame(id = 1:N,\n                  x = rnorm(n = N, mean = 10, sd = 2))\namostras2 <- combn(N, n) |> t()\n\n\nsystem.time(\n  medias2 <-\n    map_dbl(1:nrow(amostras2), function(i){\n      get_mean(df2, \"x\", amostras2, id = i)\n    })\n)\n\n\nlibrary(parallel)\nclust <- makeCluster(5)\nclusterExport(clust,\n              varlist = c(\"df2\", \"amostras2\", \"get_mean\"))\nsystem.time(\n  medias3 <-\n    parLapply(clust, 1:nrow(amostras2), function(i){\n      get_mean(df2, \"x\", amostras2, id = i)\n    })\n)\nstopCluster(clust)"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#número-igual-dentro-de-cada-estrato",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#número-igual-dentro-de-cada-estrato",
    "title": "6. Amostragem",
    "section": "Número igual dentro de cada estrato",
    "text": "Número igual dentro de cada estrato\n\nsample_random(df, n = 3, by = crm)\n\n# A tibble: 6 × 4\n     id aluno                          crm   altura\n  <int> <chr>                          <chr>  <int>\n1    37 Tassie Turcato                 xx       165\n2    30 Maria Laura Faustino Monteiro  xx       164\n3    22 Leticia Herbert Post           xx        NA\n4    27 Luiz Paulo da Silva            xy        NA\n5    40 Wesley Castilhos Drun          xy        NA\n6    15 João Pedro dos Santos Angulski xy        NA"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#proporção-da-população-em-cada-estrato",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#proporção-da-população-em-cada-estrato",
    "title": "6. Amostragem",
    "section": "Proporção da população em cada estrato",
    "text": "Proporção da população em cada estrato\n\nsample_random(df,\n              prop = 0.3,\n              by = crm)\n\n# A tibble: 12 × 4\n      id aluno                           crm   altura\n   <int> <chr>                           <chr>  <int>\n 1     3 Beatriz Haensel Teixeira        xx        NA\n 2    37 Tassie Turcato                  xx       165\n 3     1 Aline Kliauga Ferrante          xx        NA\n 4    38 Thalita Maria Gomes Rodrigues   xx       163\n 5     4 Bruna Waltrich                  xx       156\n 6     5 Carlos Eduardo Forcelini Assoni xy        NA\n 7    25 Lucas Sodre de Oliveira         xy       174\n 8    24 Lucas Paz Claudino              xy       178\n 9    23 Lucas Lopes Ribeiro             xy       175\n10    32 Matheus de Oliveira Mussi       xy        NA\n11    17 João Vitor Germano              xy       166\n12    40 Wesley Castilhos Drun           xy        NA"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html",
    "href": "FIT5306/FIT5306_07_DELN.html",
    "title": "7. Análise de Variância",
    "section": "",
    "text": "Tip\n\n\n\n“Muito melhor uma resposta aproximada à pergunta certa, que muitas vezes é vaga, do que uma resposta exata à pergunta errada, que sempre pode ser feita com precisão.” — John Tukey"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#dic",
    "href": "FIT5306/FIT5306_07_DELN.html#dic",
    "title": "7. Análise de Variância",
    "section": "DIC",
    "text": "DIC\nPara realizar a casualização em um experimento de delineamento inteiramente ao acaso, pode-se utilizar a função sketch do pacote agroR. Neste exemplo, simulo a casualização de quatro tratamentos (“C1”, “C2”, “C3” e “C4”) em um ensaio conduzido em delineamento inteiramente casualizado (DIC) com quatro repetições (r).\n\nlibrary(AgroR)\n\nWarning: package 'AgroR' was built under R version 4.2.1\n\n\n\nAttaching package: 'AgroR'\n\n\nThe following object is masked from 'package:dplyr':\n\n    desc\n\nset.seed(1)\ntrats <- c(\"C1\", \"C2\", \"C3\", \"C4\")\nsketch(trats, r = 4)"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#dbc",
    "href": "FIT5306/FIT5306_07_DELN.html#dbc",
    "title": "7. Análise de Variância",
    "section": "DBC",
    "text": "DBC\nPara casualização em DBC, a mesma função sketch é usada. No entanto, utiliza-se o argumento design para indicar que o delineamento é um DBC\n\nset.seed(1)\ntrats <- c(\"C1\", \"C2\", \"C3\", \"C4\")\n# casualização em DBC\nsketch(trats, r = 4, design = \"DBC\")\n\n\n\n# inverte a posição dos blocos\nsketch(trats, r = 4, design = \"DBC\", pos = \"column\")"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#exemplo-de-aplicação",
    "href": "FIT5306/FIT5306_07_DELN.html#exemplo-de-aplicação",
    "title": "7. Análise de Variância",
    "section": "Exemplo de aplicação",
    "text": "Exemplo de aplicação\nNa figura abaixo é mostrado como o DBC pode ser utilizado para considerar fontes de variação conhecida na área experimental. Neste caso, um gradiente de fósforo conhecido é notado no solo, onde maiores valores são observados na parte inferior e menores na parte inferior. Assim, os blocos podem ser alocados de modo que cada tratamento seja casualizado dentro de grupos de unidades experimentais homogêneas (blocos).\n\n\n\nExemplo de casualização em DBC"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#dados",
    "href": "FIT5306/FIT5306_07_DELN.html#dados",
    "title": "7. Análise de Variância",
    "section": "Dados",
    "text": "Dados\nOs dados utilizados neste exemplo estão na planilha QUALI do conjunto de dados data_R.xlsx. Os próximos códigos carregam o conjunto de dados e criam um gráfico do tipo boxplot para explorar o padrão dos dados.\n\nlibrary(tidyverse)\nlibrary(metan)\nlibrary(rio)\nlibrary(AgroR)\n\nurl <- \"http://bit.ly/df_biostat\"\ndf <- import(url, sheet = \"QUALI\")\nstr(df)\n\n'data.frame':   20 obs. of  3 variables:\n $ BLOCO  : num  1 1 1 1 1 2 2 2 2 2 ...\n $ HIBRIDO: chr  \"NP_1\" \"NP_2\" \"NP_3\" \"NP_4\" ...\n $ RG     : num  8.82 9.12 7.74 6.48 4.06 ...\n\np1 <-\n  ggplot(df, aes(HIBRIDO, RG))+\n  geom_hline(yintercept = mean(df$RG), linetype = \"dashed\")+\n  geom_boxplot()+\n  stat_summary(geom = \"point\", fun = mean, shape = 23) +\n  stat_summary(aes(label = round(after_stat(y), 2),\n                   x = HIBRIDO), \n               fun=mean,\n               geom=\"text\",\n               hjust=-0.3)\n\np2 <- \n  ggplot(df, aes(factor(BLOCO), RG))+\n  geom_hline(yintercept = mean(df$RG), linetype = \"dashed\")+\n  geom_boxplot()+\n  stat_summary(geom = \"point\", fun = mean, shape = 23) +\n  stat_summary(aes(label = round(after_stat(y), 2),\n                   x = BLOCO), \n               fun=mean,\n               geom=\"text\",\n               hjust=-0.3)\n\np1 + p2\n\n\n\n\nAnalizando o boxplot acima é razoável dizer que as médias dos tratamentos são diferentes, principalmente comparando o NP_1 com NP_5. Esta suspeita de diferença, no entanto, deve ser suportada com a realização da análise de variância."
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#anova-em-dic",
    "href": "FIT5306/FIT5306_07_DELN.html#anova-em-dic",
    "title": "7. Análise de Variância",
    "section": "Anova em DIC",
    "text": "Anova em DIC\nNo pacote AgroR, quando os fatores são qualitativos, a análise complementar aplicada é a comparção de médias. A função DIC() do pacote retorna a tabela da ANOVA, a análise de pressupostos (normalidade e homogeneidade) e o teste de comparação de médias.\n\nmod_dic <- with(df, DIC(HIBRIDO, RG))\n\n\n\n\n\n-----------------------------------------------------------------\nNormality of errors\n-----------------------------------------------------------------\n                         Method Statistic     p.value\n Shapiro-Wilk normality test(W)  0.827455 0.002285375\n\n\n-----------------------------------------------------------------\nHomogeneity of Variances\n-----------------------------------------------------------------\n                              Method Statistic   p.value\n Bartlett test(Bartlett's K-squared) 0.9557917 0.9164237\n\n\n-----------------------------------------------------------------\nIndependence from errors\n-----------------------------------------------------------------\n                 Method Statistic      p.value\n Durbin-Watson test(DW) 0.3899192 3.318679e-05\n\n\n-----------------------------------------------------------------\nAdditional Information\n-----------------------------------------------------------------\n\nCV (%) =  23.06\nMStrat/MST =  0.69\nMean =  8.2479\nMedian =  8.0515\nPossible outliers =  No discrepant point\n\n-----------------------------------------------------------------\nAnalysis of Variance\n-----------------------------------------------------------------\n          Df   Sum Sq  Mean.Sq  F value     Pr(F)\ntrat       4 32.62995 8.157488 2.254327 0.1117755\nResiduals 15 54.27888 3.618592                   \n\n\n\n\n-----------------------------------------------------------------\nMultiple Comparison Test\n-----------------------------------------------------------------\n[1] \"H0 is not rejected\"\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAs funções do pacote AgroR utilizam os dados “anexados” ao ambiente de trabalho, ou seja, um argumento data = . não existe para suas funções. Note que no exemplo acima foi utilizado a função with(qualitativo, DIC(...)). Isto permite acessar variáveis presentes no data frame. Uma outra maneira de realizar esta mesma análise é utilizando a função attach(df), qual carregará o data frame no ambiente R, assim é possível utilizar a função DIC(...). Após realizada a análise, é recomendado executar o comando detach(df) para “limpar” os dados do ambiente de trabalho.\n\n\nA interpretação da significância, ou seja, se as médias de produtividade dos híbridos foram significativamente diferentes a uma determinada probabilidade de erro é feita verificando-se o valor de \"Pr>fc\" na ANOVA. A figura abaixo mostra a distribuição F considerando os graus de liberdade de tratamento e erro \\(F_{4, 15}\\) e nos ajuda a compreender um pouco melhor isto.\n\n\nVeja o código que gerou o gráfico\ndf1 <- 4\ndf2 <- 15\nfcal <- 2.2543\nftab <- 3.055\n\nggplot() +\n  scale_x_continuous(limits = c(0,  6),\n                     breaks = c(0,  fcal, ftab,  6)) +\n  stat_function(fun = df,\n                geom = \"area\",\n                fill = \"red\",\n                xlim = c(fcal, 6),\n                args = list(\n                  df1 = df1,\n                  df2 = 63\n                )) +\n  stat_function(fun = df,\n                geom = \"area\",\n                fill = \"forestgreen\",\n                xlim = c(ftab, 6),\n                args = list(\n                  df1 = df1,\n                  df2 = 63\n                )) +\n  stat_function(fun = df,\n                geom = \"line\",\n                size = 1,\n                args = list(\n                  df1 = df1,\n                  df2 = 63\n                )) +\n  theme_bw(base_size = 16) +\n  theme(panel.grid.minor = element_blank()) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de F\",\n       y = \"Probabilidade acumulada\",\n       title = \"Distribuição F (DF1: 4, DF2: 15)\")\n\n\n\n\n\nDistribuição F com DF1 = 1 e DF2 = 15\n\n\nO valor de F calculado em nosso exemplo foi de 2,2543, o que resulta em uma probabilidade de erro acumulada de 0,1117 (11,17%). Esta probabilidade de erro acumulada está representada pela cor vermelha. Logo, não rejeitou-se a hipótese Para que uma diferença significativa a 5% de probabilidade de erro tivesse sido observada, o valor de F calculado deveria ter sido 3,055 qf(0.05, 4, 15, lower.tail = FALSE), representado neste caso pela cor verde no gráfico.\nConsiderando nosso exemplo, parece razoável dizer que 9,48 t (NP_1) é uma produção maior que 6,28 t (NP_5). Então, é justo perguntar: O que pode ter acontecido para que as médias não tenham sido consideradas diferentes considerando a probabilidade de erro, mesmo tendo fortes indícios de que elas seriam? A primeira opção que nos vem a mente –e que na maioria das vezes é encontrada em artigos científicos– é que as alterações no rendimento de grão observadas fora resultado do acaso; ou seja, neste caso, há a probabilidade de 11,17% de que uma diferença pelo menos tão grande quanto a observada no estudo possa ser gerada a partir de amostras aleatórias se os tratamentos não aferatem a variável resposta. Logo, a recomendação estatística neste caso, seria por optar por qualquer um dos tratamentos. Do ponto de vista prático, sabemos que esta recomendação está totalmente equivocada. Neste ponto surge uma importante (e polêmica) questão: a interpretação do p-valor. Um p-valor de 0,05 não significa que há uma chance de 95% de que determinada hipótese esteja correta. Em vez disso, significa que se a hipótese nula for verdadeira e todas as outras suposições feitas forem válidas, haverá 5% de chance que diferenças ao menos tão grandes quanto as observadas podem ser obtidas de amostras aleatórias. É preciso ter em mente que o p-valor relatado pelos testes é um significado probabilístico, não biológico. Assim, em experimentos biológicos, a interpretação desta estatística deve ser cautelosa, pois um p-valor pode não indicar a importância de uma descoberta. Por exemplo, um medicamento pode ter um efeito estatisticamente significativo nos níveis de glicose no sangue dos pacientes sem ter um efeito terapêutico. Sugerimos a leitura de cinco interessantes artigos relacionados a este assunto (Altman and Krzywinski 2017; Baker 2016; Singh Chawla 2017; Krzywinski and Altman 2013; Nuzzo 2014).\nEm adição à justificativa anterior (as alterações no rendimento de grão observadas fora resultado do acaso), existem pelo menos mais três razões potenciais para a não regeição da hipótese \\(H_0\\) em nosso exemplo:\n\num experimento mal projetado com poder insuficiente para detectar uma diferença (à 5% de erro) entre as médias;\nos tratamentos foram mal escolhidos e não refletiram adequadamente a hipótese inicial do estudo\no experimento foi indevidamente instalado e conduzido sem supervisão adequada, com baixo controle de qualidade sobre os protocolos de tratamento, coleta e análise de dados.\n\nEsta última opção parece ser a mais razoável aqui. É possivel observar no boxplot para o fator bloco que o bloco 4 parece ter uma média superior aos outros blocos. Sabe-ser que no DIC, toda diferença entre as repetições de um mesmo tratamento comporão o erro experimental. Logo, neste exemplo, a área experimental não era homogênea como se pressupunha na instalação do experimento. Isto ficará claro, posteriormente, ao analisarmos o mesmo conjunto de dados, no entanto considerando um DBC."
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#anova-em-dbc",
    "href": "FIT5306/FIT5306_07_DELN.html#anova-em-dbc",
    "title": "7. Análise de Variância",
    "section": "Anova em DBC",
    "text": "Anova em DBC\n\nwith(df,\n     DBC(HIBRIDO, BLOCO, RG))\n\n\n-----------------------------------------------------------------\nNormality of errors\n-----------------------------------------------------------------\n                         Method Statistic   p.value\n Shapiro-Wilk normality test(W)  0.987223 0.9920259\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered normal\n\n\n\n-----------------------------------------------------------------\nHomogeneity of Variances\n-----------------------------------------------------------------\n                              Method Statistic   p.value\n Bartlett test(Bartlett's K-squared)  7.696982 0.1033304\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, the variances can be considered homogeneous\n\n\n\n-----------------------------------------------------------------\nIndependence from errors\n-----------------------------------------------------------------\n                 Method Statistic   p.value\n Durbin-Watson test(DW)  2.565113 0.7271231\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered independent\n\n\n\n-----------------------------------------------------------------\nAdditional Information\n-----------------------------------------------------------------\n\nCV (%) =  8.2\nMStrat/MST =  0.33\nMean =  8.2479\nMedian =  8.0515\nPossible outliers =  No discrepant point\n\n-----------------------------------------------------------------\nAnalysis of Variance\n-----------------------------------------------------------------\n          Df    Sum Sq    Mean.Sq F value        Pr(F)\ntrat       4 32.629952  8.1574881 17.8475 5.449170e-05\nbloco      3 48.794088 16.2646961 35.5850 2.983658e-06\nResiduals 12  5.484793  0.4570661                     \n\n\nAs the calculated p-value, it is less than the 5% significance level. The hypothesis H0 of equality of means is rejected. Therefore, at least two treatments differ\n\n\n\n\n\n\n-----------------------------------------------------------------\nMultiple Comparison Test\n-----------------------------------------------------------------\n        resp groups\nNP_2 9.48075      a\nNP_1 9.48000      a\nNP_3 8.75075     ab\nNP_4 7.24500     bc\nNP_5 6.28300      c\n\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html",
    "href": "FIT5306/FIT5306_08_DIC.html",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "",
    "text": "library(tidyverse)  # manipulação de dados\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#características",
    "href": "FIT5306/FIT5306_08_DIC.html#características",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Características",
    "text": "Características\n\nUtiliza apenas os princípios de repetição e casualização;\nOs tratamentos são alocados nas parcelas de forma inteiramente casual, sem nenhum tipo de bloqueamento.\nExige que o material experimental e a área experimental sejam uniformes. Ele geralmente é mais utilizado em experimentos nos quais as condições experimentais podem ser bastante controladas (por exemplo em laboratórios);"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#vantagens",
    "href": "FIT5306/FIT5306_08_DIC.html#vantagens",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Vantagens",
    "text": "Vantagens\n\nDelineamento flexível, onde o número de tratamentos e repetições depende apenas da quantidade de parcelas disponíveis na área experimental.\nO número de repetições pode diferir de um tratamento para o outro (experimento não balanceado)\nA análise estatística é simples\nO número de graus de liberdade do erro é o maior possível considerando o número de repetições utilizado."
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#desvantagens",
    "href": "FIT5306/FIT5306_08_DIC.html#desvantagens",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Desvantagens",
    "text": "Desvantagens\n\nExige homogeneidade das condições ambientais\nPode estimar uma variância residual muito alta caso a área experimental apresente heterogeneidade, inflacionando o quadrado médio do erro."
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#modelo-estatístico",
    "href": "FIT5306/FIT5306_08_DIC.html#modelo-estatístico",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Modelo estatístico",
    "text": "Modelo estatístico\nO delineamento inteiramente casualizado (DIC) é um delineamento adequado para áreas uniformes (parcelas são uniformes), onde não há necessidade de controle local (bloqueamento). Neste delineamento, os tratamentos devem ser distribuídos aleatoriamente nas parcelas.\nO modelo do DIC é dado por\n\\[\n{Y_{ij}} = m + {t_i} + {\\varepsilon _{ij}}\n\\]\nOnde m é a média geral do experimento, \\(t_i\\) é o efeito de tratamentos, sendo estimado por \\(\\hat t_i = \\bar Y_{i.} - \\bar Y_{..}\\) com a seguinte restrição: \\(\\sum_i \\hat t_i = 0 ~~~~\\forall_i\\) (leia-se, o somatório dos efeitos de tratamento é zero para todo tratamento \\(i\\)). \\(\\epsilon_{ij}\\) é o erro experimental estimado por \\(\\hat e_{ij} = Y_{ij} - m - \\hat t_i\\) onde \\({e_{ij}}\\sim NID(0,{\\sigma ^2})\\)."
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#análise-de-variância-1",
    "href": "FIT5306/FIT5306_08_DIC.html#análise-de-variância-1",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Análise de variância",
    "text": "Análise de variância\nA análise de variância é computada no software R utilizando a função aov(). Considerando o Delineamento Inteiramente Casualizado (DIC), a única fonte de variação incluída no modelo é tratamento, neste caso, RAD.\n\nanova <- aov(MST ~ RAD, data = df_dic)\nsummary(anova)\n##             Df Sum Sq Mean Sq F value   Pr(>F)    \n## RAD          2  45.06  22.529   25.22 0.000205 ***\n## Residuals    9   8.04   0.893                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#comparação-de-médias",
    "href": "FIT5306/FIT5306_08_DIC.html#comparação-de-médias",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Comparação de médias",
    "text": "Comparação de médias\nEm sequência a ANOVA, quando o efeito de tratamento é significativo, teste de Tukey (5% de erro) pode ser utilizado para comparação das médias. Este teste realiza todas as combinações possíveis entre as médias (por isso o nome comparação múltipla de medias), comparando se a diferença entre duas médias é maior ou menor que uma diferença mínima significativa (DMS). Esta DMS é calculada pela seguinte fórmula \\(DMS = q \\times \\sqrt{QME/r}\\), onde q é um valor tabelado, considerando o número de tratamentos e o GL do erro; QME é o quadrado médio do erro; e r é o número de repetições (ou blocos).\n\n\n\n\n\n\nTip\n\n\n\nA fórmula da DMS descrita acima é utilizada apenas se (e somente se) o número de repetições de todos os tratamentos é igual. Caso algum tratamento apresente um número inferir de repetições, fato comumente observado em experimentos de campo devido a presença de parcelas perdidas, a DMS deste par de médias em específico deve ser corrigida. Geralmente, as análises complementares são realizadas quando a ANOVA indica significância para um determinado fator de variação, no entanto, o teste Tukey pode revelar diferença entre as médias, mesmo quando o teste F não indicar essa diferença. Isto pode ser observado, principalmente quando a probabilidade de erro for muito próxima de 5%, por exemplo, Pr>Fc = 0.0502. A recíproca também é verdadeira. O teste Tukey pode indicar que as médias não diferem, se Pr>Fc = 0.0492, por exemplo.\n\n\nO valor de q pode ser encontrado na seguinte tabela:\n\n\n\n\n\nPara este caso, considerando 3 e 9 como o número de tratamentos e o GL do erro, respectivamente, o valor de q é 3,95, que aplicado na fórmula resulta em \\(DMS = 3,95 \\times \\sqrt{0,893/4}=1,866\\). Logo, a diferença mínima entre duas médias para que estas sejam significativamente diferentes (5% de erro), deve ser de 1,866.\nPodemos realizar a comparação par-a-par utilizando a função pwpm() do pacote emmeans.\n\nmedias <- emmeans(anova, ~ RAD)\npwpm(medias)\n\n        50     70    100\n50  [11.2] 0.0061 0.0002\n70   -2.79 [14.0] 0.0428\n100  -4.72  -1.93 [15.9]\n\nRow and column labels: RAD\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nUma alternativa é o Pairwise P-value plot exibindo todos os P-values em comparações de pares. Cada comparação está associada a um segmento de linha vertical que une as posições de escala das duas médias que estão sendo comparadas e cuja posição horizontal é determinada pelo P-valor dessa comparação. Esta técnica não é indicada quando muitas comparações estão sendo testadas.\n\npwpp(medias)\n\n\n\n\nPairwise P-value plot\n\n\n\n\nOutra maneira de representar comparações graficamente por meio do argumento de comparações em plot.emm(). Nesta abordagem, a avaliação da significância das médias de dois tratamentos é dada pela sobreposição das flechas de cada tratamento. Se dois tratamentos apresentam setas que se sobrepoem (considerando o eixo x), assume-se que estes tratamentos são estatisticamente diferentes um do outro.\n\nplot(medias,\n     CIs = FALSE, # remove os intervalos de confiança das médias\n     comparisons = TRUE) # insere setas para comparação de médias (Tukey)\n\n\n\n\nComparações entre pares de médias com base no teste Tukey"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html",
    "href": "FIT5306/FIT5306_09_DBC.html",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "",
    "text": "library(tidyverse)  # manipulação de dados\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA\nlibrary(ExpDes.pt)"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#características",
    "href": "FIT5306/FIT5306_09_DBC.html#características",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Características",
    "text": "Características\n\nUtiliza apenas os princípios de repetição e casualização;\nOs tratamentos são alocados nas parcelas de forma inteiramente casual, sem nenhum tipo de bloqueamento.\nExige que o material experimental e a área experimental sejam uniformes. Ele geralmente é mais utilizado em experimentos nos quais as condições experimentais podem ser bastante controladas (por exemplo em laboratórios);"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#vantagens",
    "href": "FIT5306/FIT5306_09_DBC.html#vantagens",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Vantagens",
    "text": "Vantagens\n\nControla as diferenças que ocorrem nas condições ambientais, de um bloco para outro;\nPode haver heterogeneidade conhecida na área, desde que a alocação dos blocos seja feita de forma correta\nA variação entre blocos é isolada, logo, reduzindo a variância residual"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#desvantagens",
    "href": "FIT5306/FIT5306_09_DBC.html#desvantagens",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Desvantagens",
    "text": "Desvantagens\n\nDevido a inclusão de mais uma fonte de variação no modelo, há uma redução nos graus de liberdade do erro.\nComo exige-se homogeneidade dentro dos blocos, o número de tratamentos pode ficar limitado, visto que quanto maior é o bloco, mais difícil manter a sua homogeneidade."
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#casualização",
    "href": "FIT5306/FIT5306_09_DBC.html#casualização",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Casualização",
    "text": "Casualização\nPara realizar a casualização em um experimento em DBC, pode-se utilizar a função sketch do pacote agroR. Neste exemplo, simulo a casualização de três tratamentos em um ensaio conduzido em delineamento de blocos completos casualizados com quatro repetições (r). Apenas para fins didáticos, é apresentada também a casualização em DIC.\n\ntrats <- c(\"50\", \"70\", \"100\")\n\n# casualização em DIC\nset.seed(1)\nsketch(trats, r = 4, pos = \"line\")\n\n\n\n# casualização em DBC\nsketch(trats, r = 4, design = \"DBC\", pos = \"line\")"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#modelo-estatístico",
    "href": "FIT5306/FIT5306_09_DBC.html#modelo-estatístico",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Modelo estatístico",
    "text": "Modelo estatístico\nO modelo do DBC é dado por\n\\[\n{Y_{ij}} = m + {b_j} + {t_i} + {\\varepsilon _{ij}}\n\\]\nOnde \\(m\\) é a média geral do experimento, \\(b_j\\) é o efeito de bloco, \\(t_i\\) é o efeito de tratamentos e \\(\\epsilon_{ij}\\) é o erro experimental."
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#análise-de-variância-1",
    "href": "FIT5306/FIT5306_09_DBC.html#análise-de-variância-1",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Análise de variância",
    "text": "Análise de variância\nA análise de variância é computada no software R utilizando a função aov(). Considerando o Delineamento de Blocos Casualizados (DBC), as duas fontes de variação incluídas no modelo são a de tratamento (RAD) e bloco (REP).\n\nanova <- aov(MST ~ RAD + REP, data = df_dbc)\nsummary(anova)\n##             Df Sum Sq Mean Sq F value   Pr(>F)    \n## RAD          2  45.06  22.529  138.78 9.47e-06 ***\n## REP          3   7.07   2.356   14.51  0.00371 ** \n## Residuals    6   0.97   0.162                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#comparação-de-médias",
    "href": "FIT5306/FIT5306_09_DBC.html#comparação-de-médias",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Comparação de médias",
    "text": "Comparação de médias\nA análise de variância revelou efeito de tratamento significativo. Nesse caso, segue-se realizando uma análise de comparação múltipla de médias. Podemos realizar a comparação par-a-par utilizando a função pwpm() do pacote emmeans. Neste exemplo, o teste Tukey é utilizado.\n\nmedias_dbc <- emmeans(anova, ~ RAD)\npwpm(medias_dbc)\n\n        50     70    100\n50  [11.2] 0.0002 <.0001\n70   -2.79 [14.0] 0.0012\n100  -4.72  -1.93 [15.9]\n\nRow and column labels: RAD\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nNeste exemplo, utilizaremos a função emmeans para realizar a comparação de médias pelo teste Tukey. Nesta abordagem, a avaliação da significância das médias de dois tratamentos é dada pela sobreposição das flechas de cada tratamento. Se dois tratamentos apresentam setas que se sobrepõem (considerando o eixo x), assume-se que estes tratamentos são estatisticamente diferentes um do outro.\nApenas para fins de comparação, incluirei a comparação de médias considerando o modelo DIC. Observe que a redução da estimativa do erro experimental considerando o delineamento DBC fez com que ficasse mais fácil encontrar diferenças entre os tratamentos.\n\nanova_dic <- aov(MST ~ RAD, data = df_dbc)\nmedias_dic <- emmeans(anova_dic, ~ RAD)\n\nmedias_dbc <- emmeans(anova, ~ RAD)\n\nplot_dic <- \n  plot(medias_dic,\n       xlab = \"Matéria seca total (g)\",\n       ylab = \"Tratamentos\",\n       CIs = FALSE, # remove os intervalos de confiança das médias\n       comparisons = TRUE) # insere setas para comparação de médias (Tukey)\n\nplot_dbc <- \n  plot(medias_dbc,\n       xlab = \"Matéria seca total (g)\",\n       ylab = \"Tratamentos\",\n       CIs = FALSE, # remove os intervalos de confiança das médias\n       comparisons = TRUE) # insere setas para comparação de médias (Tukey)\n\narrange_ggplot(plot_dic,\n               plot_dbc,\n               ncol = 1,\n               tag_levels = \"a\")\n\n\n\n\nComparações entre pares de médias com base no teste Tukey considerando o delineamento inteiramente casualizado (a) e o delineamento de blocos casualizados (b)"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#criação-de-gráficos",
    "href": "FIT5306/FIT5306_09_DBC.html#criação-de-gráficos",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Criação de gráficos",
    "text": "Criação de gráficos\n\nmedias <- \n  plot_bars(df_dbc, RAD, MST,\n            lab.bar = c(\"c\", \"b\", \"a\"))\nmedias2 <- \n  plot_bars(df_dbc, RAD, MST,\n            plot_theme = theme_bw(),\n            lab.bar = c(\"c\", \"b\", \"a\"),\n            values = TRUE,\n            width.bar = 0.6,\n            y.expand = 0.2)\n\narrange_ggplot(medias, medias2, tag_levels = \"a\")"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#pacote-agror",
    "href": "FIT5306/FIT5306_09_DBC.html#pacote-agror",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Pacote AgroR",
    "text": "Pacote AgroR\nNo pacote agroR, a análise de variância neste delineamento pode ser realizada com a função DBC().\n\n\nwith(df_dbc,\n     DBC(RAD, REP, MST))\n\n\n\n## \n## -----------------------------------------------------------------\n## Normality of errors\n## -----------------------------------------------------------------\n##                          Method Statistic   p.value\n##  Shapiro-Wilk normality test(W) 0.9445588 0.5592776\n## \n## \n## -----------------------------------------------------------------\n## Homogeneity of Variances\n## -----------------------------------------------------------------\n##                               Method Statistic   p.value\n##  Bartlett test(Bartlett's K-squared) 0.4182676 0.8112867\n## \n## \n## -----------------------------------------------------------------\n## Independence from errors\n## -----------------------------------------------------------------\n##                  Method Statistic   p.value\n##  Durbin-Watson test(DW)  1.521488 0.1169862\n## \n## \n## -----------------------------------------------------------------\n## Additional Information\n## -----------------------------------------------------------------\n## \n## CV (%) =  2.94\n## MStrat/MST =  0.9\n## Mean =  13.7232\n## Median =  13.5946\n## Possible outliers =  No discrepant point\n## \n## -----------------------------------------------------------------\n## Analysis of Variance\n## -----------------------------------------------------------------\n##           Df     Sum Sq    Mean.Sq   F value        Pr(F)\n## trat       2 45.0579657 22.5289828 138.78145 9.473392e-06\n## bloco      3  7.0667049  2.3555683  14.51061 3.707071e-03\n## Residuals  6  0.9740055  0.1623343                       \n## \n## \n## -----------------------------------------------------------------\n## Multiple Comparison Test\n## -----------------------------------------------------------------\n##         resp groups\n## 100 15.94093      a\n## 70  14.00834      b\n## 50  11.22022      c"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#dados",
    "href": "FIT5306/FIT5306_09_DBC.html#dados",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Dados",
    "text": "Dados\n\nurl <- \"https://docs.google.com/spreadsheets/d/1vpVGdIkggRxmdnwrkllHbVA0TIHN85UK/edit#gid=1486281449\"\ndf_maize <-  import(url, dec = \",\")\n\ntabela <- \n  df_maize %>% \n  make_mat(HIBRIDO, BLOCO, RG) %>% \n  row_col_sum()\n\ntabela\n\n             B1     B2    B3     B4 row_sums\nNP_1      8.820  9.360  7.98 11.760   37.920\nNP_2      9.123  7.860  8.82 12.120   37.923\nNP_3      7.740  8.123  7.92 11.220   35.003\nNP_4      6.480  6.720  6.12  9.660   28.980\nNP_5      4.060  5.180  5.90  9.992   25.132\ncol_sums 36.223 37.243 36.74 54.752  164.958"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#r-base",
    "href": "FIT5306/FIT5306_09_DBC.html#r-base",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "R base",
    "text": "R base\n\nmod_hib <- aov(RG ~ HIBRIDO + BLOCO, data = df_maize)\nmed_hib <- emmeans(mod_hib, ~HIBRIDO)\npwpm(med_hib)\n\n         NP_1     NP_2     NP_3     NP_4   NP_5\nNP_1   [9.48]   1.0000   0.5666   0.0040 0.0002\nNP_2 -0.00075   [9.48]   0.5657   0.0040 0.0002\nNP_3  0.72925  0.73000   [8.75]   0.0533 0.0018\nNP_4  2.23500  2.23575  1.50575   [7.24] 0.3168\nNP_5  3.19700  3.19775  2.46775  0.96200 [6.28]\n\nRow and column labels: HIBRIDO\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nplot(med_hib, comparisons = TRUE, CIs = FALSE)"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#agror",
    "href": "FIT5306/FIT5306_09_DBC.html#agror",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "AgroR",
    "text": "AgroR\n\nwith(df_maize,\n     DBC(HIBRIDO, BLOCO, RG))\n\n\n-----------------------------------------------------------------\nNormality of errors\n-----------------------------------------------------------------\n                         Method Statistic   p.value\n Shapiro-Wilk normality test(W)  0.987223 0.9920259\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered normal\n\n\n\n-----------------------------------------------------------------\nHomogeneity of Variances\n-----------------------------------------------------------------\n                              Method Statistic   p.value\n Bartlett test(Bartlett's K-squared)  7.696982 0.1033304\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, the variances can be considered homogeneous\n\n\n\n-----------------------------------------------------------------\nIndependence from errors\n-----------------------------------------------------------------\n                 Method Statistic   p.value\n Durbin-Watson test(DW)  2.565113 0.7271231\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered independent\n\n\n\n-----------------------------------------------------------------\nAdditional Information\n-----------------------------------------------------------------\n\nCV (%) =  8.2\nMStrat/MST =  0.33\nMean =  8.2479\nMedian =  8.0515\nPossible outliers =  No discrepant point\n\n-----------------------------------------------------------------\nAnalysis of Variance\n-----------------------------------------------------------------\n          Df    Sum Sq    Mean.Sq F value        Pr(F)\ntrat       4 32.629952  8.1574881 17.8475 5.449170e-05\nbloco      3 48.794088 16.2646961 35.5850 2.983658e-06\nResiduals 12  5.484793  0.4570661                     \n\n\nAs the calculated p-value, it is less than the 5% significance level. The hypothesis H0 of equality of means is rejected. Therefore, at least two treatments differ\n\n\n\n\n\n\n-----------------------------------------------------------------\nMultiple Comparison Test\n-----------------------------------------------------------------\n        resp groups\nNP_2 9.48075      a\nNP_1 9.48000      a\nNP_3 8.75075     ab\nNP_4 7.24500     bc\nNP_5 6.28300      c\n\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html",
    "href": "FIT5306/FIT5306_10_FAT.html",
    "title": "10. Experimentos Fatoriais",
    "section": "",
    "text": "library(tidyverse)\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#casualização",
    "href": "FIT5306/FIT5306_10_FAT.html#casualização",
    "title": "10. Experimentos Fatoriais",
    "section": "Casualização",
    "text": "Casualização\n\nDelineamento Inteiramente Casualizado\n\nsketch(trat= c(\"A1\", \"A2\"),\n       trat1 = c(\"B1\", \"B2\", \"B3\"),\n       design = \"FAT2DIC\",\n       r = 4)\n\n\n\n\n\n\nDelineamento de Blocos Casualizados\n\nsketch(trat= c(\"A1\", \"A2\"),\n       trat1 = c(\"B1\", \"B2\", \"B3\"),\n       design = \"FAT2DBC\",\n       r = 4)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#tipos-de-interação",
    "href": "FIT5306/FIT5306_10_FAT.html#tipos-de-interação",
    "title": "10. Experimentos Fatoriais",
    "section": "Tipos de interação",
    "text": "Tipos de interação\n\nAusência de interação\n\n# sem interação\ndfsi <- tribble(\n  ~GEN, ~FONTEN, ~RG,\n  \"Híbrido 1\",\"Ureia\",   5.7,\n  \"Híbrido 1\",\"Nitrato\", 6.8,\n  \"Híbrido 2\",\"Ureia\",   8.2,\n  \"Híbrido 2\",\"Nitrato\", 9.3)\n\np1 <-\n  plot_factbars(dfsi, GEN, FONTEN, resp = RG,\n                ylab = expression(paste(\"RG (Mg \",ha^-1, \")\")),\n                y.expand = 0.2,\n                size.text = 16,\n                values = TRUE,\n                errorbar = F,\n                xlab = \"Híbrido\",\n                legend.position = c(0.2, 0.89)) +\n  ggtitle(\"Ausência de interação\")\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\np1\n\n\n\n\nDe posse dos dados, vamos construir uma tabela dupla entrada com os valores totais e outra com os valores médios. Os efeitos da interação são calculados como…\n\nmat_dfsi <- make_mat(dfsi, GEN, FONTEN, RG)\nmat_dfsi\n\n          Nitrato Ureia\nHíbrido 1     6.8   5.7\nHíbrido 2     9.3   8.2\n\n# tabela dupla entrada (totais)\nmat_dfsi |> \n  row_col_sum()\n\n          Nitrato Ureia row_sums\nHíbrido 1     6.8   5.7     12.5\nHíbrido 2     9.3   8.2     17.5\ncol_sums     16.1  13.9     30.0\n\n# tabela dupla entrada (totais)\nmat_dfsi |> \n  row_col_mean()\n\n          Nitrato Ureia row_means\nHíbrido 1    6.80  5.70      6.25\nHíbrido 2    9.30  8.20      8.75\ncol_means    8.05  6.95      7.50\n\n# soma de quadrados do fator GEN\nrowSums(mat_dfsi) ^ 2\n\nHíbrido 1 Híbrido 2 \n   156.25    306.25 \n\nmodsi <- aov(RG ~ GEN * FONTEN, data = dfsi)\nsummary(modsi)\n\n            Df Sum Sq Mean Sq\nGEN          1   6.25    6.25\nFONTEN       1   1.21    1.21\nGEN:FONTEN   1   0.00    0.00\n\n\n\n\nInteração simples (quantitativa)\n\n# interação simples\ndf_is <- tribble(\n  ~GEN, ~FONTEN, ~RG,\n  \"Híbrido 1\",\"Ureia\",   4.5,\n  \"Híbrido 1\",\"Nitrato\", 1.9,\n  \"Híbrido 2\",\"Ureia\",   11,\n  \"Híbrido 2\",\"Nitrato\", 5.3)\n\n\np2 <-\n  plot_factbars(df_is, GEN, FONTEN, resp = RG,\n                ylab = expression(paste(\"RG (Mg \",ha^-1, \")\")),\n                y.expand = 0.2,\n                size.text = 16,\n                errorbar = F,\n                values = TRUE,\n                xlab = \"Híbrido\",\n                legend.position = c(0.2, 0.89)) +\n  ggtitle(\"Interação simples\")\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\np2\n\n\n\n\n\n\nInteração complexa (qualitativa)\n\n# interação complexa\ndf_ic <- tribble(\n  ~GEN, ~FONTEN, ~RG,\n  \"Híbrido 1\",\"Ureia\",   4.1,\n  \"Híbrido 1\",\"Nitrato\", 1.4,\n  \"Híbrido 2\",\"Ureia\",   6.2,\n  \"Híbrido 2\",\"Nitrato\", 8.4)\n\np3 <-\n  plot_factbars(df_ic, GEN, FONTEN, resp = RG,\n                ylab = expression(paste(\"RG (Mg \",ha^-1, \")\")),\n                y.expand = 0.2,\n                size.text = 16,\n                errorbar = F,\n                values = TRUE,\n                xlab = \"Híbrido\",\n                legend.position = c(0.2, 0.89)) +\n  ggtitle(\"Interação complexa\")\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\np3"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#modelo-estatístico",
    "href": "FIT5306/FIT5306_10_FAT.html#modelo-estatístico",
    "title": "10. Experimentos Fatoriais",
    "section": "Modelo estatístico",
    "text": "Modelo estatístico\nVamos considerar como exemplo, um experimento que avaliou a influencia de dois fatores, digamos \\(\\alpha\\) e \\(\\tau\\), em uma determinada variável resposta. O modelo estatístico considerado neste tipo de experimento é:\n\\[\n{y_{ijk}} = {\\rm{ }}\\mu {\\rm{ }} + {\\rm{ }}\\mathop \\beta \\nolimits_{k}  + \\mathop \\alpha \\nolimits_i  + \\mathop \\tau \\nolimits_j  + \\mathop {(\\alpha \\tau )}\\nolimits_{ij}  + {\\rm{ }}\\mathop \\varepsilon \\nolimits_{ijk}\n\\]\nonde \\({y_{ijk}}\\) é o valor observado da combinação do i-ésimo nível do fator \\(\\alpha\\) com o j-ésimo nível do fator \\(\\tau\\) no k-ésimo bloco; \\(\\mu\\) é a média geral; \\(\\mathop \\beta \\nolimits_{k}\\) é o efeito do bloco k; \\(\\mathop \\alpha \\nolimits_i\\) é o efeito do i-ésimo nível de \\(\\alpha\\) ; \\(\\mathop \\tau \\nolimits_j\\) é o efeito do j-ésimo nível de \\(\\tau\\) ; \\(\\mathop {(\\alpha \\tau )}\\nolimits_{ij}\\) é o efeito da interação do i-ésimo nível de \\(\\alpha\\) com o j-ésimo nível de \\(\\tau\\); e \\(\\mathop \\varepsilon \\nolimits_{ijk}\\) é o erro aleatório associado a \\({y_{ijk}}\\), assumindo \\(\\mathop \\varepsilon \\nolimits_{ijk} \\mathop \\cap \\limits^{iid} N(0,\\mathop \\sigma \\nolimits^2 )\\).\nBasicamente, estes fatores podem ser divididos em dois tipos: qualitativos e quantitativos. Um fator qualitativo é, como o nome já diz, relacionado a qualidade, ou seja, diferentes em tipo, mas não em quantidade. Como exemplo, podemos citar cultivares, defensivos agrícolas, práticas de manejo, etc. Um fator quantitativo, por outro lado, é caracterizado pela quantidade utilizada no experimento. Podemos citar, por exemplo, doses de adubação. Cabe ressaltar que o termo fatorial não indica um delineamento experimental, mas uma forma de arranjo de tratamentos na área parcela. Estes experimentos podem ser conduzidos tanto em DIC quanto DBC. Assim, em cada repetição/bloco, o tratamento a ser aplicado é a combinação dos níveis dos dois fatores."
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#conjunto-de-dados",
    "href": "FIT5306/FIT5306_10_FAT.html#conjunto-de-dados",
    "title": "10. Experimentos Fatoriais",
    "section": "Conjunto de dados",
    "text": "Conjunto de dados\nO conjunto de dados utilizado neste exemplo é adaptado de OLIVOTO et al. (2016) sendo oriundo de um experimento que testou o efeito de diferentes parcelamentos de nitrogênio (N) associado ao uso de enxofre (S) na produtividade, componentes do rendimento e qualidade reológica da farinha de trigo.\n\nOLIVOTO, T. et al. Sulfur and nitrogen effects on industrial quality and grain yield of wheat. Revista de Ciências Agroveterinárias, v. 15, n. 1, p. 24–33, 2016. Disponível em: https://doi.org/10.5965/223811711512016024\n\nOs tratamentos consistiram da combinação de três níveis de parcelamento de N (DA: 100% no duplo anel; AF+DA: 50% no afilhamento + 50% no duplo anel; DA+ES: 50% no afilhamento + 50% no espigamento) e dois níveis de enxofre (S+: com enxofre; S-: sem enxofre).\nPara fins didáticos, a extensibilidade da massa (L, mm) é utilizada. Para importação, utiliza-se a função import() do pacote rio. A função as_factor converte as primeiras três colunas para fator.\n\nurl <- \"https://bit.ly/df_biostat\"\ndf_fat <- \n  import(url, sheet = \"FAT1_CI2\", setclass = \"tbl\") |>\n  as_factor(1:3)\n\nNo seguinte gráfico, apresento as médias observadas da extensibilidade nos diferentes tratamentos.\n\nplot_factbars(df_fat, ENX, NIT, resp = L)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#verificação-de-outliers",
    "href": "FIT5306/FIT5306_10_FAT.html#verificação-de-outliers",
    "title": "10. Experimentos Fatoriais",
    "section": "Verificação de outliers",
    "text": "Verificação de outliers\nA função inspect do pacote metan é utilizada para inspecionar o conjunto de dados. Com esta função, é possível identificar possíveis outliers, bem como valores faltantes.\n\ninspect(df_fat, plot = TRUE)\n## # A tibble: 4 × 10\n##   Variable Class   Missing Levels Valid_n   Min Median   Max Outlier Text \n##   <chr>    <chr>   <chr>   <chr>    <int> <dbl>  <dbl> <dbl>   <dbl> <lgl>\n## 1 ENX      factor  No      2           24    NA   NA      NA      NA NA   \n## 2 NIT      factor  No      3           24    NA   NA      NA      NA NA   \n## 3 REP      factor  No      4           24    NA   NA      NA      NA NA   \n## 4 L        numeric No      -           24    67   78.5    96       0 NA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#estatística-descritiva",
    "href": "FIT5306/FIT5306_10_FAT.html#estatística-descritiva",
    "title": "10. Experimentos Fatoriais",
    "section": "Estatística descritiva",
    "text": "Estatística descritiva\nA função desc_stat() do pacote metan computa estatísticas descritivas para a variável L.\n\ndesc_stat(df_fat)\n## # A tibble: 1 × 10\n##   variable    cv   max  mean median   min sd.amo    se  ci.t n.valid\n##   <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>\n## 1 L         10.5    96  80.4   78.5    67   8.43  1.72  3.56      24"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#análise-de-variância",
    "href": "FIT5306/FIT5306_10_FAT.html#análise-de-variância",
    "title": "10. Experimentos Fatoriais",
    "section": "Análise de variância",
    "text": "Análise de variância\n\nManual\n\nmat_df_fat <- make_mat(df_fat, ENX, NIT, L, fun = sum)\nmat_df_fat\n\n   AF+DA  DA DA+ES\nS-   297 316   310\nS+   286 373   347\n\n# total dos blocos\ntbloco <- sum_by(df_fat, REP) |> pull()\n\nI <- nlevels(df_fat$ENX)\nJ <- nlevels(df_fat$NIT)\nK <- nlevels(df_fat$REP)\n\n# fator de correção\nC <- sum(df_fat$L) ^ 2  / (I*J*K)\n# soma de quadrado total\nsqtot <- sum(df_fat$L ^ 2) - C\n# soma de quadrado de bloco\nsqbloco <- sum(tbloco ^ 2) / (I*J) - C\n# soma de quadrados de ENX (a)\nsqa <- sum(rowSums(mat_df_fat) ^ 2)  / (J * K) -  C\n# soma de quadrados de NIT (b)\nsqb <- sum(colSums(mat_df_fat) ^ 2)  / (I * K) -  C\n# soma de quadrados da interação (a x b)\nsqab <- sum(mat_df_fat ^ 2)  / K -  C - sqa - sqb\n# soma de quadrado do erro\nsqerr <- sqtot - sqa - sqb - sqab - sqbloco\n\n\n# montar a tabela\nFV <- c(\"BLOCO\", \"ENX\", \"NIT\", \"ENX*NIT\", \"ERRO\", \"TOTAL\")\nGL <- c(3, 1, 2, 2, 15, 23)\nSQ <- c(sqbloco, sqa, sqb, sqab, sqerr, sqtot)\nQM <- SQ / GL\nFC <- QM / QM[5]\nFC[5:6] <- NA\n\ndata.frame(FV = FV, GL = GL, SQ = SQ, QM = QM, FC = FC)\n\n       FV GL         SQ         QM         FC\n1   BLOCO  3   10.45833   3.486111  0.1779889\n2     ENX  1  287.04167 287.041667 14.6553680\n3     NIT  2  739.00000 369.500000 18.8654092\n4 ENX*NIT  2  305.33333 152.666667  7.7946391\n5    ERRO 15  293.79167  19.586111         NA\n6   TOTAL 23 1635.62500  71.114130         NA\n\n\nA análise de variância é computada no software R utilizando a função aov(). Considerando o Delineamento de Blocos Casualizados (DBC), as três fontes de variação incluídas no modelo são a de enxofre (ENX), nitrogênio (NIT) e bloco (REP). Note que todos os termos (efeito principal e interação) podem ser declarados quando se utiliza ENX*NIT; também é possível indicar termos específicos no modelo.\n\n# opção 1\nanova <- aov(L ~ ENX*NIT + REP, data = df_fat)\n# modelo idêntico, indicando os termos explicitamente\nanova <- aov(L ~ ENX + NIT + ENX:NIT + REP, data = df_fat)\nsummary(anova)\n##             Df Sum Sq Mean Sq F value   Pr(>F)    \n## ENX          1  287.0   287.0  14.655  0.00165 ** \n## NIT          2  739.0   369.5  18.865 8.04e-05 ***\n## REP          3   10.5     3.5   0.178  0.90965    \n## ENX:NIT      2  305.3   152.7   7.795  0.00477 ** \n## Residuals   15  293.8    19.6                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#comparação-de-médias",
    "href": "FIT5306/FIT5306_10_FAT.html#comparação-de-médias",
    "title": "10. Experimentos Fatoriais",
    "section": "Comparação de médias",
    "text": "Comparação de médias\nA análise de variância revelou efeito significativo da interação. Nesse caso, segue-se comparando as médias do fator nitrogênio dentro de cada nível do fator enxofre e do enxofre dentro de cada nível do fator nitrogênio. Para isso, utilizo o pacote emmeans (teste Tukey). Nesta abordagem, a avaliação da significância das médias de dois tratamentos é dada pela sobreposição das flechas de cada tratamento. Se dois tratamentos apresentam setas que se sobrepõem (considerando o eixo x), assume-se que estes tratamentos são estatisticamente diferentes um do outro.\n\nmedias_fat <- emmeans(anova, ~ NIT | ENX)\nplot(medias_fat,\n     CIs = FALSE, # remove os intervalos de confiança das médias\n     comparisons = TRUE) # insere setas para comparação de médias (Tukey)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#pacote-agror",
    "href": "FIT5306/FIT5306_10_FAT.html#pacote-agror",
    "title": "10. Experimentos Fatoriais",
    "section": "Pacote AgroR",
    "text": "Pacote AgroR\nNo pacote agroR, a análise de variância neste delineamento pode ser realizada com a função FAT2DBC().\n\nwith(df_fat,\n     FAT2DBC(ENX, NIT, REP, L))\n## \n## -----------------------------------------------------------------\n## Normality of errors\n## -----------------------------------------------------------------\n##                          Method Statistic    p.value\n##  Shapiro-Wilk normality test(W)  0.922206 0.06536118\n## \n## \n## -----------------------------------------------------------------\n## Homogeneity of Variances\n## -----------------------------------------------------------------\n##                               Method Statistic  p.value\n##  Bartlett test(Bartlett's K-squared)  2.459752 0.782544\n## \n## \n## -----------------------------------------------------------------\n## Independence from errors\n## -----------------------------------------------------------------\n##                  Method Statistic    p.value\n##  Durbin-Watson test(DW)  1.682362 0.04036279\n## \n## \n## -----------------------------------------------------------------\n## Additional Information\n## -----------------------------------------------------------------\n## \n## CV (%) =  5.51\n## Mean =  80.375\n## Median =  78.5\n## Possible outliers =  No discrepant point\n## \n## -----------------------------------------------------------------\n## Analysis of Variance\n## -----------------------------------------------------------------\n##               Df    Sum Sq    Mean.Sq    F value        Pr(F)\n## Fator1         1 287.04167 287.041667 14.6553680 1.645485e-03\n## Fator2         2 739.00000 369.500000 18.8654092 8.038974e-05\n## bloco          3  10.45833   3.486111  0.1779889 9.096501e-01\n## Fator1:Fator2  2 305.33333 152.666667  7.7946391 4.774361e-03\n## Residuals     15 293.79167  19.586111                        \n## \n## -----------------------------------------------------------------\n## \n## Significant interaction: analyzing the interaction\n## \n## -----------------------------------------------------------------\n## \n## -----------------------------------------------------------------\n## Analyzing  F1  inside of each level of  F2\n## -----------------------------------------------------------------\n##                        Df Sum Sq Mean Sq F value    Pr(>F)    \n## bloco                   3  10.46    3.49  0.1780 0.9096501    \n## Fator2                  2 739.00  369.50 18.8654 8.039e-05 ***\n## Fator2:Fator1           3 592.38  197.46 10.0815 0.0006909 ***\n##   Fator2:Fator1: AF+DA  1  15.13   15.13  0.7722 0.3933874    \n##   Fator2:Fator1: DA     1 406.12  406.12 20.7354 0.0003805 ***\n##   Fator2:Fator1: DA+ES  1 171.12  171.12  8.7371 0.0098160 ** \n## Residuals              15 293.79   19.59                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## -----------------------------------------------------------------\n## Analyzing  F2  inside of the level of  F1\n## -----------------------------------------------------------------\n## \n##                     Df  Sum Sq Mean Sq F value    Pr(>F)    \n## bloco                3   10.46    3.49  0.1780  0.909650    \n## Fator1               1  287.04  287.04 14.6554  0.001645 ** \n## Fator1:Fator2        4 1044.33  261.08 13.3300 7.897e-05 ***\n##   Fator1:Fator2: S-  2   47.17   23.58  1.2041  0.327368    \n##   Fator1:Fator2: S+  2  997.17  498.58 25.4560 1.508e-05 ***\n## Residuals           15  293.79   19.59                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n## \n## -----------------------------------------------------------------\n## Final table\n## -----------------------------------------------------------------\n##      AF+DA      DA   DA+ES\n## S- 74.2 aA 79.0 bA 77.5 bA\n## S+ 71.5 aB 93.2 aA 86.8 aA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#casualização-1",
    "href": "FIT5306/FIT5306_10_FAT.html#casualização-1",
    "title": "10. Experimentos Fatoriais",
    "section": "Casualização",
    "text": "Casualização\n\nsketch(trat= c(\"A1\", \"A2\"),\n       trat1 = c(\"B1\", \"B2\", \"B3\"),\n       design = \"PSUBDBC\",\n       r = 4)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#análise-de-variância-1",
    "href": "FIT5306/FIT5306_10_FAT.html#análise-de-variância-1",
    "title": "10. Experimentos Fatoriais",
    "section": "Análise de variância",
    "text": "Análise de variância\nConsiderando o mesmo conjunto de dados do exemplo anterior e assumindo que o enxofre estava casualizado nas parcelas principais e o nitrogênio nas subparcelas, a análise de variância no software R é computada conforme segue\n\nanova_psub <- aov(L ~ ENX*NIT + Error(REP/ENX), data = df_fat)\nsummary(anova_psub)\n\n\nError: REP\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  3  10.46   3.486               \n\nError: REP:ENX\n          Df Sum Sq Mean Sq F value Pr(>F)  \nENX        1 287.04  287.04   18.94 0.0224 *\nResiduals  3  45.46   15.15                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nNIT        2  739.0   369.5  17.855 0.000253 ***\nENX:NIT    2  305.3   152.7   7.377 0.008142 ** \nResiduals 12  248.3    20.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#pacote-agror-1",
    "href": "FIT5306/FIT5306_10_FAT.html#pacote-agror-1",
    "title": "10. Experimentos Fatoriais",
    "section": "Pacote AgroR",
    "text": "Pacote AgroR\nNo pacote agroR, a análise de variância neste delineamento pode ser realizada com a função PSUBDBC().\n\nwith(df_fat,\n     PSUBDBC(ENX, NIT, REP, L))\n## \n## -----------------------------------------------------------------\n## Normality of errors\n## -----------------------------------------------------------------\n##                          Method Statistic    p.value\n##  Shapiro-Wilk normality test(W)  0.922206 0.06536118\n## \n## \n## \n## -----------------------------------------------------------------\n## Homogeneity of Variances\n## -----------------------------------------------------------------\n## Plot\n##                               Method Statistic   p.value\n##  Bartlett test(Bartlett's K-squared) 0.6768708 0.4106663\n## \n## \n## ----------------------------------------------------\n## Split-plot\n##                               Method Statistic   p.value\n##  Bartlett test(Bartlett's K-squared)  1.817323 0.4030634\n## \n## \n## ----------------------------------------------------\n## Interaction\n##                               Method Statistic  p.value\n##  Bartlett test(Bartlett's K-squared)  2.459752 0.782544\n## \n## \n## -----------------------------------------------------------------\n## Additional Information\n## -----------------------------------------------------------------\n## \n## CV1 (%) =  4.84\n## CV2 (%) =  5.66\n## Mean =  80.375\n## Median =  78.5\n## \n## -----------------------------------------------------------------\n## Analysis of Variance\n## -----------------------------------------------------------------\n##         Df Sum Sq    Mean Sq    F value    Pr(>F) \n## F1       1 287.04167 287.041667 18.9431714 0.022  \n## Block    3  10.45833   3.486111  0.2300642 0.871  \n## Error A  3  45.45833  15.152778                   \n## F2       2 739.00000 369.500000 17.8550336 p<0.001\n## F1 x F2  2 305.33333 152.666667  7.3771812 0.008  \n## Error B 12 248.33333  20.694444                   \n## -----------------------------------------------------------------\n## Significant interaction: analyzing the interaction\n## -----------------------------------------------------------------\n## Analyzing  F1  inside of each level of  F2\n## -----------------------------------------------------------------\n##                      GL       SQ        QM        Fc  p.value\n## F1 : F2 AF+DA   1.00000  15.1250  15.12500  0.802506 0.384898\n## F1 : F2 DA      1.00000 406.1250 406.12500 21.548268 0.000343\n## F1 : F2 DA+ES   1.00000 171.1250 171.12500  9.079587 0.008963\n## Combined error 14.57876 274.7691  18.84722                   \n## \n## -----------------------------------------------------------------\n## Analyzing  F2  inside of the level of  F1\n## -----------------------------------------------------------------\n##             GL        SQ        QM        Fc  p.value\n## F2 : F1 S-   2  47.16667  23.58333  1.139597 0.352262\n## F2 : F1 S+   2 997.16667 498.58333 24.092617  6.3e-05\n## Error b     12 248.33333  20.69444\n\n\n\n## \n## -----------------------------------------------------------------\n## Final table\n## -----------------------------------------------------------------\n##      AF+DA      DA   DA+ES\n## S- 74.2 aA 79.0 bA 77.5 bA\n## S+ 71.5 aB 93.2 aA 86.8 aA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#experimento1",
    "href": "FIT5306/FIT5306_10_FAT.html#experimento1",
    "title": "10. Experimentos Fatoriais",
    "section": "Coberturas de solo e doses de nitrogênio (efeito na massa de cobertura de inverno)",
    "text": "Coberturas de solo e doses de nitrogênio (efeito na massa de cobertura de inverno)\nO delineamento experimental utilizado foi o delineamento de blocos casualizados com parcelas subdivididas em esquema fatorial 4x2 com quatro repetições. quatro espécies: aveia preta cv. BRS 139 (Neblina), com densidade de 120 kg ha\\(^{-1}\\) de semente; triticale cv. BRS SATURNO, com densidade de 160 kg ha\\(^{-1}\\) de semente e centeio cv. BRS PROGRESSO, com densidade de 160 kg ha\\(^{-1}\\) de semente, além do pousio, com presença de diferentes plantas que se desenvolvem nesta época (três espécies de gramíneas); com dois manejos de nitrogênio (com ou sem N em cobertuta). Os tratamentos foram alocados na área experimental em formato de parcelas subdivididas. Na parcela principal foram alocadas as espécies nas subparcela o manejo de nitrogênio. Nas parcelas que receberam N utilizou-se como fonte a ureia (45% de N) na dose de 100 kg ha\\(^{-1}\\).\n\nPacotes e dados\nAssumindo que todos estão instalados, é só carregar com\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\ndf_cobmassa <- import(url, sheet = \"COBERTURA_N_MASSA\", setclass = \"tbl\")\ndf_cobmassa <- as_factor(df_cobmassa, 1:3)\n\n# Apenas para mostrar a estrutura dos dados\ndf_cobmassa\n\n# A tibble: 32 × 6\n   NITROGENIO ESPECIE     REP       MV    MS   MSR\n   <fct>      <fct>       <fct>  <dbl> <dbl> <dbl>\n 1 Sem N      Aveia Preta 1     17939. 3640.  53.2\n 2 Sem N      Aveia Preta 2     20738. 4190. 709. \n 3 Sem N      Aveia Preta 3     37780  6958. 688  \n 4 Sem N      Aveia Preta 4     15448  3055.  98  \n 5 Sem N      Centeio     1     30836. 7001. 347. \n 6 Sem N      Centeio     2     22246  5540  246. \n 7 Sem N      Centeio     3     12422  3330. 169. \n 8 Sem N      Centeio     4     15220. 3797. 213. \n 9 Sem N      Triticale   1     14700. 2989. 268. \n10 Sem N      Triticale   2     19146. 3652. 399. \n# … with 22 more rows\n\n\n\n\nEstatistica descritiva\n\ndesc_stat(df_cobmassa, stats = c(\"min, mean, max\"))\n\n# A tibble: 3 × 4\n  variable    min   mean    max\n  <chr>     <dbl>  <dbl>  <dbl>\n1 MS       1576.   5053.  7573.\n2 MSR        53.2   373.   738 \n3 MV       6413.  25210. 45076.\n\n\n\n\nANOVA\nO modelo considerado para este exemplo de parcela subdivididas é o seguinte\n\\[\n{y_{ijk}} = {\\rm{ }}\\mu {\\rm{ }} + {\\rm{ }}\\mathop \\alpha \\nolimits_i + \\mathop \\beta \\nolimits_{k} + \\mathop \\eta \\nolimits_{ik}  +\\mathop \\tau \\nolimits_j  + \\mathop {(\\alpha \\tau )}\\nolimits_{ij}  + {\\rm{ }}\\mathop \\varepsilon \\nolimits_{ijk}\n\\]\nonde \\({y_{ijk}}\\) é a variável resposta observada; \\(\\mu\\) é a média geral; \\(\\mathop \\alpha \\nolimits_i\\) é o efeito do \\(i\\)-ésimo nível do fator espécie de cobertura ; \\(\\mathop \\beta \\nolimits_{k}\\) é o efeito do bloco \\(k\\); \\(\\mathop \\eta \\nolimits_{ik}\\) é o erro de parcela, mais conhecido como erro a; \\(\\mathop \\tau \\nolimits_j\\) é o efeito do \\(j\\)-ésimo nível do fator nitrogênio; \\(\\mathop {(\\alpha \\tau )}\\nolimits_{ij}\\) é o efeito da interação do \\(i\\)-ésimo nível do fator espécie com o \\(j\\)-ésimo nível do fator nitrogênio; e \\(\\mathop \\varepsilon \\nolimits_{ijk}\\) é o erro da subparcela, mais conhecido como erro b.\n\nMassa verde (MV) por ha\nANOVA\n\nwith(df_cobmassa,\n     psub2.dbc(fator1 = ESPECIE,\n               fator2 = NITROGENIO,\n               bloco = REP,\n               resp = MV,\n               fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1 (parcela):  ESPECIE \nFATOR 2 (subparcela):  NITROGENIO \n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL         SQ        QM      Fc  Pr(>Fc)    \nESPECIE             3  416543558 138847853  1.2283 0.354965    \nBloco               3   77123097  25707699  0.2274 0.875004    \nErro a              9 1017377902 113041989                     \nNITROGENIO          1  743336547 743336547 20.7774 0.000657 ***\nESPECIE*NITROGENIO  3   86334790  28778264  0.8044 0.515204    \nErro b             12  429314110  35776176                     \nTotal              31 2770030005                               \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n------------------------------------------------------------------------\nCV 1 = 42.17338 %\nCV 2 = 23.72551 %\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis   Medias\n1 Aveia Preta 30469.15\n2     Centeio 24084.35\n3      Pousio 20441.70\n4   Triticale 25846.80\n------------------------------------------------------------------------\nNITROGENIO\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    Com N   30030.17 \n b   Sem N   20390.83 \n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo somente foi observado efeito significativo para o fator nitrogênio, prossegue-se com a comparação de médias para o efeito de N, conforme resultado do Teste Tukey acima. Neste gráfico, as barras mostram a média e as barras de erro, o erro padrão da média. Apenas para apresentação, incluo também a média do fator cobertura de solo, sem as letras pois o seu efeito não foi significativo, segundo a ANOVA.\n\npn_mv <- \n  plot_bars(df_cobmassa,\n            x = NITROGENIO,\n            y = MV,\n            lab.bar = c(\"a\", \"b\"),\n            xlab = \"Aplicação de Nitrogênio (N)\",\n            ylab = \"Matéria verde (kg/ha)\")\n\npcob_mv <- \n  plot_bars(df_cobmassa,\n            x = ESPECIE,\n            y = MV,\n            xlab = \"Espécies\",\n            ylab = \"Matéria verde (kg/ha)\") +\n  geom_hline(yintercept = mean(df_cobmassa$MV))\n\n# organiza os gráficos\narrange_ggplot(pn_mv, pcob_mv)\n\n\n\n\n\n\nMassa seca (MS) por ha\nANOVA\n\nwith(df_cobmassa,\n     psub2.dbc(fator1 = ESPECIE,\n               fator2 = NITROGENIO,\n               bloco = REP,\n               resp = MS,\n               fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1 (parcela):  ESPECIE \nFATOR 2 (subparcela):  NITROGENIO \n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL       SQ       QM     Fc Pr(>Fc)  \nESPECIE             3 11614132  3871377 1.0190 0.42877  \nBloco               3  1466451   488817 0.1287 0.94066  \nErro a              9 34191281  3799031                 \nNITROGENIO          1 14139498 14139498 8.1851 0.01433 *\nESPECIE*NITROGENIO  3  1476172   492057 0.2848 0.83542  \nErro b             12 20729720  1727477                 \nTotal              31 83617255                          \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n------------------------------------------------------------------------\nCV 1 = 38.57428 %\nCV 2 = 26.01163 %\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis  Medias\n1 Aveia Preta 5402.25\n2     Centeio 5647.55\n3      Pousio 4065.85\n4   Triticale 5095.85\n------------------------------------------------------------------------\nNITROGENIO\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    Com N   5717.6 \n b   Sem N   4388.15 \n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo somente foi observado efeito significativo para o fator nitrogênio, prossegue-se com a comparação de médias para o efeito de N, conforme resultado do Teste Tukey acima. Apenas para apresentação, incluo também a média do fator cobertura de solo, sem as letras pois o seu efeito não foi significativo, segundo a ANOVA.\n\npn_ms <- \n  plot_bars(df_cobmassa,\n            x = NITROGENIO,\n            y = MS,\n            lab.bar = c(\"a\", \"b\"),\n            xlab = \"Aplicação de Nitrogênio (N)\",\n            ylab = \"Matéria seca (kg/ha)\")\n\npcob_ms <- \n  plot_bars(df_cobmassa,\n            x = ESPECIE,\n            y = MS,\n            xlab = \"Espécies\",\n            ylab = \"Matéria seca (kg/ha)\") +\n  geom_hline(yintercept = mean(df_cobmassa$MS))\n\n# organiza os gráficos\narrange_ggplot(pn_ms, pcob_ms)\n\n\n\n\n\n\nMassa seca de raiz (MSR) por ha\nANOVA\n\nwith(df_cobmassa,\n     psub2.dbc(fator1 = ESPECIE,\n               fator2 = NITROGENIO,\n               bloco = REP,\n               resp = MSR,\n               fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1 (parcela):  ESPECIE \nFATOR 2 (subparcela):  NITROGENIO \n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL      SQ     QM      Fc  Pr(>Fc)    \nESPECIE             3  160868  53623  0.9543 0.454941    \nBloco               3  217735  72578  1.2916 0.335534    \nErro a              9  505724  56192                     \nNITROGENIO          1  141512 141512 21.4205 0.000582 ***\nESPECIE*NITROGENIO  3   44728  14909  2.2568 0.134138    \nErro b             12   79277   6606                     \nTotal              31 1149844                            \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n------------------------------------------------------------------------\nCV 1 = 63.48783 %\nCV 2 = 21.76891 %\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis Medias\n1 Aveia Preta  405.7\n2     Centeio  365.6\n3      Pousio  264.4\n4   Triticale  457.8\n------------------------------------------------------------------------\nNITROGENIO\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    Com N   439.875 \n b   Sem N   306.875 \n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo somente foi observado efeito significativo para o fator nitrogênio, prossegue-se com a comparação de médias para o efeito de N, conforme resultado do Teste Tukey acima. Apenas para apresentação, incluo também a média do fator cobertura de solo, sem as letras pois o seu efeito não foi significativo, segundo a ANOVA.\n\npn_msr <- \n  plot_bars(df_cobmassa,\n            x = NITROGENIO,\n            y = MSR,\n            lab.bar = c(\"a\", \"b\"),\n            xlab = \"Aplicação de Nitrogênio (N)\",\n            ylab = \"Massa seca de raiz (kg/ha)\")\n\npcob_msr <- \n  plot_bars(df_cobmassa,\n            x = ESPECIE,\n            y = MSR,\n            xlab = \"Espécies\",\n            ylab = \"Massa seca de raiz (kg/ha)\") +\n  geom_hline(yintercept = mean(df_cobmassa$MSR))\n\n# organiza os gráficos\narrange_ggplot(pn_msr, pcob_msr)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#coberturas-de-solo-e-doses-de-nitrogênio-efeito-na-cultura-da-soja",
    "href": "FIT5306/FIT5306_10_FAT.html#coberturas-de-solo-e-doses-de-nitrogênio-efeito-na-cultura-da-soja",
    "title": "10. Experimentos Fatoriais",
    "section": "Coberturas de solo e doses de nitrogênio (efeito na cultura da soja)",
    "text": "Coberturas de solo e doses de nitrogênio (efeito na cultura da soja)\nOs tratamentos e delineamentos são descritos no exemplo anterior. Aqui, são analisados os dados observados na cultura da soja, semeada na resteva de cada tratamento (combinação de N e espécies de cobertura)\n\nPacotes e dados\nAssumindo que todos estão instalados, é só carregar com\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\ndf_cobsoja <- import(url, sheet = \"COBERTURA_N_SOJA\", setclass = \"tbl\")\ndf_cobsoja <- as_factor(df_cobsoja, 1:3)\n\n# Apenas para mostrar a estrutura dos dados\ndf_cobsoja\n\n# A tibble: 32 × 7\n   ESPECIE     NITROGENIO REP      NL   NGL   MMG    RG\n   <fct>       <fct>      <fct> <dbl> <dbl> <dbl> <dbl>\n 1 Aveia Preta Sem N      R1     30    2.25   180 3547.\n 2 Aveia Preta Sem N      R2     40.8  2.55   190 4117.\n 3 Aveia Preta Sem N      R3     34.6  2.6    170 3381.\n 4 Aveia Preta Sem N      R4     37.6  2.52   160 3733.\n 5 Centeio     Sem N      R1     38.6  2.15   180 3819.\n 6 Centeio     Sem N      R2     40.6  2.1    170 1739.\n 7 Centeio     Sem N      R3     37.6  2.48   180 3928.\n 8 Centeio     Sem N      R4     38    2.39   150 3339.\n 9 Triticale   Sem N      R1     35.6  2.46   210 4400 \n10 Triticale   Sem N      R2     32.2  2.42   200 4378.\n# … with 22 more rows\n\n\n\n\nEstatistica descritiva\n\ndesc_stat(df_cobsoja, stats = c(\"min, mean, max\"))\n\n# A tibble: 4 × 4\n  variable    min    mean     max\n  <chr>     <dbl>   <dbl>   <dbl>\n1 MMG      150     178.    210   \n2 NGL        1.97    2.43    2.82\n3 NL        22.6    38.6    53.2 \n4 RG       675    3288.   4861.  \n\n\n\n\nANOVA\nO modelo considerado é descrito no exemplo anterior.\n\nVariável número de legumes por planta (NL)\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = NL,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL      SQ QM     Fc   Pr>Fc\nBloco               3   18.72  6 0.1640 0.91940\nESPECIE             3  148.99  5 1.3051 0.29904\nNITROGENIO          1    2.76  3 0.0726 0.79027\nESPECIE*NITROGENIO  3  430.67  2 3.7724 0.02607\nResiduo            21  799.15  4               \nTotal              31 1400.30  1               \n------------------------------------------------------------------------\nCV = 16 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.5520582 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n\n\nInteracao significativa: desdobrando a interacao\n------------------------------------------------------------------------\n\nDesdobrando  ESPECIE  dentro de cada nivel de  NITROGENIO \n------------------------------------------------------------------------\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                         GL         SQ        QM     Fc  Pr.Fc\nBloco                     3   18.72375   6.24125  0.164 0.9194\nNITROGENIO                1    2.76125   2.76125 0.0726 0.7903\nESPECIE:NITROGENIO Com N  3  513.04000 171.01333 4.4939 0.0138\nESPECIE:NITROGENIO Sem N  3   66.62750  22.20917 0.5836 0.6323\nResiduo                  21  799.14625  38.05458              \nTotal                    31 1400.29875  45.17093              \n------------------------------------------------------------------------\n\n\n\n ESPECIE  dentro do nivel  Com N  de  NITROGENIO \n------------------------------------------------------------------------\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    1   44.65 \na    2   43.55 \nab   4   36.55 \n b   3   30.65 \n------------------------------------------------------------------------\n\n\n ESPECIE  dentro do nivel  Sem N  de  NITROGENIO \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  35.75\n2      2  38.70\n3      3  41.30\n4      4  37.30\n------------------------------------------------------------------------\n\n\n\nDesdobrando  NITROGENIO  dentro de cada nivel de  ESPECIE \n------------------------------------------------------------------------\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                               GL         SQ        QM     Fc  Pr.Fc\nBloco                           3   18.72375   6.24125  0.164 0.9194\nESPECIE                         3  148.99375  49.66458 1.3051  0.299\nNITROGENIO:ESPECIE Aveia Preta  1  158.42000 158.42000  4.163 0.0541\nNITROGENIO:ESPECIE Centeio      1   47.04500  47.04500 1.2363 0.2788\nNITROGENIO:ESPECIE Pousio       1  226.84500 226.84500  5.961 0.0236\nNITROGENIO:ESPECIE Triticale    1    1.12500   1.12500 0.0296 0.8651\nResiduo                        21  799.14625  38.05458              \nTotal                          31 1400.29875  45.17093              \n------------------------------------------------------------------------\n\n\n\n NITROGENIO  dentro do nivel  Aveia Preta  de  ESPECIE \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  44.65\n2      2  35.75\n------------------------------------------------------------------------\n\n\n NITROGENIO  dentro do nivel  Centeio  de  ESPECIE \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  43.55\n2      2  38.70\n------------------------------------------------------------------------\n\n\n NITROGENIO  dentro do nivel  Pousio  de  ESPECIE \n------------------------------------------------------------------------\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    2   41.3 \n b   1   30.65 \n------------------------------------------------------------------------\n\n\n NITROGENIO  dentro do nivel  Triticale  de  ESPECIE \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  36.55\n2      2  37.30\n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo não a houve diferença para os efeitos principais (ESPECIE E NITROGÊNIO) mas deu interação entre estes fatores, vamos apresentar um gráfico mostrando essa interação. No gráfico, letras maiúsculas comparam as espécies dentro de cada manejo de N e minúsculas comparam o manejo de N dentro de cada espécie. As barras mostram a média e as barras de erro, o erro padrão da média.\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = NL,\n              lab.bar = c(\"Aa\", \"Aa\", \"Aa\", \"Aa\", \"Bb\", \"Aa\", \"ABa\", \"Aa\"),\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"Número de legumes por planta\")\n\n\n\n\n\n\nVariável número de grãos por legume (NGL)\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = NGL,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL      SQ QM     Fc    Pr>Fc\nBloco               3 0.19640  5 2.3475 0.101764\nESPECIE             3 0.14872  4 1.7776 0.182257\nNITROGENIO          1 0.08405  6 3.0138 0.097208\nESPECIE*NITROGENIO  3 0.14872  3 1.7776 0.182257\nResiduo            21 0.58565  2                \nTotal              31 1.16355  1                \n------------------------------------------------------------------------\nCV = 6.88 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.3640228 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis  Medias\n1 Aveia Preta 2.42250\n2     Centeio 2.32875\n3      Pousio 2.44375\n4   Triticale 2.52000\n------------------------------------------------------------------------\nNITROGENIO\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1  Com N 2.4800\n2  Sem N 2.3775\n------------------------------------------------------------------------\n\n\n\nCOMO NÃO DEU DIFERENÇA SIGNIFICATIVA PARA NENHUM FATOR, PODE-SE APENAS APRESENTAR O GRÁFICO, MAS SEM DISCUTIR DIFERENÇAS ENTRE OS TRATAMENTOS/N\n\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = NGL,\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"Número de grãos por legume\")\n\n\n\n\n\n\nVariável massa de mil grãos (MMG)\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = MMG,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL     SQ QM     Fc   Pr>Fc\nBloco               3 3409.4  2 6.5107 0.00275\nESPECIE             3 1309.4  5 2.5004 0.08733\nNITROGENIO          1   28.1  4 0.1611 0.69218\nESPECIE*NITROGENIO  3  209.4  6 0.3998 0.75454\nResiduo            21 3665.6  3               \nTotal              31 8621.9  1               \n------------------------------------------------------------------------\nCV = 7.4 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.858878 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis Medias\n1 Aveia Preta 176.25\n2     Centeio 171.25\n3      Pousio 188.75\n4   Triticale 177.50\n------------------------------------------------------------------------\nNITROGENIO\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis  Medias\n1  Com N 177.500\n2  Sem N 179.375\n------------------------------------------------------------------------\n\n\n\nCOMO NÃO DEU DIFERENÇA SIGNIFICATIVA PARA NENHUM FATOR, PODE-SE APENAS APRESENTAR O GRÁFICO, MAS SEM DISCUTIR DIFERENÇAS ENTRE OS TRATAMENTOS/N\n\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = MMG,\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"Massa de mil grãos (g)\")\n\n\n\n\n\n\nVariável RG\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = RG,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL       SQ QM      Fc   Pr>Fc\nBloco               3  9602221  4 1.97873 0.14806\nESPECIE             3   219192  6 0.04517 0.98689\nNITROGENIO          1   461200  5 0.28512 0.59897\nESPECIE*NITROGENIO  3  3950128  2 0.81400 0.50045\nResiduo            21 33969089  3                \nTotal              31 48201830  1                \n------------------------------------------------------------------------\nCV = 38.68 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.1875762 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis   Medias\n1 Aveia Preta 3368.403\n2     Centeio 3305.556\n3      Pousio 3150.000\n4   Triticale 3327.778\n------------------------------------------------------------------------\nNITROGENIO\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1  Com N 3167.882\n2  Sem N 3407.986\n------------------------------------------------------------------------\n\n\n\nCOMO NÃO DEU DIFERENÇA SIGNIFICATIVA PARA NENHUM FATOR, PODE-SE APENAS APRESENTAR O GRÁFICO, MAS SEM DISCUTIR DIFERENÇAS ENTRE OS TRATAMENTOS/N\n\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = RG,\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"RG (kg/ha)\")"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#doses-de-nitrogênio-x-híbridos-de-milho",
    "href": "FIT5306/FIT5306_10_FAT.html#doses-de-nitrogênio-x-híbridos-de-milho",
    "title": "10. Experimentos Fatoriais",
    "section": "Doses de Nitrogênio x híbridos de milho",
    "text": "Doses de Nitrogênio x híbridos de milho\n\nSem interação significativa\nO conjunto de dados utilizado neste exemplo será o FAT2_SI. Como já de conhecimento prévio, a interação não é significativa neste exemplo.\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\nFAT2_SI <- import(url, sheet = \"FAT2_SI\", setclass = \"tbl\")\nFAT2_SI\n\n# A tibble: 40 × 4\n   BLOCO HIBRIDO DOSEN    RG\n   <dbl> <chr>   <dbl> <dbl>\n 1     1 NUPEC_1     0  6.9 \n 2     1 NUPEC_1    25  7.44\n 3     1 NUPEC_1    50  7.65\n 4     1 NUPEC_1    75  7.5 \n 5     1 NUPEC_1   100  7.03\n 6     1 NUPEC_2     0  6.68\n 7     1 NUPEC_2    25  7.14\n 8     1 NUPEC_2    50  7.26\n 9     1 NUPEC_2    75  7.03\n10     1 NUPEC_2   100  6.69\n# … with 30 more rows\n\n\nA função fat2.rdb()é utilizada neste exemplo. Como o fator DOSEN é quantitativo, precisamos informar isto no argumento quali da função.\n\nwith(FAT2_SI, \n     fat2.dbc(fator1 =  HIBRIDO,\n              fator2 =  DOSEN,\n              bloco = BLOCO,\n              resp =  RG,\n              quali = c(TRUE, FALSE),\n              fac.names = c(\"HIBRIDO\", \"DOSE\")))\n\nComo a interação não foi significativa, proceder-se-a a comparação de médias dos dois híbridos considerando a média de todas as doses de nitrogênio, e o ajuste de apenas uma regressão para os dois híbridos. Como o grau do polinômio significativo foi quadrático, declararmos fit = 2 na função plot_lines() do pacote metan.\n\nh <- plot_bars(FAT2_SI, HIBRIDO, RG,\n               width.bar = 0.5,\n               lab.bar = c(\"a\", \"b\"))\nd <- plot_lines(FAT2_SI, DOSEN, RG,\n                fit = 2,\n                col = FALSE,\n                xlab = \"Doses de nitrogênio\",\n                ylab = \"Rendimento de grãos (Mg/ha)\") +\n  geom_text(aes(0, 6.5, label=(paste(expression(\"y = 6,8326 + 0,0012x - 0,0003x\"^2*\"  R\" ^2*\" = 0,99 \")))),\n            hjust = 0,\n            col = \"black\",\n            parse = TRUE) \narrange_ggplot(h, d, tag_levels = list(c(\"h\", \"d\")), widths = c(1, 3))\n\n\n\n\n\n\n\n\n\n\nCom interação significativa\nO conjunto de dados utilizado neste exemplo será o FAT2_CI. Neste exemplo já sabe-se que a interação híbrido x dose de N é significativa.\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\nFAT2_CI <- import(url, sheet = \"FAT2_CI\", setclass = \"tbl\")\nFAT2_CI\n\n# A tibble: 40 × 4\n   BLOCO HIBRIDO DOSEN    RG\n   <dbl> <chr>   <dbl> <dbl>\n 1     1 NUPEC_1     0 11.2 \n 2     1 NUPEC_1    25 12.4 \n 3     1 NUPEC_1    50 13   \n 4     1 NUPEC_1    75 12.5 \n 5     1 NUPEC_1   100 11.4 \n 6     1 NUPEC_2     0  9.22\n 7     1 NUPEC_2    25  9.70\n 8     1 NUPEC_2    50 10.1 \n 9     1 NUPEC_2    75 10.9 \n10     1 NUPEC_2   100 11.4 \n# … with 30 more rows\n\n\n\nwith(FAT2_CI, \n     fat2.dbc(fator1 =  HIBRIDO,\n              fator2 =  DOSEN,\n              bloco = BLOCO,\n              resp =  RG,\n              quali = c(TRUE, FALSE),\n              fac.names = c(\"HIBRIDO\", \"DOSE\")))\n## ------------------------------------------------------------------------\n## Legenda:\n## FATOR 1:  HIBRIDO \n## FATOR 2:  DOSE \n## ------------------------------------------------------------------------\n## \n## \n## Quadro da analise de variancia\n## ------------------------------------------------------------------------\n##              GL     SQ QM      Fc   Pr>Fc\n## Bloco         3  0.119  3    1.29 0.29725\n## HIBRIDO       1 40.076  6 1306.48 0.00000\n## DOSE          4  8.436  4   68.75 0.00000\n## HIBRIDO*DOSE  4  9.814  5   79.98 0.00000\n## Residuo      27  0.828  2                \n## Total        39 59.272  1                \n## ------------------------------------------------------------------------\n## CV = 1.56 %\n## \n## ------------------------------------------------------------------------\n## Teste de normalidade dos residuos (Shapiro-Wilk)\n## valor-p:  0.03477145 \n## ATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais!\n## ------------------------------------------------------------------------\n## \n## \n## \n## Interacao significativa: desdobrando a interacao\n## ------------------------------------------------------------------------\n## \n## Desdobrando  HIBRIDO  dentro de cada nivel de  DOSE \n## ------------------------------------------------------------------------\n## ------------------------------------------------------------------------\n## Quadro da analise de variancia\n## ------------------------------------------------------------------------\n##                  GL       SQ       QM       Fc  Pr.Fc\n## Bloco             3  0.11891  0.03964   1.2921 0.2972\n## DOSE              4  8.43556  2.10889  68.7499      0\n## HIBRIDO:DOSE 0    1 11.10618 11.10618 362.0622      0\n## HIBRIDO:DOSE 25   1 14.34872 14.34872 467.7692      0\n## HIBRIDO:DOSE 50   1 17.81448 17.81448  580.753      0\n## HIBRIDO:DOSE 75   1  6.55582  6.55582 213.7201      0\n## HIBRIDO:DOSE 100  1  0.06444  0.06444   2.1008 0.1587\n## Residuo          27  0.82822  0.03067                \n## Total            39 59.27234  1.51980                \n## ------------------------------------------------------------------------\n## \n## \n## \n##  HIBRIDO  dentro do nivel  0  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     11.56 \n##  b    NUPEC_2     9.2035 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  25  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     12.595 \n##  b    NUPEC_2     9.9165 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  50  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     12.935 \n##  b    NUPEC_2     9.9505 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  75  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     12.625 \n##  b    NUPEC_2     10.8145 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  100  de  DOSE \n## \n## De acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n## ------------------------------------------------------------------------\n##    Niveis  Medias\n## 1 NUPEC_1 11.5465\n## 2 NUPEC_2 11.3670\n## ------------------------------------------------------------------------\n## \n## \n## \n## Desdobrando  DOSE  dentro de cada nivel de  HIBRIDO \n## ------------------------------------------------------------------------\n## ------------------------------------------------------------------------\n## Quadro da analise de variancia\n## ------------------------------------------------------------------------\n##                      GL       SQ       QM        Fc  Pr.Fc\n## Bloco                 3  0.11891  0.03964    1.2921 0.2972\n## HIBRIDO               1 40.07604 40.07604 1306.4809      0\n## DOSE:HIBRIDO NUPEC_1  4  6.79944  1.69986   55.4156      0\n## DOSE:HIBRIDO NUPEC_2  4 11.44973  2.86243   93.3155      0\n## Residuo              27  0.82822  0.03067                 \n## Total                39 59.27234  1.51980                 \n## ------------------------------------------------------------------------\n## \n## \n## \n##  DOSE  dentro do nivel  NUPEC_1  de  HIBRIDO \n## ------------------------------------------------------------------------\n## Ajuste de modelos polinomiais de regressao\n## ------------------------------------------------------------------------\n## \n## Modelo Linear\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0  12.2517     0.0678    180.6175    0   \n## b1  0.00001     0.0011     0.0108  0.9914 \n## ------------------------------------------\n## \n## R2 do modelo linear\n## --------\n## 0.000001\n## --------\n## \n## Analise de variancia do modelo linear\n## ===================================================\n##                      GL   SQ     QM    Fc   valor.p\n## ---------------------------------------------------\n## Efeito linear        1    0      0      0   0.99144\n## Desvios de Regressao 3  6.7994 2.2665 73.89    0   \n## Residuos             27 0.8282 0.0307              \n## ---------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo quadratico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0  11.5550     0.0824    140.2044    0   \n## b1   0.0557     0.0039    14.2760     0   \n## b2  -0.0006     0.00004   -14.8843    0   \n## ------------------------------------------\n## \n## R2 do modelo quadratico\n## --------\n## 0.999458\n## --------\n## \n## Analise de variancia do modelo quadratico\n## ====================================================\n##                      GL   SQ     QM     Fc   valor.p\n## ----------------------------------------------------\n## Efeito linear        1    0      0      0    0.99144\n## Efeito quadratico    1  6.7958 6.7958 221.54    0   \n## Desvios de Regressao 2  0.0037 0.0018  0.06  0.94178\n## Residuos             27 0.8282 0.0307               \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo cubico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0  11.5623     0.0869    132.9870    0   \n## b1   0.0536     0.0088     6.0633     0   \n## b2  -0.0005     0.0002    -2.2190  0.0351 \n## b3 -0.000000       0      -0.2654  0.7927 \n## ------------------------------------------\n## \n## R2 do modelo cubico\n## --------\n## 0.999775\n## --------\n## \n## Analise de variancia do modelo cubico\n## ====================================================\n##                      GL   SQ     QM     Fc   valor.p\n## ----------------------------------------------------\n## Efeito linear        1    0      0      0    0.99144\n## Efeito quadratico    1  6.7958 6.7958 221.54    0   \n## Efeito cubico        1  0.0022 0.0022  0.07  0.79271\n## Desvios de Regressao 1  0.0015 0.0015  0.05  0.82509\n## Residuos             27 0.8282 0.0307               \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## \n##  DOSE  dentro do nivel  NUPEC_2  de  HIBRIDO \n## ------------------------------------------------------------------------\n## Ajuste de modelos polinomiais de regressao\n## ------------------------------------------------------------------------\n## \n## Modelo Linear\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0   9.2054     0.0678    135.7082    0   \n## b1   0.0209     0.0011    18.8680     0   \n## ------------------------------------------\n## \n## R2 do modelo linear\n## --------\n## 0.953756\n## --------\n## \n## Analise de variancia do modelo linear\n## ====================================================\n##                      GL   SQ      QM     Fc  valor.p\n## ----------------------------------------------------\n## Efeito linear        1  10.9202 10.9202 356     0   \n## Desvios de Regressao 3  0.5295  0.1765  5.75 0.00354\n## Residuos             27 0.8282  0.0307              \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo quadratico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0   9.2781     0.0824    112.5776    0   \n## b1   0.0151     0.0039     3.8624  0.0006 \n## b2   0.0001     0.00004    1.5534  0.1320 \n## ------------------------------------------\n## \n## R2 do modelo quadratico\n## --------\n## 0.960221\n## --------\n## \n## Analise de variancia do modelo quadratico\n## ====================================================\n##                      GL   SQ      QM     Fc  valor.p\n## ----------------------------------------------------\n## Efeito linear        1  10.9202 10.9202 356     0   \n## Efeito quadratico    1  0.0740  0.0740  2.41 0.13196\n## Desvios de Regressao 2  0.4555  0.2277  7.42 0.0027 \n## Residuos             27 0.8282  0.0307              \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo cubico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0   9.2414     0.0869    106.2918    0   \n## b1   0.0256     0.0088     2.8956  0.0074 \n## b2  -0.0002     0.0002    -1.0496  0.3032 \n## b3  0.000002       0       1.3271  0.1956 \n## ------------------------------------------\n## \n## R2 do modelo cubico\n## --------\n## 0.964939\n## --------\n## \n## Analise de variancia do modelo cubico\n## =====================================================\n##                      GL   SQ      QM     Fc   valor.p\n## -----------------------------------------------------\n## Efeito linear        1  10.9202 10.9202  356     0   \n## Efeito quadratico    1  0.0740  0.0740  2.41  0.13196\n## Efeito cubico        1  0.0540  0.0540  1.76  0.1956 \n## Desvios de Regressao 1  0.4014  0.4014  13.09 0.00121\n## Residuos             27 0.8282  0.0307               \n## -----------------------------------------------------\n## ------------------------------------------------------------------------\n\nA análise de indicou efeitos significativos tanto para os efeitos principais, quanto para a interação. Assim, as análises complementares realizadas foram (i) a comparação das médias pelo teste Tukey em cada nível da dose de N; e (ii) uma regressão polinomial ajustada para cada híbrido. Por padrão, o máximo grau do polinômio ajustado é 3 (modelo cúbico).\n\nComparação das médias dos híbridos em cada dose de nitrogênio.\n\nAs comparações de médias são apresentadas como saída da função fat2.dbc() após a análise de variância. Neste momento, utilizaremos a função plot_factbars() pacote metan** para plotar as médias dos híbridos em cada dose de nitrogênio. A apresentação gráfica de resultados, mesmo considerando médias, é uma alternativa interessante à tabela, pois permite uma interpretação mais clara e intuitiva dos resultados.\n\nplot_factbars(FAT2_CI, DOSEN, HIBRIDO,\n              resp = RG,\n              xlab = \"Doses de nitrogênio\",\n              ylab = expression(paste(\"Rendimento de grãos (Mg ha\"^-1,\")\")),\n              palette = \"Greys\",\n              lab.bar = c(\"a\", \"b\", # 0\n                          \"a\", \"b\", # 25\n                          \"a\", \"b\", # 50\n                          \"a\", \"b\", # 75\n                          \"a\", \"a\")) # 100\n\n\n\n\nGráfico das médias dos híbridos em cada dose de nitrogênio.\n\n\n\n\n\nAjuste de regressão para cada híbrido\n\nNo exemplo anterior, apresentamos as médias dos híbridos em cada dose de nitrogênio. Agora, criaremos um gráfico com o grau do polinômio significativo ajustado de cada híbrido. O grau a ser ajustado deve ser identificado na saída da ANOVA . Para fins didáticos apresento as equações que serão utilizadas.\nNUPEC_1: modelo quadrático \\(y = 11,555 + 0,05575\\times x -0,0005574\\times x^2, R^2 = 0.999\\)\nNUPEC_2: modelo linear \\(y = 9,2054 + 0,0209\\times x, R^2 = 0.986\\)\nUtilizando uma equação, é possível estimar a produtividade para uma dose de nitrogênio específica não testada, desde que ela esteja dentro do intervalo estudado. Para isto, basta substituir o x na equação pela dose a ser testada. Por exemplo, para estimar qual seria a produtividade do híbrido NUPEC_2 se tivéssemos aplicado 60 kg de N ha\\(^{-1}\\) basta resolver: \\(y = 9,2054 + 0,0209\\times 60\\), resultando em \\(y \\approx 10.5\\) Mg ha\\(^{-1}\\). A interpretação deste resultado, no entanto, deve ser cautelosa. Inconscientemente, concluiríamos que a produtividade do híbrido aumentaria 0,0209 Mg ha\\(^{-1}\\) a cada kg de nitrogênio aplicado por hectare. Este fato, no entanto, não é observado na prática. Por exemplo, a produtividade não irá aumentar infinitamente a medida em que se aumenta a dose de nitrogênio aplicado. A única conclusão válida, neste caso, é que a produtividade aumenta linearmente até 100 kg de N ha\\(^{-1}\\). Este resultado se deu em virtude de as doses testadas não terem sido o suficiente para identificar um outro comportamento na variável testada. Nestes casos, indica-se para estudos futuros aumentar o número de doses. Quando não se conhece o intervalo de dose em que a variável em estudo apresenta uma resposta explicável, estudos pilotos podem ser realizados. Neste caso, testar-se-iam o mesmo número de tratamentos (número de doses), no entanto com um intervalo maior entre as doses (por exemplo, 0, 100, 200, 300 e 400 kg de N ha\\(^{-1}\\). Possivelmente, nesta amplitude, o comportamento da produtividade não seria linear, pois em uma determinada dose, a produtividade estabilizaria.\nO ponto em X (dose) em que a produtividade é máxima é chamado de máxima eficiência técnica (MET) e pode ser estimado por:\n\\[\nMET = \\frac{{ - {\\beta _1}}}{{2 \\times {\\beta _2}}}\n\\]\nSubstituindo com os parâmetros estimados, temos:\n\\[\nMET = \\frac{{ - 0,05575}}{{2 \\times  -0,0005574}} = 50\n\\]\n\nx_met <- -0.05575 / (2 * -0.0005574)\nx_met\n\n[1] 50.00897\n\n\nLogo, a dose que proporciona a máxima produtividade para o híbrido NUPEC_1 é aproximadamente 50 kg de N ha\\(^{-1}\\). Assim para sabermos qual é esta produtividade estimada, basta substituir o x da equação por 50, resultando em \\(y_{máx}\\) = 12,949 Mg ha\\(^{-1}\\).\n\ny_met <- 11.555 + 0.05575 * 50 - 0.0005574 * 50^2\n\nOutro ponto importante que é possível de estimar utilizando uma equação de segundo grau, é a máxima eficiência econômica (MEE), ou seja, a dose máxima, neste caso de nitrogênio, em que é possível aplicar obtendo-se lucro. Este ponto é importante, pois a partir de uma certa dose, os incrementos em produtividade não compensariam o preço pago pelo nitrogênio aplicado. Este ponto pode ser facilmente estimado por:\n\\[\nMEE = MET + \\frac{u}{{2 \\times \\beta_2 \\times m}}\n\\]\nonde u e m são os preços do nitrogênio e do milho em grão, respectivamente, na mesma unidade utilizada para a estimativa da equação (neste caso, preço do nitrogênio por kg e preço do milho por tonelada). Considerando o preço de custo do nitrogênio como R$ 5,00 por kg e o preço de venda do milho a R$ 1300,00 por tonelada, substituindo-se na formula obtém-se:\n\\[\nMEE = 50 + \\frac{{5}}{{2 \\times (-0,0005574) \\times 1300}} \\approx 46\n\\]\nAssim, a dose máxima de nitrogênio que em que os incrementos de produtividade são lucrativos é de \\(\\approx 48\\) Kg ha\\(^{-1}\\).\n\nx_mee <- x_met + (5 / (2 * -0.0005574 * 1300))\nx_mee\n\n[1] 46.55889\n\n# predito na mee\n\ny_mee <- 11.555 + 0.05575 * x_mee - 0.0005574 * x_mee^2\ny_mee\n\n[1] 12.94237\n\n\nSemelhante ao exemplo das médias nas doses de nitrogênio, utilizaremos a função plot_factlines() para plotar, agora, uma regressão ajustada para cada híbrido. Os argumentos a serem informados são os seguintes: .data, o conjunto de dados (neste caso FAT2_CI); x e y, as colunas dos dados correspondentes aos eixos x e y do gráfico, respectivamente; group a coluna que contém os níveis dos fatores em que as regressões serão ajustadas; fit um vetor de comprimento igual ao número de níveis da coluna informada em group. O número indicado em cada posição do vetor, corresponde ao grau do polinômio ajustado (máximo grau ajustado = 4). Em nosso exemplo, utilizaremos fit = c(2, 1) para ajustar uma regressão quadrática para o híbrido NUPEC_1 e uma regressão linear para o híbrido NUPEC_2.\n\nplot_factlines(FAT2_CI, DOSEN, RG,\n               group = HIBRIDO,\n               fit = c(2, 1)) +\n  # Linhas e ponto da MET\n  geom_segment(aes(x = x_met,\n                   y = y_met,\n                   xend = x_met,\n                   yend = 8.5),\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_segment(aes(x = 0,\n                   y = y_met,\n                   xend = x_met,\n                   yend = y_met),\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_point(aes(x = x_met, y = y_met), shape = 19, size = 3, color = \"blue\") +\n  # Linhas e ponto da MEE\n  geom_segment(aes(x = x_mee,\n                   y = y_mee,\n                   xend = x_mee,\n                   yend = 8.5),\n               linetype = 2,\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_segment(aes(x = 0,\n                   y = y_mee,\n                   xend = x_mee,\n                   yend = y_mee),\n               linetype = 2,\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_point(aes(x = x_mee, y = y_mee), shape = 17, size = 3, color = \"blue\") +\n  # Equações no gráfico\n  geom_text(aes(0, 11,\n                label=(\n                  paste(\n                    expression(\"y = 11.555 + 0.05575x - 0.0005574x\"^2*\"  R\" ^2*\" = 0,999\"))\n                )\n  ),\n  hjust = 0,\n  size = 5,\n  col = \"black\",\n  parse = TRUE) + \n  geom_text(aes(0, 8.5,\n                label=(\n                  paste(\n                    expression(\"y = 9.2054 + 0.0209x R\" ^2*\" = 0,95\"))\n                )\n  ),\n  hjust = 0,\n  size = 5,\n  col = \"black\",\n  parse = TRUE) \n\n\n\n\nObservando-se a figura acima, é possível identificar o comportamento quadrático da variável resposta do híbrido NUPEC_1. Para este híbrido, houve um incremento positivo na produtividade até um ponto, posteriormente observa-se que a produtividade tendeu a reduzir. Uma explicação biológica para esta redução seria que o excesso de nitrogênio aplicado proporcionou um alto vigor vegetativo as plantas, podendo ter ocorrido competição entre as plantas por água, luz e outros nutrientes, ou até mesmo tombamento das plantas.\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html",
    "href": "FIT5306/FIT5306_11_REG.html",
    "title": "11. Regressão e correlação",
    "section": "",
    "text": "library(tidyverse)\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(AgroR)\nlibrary(broom)"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#introdução",
    "href": "FIT5306/FIT5306_11_REG.html#introdução",
    "title": "11. Regressão e correlação",
    "section": "Introdução",
    "text": "Introdução\nA análise de regressão tem como objetivo verificar como uma variável independente (x) influencia a resposta de uma variável dependente (y). A análise de regressão é amplamente utilizada nas ciências agrárias. O modelo mais simples de regressão linear é a de primeiro grau, descrita conforme o modelo a seguir:\n\\[\nY_i = {\\beta _0} + {\\beta _1}x + \\varepsilon_i  \n\\]\nOnde \\(Y_i\\) é o valor observado da variável dependente no i-ésimo nível da variável independente; \\(x_i\\) é o valor do i-ésimo nível da variável independente, \\(\\beta_0\\) é o intercepto (valor que a reta predita intercepta o eixo y quando x é igual a zero); \\(\\beta_1\\) é a inclinação da reta (quantas unidades mudam em y a cada unidade alterada em x) e \\(\\varepsilon\\) é o desvio."
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#o-problema",
    "href": "FIT5306/FIT5306_11_REG.html#o-problema",
    "title": "11. Regressão e correlação",
    "section": "O problema",
    "text": "O problema\n\n\n\n\n\n\nNote\n\n\n\nNo seguinte exemplo é apresentado o valor do rendimento de grãos de um certo híbrido de milho (eixo y) em função da dose de N (eixo x).\n\nx <- seq(0, 150, by = 25)\ny <- c(8.6, 8.9, 9.5, 9.9, 10, 10.2, 10.5)\ndf <- data.frame(x = x, y = y)\n\n# plotar os valores\nggplot(df, aes(x, y)) +\n  geom_point(size = 4, color = \"red\") + \n  geom_smooth(se = FALSE, method = \"lm\") +\n  scale_x_continuous(breaks = x) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y= \"Rendimento de grãos (t/ha)\")\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nO problema consiste em obter o valor de \\(\\beta_0\\) e \\(\\beta_1\\) de melhor ajuste para a equação, de modo que a soma de quadrado dos desvios (diferença entre os pontos observados e a reta de predição) seja mínima. Assim, adota-se o critério de obter a solução que minimiza soma dos quadrados dos resídulos (\\(\\sum\\nolimits_{i = 1}^n {{e_i}^2}\\)), método conhecido como Método dos Mínimos Quadrados\n\\[\n{b_1} = \\frac{{S{P_{xy}}}}{{S{Q_x}}}\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\n\\[\n{b_0} = \\bar y - {b_1} \\times \\bar x\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\nOnde\n\\[\nS{P_{xy}} = \\sum\\limits_{i = 1}^n {{x_i}{y_i}}  - \\frac{{\\left( {\\sum\\limits_{i = 1}^n {{x_i}} } \\right)\\left( {\\sum\\limits_{i = 1}^n {{y_i}} } \\right)}}{n}\n\\tag{1}\\]\n\\[\n\\\\S{Q_x} = \\sum\\limits_{i = 1}^n {x_i^2}  - \\frac{{{{\\left( {\\sum\\limits_{i = 1}^n {x_i^{}} } \\right)}^2}}}{n}\n\\tag{2}\\]\n\\[\n\\\\S{Q_y} = \\sum\\limits_{i = 1}^n {y_i^2}  - \\frac{{{{\\left( {\\sum\\limits_{i = 1}^n {y_i^{}} } \\right)}^2}}}{n}\n\\tag{3}\\]\nDe posse deste valor pode ser obtidas as somas de quadrados:\n\\[\nS{Q_{total}} = S{Q_y}\n\\]\n\\[\nS{Q_{reg}} = \\frac{{S{P_{xy}}^2}}{{S{Q_x}}}\n\\]\n\\[\nS{Q_{erro}} = S{Q_{total}} - S{Q_{reg}}\n\\]"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#estimação-dos-coeficientes",
    "href": "FIT5306/FIT5306_11_REG.html#estimação-dos-coeficientes",
    "title": "11. Regressão e correlação",
    "section": "Estimação dos coeficientes",
    "text": "Estimação dos coeficientes\nNo seguinte exemplo, são calculados as somas de x e y, as somas de \\(x^2\\) e \\(y^2\\) e também as somas de \\(x\\times y\\) .\n\ndf2 <- \n  mutate(df,\n         x2 = x ^ 2,\n         y2 = y ^ 2,\n         xy = x * y)\ndf2\n\n    x    y    x2     y2     xy\n1   0  8.6     0  73.96    0.0\n2  25  8.9   625  79.21  222.5\n3  50  9.5  2500  90.25  475.0\n4  75  9.9  5625  98.01  742.5\n5 100 10.0 10000 100.00 1000.0\n6 125 10.2 15625 104.04 1275.0\n7 150 10.5 22500 110.25 1575.0\n\n# número de pontos\n(n <- length(x))\n\n[1] 7\n\n# soma de xi\n(sum_xi <- sum(x))\n\n[1] 525\n\n# soma de xi ao quadrado\n(sum_xi2 <- sum(x ^ 2))\n\n[1] 56875\n\n# soma de yi\n(sum_yi <- sum(y))\n\n[1] 67.6\n\n# soma de yi ao quadrado\n(sum_yi2 <- sum(y ^ 2))\n\n[1] 655.72\n\n# soma de xi * yi\n(sum_xiyi <- sum(x * y))\n\n[1] 5290\n\n\nNote que estas mesmas somas podem ser obtidas facilmente utilizando duas outras abordagens. A primeira usando a função colSums() e outra a função apply().\n\ncolSums(df2)\n\n       x        y       x2       y2       xy \n  525.00    67.60 56875.00   655.72  5290.00 \n\napply(df2, 2, sum)\n\n       x        y       x2       y2       xy \n  525.00    67.60 56875.00   655.72  5290.00 \n\n\nDe posse destes valores é possível computar a soma de produtos de x e y , bem como suas somas de quadrados.\n\n# soma de produtos de X e Y\n(SPxy <- sum_xiyi - (sum_xi * sum_yi) / n)\n\n[1] 220\n\n# soma de quadrados de X\n(SQx <- sum_xi2 - (sum_xi ^2) / n)\n\n[1] 17500\n\n# soma de quadrados de Y\n(SQy <- sum_yi2 - (sum_yi ^ 2) / n)\n\n[1] 2.897143\n\n# computar o b1\n(b1 <- SPxy / SQx)\n\n[1] 0.01257143\n\n# computar o b0\n(b0 <- mean(y) - b1 * mean(x))\n\n[1] 8.714286"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#regressão-ajustada-e-tabela-anova",
    "href": "FIT5306/FIT5306_11_REG.html#regressão-ajustada-e-tabela-anova",
    "title": "11. Regressão e correlação",
    "section": "Regressão ajustada e tabela ANOVA",
    "text": "Regressão ajustada e tabela ANOVA\nA equação ajustada é então \\(y = 8,7142 + 0,01257x\\). As somas de quadrados de regressão e resídulo são dadas à seguir\n\n# soma de quadrado total\n(SQtot <- SQy)\n\n[1] 2.897143\n\n(SQreg <- SPxy ^ 2 / SQx)\n\n[1] 2.765714\n\n(SQerro <- SQtot - SQreg)\n\n[1] 0.1314286\n\n\nPode-se ainda obter a análise da variância da regressão, cujo esquema é apresentado a seguir na Tabela.\n\nFV <- c(\"Regressão\", \"Desvio\", \"Total\")\nGL <- c(1, n - 2, n - 1)\nSQ <- c(SQreg, SQerro, SQtot)\nQM <- SQ / GL\nFC <- c(QM[[1]] / QM[[3]], NA, NA)\ndata.frame(FV, GL, SQ, QM, FC) |> knitr::kable()\n\n\n\n\nFV\nGL\nSQ\nQM\nFC\n\n\n\n\nRegressão\n1\n2.7657143\n2.7657143\n5.727811\n\n\nDesvio\n5\n0.1314286\n0.0262857\nNA\n\n\nTotal\n6\n2.8971429\n0.4828571\nNA"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#grau-de-ajuste-do-modelo",
    "href": "FIT5306/FIT5306_11_REG.html#grau-de-ajuste-do-modelo",
    "title": "11. Regressão e correlação",
    "section": "Grau de ajuste do modelo",
    "text": "Grau de ajuste do modelo\nA proporção da variação de y que é explicada pelos níveis de x é conhecido como coeficiente de determinação (\\(R^2\\)) e é calculado por:\n\\[\nR^2 = \\frac{SQ_{reg}}{SQ_{tot}}\n\\]\n\n(R2 <- SQreg / SQtot)\n\n[1] 0.9546351\n\n\nPode-se ainda obter o (\\(R^2\\)) ajustado (\\(R^2_{adj}\\)) . O \\(R^2_{adj}\\) pode ser usado quando desejar comparar modelos que têm diferentes números de preditores. O (\\(R^2\\)) sempre aumenta quando você adiciona um preditor ao modelo, mesmo quando não existe uma verdadeira melhoria ao modelo. O valor de (\\(R^2_{adj}\\)) ajustado o número de preditores no modelo para ajudá-lo a escolher o modelo correto1, sendo calculado por:\n\\[\nR^2_{adj} = 1 -\\frac{(n - 1)(1 -  R^2)}{n - p}\n\\] Sendo que para a regressão linear simples estima-se 2 parâmetros (\\(\\beta_0\\) e \\(\\beta_1\\)).\n\nR2adj <- 1 - ((n - 1)*(1 - R2)) / (n - 2)\nR2adj\n\n[1] 0.9455621"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#valores-preditos-e-resíduos",
    "href": "FIT5306/FIT5306_11_REG.html#valores-preditos-e-resíduos",
    "title": "11. Regressão e correlação",
    "section": "Valores preditos e resíduos",
    "text": "Valores preditos e resíduos\nOs valores preditos são obtidos substituindo-se o x da equação pelo valor de x testado. Como o R trabalha de forma vetorizada, podemos facilmente obter os valores preditos para cada elemento de x com:\n\n(pred <- b0 + b1 * x)\n\n[1]  8.714286  9.028571  9.342857  9.657143  9.971429 10.285714 10.600000\n\n\nOs desvios são computados como a diferença entre o valor observado e o valor predito. Assim, pode calculá-los com:\n\n(desvios <- y - pred)\n\n[1] -0.11428571 -0.12857143  0.15714286  0.24285714  0.02857143 -0.08571429\n[7] -0.10000000\n\n\nFica fácil identificar estes desvios plotando-os no gráfico abaixo.\n\n# gráfico base\nggplot(df, aes(x, y)) +\n  geom_segment(aes(x = x,\n                   y = y,\n                   xend = x,\n                   yend = pred)) +\n  geom_point(size = 4, color = \"red\") + \n  geom_smooth(se = FALSE, method = \"lm\") +\n  scale_x_continuous(breaks = x) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y= \"Rendimento de grãos (t/ha)\")\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nA soma de quadrado dos desvios obtida anteriormente pode ser obtida aqui também, ao somarmos o quadrado dos desvios.\n\nsum(desvios ^ 2)\n\n[1] 0.1314286"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#a-função-lm",
    "href": "FIT5306/FIT5306_11_REG.html#a-função-lm",
    "title": "11. Regressão e correlação",
    "section": "A função lm()",
    "text": "A função lm()\nNo R, a função lm() (linear model) pode ser utilizada para ajustar a equação linear. Para isso, utiliza-se uma fórmula to tipo y ~ x (ou seja, y em função de x). Note que y e x são os nomes das variáveis presentes no data frame, informado no argumento data.\n\n# ajustar modelo de regressão linear\nmod <- lm(y ~ x, data = df)\n\n# coeficientes\nsummary(mod)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n       1        2        3        4        5        6        7 \n-0.11429 -0.12857  0.15714  0.24286  0.02857 -0.08571 -0.10000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 8.714286   0.110472   78.88  6.2e-09 ***\nx           0.012571   0.001226   10.26 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1621 on 5 degrees of freedom\nMultiple R-squared:  0.9546,    Adjusted R-squared:  0.9456 \nF-statistic: 105.2 on 1 and 5 DF,  p-value: 0.0001513\n\n# Análise de variância\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: y\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nx          1 2.76571 2.76571  105.22 0.0001513 ***\nResiduals  5 0.13143 0.02629                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nConferindo os resultados\n\n\n\nCompare os valores obtidos no cálculo passo-a-passo com os valores dos coeficientes obtidos com a função summary(mod) e anova(mod). Os valores conferem?\n\n\nNo código abaixo é criado um novo conjunto de dados, contendo os valores preditos e os resíduos.\n\n# valores preditos\npred <- \n  df %>% \n  mutate(predito = predict(mod),\n         residual = y - predito)\npred\n\n    x    y   predito    residual\n1   0  8.6  8.714286 -0.11428571\n2  25  8.9  9.028571 -0.12857143\n3  50  9.5  9.342857  0.15714286\n4  75  9.9  9.657143  0.24285714\n5 100 10.0  9.971429  0.02857143\n6 125 10.2 10.285714 -0.08571429\n7 150 10.5 10.600000 -0.10000000\n\n\nOs valores preditos são obtidos ao substituir o x da equação pelo valor utilizado. Pode-se criar uma função para retornar os valores preditos utilizando um modelo ajustado e o valor de x desejado. No seguinte exemplo, o valor de y quando x é 75 é calculado e plotado no gráfico.\n\n# modelo ajustado o valor predito para x = 75\n# função auxiliar\npred_linear <- function(mod, x){\n  b0 <- coef(mod)[[1]]\n  b1 <- coef(mod)[[2]]\n  pred <- b0 + b1 * x\n  return(pred)\n}\n\npred_75 <- pred_linear(mod, 75)\npred_75\n\n[1] 9.657143\n\nggplot(df, aes(x, y)) +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  geom_segment(aes(x = 75, y = 8.5, xend = 75, yend = pred_75)) +\n  geom_segment(aes(x = 0, y = pred_75, xend = 75, yend = pred_75)) +\n  geom_point(aes(x = 75, y = pred_75), color = \"blue\", size = 4) +\n  geom_point(size = 4, color = \"red\") + \n  scale_x_continuous(breaks = x) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y= \"Rendimento de grãos (t/ha)\",\n       title = \"Reta predita para o modelo de regressão\",\n       subtitle = \"O ponto azul representa o RG predito com 75 kg/ha de N\")\n\n`geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#regressão-linear-com-repetições",
    "href": "FIT5306/FIT5306_11_REG.html#regressão-linear-com-repetições",
    "title": "11. Regressão e correlação",
    "section": "Regressão linear com repetições",
    "text": "Regressão linear com repetições\n\nurl <- \"https://bit.ly/df_biostat\"\ndf_reg <- import(url, sheet = \"REG_DEL_DATA\", setclass = \"tbl\")\n\n\n# anova em DBC\ndf_factors <- df_reg %>% as_factor(1:2)\nanova <- aov(RG ~ DOSEN + BLOCO, data = df_factors)\ntidy(anova) %>% as.data.frame()\n\n       term df      sumsq     meansq statistic      p.value\n1     DOSEN  4 14.8617548 3.71543870  116.2335 1.737670e-09\n2     BLOCO  3  0.1568282 0.05227605    1.6354 2.333476e-01\n3 Residuals 12  0.3835836 0.03196530        NA           NA\n\n# regressão\nreg <- lm(RG ~ DOSEN, data = df_reg)\ntidy(reg) %>% as.data.frame()\n\n         term estimate   std.error statistic      p.value\n1 (Intercept) 8.434550 0.078237590 107.80687 9.383071e-27\n2       DOSEN 0.024222 0.001277614  18.95877 2.419233e-13\n\n# anova da regressão\nanova_reg <- aov(reg)\ntidy(anova_reg) %>% as.data.frame() %>% slice(1)\n\n   term df    sumsq   meansq statistic      p.value\n1 DOSEN  1 14.66763 14.66763   359.435 2.419233e-13\n\n# pontos plotados\nggplot(df_reg, aes(DOSEN, RG)) +\n  geom_point(color = \"red\") +\n  stat_summary(geom = \"point\",\n               fun = mean,\n               shape = 23) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y = \"Rendimento de grãos (t/ha)\") +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#polinômio-de-segundo-grau",
    "href": "FIT5306/FIT5306_11_REG.html#polinômio-de-segundo-grau",
    "title": "11. Regressão e correlação",
    "section": "Polinômio de segundo grau",
    "text": "Polinômio de segundo grau\nA regressão polinomial de segundo grau (que também é linear!) é uma outra opção muito útil para analisar dados que apresentem comportamento de parábola, por vezes observado em ensaios que testam dosagens de algum produto/fertilizante, etc. Neste tipo, um parâmetro a mais é adicionado ao modelo, ficando na forma:\n\\[\nY_i = {\\beta _0} + {\\beta _1}x + {\\beta _2}x^2 + \\varepsilon_i  \n\\]\nComo motivação, utilizaremos os dados abaixo. Para ajustar um modelo polinomial, utilizamos a função poly() e informamos o grau do polinômio desejado. É válido lembrar, que o grau máximo possível de polinômio é dado pelo número de níveis da variável independente/preditora menos 1.\n\nDOSEN <- c(0, 50, 100, 150, 200, 250)\nRG    <- c(7.1, 7.3, 7.66, 7.71, 7.62, 7.6)\ndf2 <- data.frame(DOSEN = DOSEN, RG = RG)\n\n# modelo de regressão\nmod2 <- lm(RG ~ poly(DOSEN, 2, raw = TRUE), data = df2)\nsummary(mod2)\n\n\nCall:\nlm(formula = RG ~ poly(DOSEN, 2, raw = TRUE), data = df2)\n\nResiduals:\n       1        2        3        4        5        6 \n 0.02500 -0.08243  0.07371  0.02343 -0.06329  0.02357 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  7.075e+00  7.013e-02 100.882 2.15e-06 ***\npoly(DOSEN, 2, raw = TRUE)1  7.184e-03  1.319e-03   5.445   0.0122 *  \npoly(DOSEN, 2, raw = TRUE)2 -2.071e-05  5.066e-06  -4.089   0.0264 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.07738 on 3 degrees of freedom\nMultiple R-squared:  0.9389,    Adjusted R-squared:  0.8982 \nF-statistic: 23.06 on 2 and 3 DF,  p-value: 0.0151\n\n# valores preditos\npred2 <- \n  df2 %>% \n  mutate(predito = predict(mod2),\n         residual = RG - predito)\npred2\n\n  DOSEN   RG  predito    residual\n1     0 7.10 7.075000  0.02500000\n2    50 7.30 7.382429 -0.08242857\n3   100 7.66 7.586286  0.07371429\n4   150 7.71 7.686571  0.02342857\n5   200 7.62 7.683286 -0.06328571\n6   250 7.60 7.576429  0.02357143\n\n# gráfico base\np1 <-\n  ggplot(df2, aes(DOSEN, RG)) +\n  geom_point(size = 4, color = \"red\") + \n  geom_smooth(se = FALSE,\n              method = \"lm\",\n              formula = y ~ poly(x, 2)) +\n  scale_x_continuous(breaks = DOSEN) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y = \"Rendimento de grãos (t/ha)\")\np1\n\n\n\n\nO ponto em X (dose de N) em que a produtividade é máxima é chamado de máxima eficiência técnica (MET) e pode ser estimado por:\n\\[\nMET = \\frac{{ - {\\beta _1}}}{{2 \\times {\\beta _2}}}\n\\]\nSubstituindo com os parâmetros estimados, temos:\n\\[\nMET = \\frac{{ - 0,007184}}{{2 \\times  -2,071^{-05}}} \\approx 173,4\n\\]\nNo R, podemos criar uma função auxiliar para calcular o ponto de MET.\n\n# máxima eficiência técnica\n# mod é o modelo quadrático ajustado\nmet <- function(mod){\n  b1 <- coef(mod)[[2]]\n  b2 <- coef(mod)[[3]]\n  res <- -b1 / (2 * b2)\n  return(res)\n}\n\nx_met <- met(mod2)\nx_met\n\n[1] 173.4138\n\n\nEm nosso exemplo, o ponto em x (dose de N) que proporciona o máximo rendimento predito é 173,413. Assim para sabermos qual é este rendimento estimado, basta substituir o x da equação por 173,4: \\(y = 7,075 + 0,007184\\times 173,413 -2,071^{-05}\\times 173,413^2 \\approx 7,70\\)\nUma função auxiliar para predição de y em um determinado valor de x considerando um modelo quadrático ajustado é fornecida abaixo.\n\n# valor predito para x = MET\n# função auxiliar\npred_quad <- function(mod, x){\n  b0 <- coef(mod)[[1]]\n  b1 <- coef(mod)[[2]]\n  b2 <- coef(mod)[[3]]\n  pred <- b0 + b1 * x + b2 * x ^ 2\n  return(pred)\n}\npred_met <- pred_quad(mod2, x = x_met)\npred_met\n\n[1] 7.697927\n\n\nOutro ponto importante que é possível de estimar utilizando uma equação de segundo grau, é a máxima eficiência econômica (MEE), ou seja, a dose máxima, neste caso de nitrogênio, em que é possível aplicar obtendo-se lucro. Este ponto é importante, pois a partir de uma certa dose, os incrementos em produtividade não compensariam o preço pago pelo nitrogênio aplicado. Este ponto pode ser facilmente estimado por:\n\\[\nMEE = MET + \\frac{u}{{2 \\times \\beta_2 \\times m}}\n\\]\nonde u e m são os preços do nitrogênio e do milho em grão, respectivamente, na mesma unidade utilizada para a estimativa da equação (neste caso, preço do nitrogênio por kg e preço do milho por tonelada). Considerando o preço de custo do nitrogênio como R 3 por kg e o preço de venda do milho a 1,300 por tonelada, substituindo-se na formula obtêm-se:\n\\[\nMEE = 173,41 + \\frac{{3,0}}{{2 \\times (-2,071^{-05}) \\times 1.300}} \\approx 117\n\\]\n\nmee <- function(mod, px, py){\n  x_met <- met(mod)\n  mee <- x_met + px / (2 * coef(mod)[[3]] * py)\n  return(mee)\n}\n\nx_mee <- mee(mod2, 3, 1300)\nx_mee\n\n[1] 117.7109\n\n\nAssim, a dose máxima de nitrogênio que em que os incrementos de produtividade são lucrativos é de \\(\\approx 117\\) Kg ha\\(^{-1}\\), em um rendimento estimado de \\(\\approx\\) 7,63 Mg ha\\(^{-1}\\).\n\n# Máxima eficiência econõmica (y)\nrg_mee <- pred_quad(mod2, x = x_mee)\nrg_mee\n\n[1] 7.633655\n\n\nDe posse das informações, um gráfico elaborado, que deveria ser apresentado em todo trabalho deste tipo pode ser confeccionado com a função plot_lines() do pacote metan combinado com algumas funções do pacote ggplot2. Sugiro a leitura do capítulo 8 deste material para mais informações sobre confecção de gráficos no R.\n\np1 +\n  labs(title = \"Equação quadrática\",\n       subtitle = \"Trigângulo e cículo representam os pontos de MME e MET, respectivamente\",\n       caption = \"MME = Máxima eficiência econômica\\n MET = máxima eficiência técnica\") +\n  # Linhas e ponto da MET\n  geom_segment(aes(x = x_met, y = pred_met, xend = x_met, yend = 6.7)) +\n  geom_segment(aes(x = 0, y = pred_met, xend = x_met, yend = pred_met)) +\n  geom_point(aes(x = x_met, y = pred_met), shape = 19, size = 3, color = \"blue\") +\n  # Linhas e ponto da MEE\n  geom_segment(aes(x = x_mee, y = rg_mee, xend = x_mee, yend = 6.7), linetype = 2) +\n  geom_segment(aes(x = 0, y = rg_mee, xend = x_mee, yend = rg_mee), linetype = 2) +\n  geom_point(aes(x = x_mee, y = rg_mee), shape = 17, size = 3, color = \"blue\") +\n  # Equação no gráfico\n  geom_text(aes(0, 7.9,\n                label=(\n                  paste(\n                    expression(\"y = 7.075 + 0.007184x - 2,071e\"^{-5}*\"x\"^2*\"  R\" ^2*\" = 0,938 \"))\n                )\n  ),\n  hjust = 0,\n  size = 5,\n  col = \"black\",\n  parse = TRUE)"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#exercício",
    "href": "FIT5306/FIT5306_11_REG.html#exercício",
    "title": "11. Regressão e correlação",
    "section": "Exercício",
    "text": "Exercício\n\nDados\n\nNeste exemplo, serão utilizados dados de produtividade de grãos de milho (Kg /ha) de acordo com diferentes doses de dejeto suíno (m3/ha) aplicadas na cultura do milho2.\n\n\nurl <- \"https://bit.ly/df_biostat\"\nreg_ex <- import(url, sheet = \"REG_EXERCICIO\", setclass = \"tbl\")\nreg_ex\n\n# A tibble: 4 × 2\n   DOSE    RG\n  <dbl> <dbl>\n1    20  7.09\n2    30  7.37\n3    40  8.28\n4    50  8.32\n\n\n\n\nCálculo dos coeficientes (manual)\n\nAjuste o modelo de regressão linear da forma \\(y_i = \\beta_0 + \\beta_1x_i\\), apresentando o valor dos parâmetros \\(\\beta_0\\) e \\(\\beta_1\\).\n\n\n(x <- reg_ex$DOSE)\n\n[1] 20 30 40 50\n\n(y <- reg_ex$RG)\n\n[1] 7.09 7.37 8.28 8.32\n\n# número de pontos\n(n <- length(x))\n\n[1] 4\n\n# médias\n(mx <- mean(x))\n\n[1] 35\n\n(my <- mean(y))\n\n[1] 7.765\n\n# soma de x\n(sumx <- sum(x))\n\n[1] 140\n\n# soma de y\n(sumy <- sum(y))\n\n[1] 31.06\n\n# soma de x * y\n(sumxy <- sum(x * y))\n\n[1] 1110.1\n\n# soma de x ao quadrado\n(sumx2 <- sum(x ^ 2))\n\n[1] 5400\n\n# soma de y ao quadrado\n(sumy2 <- sum(y ^ 2))\n\n[1] 242.3658\n\n# soma de produtos xy (SPxy)\n(SPxy <- sumxy - (sumx * sumy / n))\n\n[1] 23\n\n# soma de quadrados de x SQx\n(SQx <- sumx2 - sumx ^ 2 / n)\n\n[1] 500\n\n# soma de quadrados de y\n(SQy <- sumy2 - sumy ^ 2 / n)\n\n[1] 1.1849\n\n## coeficientes\n# b1\n(b1 <- SPxy / SQx)\n\n[1] 0.046\n\n# b0\n(b0 <- my - mx * b1)\n\n[1] 6.155\n\n# equação: y = 6150 + 6,15x\n\n\nInterprete o valor dos coeficientes, indicando sua aplicação prática.\n\n\n\n\n\n\n\nInterpretação dos coeficientes\n\n\n\nO intercept indica ….\no coeficiente angular…\n\n\n\nCalcule o valor do coeficiente de determinação (R2) do modelo ajustado e interprete os resultados\n\n\n################## SOMAS DE QUADRADOS DA REGRESSÃO E R2 ############\n\n# soma de quadrado total\n(SQtot <- SQy)\n\n[1] 1.1849\n\n# soma de quadrados da regressão\n(SQreg <- SPxy ^ 2 / (SQx))\n\n[1] 1.058\n\n# soma de quadrados do resíduo\n(SQres <- SQtot - SQreg)\n\n[1] 0.1269\n\n# coeficiente de determinação\n(R2 <- SQreg / SQtot)\n\n[1] 0.8929024\n\n\n\nRealize a predição da produtividade para uma dose de dejeto aplicado de 35 metros cúbicos por ha.\n\n\n# y predito com x = 35\n(yx35 <- b0 + b1 * 35)\n\n[1] 7.765\n\n\n\nAjuste a regressão no software R utilizando a função lm(). Após, construa um gráfico de dispersão com a reta de predição do modelo.\n\n\nreg <- lm(RG ~ DOSE, data = reg_ex)\n# coeficientes e R2\nsummary(reg)\n\n\nCall:\nlm(formula = RG ~ DOSE, data = reg_ex)\n\nResiduals:\n     1      2      3      4 \n 0.015 -0.165  0.285 -0.135 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  6.15500    0.41390  14.871  0.00449 **\nDOSE         0.04600    0.01126   4.083  0.05506 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2519 on 2 degrees of freedom\nMultiple R-squared:  0.8929,    Adjusted R-squared:  0.8394 \nF-statistic: 16.67 on 1 and 2 DF,  p-value: 0.05506\n\n# anova\nanova(reg)\n\nAnalysis of Variance Table\n\nResponse: RG\n          Df Sum Sq Mean Sq F value  Pr(>F)  \nDOSE       1 1.0580 1.05800  16.674 0.05506 .\nResiduals  2 0.1269 0.06345                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nGráfico\n\n\nMostrar código\nlibrary(ggpmisc) # adiciona a equação no gráfico\n\n\nWarning: package 'ggpmisc' was built under R version 4.2.1\n\n\nCarregando pacotes exigidos: ggpp\n\n\n\nAttaching package: 'ggpp'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\n\nMostrar código\np1 <-\n  ggplot(reg_ex, aes(DOSE, RG)) +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  geom_point(size = 4, color = \"blue\") +\n  stat_poly_eq(formula = y ~ x,\n               aes(label = paste(..eq.label.., ..rr.label.., sep = \"~~~~\")),\n               coef.digits = 5) +\n  labs(x = expression(Doses~de~dejeto~(m^3~ha^{-1})),\n       y = expression(Rendimento~de~grãos~(t~ha^{-1})),\n       title = \"Rendimento de grãos em função da dose de dejeto\")\n\np2 <-\n  ggplot(reg_ex, aes(DOSE, RG)) +\n    geom_abline(intercept = b0,\n              slope = b1,\n              color = \"red\") +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  geom_point(size = 4, color = \"blue\") +\n  stat_poly_eq(formula = y ~ x,\n               aes(label = paste(..eq.label.., ..rr.label.., sep = \"~~~~\")),\n               coef.digits = 5) +\n  labs(x = expression(Doses~de~dejeto~(m^3~ha^{-1})),\n       y = expression(Rendimento~de~grãos~(t~ha^{-1})),\n       title = expression(Compreendendo~o~intercept~(beta[0]))) +\n  scale_x_continuous(limits = c(0, 50),\n                     expand = expansion(c(0, 0.05))) +\n  scale_y_continuous(limits = c(6, 9),\n                     breaks = c(6, 6.155, 7, 8, 9)) +\n  theme(panel.grid.minor = element_blank())\n\np1 + p2\n\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n\n\nValores preditos\nPara obter os valores preditos, precisamos considerar os parâmetros estimados da regressão linear, substituindo o x pelos valores observados de x. Felizmente, a vetorização proporcionada pelo R, nos facilita este procedimento, bastando realizar o seguinte comando\n\n(pred <- b0 + b1 * x)\n\n[1] 7.075 7.535 7.995 8.455\n\n\nOs valores preditos também podem ser obtidos com a função predict(), informando o modelo ajustado\n\n(pred2 <- predict(reg))\n\n    1     2     3     4 \n7.075 7.535 7.995 8.455 \n\n\n\n\nResiduais\nOs resíduos são obtidos pela diferença entre os valores observados e os preditos pelo modelo ajustado. Para isso, utilizamos o seguinte comando:\n\n(res <- y - pred)\n\n[1]  0.015 -0.165  0.285 -0.135\n\n# o mesmo com a função residuals()\n(res2 <- residuals(reg))\n\n     1      2      3      4 \n 0.015 -0.165  0.285 -0.135 \n\n\nApenas para fins de comprovação, observe que a soma de quadrado do resíduo obtida anteriormente pode ser calculada agora como:\n\n(sqres2 <- sum(res ^ 2))\n\n[1] 0.1269\n\n\nPor fim, é possível mutar o conjunto de dados incluindo os valores preditos e residuais.\n\nmutate(reg_ex,\n       predito = pred,\n       residual = res)\n\n# A tibble: 4 × 4\n   DOSE    RG predito residual\n  <dbl> <dbl>   <dbl>    <dbl>\n1    20  7.09    7.07   0.0150\n2    30  7.37    7.53  -0.165 \n3    40  8.28    7.99   0.285 \n4    50  8.32    8.45  -0.135"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#cálculo-do-coeficiente-de-correlação",
    "href": "FIT5306/FIT5306_11_REG.html#cálculo-do-coeficiente-de-correlação",
    "title": "11. Regressão e correlação",
    "section": "Cálculo do coeficiente de correlação",
    "text": "Cálculo do coeficiente de correlação\nUtilizando o método dos mínimos quadrados, a correlação entre duas variáveis (x e y) é dada por:\n\\[\nr = \\frac{SP_{xy}}{\\sqrt{SQ_x\\times SQ_y}}\n\\]\nAs definições de \\(SP_{xy}\\), \\(SQ_{x}\\) e \\(SQ_{y}\\) foram apresentadas nas Equações Equation 1, Equation 2 e Equation 3, respectivamente.\nA significância da correlação (r) é testada utilizando um teste t com \\(t_{\\alpha(n-2)}\\) graus liberdade. As hipóteses são:\n\\[\n{H_0}:r = 0\n\\]\n\\[\n{H_1}:r \\ne 0\n\\]\nO valor de t calculado é dado por:\n\\[\n{t_0} = r\\sqrt {\\frac{{n - 2}}{{1 - {r^2}}}}\n\\]\nPor fim, compara-se o t calculado com o tabelado ao nível \\(\\alpha\\) de significância de erro (teste bilateral), com n menos dois graus liberdade.\n\\[\n{t_0} > {t_{\\alpha (n - 2)}} = r \\ne 0\n\\]"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#a-função-cor-do-r",
    "href": "FIT5306/FIT5306_11_REG.html#a-função-cor-do-r",
    "title": "11. Regressão e correlação",
    "section": "A função cor() do R",
    "text": "A função cor() do R\nUtilizando a função do R cor() é possível obter o coeficiente de correlação entre duas variáveis, por exemplo, APLA e AIES do seguinte conjunto de dados:\n\nurl <- \"https://bit.ly/df_biostat\"\ndf_mat <- \n  import(url, sheet = \"maize\", setclass = \"tbl\") |> \n  select(APLA:MGRA)\n\n# correlação de pearson (APLA e AIES)\ncor(df_mat$APLA, df_mat$AIES)\n\n[1] 0.8407699\n\n\nUma matriz de correlação também pode ser calculada informando um data frame de variáveis numéricas\n\n# Matriz gráfica de correlação\ncor(df_mat)\n\n          APLA      AIES      CESP      DIES      MGRA\nAPLA 1.0000000 0.8407699 0.2349817 0.4693013 0.5096475\nAIES 0.8407699 1.0000000 0.2080551 0.4588893 0.4649353\nCESP 0.2349817 0.2080551 1.0000000 0.3985263 0.6763286\nDIES 0.4693013 0.4588893 0.3985263 1.0000000 0.7649486\nMGRA 0.5096475 0.4649353 0.6763286 0.7649486 1.0000000\n\n\nUsando a função corr_plot() do pacote metan, é possível obter uma matriz mista (gráfico e número), contendo a distribuição dos pontos e o coeficiente de correlação entre as variáveis.\n\n# Matriz gráfica de correlação\ncorr_plot(df_mat)"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#exercício-1",
    "href": "FIT5306/FIT5306_11_REG.html#exercício-1",
    "title": "11. Regressão e correlação",
    "section": "Exercício",
    "text": "Exercício\n\nDados\n\nNeste exemplo, serão utilizados dados referentes ao número de grãos (NGRA) e massa de grãos (MGRA) observados em 15 espigas de milho (n = 15).\n\n\nurl <- \"https://bit.ly/df_biostat\"\ncor_ex <- import(url, sheet = \"COR_EXERCICIO\", setclass = \"tbl\")\n\n(x <- cor_ex$NGRA)\n\n [1] 519 522 624 670 518 547 670 546 444 611 557 702 443 430 481\n\n(y <- cor_ex$MGRA)\n\n [1] 173.5 213.5 221.1 261.5 220.1 177.8 250.8 192.0 193.5 255.6 245.9 207.4\n[13] 185.3 166.6 202.4\n\n(n <- length(x))\n\n[1] 15\n\n\n\n\nMétodo dos mínimos quadrados\n\n(xy <- x * y)\n\n [1]  90046.5 111447.0 137966.4 175205.0 114011.8  97256.6 168036.0 104832.0\n [9]  85914.0 156171.6 136966.3 145594.8  82087.9  71638.0  97354.4\n\n(x2 <- x ^ 2)\n\n [1] 269361 272484 389376 448900 268324 299209 448900 298116 197136 373321\n[11] 310249 492804 196249 184900 231361\n\n(y2 <- y ^ 2)\n\n [1] 30102.25 45582.25 48885.21 68382.25 48444.01 31612.84 62900.64 36864.00\n [9] 37442.25 65331.36 60466.81 43014.76 34336.09 27755.56 40965.76\n\n# soma de xy\n(somxy <- sum(xy))\n\n[1] 1774528\n\n# soma de x\n(somx <- sum(x))\n\n[1] 8284\n\n# soma de y\n(somy <- sum(y))\n\n[1] 3167\n\n# soma de x2\n(somx2 <- sum(x2))\n\n[1] 4680690\n\n# soma de y2\n(somy2 <- sum(y2))\n\n[1] 682086\n\n# adiciona as colunas nos dados originais usando mutate()\ncor_ex <-\n  mutate(cor_ex,\n         xy = xy,\n         x2 = x2,\n         y2 = y2)\ndata.frame(cor_ex)\n\n   NGRA  MGRA       xy     x2       y2\n1   519 173.5  90046.5 269361 30102.25\n2   522 213.5 111447.0 272484 45582.25\n3   624 221.1 137966.4 389376 48885.21\n4   670 261.5 175205.0 448900 68382.25\n5   518 220.1 114011.8 268324 48444.01\n6   547 177.8  97256.6 299209 31612.84\n7   670 250.8 168036.0 448900 62900.64\n8   546 192.0 104832.0 298116 36864.00\n9   444 193.5  85914.0 197136 37442.25\n10  611 255.6 156171.6 373321 65331.36\n11  557 245.9 136966.3 310249 60466.81\n12  702 207.4 145594.8 492804 43014.76\n13  443 185.3  82087.9 196249 34336.09\n14  430 166.6  71638.0 184900 27755.56\n15  481 202.4  97354.4 231361 40965.76\n\n# soma de produtos xy\n(sxy <- somxy - (somx * somy / n))\n\n[1] 25499.77\n\n# soma de quadrados de x\n(sx <- somx2 - somx ^ 2 / n)\n\n[1] 105712.9\n\n# soma de quadrados de y\n(sy <- somy2 - somy ^ 2 / n)\n\n[1] 13426.77\n\n# coeficiente de correlaçao\n(r <- sxy / (sqrt(sx * sy)))\n\n[1] 0.6768405\n\n# t calculado\n(tc <- r * sqrt((n - 2) / (1 - r ^ 2)))\n\n[1] 3.315153\n\n# t tabelado (cauda direita) = 2.16\n# como é bicaudal, considera-se 0.05 / 2\nqt(0.025, df = 13, lower.tail = FALSE)\n\n[1] 2.160369\n\n\n\n\nFunção cor e cor.test()\n\n# somente calcula o r\ncor(x, y)\n\n[1] 0.6768405\n\n# computa o r e realiza o teste de hipótese\ncor.test(x, y)\n\n\n    Pearson's product-moment correlation\n\ndata:  x and y\nt = 3.3152, df = 13, p-value = 0.005583\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2519252 0.8829624\nsample estimates:\n      cor \n0.6768405 \n\n\nFree website hit counter"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html",
    "href": "RGV410046/RGV410046_00_ABOUT.html",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "",
    "text": "Bem-vindo ao material de apoio da disciplina RGV410046 (Introdução à linguagem R de programação)! Esta página contém os dados e scripts R necessários para aplicação prática dos conteúdos vistos na disciplina."
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1150",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1150",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "21/11/2022 (08:20 às 11:50)",
    "text": "21/11/2022 (08:20 às 11:50)\n\nIntrodução à disciplina\nInstalação do R e Rstudio\nIntrodução ao R\n\nScript\nBásico de funções\nPacotes\nFóruns e materiais de apoio\n\nExercício (encontrar pacotes)"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1600",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1600",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "23/11/2022 (13:30 às 16:00)",
    "text": "23/11/2022 (13:30 às 16:00)\n\nDinâmica aula anterior\nTipos de dados\n\nNumérico\nLógico\nCaractere\n\nEstrutura de dados;\n\nVetor\nMatriz\nData frame\nTibbles\nArray\n\nLógica de programação\n\nBase\nTidyverse\n\nExercício (lógica de programação)"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1600-1",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1600-1",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "24/11/2022 (13:30 às 16:00)",
    "text": "24/11/2022 (13:30 às 16:00)\n\nImportação de dados (pc, repositório)\ndados tidy\nConversão de dados\nExercício descrição dos dados, arrumar tipo de dados\nExportação de dados"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1600-2",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1600-2",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "25/11/2022 (13:30 às 16:00)",
    "text": "25/11/2022 (13:30 às 16:00)\n\nMutação de dados\n\nselect\nfilter\narrange\nmutate\ngroup_by\n\n(dados próprios para o dia 1)"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1150-1",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1150-1",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "28/11/2022 (08:20 às 11:50)",
    "text": "28/11/2022 (08:20 às 11:50)\n\nSintetização de dados\n\nsummarise\nacross"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1600-3",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1600-3",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "30/11/2022 (13:30 às 16:00)",
    "text": "30/11/2022 (13:30 às 16:00)\n\nManipulação de dados\n\nLonger (dados errados, para arrumar)\nWider\nrename\nSeparate\nUnite"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1600-4",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1600-4",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "01/12/2022 (13:30 às 16:00)",
    "text": "01/12/2022 (13:30 às 16:00)\n\nSeus dados, suas análises"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#às-1500",
    "href": "RGV410046/RGV410046_00_ABOUT.html#às-1500",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "02/12/2022 (13:30 às 15:00)",
    "text": "02/12/2022 (13:30 às 15:00)\n\no básico do ggplot2\nFechamento da disciplina"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#médias-amostrais",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#médias-amostrais",
    "title": "6. Amostragem",
    "section": "Médias amostrais",
    "text": "Médias amostrais\nA seguinte função, computa a média das 120 amostras. Assim, obtém-se a distribuição das médias amostrais.\n\nmedias <- NULL\n# abordagem com for-loop\nfor (i in 1:nrow(amostras)) {\n  individ <- amostras[i,]\n  valores <- df2$x[individ]\n  medias <- append(medias, mean(valores))\n}\n\n# criar um data frame com as médias\ndf_medias <- data.frame(amostras) |> mutate(media = medias)\nhead(df_medias)\n\n  X1 X2 X3     media\n1  1  2  3  9.147707\n2  1  2  4 10.768314\n3  1  2  5  9.924465\n4  1  2  6  9.157814\n5  1  2  7 10.029746\n6  1  2  8 10.197009\n\ntail(df_medias)\n\n    X1 X2 X3     media\n115  6  8 10  9.741645\n116  6  9 10  9.633283\n117  7  8  9 11.201023\n118  7  8 10 10.613577\n119  7  9 10 10.505215\n120  8  9 10 10.672478\n\n\nAo computar a média das medias amostrais, obtém-se a média populacional\n\nmed_amostral <- mean(df_medias$media)\nmed_pop <-  mean(df2$x)\n\nidentical(med_amostral, med_pop)\n\n[1] TRUE\n\nggplot(df_medias, aes(x = media)) +\n  geom_histogram(bins = 8, color = \"black\", fill = \"gray\") +\n  geom_vline(xintercept = med_pop, color = \"red\", size = 1)"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#tamanho-da-amostra-vs-acurácia",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#tamanho-da-amostra-vs-acurácia",
    "title": "6. Amostragem",
    "section": "Tamanho da amostra vs acurácia",
    "text": "Tamanho da amostra vs acurácia\nNo seguinte exemplo, vamos investigar o impacto do tamanho da amostra na acurácia da média. Para isso, serão amostradas aleatoriamente 1:120 médias amostrais do conjunto df_medias e calculado o desvio em relação a média populacional. O processo é repetido nboot vezes utilizando a técnica bootstrap.\n\nnboot <- 200\n\nsamples <- list()\nfor(j in 1:nboot){\n  tmp <- \n    map_dbl(1:nrow(df_medias), function(x){\n      rows <- sample(1:nrow(df_medias), x)\n      mean(df_medias[rows,]$media)\n    })\n  samples[[j]] <- tmp\n}\n\n# cada coluna contém as médias amostrais de um procedimento bootstrap\nsamples <- do.call(cbind, lapply(samples, data.frame))\ncolnames(samples) <- paste0(\"v\", 1:ncol(samples))\n\n# criar dados longo\nsamples_long <- \n  samples |> \n  pivot_longer(everything()) |> \n  mutate(desvio  = value -  mean(df2$x),\n         x = rep(1:nrow(df_medias), each = nboot))\n\n# média dos procedimentos bootstrap\nsamples_mean <- \n  samples_long |> \n  group_by(x) |> \n  summarise(mu = mean(desvio))\n\n\n# criar o gráfico\nggplot(samples_long, aes(x = x,\n                         y = desvio,\n                         group = name)) +\n  geom_line(alpha = 0.1) +\n  geom_line(aes(x = x, y = mu, group = 1),\n            data = samples_mean,\n            color = \"red\") +\n  scale_x_continuous(breaks = seq(0, 120, by = 10)) +\n  theme_bw(base_size = 16) +\n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"Número de médias amostrais incluídas\",\n       y = \"Desvio em relação a média populacional\",\n       title = \"Resultado de 200 procedimentos bootstrap\",\n       caption = glue::glue(\"Média: {round(mean(df2$x), 3)}\"))"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#exemplo-da-altura-da-turma",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#exemplo-da-altura-da-turma",
    "title": "6. Amostragem",
    "section": "Exemplo da altura da turma",
    "text": "Exemplo da altura da turma\n\ndf_turma <- \n  import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=1590128876\") |> \n  metan::remove_rows_na()\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\nWarning: Row(s) 1, 2, 3, 5, 8, 10, 15, 22, 26, 27, 28, 31, 32, 33, 34, 40 with\nNA values deleted.\n\nlinhas <- sample(1:25, 4)\ndf_turma[linhas,]\n\n   id                          aluno crm altura\n39 39 Wanessa Pedrinha do Nascimento  xx    177\n24 24             Lucas Paz Claudino  xy    178\n19 19  José Eduardo Pimentel e Silva  xy    169\n9   9          Gabriel Loche Lopasso  xy    188\n\nset.seed(4)\n\nnboot <- 1000\n\nsamples <- list()\nfor(j in 1:nboot){\n  tmp <- \n    map_dbl(1:nrow(df_turma), function(x){\n      rows <- sample(1:nrow(df_turma), x)\n      mean(df_turma[rows,]$altura)\n    })\n  samples[[j]] <- tmp\n}\n\n# cada coluna contém as médias amostrais de um procedimento bootstrap\nsamples <- do.call(cbind, lapply(samples, data.frame))\ncolnames(samples) <- paste0(\"v\", 1:ncol(samples))\n\n# criar dados longo\nsamples_long <- \n  samples |> \n  pivot_longer(everything()) |> \n  mutate(desvio  = value -  mean(df_turma$altura),\n         x = rep(1:nrow(df_turma), each = nboot))\n\n# média dos procedimentos bootstrap\nsamples_mean <- \n  samples_long |> \n  group_by(x) |> \n  summarise(mu = mean(desvio))\n\n\n# criar o gráfico\nggplot(samples_long, aes(x = x,\n                         y = desvio,\n                         group = name)) +\n  geom_line(alpha = 0.1) +\n  geom_line(aes(x = x, y = mu, group = 1),\n            data = samples_mean,\n            color = \"red\") +\n  scale_x_continuous(breaks = seq(1, nrow(df_turma), by = 1)) +\n  theme_bw(base_size = 16) +\n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"Número de alunos incluídos na amostra\",\n       y = \"Desvio em relação a média populacional\",\n       title = \"Resultado de 200 procedimentos bootstrap\",\n       caption = glue::glue(\"Média: {round(mean(df_turma$altura), 3)}; N = {nrow(df_turma)}\"))"
  }
]