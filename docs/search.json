[
  {
    "objectID": "00_about.html",
    "href": "00_about.html",
    "title": "Material de apoio à disciplinas",
    "section": "",
    "text": "Esta página contém os materiais de apoio em linguagem R das disciplinas ministradas pelo Prof. Tiago Olivoto no Departamento de Fitotecnia do Centro de Ciências Agrárias da Universidade Federal de Santa Catarina\n\nInstalação dos softwares\nPara reprodução dos exemplos deste material, os softwares R e RStudio são necessários\n\n\n  \n\n\n\n\n\n Download do R\n Download do RStudio\n\n\nProfessor\n\n\n\n\n\n\nNote\n\n\n\nTécnico Agrícola pela Escola Estadual de Educação Básica Viadutos (2008), Engenheiro agrônomo pela Universidade do Oeste de Santa Catarina (2014), Mestre em Agronomia: Agricultura e Ambiente pela Universidade Federal de Santa Maria (2017) e Doutor em Agronomia com ênfase em Melhoramento Genético Vegetal e Experimentação Agrícola pela Universidade Federal de Santa Maria (2020). Atualmente é Professor Adjunto A1 do Departamento de Fitotecnia da Universidade Federal de Santa Catarina (UFSC), atuando na área de Melhoramento Genético Vegetal e Experimentação Agrícola. Exerce atividades relacionadas ao planejamento, condução e avaliação de experimentos com culturas anuais, com ênfase no desenvolvimento e aperfeiçoamento de métodos estatístico-experimentais para avaliação de ensaios multi-ambientes em melhoramento genético de plantas. Em seu Currículo, os termos mais frequentes na contextualização da produção científica são: análise de ensaios multi-ambientes, índices multivariados, intervalo de confiança para correlação, planejamento de experimentos, seleção indireta, interação genótipo-vs-ambiente, modelos mistos e parâmetros genéticos. É membro atuante da International Biometric Society (IBS) e integrante da comissão de Jovens Pesquisadores da Região Brasileira da Sociedade Internacional de Biometria, RBras, (JP-RBras) representando os estados do RS, SC e PR. Atua também como revisor ad hoc em revistas científicas nacionais e internacionais. Tem experiência com os softwares Gênes, GEA-R, R, SAS e SPSS. Vem desenvolvendo os pacotes para software R metan, voltado para a checagem, manipulação, análise e apresentação de dados de ensaios multi-ambientes e pliman voltado para a análise de imagens de plantas.\n\n\n\n\n\n\n\n\n\nPacotes úteis\nPara reprodução dos exemplos deste repositório é sugerido instalar os seguintes pacotes. Para saber como instalar pacotes no R, visite este vídeo!\n\nlibrary(tidyverse)  # manipulação de dados\nlibrary(metan)      # estatísticas descritivas/gráficos\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA\n\n\n\nLicença\nEste conteúdo está licenciado com uma Licença Creative Commons - Atribuição-NãoComercial-CompartilhaIgual 4.0 Internacional. O resumo legível da licença afirma que você tem o direito de:\n\nCompartilhar — copie e redistribua o material em qualquer meio ou formato.\nAdaptar — remixar, transformar e construir sobre o material\nAtribuir — Você deve dar o crédito apropriado, fornecer um link para a licença e indicar se foram feitas alterações. Você deve fazê-lo sob quaisquer circunstâncias razoáveis, mas de forma alguma sugerindo que o licenciante endossa você ou seu uso.\n\nEsta licença e válida sob os seguintes termos:\n\nNão comercial (NC) — Você não pode usar o material para fins comerciais.\nShare Alike (SA) — Se você remixar, transformar ou desenvolver o material, deverá distribuir suas contribuições sob a mesma licença do original.\nSem restrições adicionais — Você não pode aplicar termos legais ou medidas tecnológicas que restrinjam legalmente outras pessoas de fazer qualquer coisa que a licença permita.\n\n\n\nSelo DC\n\nO selo selo Democratizando Conhecimento (DC) é uma ideia criada pelo Prof. Ben Dêivid. O selo é compatível com a licença Creative Commons CC BY NC SA 4.0 e é utilizado aqui para garantir que o acesso de todo esse material seja livre, gratuíto e de código aberto. Meu principal objetivo com isso é democratizar o uso e aplicação do R nas Ciências Agrárias.\n\n\nVisite-nos!\n\n\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html",
    "href": "FIT5306/FIT5306_00_ABOUT.html",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "",
    "text": "Bem-vindo ao material de apoio da disciplina FIT5306 (Bioestatística e Experimentação Agrícola)! Esta página contém os dados e scripts R necessários para aplicação prática dos conteúdos vistos na disciplina."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#regressão",
    "href": "FIT5306/FIT5306_00_ABOUT.html#regressão",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Regressão",
    "text": "Regressão\n\nREG_DATA: dados sem repetição (hipotéticos) do RG observados em diferentes doses de Nitrogênio.\nREG_ANALISE: Análise de regressão linear de primeiro grau dos dados REG_DATA.\nREG_DEL_DATA: dados com repetições do rendimento de grãos observados em diferentes doses de Nitrogênio.\nREG_DEL_ANALISE: Análise de regressão dos dados REG_DEL_DATA.\nREG_PRATICA: dados referente a uma amostra de tamanho n = 11, na qual se aplicou CO2 em diferentes concentrações em folhas de trigo (X). A quantidade de C02 absorvida (Y) em cm3 / dm2 / hora foi avaliada. Esse exemplo foi apresentado por Ferreira (2009)[^1].\nREG_PRATICA_ANALISE: Análise de regressão dos dados REG_PRATICA."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#correlação",
    "href": "FIT5306/FIT5306_00_ABOUT.html#correlação",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Correlação",
    "text": "Correlação\n\nCOR_DATA_DENSIDADE: Dois métodos de mensurar a densidade média da madeira (g /cm\\(^3\\)) em Eucalyptus grandis foram aplicados a uma amostra de n = 13 árvores. O primeiro método (X) é determinado utilizando um paquímetro e uma sonda Pressler de 0,5 cm na região da árvore determinada no diâmetro à altura do peito (DAP). A segunda, variável (Y) também foi mensurada no DAP utilizando cortes transversais no tronco. Esse exemplo foi apresentado por Ferreira (2009)[^1].\nCORRELACAO_DATA: dados de altura de planta (AP) e altura da espiga (AE) observados em 10 plantas de milho.\nCORRELACAO_ANALISE: Análise de correlação para os dados CORRELACAO_DATA."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#experimentos-unifatoriais",
    "href": "FIT5306/FIT5306_00_ABOUT.html#experimentos-unifatoriais",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Experimentos unifatoriais",
    "text": "Experimentos unifatoriais\n\n\n\n\n\n\nNote\n\n\n\nOs dados COBERTURA_N_MASSA e COBERTURA_N_SOJA foram obtidos em um trabalho conduzido em grupo no Centro Universitário Unideau, tendo como participantes os alunos Bernardo Pinheiro Busatta, Tiago Jonatan Fochesatto, Diogo Andre Ody, Gustavo Peretti e Paulo Sérgio Trevisol.\n\n\n\nCOBERTURA_N_MASSA: dados de um experimento bifatorial com dois níveis de nitrogênio (com e sem) e quatro níveis de plantas de cobertura (aveia preta, centeio, triticale e pousio), conduzido em um DBC com quatro repetições. Foram avaliados a matéria verde (MV) e matéria seca (MS) das plantas, bem como a matéria seca de raiz (MSR).\nCOBERTURA_N_SOJA: Com os mesmos tratamentos apresentados em COBERTURA_N_MASSA, o experimento avaliou caracteres morfológicos e o rendimento de grãos de soja cultivada na resteva das respectivas coberturas de solo. Foram avaliados o número de legumes por planta (NL), número de grãos por legume (NGL), massa de mil grãos (MMG) e o rendimento de grãos (RG).\nDIC-DBC: dados de área foliar (AF) e matéria seca de planta (MST) de plantas de chicória avaliadas em diferentes níveis de radiação solar (50%, 70% e 100%). O experimento foi conduzido em delineamento de blocos completos casualizados, com quatro repetições.\nEFEITOS: Os efeitos de tratamento e erro (delineamento inteiramente casualizado) para os dados da planilha DIC-DBC.\nDIC-DBC-ANOVA: análise de variância nos delineamentos DIC e DBC, para efeitos de comparação, dos dados da planilha DIC-DBC.\nQUALI: Dados do rendimento de grãos (RG) de 10 híbridos de milho avaliados em um delineamento de blocos completos casualizados, com quatro repetições.\nQUANTI_LINEAR: Dados do rendimento de grãos (RG) de um híbrido de milho sob diferentes doses de nitrogênio, avaliados em um delineamento de blocos completos casualizados, com quatro repetições. O conjunto apresenta um comportamento linear.\nQUANTI_LINEAR: Dados do rendimento de grãos (RG) de um híbrido de milho sob diferentes doses de nitrogênio, avaliados em um delineamento de blocos completos casualizados, com quatro repetições. O conjunto apresenta um comportamento linear.\nQUANTI_QUADRÁTICA: Dados do rendimento de grãos (RG) de um híbrido de milho sob diferentes doses de nitrogênio, avaliados em um delineamento de blocos completos casualizados, com quatro repetições. O conjunto apresenta um comportamento quadrático.\nmaize: Dados de um ensaio multi-ambientes onde 13 híbridos de milho foram avaliados em quatro localidades, sendo que em cada localidade um delineamento de blocos completos casualizados com três repetições foi utilizado. São apresentados dados de sete caracteres quantitativos avaliados em cinco plantas aleatoriamente escolhidas em cada parcela."
  },
  {
    "objectID": "FIT5306/FIT5306_00_ABOUT.html#experimentos-bifatoriais",
    "href": "FIT5306/FIT5306_00_ABOUT.html#experimentos-bifatoriais",
    "title": "FIT5306 - Bioestatística e Experimentação Agrícola",
    "section": "Experimentos bifatoriais",
    "text": "Experimentos bifatoriais\nAs seguintes planilhas contém dados de experimentos bifatoriais com diferentes combinações de fatores qualitativos e quantitativos na presença de interação significativa e não significativa. Em todos os exemplos, é utilizado o delineamento de blocos completos casualizados.\n\nFAT1_SI: Fator 1 qualitativo (fontes de nitrogênio), com três níveis; Fator 2 qualitativo (híbridos), com três níveis, com interação significativa.\nFAT1_CI: Fator 1 qualitativo (dias de avaliação), com três níveis; Fator 2 qualitativo (radiação solar), com três níveis, sem interação significativa.\nFAT1_C2I1: Fator 1 Qualitativo (enxofre), com dois níveis; Fator 2 qualitativo (parcelamento de N), com três níveis, com interação significativa.\nFAT2_SI: Fator 1 qualitativo (híbridos), com dois níveis; Fator 2 quantitativo (doses de N), com cinco níveis, sem interação significativa.\nFAT2_CI: Fator 1 qualitativo (híbridos), com dois níveis; Fator 2 quantitativo (doses de N), com cinco níveis, com interação significativa.\nFAT3: Fator 1 quantitativo (doses de N), com quatro níveis; Fator 2 quantitativo (doses de K), com cinco níveis, com interação significativa.\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html",
    "href": "FIT5306/FIT5306_01_DESC.html",
    "title": "1. Estatística Descritiva",
    "section": "",
    "text": "library(tidyverse)\nlibrary(metan)"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#média",
    "href": "FIT5306/FIT5306_01_DESC.html#média",
    "title": "1. Estatística Descritiva",
    "section": "Média",
    "text": "Média\n\nMédia aritmética\nSeja uma amostra \\(X_1\\), \\(X_2\\), \\(X_n\\), de uma população \\(X_1\\), \\(X_2\\), \\(X_N\\) de tamanho \\(n\\) e \\(N\\), definimos a média aritmética por\n\\[\n\\mu  = \\frac{\\displaystyle\\sum_{i=1}^{N}X_i}{N}, \\quad \\textrm{(População)}\n\\]\n\\[\n\\bar{X} = \\frac{\\displaystyle\\sum_{i=1}^{n}X_i}{n}. \\quad \\textrm{(Amostra)}\n\\]\nConsidere a altura (em cm) de cinco plantas de milho, armazenada no objeto altura. Para calcular a média aritmética destas alturas, utilziamos a função mean().\n\naltura <- c(245, 250, 269, 280, 262)\nmean(altura)\n\n[1] 261.2\n\n\n\n\nMédia geométrica\nA média geométrica (\\(m_g\\)) entre um conjunto de n dados é a n-ésima raíz do produto desses dados.\n\\[\nm_g = \\sqrt[n]{\\prod\\limits_{i = 1}^n {{x_i}} }\n\\]\n\n\nMédia harmônica\nA média harmônica (\\(m_h\\)) é definida como sendo o inverso da média aritmética dos inversos, representada como segue\n\\[\nm_h = \\frac{n}{{\\sum\\limits_{i = 1}^n {\\frac{1}{{{x_i}}}} }}\n\\]\nA escolha pelo uso da média harmônica para representação da média de um conjunto está ligada a situações que envolvem grandezas inversamente proporcionais, por exemplo a velocidade média.\n\n\n\n\n\n\nExemplo de aplicação\n\n\n\nUm carro percorre um percurso de mesma distância duas vezes. No primeira, ele faz o percurso com uma velocidade V1 = 80 km/h. No segunda, ele realiza o mesmo percurso com velocidade de V2 = 120 km/h. Pede-se: qual foi a velocidade média dos dois percursos?\nIntuitivamente (e erroneamente) computaríamos a média aritmética (\\((80 + 120) / 2 = 100\\)). Note que a distância é a mesma, para os dois percursos, o que muda é a velocidade e, consequentemente, o tempo. A resolução correta do problema é a seguinte:\nSejam,\n\\(d\\), a distância do percurso \\(v_1\\), a velocidade média do percurso \\(t_i\\), o tempo de viagem do percurso\nEntão, temos que \\(d = v_1t_1=v_2t_2\\). Se \\(v\\) é a velocidad média nos dois trajetos, então \\(2d=v(t_1+t_2)\\), ou \\(2d=v(d/v_1+d/v_2)\\). Moral da história: a velocidade média no percurso todo é a média harmônica das velocidades dos dois percursos:\n\\[\nm_h = \\frac{2}{{{\\frac{1}{{{80}}} + \\frac{1}{{{120}}}} }} = 96\n\\]\n\n\nNo R base, não existe uma função específica para a média harmônica. Pode-se utilizar, então, a função hmean() do pacote metan2.\n\nlibrary(metan)\nhmean(c(80, 120))\n\n[1] 96"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#mediana",
    "href": "FIT5306/FIT5306_01_DESC.html#mediana",
    "title": "1. Estatística Descritiva",
    "section": "Mediana",
    "text": "Mediana\nA mediana é calculada com a função median().\n\naltura <- c(245, 250, 269, 280, 262)\n\n# Média\n(media <- mean(altura))\n\n[1] 261.2\n\n# Mediana\n# Ordenar os dados\nsort(altura)\n\n[1] 245 250 262 269 280\n\n# Calcular a mediana\n(mediana <- median(altura))\n\n[1] 262"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#amplitude",
    "href": "FIT5306/FIT5306_01_DESC.html#amplitude",
    "title": "1. Estatística Descritiva",
    "section": "Amplitude",
    "text": "Amplitude\nA primeira medida de dispersão que definiremos é a amplitude ou amplitude total, denotada por \\(A_p = X_{(max)} - X_{(min)}\\), onde \\(X_{(max)}\\) e \\(X_{(min)}\\) são os valores máximos e mínimos do conjunto de dados, respectivamente. Os valores extremos podem ser encontrados com a função range().\n\n(extremos <- range(altura))\n\n[1] 245 280\n\n(amplitude <- extremos[2] - extremos[1])\n\n[1] 35"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#desvios-médios",
    "href": "FIT5306/FIT5306_01_DESC.html#desvios-médios",
    "title": "1. Estatística Descritiva",
    "section": "Desvios médios",
    "text": "Desvios médios\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(X_n\\), de uma população \\(X_1\\), \\(X_2\\), \\(X_N\\) de tamanho \\(n\\) e \\(N\\), a soma dos desvios é dada por\n\\[\nDM  = \\sum_{i = 1}^{n} \\left(X_i - \\bar{X} \\right)\n\\]\nPara calcularmos os desvios, basta utilizar o operador - no R.\n\n(desvios <- altura - media)\n\n[1] -16.2 -11.2   7.8  18.8   0.8\n\n\nPara expressar estes desvios, vamos construir um gráfico utilizando o pacote ggplot2.\n\ndf <- data.frame(pessoa = paste(\"Planta\", 1:5),\n                 altura = altura,\n                 altura_media = media,\n                 desvio = desvios)\n\nggplot(df, aes(x = altura, y = pessoa)) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  geom_segment(aes(x = media,\n                   xend = altura,\n                   y = pessoa,\n                   yend = pessoa)) +\n  geom_vline(xintercept = media, linetype = 2, color = \"red\") +\n  geom_text(aes(x = altura, y = pessoa, label = round(desvio, digits = 3),\n                hjust = ifelse(desvio < 0, 1.5, -0.5))) +\n  scale_x_continuous(limits = c(230, 300)) + \n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"Altura da planta (cm)\",\n       y = \"Planta\")\n\n\n\n\nA expressão anterior resulta em\n\\[\nDM  = \\sum_{i = 1}^{n} \\left(X_i - \\bar{X} \\right) = 0\n\\]\n\nsum(desvios) |> round()\n\n[1] 0\n\n\nIsso significa que essa medida não traz ganho algum a descrição dos dados, porque os desvios positivos anulam-se com os desvios negativos no somatório. Para isso, podemos contornar essa situação inserindo uma função modular nessa medida anterior, e criar o módulo do desvio. Assim, o desvio médio é dado por:\n\\[\nS_{|\\bar{X}|} = \\frac{\\sum_{i = 1}^{n} \\left|X_i - \\bar{X} \\right|}{n}\n\\]\n\n# soma dos desvios em módulo\n(somadesv <- desvios |> abs() |> sum())\n\n[1] 54.8\n\n# desvio médio\nsomadesv / 5\n\n[1] 10.96"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#variância",
    "href": "FIT5306/FIT5306_01_DESC.html#variância",
    "title": "1. Estatística Descritiva",
    "section": "Variância",
    "text": "Variância\nUtilizando uma função quadrática na medida surge uma outra medida de variabilidade que é a soma de quadrados. A soma de quadrados apresenta uma outra informação interessante que é penalizar as observações quanto mais estiver distante do valor central. Assim, quando elevamos ao quadrado um alto desvio, esse valor se torna maior ainda, mas quando elevamos ao quadrado um desvio pequeno, esse valor não cresce tanto. Com isso, conseguimos compreender quais os dados que estão mais dispersos em torno da média. Ao dividir a soma de quadrados por \\(n-1\\) temos o estimador da variância amostral (\\(S^2\\)), dado por:\n\\[\nS^2 = \\frac{\\sum_{i = 1}^{n} \\left(X_i - \\bar X_i \\right)^2}{n-1}\n\\]\n\n# Desvios ao quadrado\n(desvq <- desvios ^ 2)\n\n[1] 262.44 125.44  60.84 353.44   0.64\n\n# soma dos desvios ao quadrado\n(somadesvq <- sum(desvq))\n\n[1] 802.8\n\n# divisão por n - 1\n(var_altura <- somadesvq / 4)\n\n[1] 200.7\n\n\nAnteriormente, vimos o passo a passo para o cálculo da variância amostral. No R, a função var() pode ser utilizada para este fim.\n\nvar(altura)\n\n[1] 200.7"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#desvio-padrão",
    "href": "FIT5306/FIT5306_01_DESC.html#desvio-padrão",
    "title": "1. Estatística Descritiva",
    "section": "Desvio padrão",
    "text": "Desvio padrão\nA variância, como medida de dispersão, apresenta sua unidade ao quadrado da unidade da variável em estudo. Em outras palavras, que se tivermos usando uma variável na escala de centímetros (ex., algura), a dispersão dada pela variância estará na escala de área (cm\\(^2\\)). Isso se torna difícil a percepção de dispersão quando observamos os dados. Para contornar isso, utilizamos o desvio padrão, que é a raíz quadrada da variância, dado por\n\\[\nS = \\sqrt{S^2}\n\\]\nPara o exemplo acima, computamos o desvio padrão extraíndo a raíz de var_altura, ou, como para a variância, utilizando uma função específica do R para isso: sd() (de standard deviation).\n\n(desv_altura <- sqrt(var_altura))\n\n[1] 14.16686\n\n# utilizando a função sd()\nsd(altura)\n\n[1] 14.16686"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#coeficiente-de-variação",
    "href": "FIT5306/FIT5306_01_DESC.html#coeficiente-de-variação",
    "title": "1. Estatística Descritiva",
    "section": "Coeficiente de variação",
    "text": "Coeficiente de variação\nAs medidas de variabilidade tais como a variância e desvio padrão, são conhecidas como medidas de dispersão absoluta. Isto significa que elas serão diretamente influenciadas pela magnitude da variável. Vamos tomar como motivação, os valores em altura, tomados em cm. Consideremos que estes dados são transformados para metros, por tanto, cada observação será dividida por 100. Observe abaixo o resultado do desvio padrão da mesma variável, mas com escala diferente.\n\n(altura_m <- altura / 100)\n\n[1] 2.45 2.50 2.69 2.80 2.62\n\n(desv_altura_m <- sd(altura_m))\n\n[1] 0.1416686\n\n\nPara contornar este problema, podemos utilizar uma medida relativa de variabilidade chamada de Coeficiente de Variação (CV). Este pode ser usada para comparar a variabilidade entre quaisquer grupo de dados, independentemente da sua escala. O coeficiente de variação é definido por:\n\\[\nCV = \\frac{S}{\\bar{X}} \\times 100\n\\]\n\n# coeficiente de variação da variável em centímetros\n(cv_altura <- desv_altura / media * 100)\n\n[1] 5.423761\n\n# coeficiente de variação da variável em metros\n(cv_altura2 <- desv_altura_m / mean(altura_m) * 100)\n\n[1] 5.423761\n\n\nNão existe no R base uma função para computar o coeficiente de variação, então vamos criá-la utilizando a abordagem function().\n\nCV <- function(dados){\n  if(!class(dados) == \"numeric\"){\n    stop(\"Os dados precisam ser numéricos\")\n  } #Indica que os dados devem ser numéricos\n  media <- mean(dados)\n  sd <- sd(dados)\n  CV <- (sd/media) * 100\n  return(CV) # Valor que será retornado pela função\n}\n\nCV(altura)\n\n[1] 5.423761"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#erro-padrão-da-média",
    "href": "FIT5306/FIT5306_01_DESC.html#erro-padrão-da-média",
    "title": "1. Estatística Descritiva",
    "section": "Erro padrão da média",
    "text": "Erro padrão da média\nO erro padrão da média é a estimativa do desvio padrão de sua distribuição amostral. O desvio padrão visto anteriormente reflete a variabilidade de cada observação em torno da média amostral. Já o erro padrão da média, representa a variabilidade de cada média amostral de todas amostra possíveis, em relação a média populacional. Sua estimativa é dada por:\n\\[\nS_{\\bar{X}}  = \\frac{S}{\\sqrt{n}}\n\\]\nÉ fácil observar que à medida que \\(n \\to N\\), isto é, à medida que\n\\(n\\) aumenta, a média amostral (\\(\\bar X\\)) tende a média populacional (\\(\\mu\\)). Isso significa que a média amostral é mais precisa porque se aproxima cada vez mais da média populacional. Para os dados em altura, o erro padrão da média é calculado com:\n\n(epm <- desv_altura / sqrt(5))\n\n[1] 6.335614"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#exemplo-da-altura-de-planta",
    "href": "FIT5306/FIT5306_01_DESC.html#exemplo-da-altura-de-planta",
    "title": "1. Estatística Descritiva",
    "section": "Exemplo da altura de planta",
    "text": "Exemplo da altura de planta\nPara calcular todas as estatísticas de uma só vez, podemos usar desc_stat() do pacote metan. Esta função pode ser usada para calcular medidas de tendência central, posição e dispersão. Por padrão (stats = \"main\"), sete estatísticas (coeficiente de variação, máximo, média, mediana, mínimo, desvio padrão da amostra, erro padrão e intervalo de confiança da média) são calculadas. Outros valores permitidos são \"all\" para mostrar todas as estatísticas, \"robust\" para mostrar estatísticas robustas, \"quantile\" para mostrar estatísticas quantílicas ou escolher uma (ou mais) estatísticas usando um vetor separado por vírgula com os nomes das estatísticas, por exemplo, stats = c(\"mean, cv\"). Também podemos usar hist = TRUE para criar um histograma para cada variável. Para mais detalhes consulte este material.\n\nlibrary(metan)\ndesc_stat(altura, stats = \"all\") |> as.data.frame()\n\n  variable av.dev    ci.t    ci.z     cv    gmean    hmean iqr    kurt     mad\n1      val  10.96 17.5905 12.4176 5.4238 260.8937 260.5887  19 -1.3829 17.7912\n  max  mean median min n n.valid n.missing n.unique      ps  q2.5 q25 q75 q97.5\n1 280 261.2    262 245 5       5         0        5 14.0741 245.5 250 269 278.9\n  range  sd.amo  sd.pop     se   skew  sum sum.dev ave.dev sum.sq.dev var.amo\n1    35 14.1669 12.6712 6.3356 0.2144 1306    54.8   10.96      802.8   200.7\n  var.pop\n1  160.56\n\n# estatísticas vistas neste material\ndesc_stat(altura,\n          stats = c(\"mean, median, range, ave.dev, var.amo, sd.amo, cv, se\")) |> \n  as.data.frame()\n\n  variable  mean median range ave.dev var.amo  sd.amo     cv     se\n1      val 261.2    262    35   10.96   200.7 14.1669 5.4238 6.3356"
  },
  {
    "objectID": "FIT5306/FIT5306_01_DESC.html#exemplo-com-os-dados-coletados-em-aula",
    "href": "FIT5306/FIT5306_01_DESC.html#exemplo-com-os-dados-coletados-em-aula",
    "title": "1. Estatística Descritiva",
    "section": "Exemplo com os dados coletados em aula",
    "text": "Exemplo com os dados coletados em aula\nNeste exemplo, mostro como as estatísticas descritivas para os dados coletados em aula podem ser calculadas utilizando o pacote metan. Os dados são importados diretamente da planilha armazenada no drive, utilizando a função import() do pacote rio.\n\nlibrary(rio)\n\nWarning: package 'rio' was built under R version 4.2.2\n\n# link dos dados\nlink <- \"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=0\"\n\n# função para importar os dados\ndf <- \n  import(link, dec = \",\") |> \n  as_character(1:2) \n\n# estrutura dos dados \nstr(df)\n\n'data.frame':   21 obs. of  4 variables:\n $ ramo       : chr  \"Ramo 1\" \"Ramo 1\" \"Ramo 1\" \"Ramo 1\" ...\n $ observacao : chr  \"1\" \"2\" \"3\" \"4\" ...\n $ comprimento: num  16 15 16.5 16 15 13 16.5 16 14 15 ...\n $ largura    : num  6 6 7.5 7 6.5 5 6 6 5.9 6.5 ...\n\n# primeiras linhas\nhead(df)\n\n    ramo observacao comprimento largura\n1 Ramo 1          1        16.0     6.0\n2 Ramo 1          2        15.0     6.0\n3 Ramo 1          3        16.5     7.5\n4 Ramo 1          4        16.0     7.0\n5 Ramo 1          5        15.0     6.5\n6 Ramo 1          6        13.0     5.0\n\n\nOs dados foram organziados de maneira que cada fator/variável estivessem em uma coluna. Isto possibilita o cálculo das estatísticas para cada nível destes fatores. As duas variáveis quantitativas contínuas são: comprimento (o comprimento da folha em cm); e largura(largura da folha em mm).\n\nEstatísticas gerais\nPara saber as estatísticas descritivas gerais vamos utilizar a função desc_stat9). Por padrão, a função calcula as estatísticas descritivas para todas as variáveis numéricas do conjunto de dados. Sendo assim, não há necessidade de informar qual variável analisar.\n\nstats = c(\"mean, median, range, ave.dev, var.amo, sd.amo, cv, se, n\")\ndf |> \n  desc_stat(stats = stats)\n\n# A tibble: 2 × 10\n  variable     mean median range ave.dev var.amo sd.amo    cv    se     n\n  <chr>       <dbl>  <dbl> <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 comprimento 13.2    14.2   9     2.37     8.21   2.86  21.6 0.625    21\n2 largura      5.67    6     3.7   0.969    1.24   1.12  19.7 0.243    21\n\n\n\n\nEstatísticas por ramo\nPara obter as estatística para cada ramo, basta vamos utilizar a função group_by() para agrupar por ramo. Com isso, as estatísticas serão calculadas separadamente para ramo 1 e ramo 2.\n\ndf |> \n  group_by(ramo) |> \n  desc_stat(stats = stats)\n\n# A tibble: 4 × 11\n  ramo   variable     mean median range ave.dev var.amo sd.amo    cv    se     n\n  <chr>  <chr>       <dbl>  <dbl> <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 Ramo 1 comprimento 13.5    15     9     2.46     8.92   2.99  22.1 0.771    15\n2 Ramo 1 largura      5.59    6     3.7   0.941    1.24   1.12  19.9 0.288    15\n3 Ramo 2 comprimento 12.6    13.8   6.1   2.24     7.09   2.66  21.2 1.09      6\n4 Ramo 2 largura      5.87    6.5   2.8   1.01     1.43   1.19  20.4 0.488     6\n\n\n\n\nBoxplot (descritiva e teste t)\n\nlibrary(ggstatsplot)\n\nWarning: package 'ggstatsplot' was built under R version 4.2.2\n\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\nggbetweenstats(df,\n               x = ramo,\n               y = comprimento,\n               plot.type = \"box\",\n               ylab = \"rendimento\")"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html",
    "href": "FIT5306/FIT5306_02_FREQ.html",
    "title": "2. Distribuição de frequências",
    "section": "",
    "text": "Uma forma de lidar com grandes conjuntos de dados e identificar informações relevantes é agrupar estes dados. O agrupamento é feito em tabelas, denominadas de distribuições de frequências. A construção de distribuição de frequências é geralmente realizada de forma distinta para variáveis discretas (distribuição por pontos) e contínuas (distribuição por classes ou intervalos).\nNeste exemplo, vamos utilizar os dados coletados do comprimento, diâmetro e cor de grão de café."
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#representação-tabular",
    "href": "FIT5306/FIT5306_02_FREQ.html#representação-tabular",
    "title": "2. Distribuição de frequências",
    "section": "Representação tabular",
    "text": "Representação tabular\nPode-se criar facilmente esta tabela de frequência combinando as funções count() e mutate() do pacote dplyr (parte do tidyverse).\n\ntab_feq <- \n  df %>%\n  count(cor_grao) |>\n  mutate(abs_freq = n,\n         abs_freq_ac = cumsum(abs_freq),\n         rel_freq = abs_freq / sum(abs_freq),\n         rel_freq_ac = cumsum(rel_freq))\n\nknitr::kable(tab_feq)\n\n\n\n\ncor_grao\nn\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\namarelo\n6\n6\n6\n0.2142857\n0.2142857\n\n\nverde\n15\n15\n21\n0.5357143\n0.7500000\n\n\nvermelho\n7\n7\n28\n0.2500000\n1.0000000"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#representação-gráfica",
    "href": "FIT5306/FIT5306_02_FREQ.html#representação-gráfica",
    "title": "2. Distribuição de frequências",
    "section": "Representação gráfica",
    "text": "Representação gráfica\nPara apresentar estes dados graficamente, pode-se construir um gráfico de barras, mostrando a contagem em cada classe.\n\nggplot(df, aes(cor_grao)) + \n  geom_histogram(stat=\"count\") +\n  scale_y_continuous(breaks = 0:15) + \n  labs(x = \"Cor do grão\",\n       y = \"Número de observações\") +\n  theme(panel.grid.minor = element_blank())\n\nWarning in geom_histogram(stat = \"count\"): Ignoring unknown parameters:\n`binwidth`, `bins`, and `pad`"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#apresentação-tabular",
    "href": "FIT5306/FIT5306_02_FREQ.html#apresentação-tabular",
    "title": "2. Distribuição de frequências",
    "section": "Apresentação tabular",
    "text": "Apresentação tabular\n\nfrequencias <- freq_table(df, comp_grao)\nknitr::kable(frequencias$freqs)\n\n\n\n\n\n\n\n\n\n\n\nclass\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\n8.229 |— 9.952\n2\n2\n0.071\n0.071\n\n\n9.952 |— 11.675\n5\n7\n0.179\n0.250\n\n\n11.675 |— 13.398\n10\n17\n0.357\n0.607\n\n\n13.398 |— 15.121\n8\n25\n0.286\n0.893\n\n\n15.121 |—| 16.844\n3\n28\n0.107\n1.000\n\n\nTotal\n28\n28\n1.000\n1.000"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#apresentação-gráfica",
    "href": "FIT5306/FIT5306_02_FREQ.html#apresentação-gráfica",
    "title": "2. Distribuição de frequências",
    "section": "Apresentação gráfica",
    "text": "Apresentação gráfica\n\nfreq_hist(frequencias)"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#cor-do-grão-do-café",
    "href": "FIT5306/FIT5306_02_FREQ.html#cor-do-grão-do-café",
    "title": "2. Distribuição de frequências",
    "section": "Cor do grão do café",
    "text": "Cor do grão do café\n\ndf_cor_grao <- import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=1550268554\",\n                      dec = \",\")\n\nfreq_cafe <- freq_table(df_cor_grao, var = cor)\nknitr::kable(freq_cafe$freqs)\n\n\n\n\ncor\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\namarelo\n6\n6\n0.25\n0.25\n\n\nverde\n18\n24\n0.75\n1.00\n\n\nTotal\n24\n24\n1.00\n1.00\n\n\n\n\n# criar um histograma\nfreq_hist(freq_cafe)"
  },
  {
    "objectID": "FIT5306/FIT5306_02_FREQ.html#comprimento-da-folha-do-café",
    "href": "FIT5306/FIT5306_02_FREQ.html#comprimento-da-folha-do-café",
    "title": "2. Distribuição de frequências",
    "section": "Comprimento da folha do café",
    "text": "Comprimento da folha do café\n\ncomp_folha <- import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=0\",\n                    dec = \",\")\n\n# Tabela\ndist_comprimento <- freq_table(comp_folha, var = comprimento)\nknitr::kable(dist_comprimento$freqs)\n\n\n\n\n\n\n\n\n\n\n\nclass\nabs_freq\nabs_freq_ac\nrel_freq\nrel_freq_ac\n\n\n\n\n6.375 |— 8.625\n2\n2\n0.095\n0.095\n\n\n8.625 |— 10.875\n3\n5\n0.143\n0.238\n\n\n10.875 |— 13.125\n3\n8\n0.143\n0.381\n\n\n13.125 |— 15.375\n8\n16\n0.381\n0.762\n\n\n15.375 |—| 17.625\n5\n21\n0.238\n1.000\n\n\nTotal\n21\n21\n1.000\n1.000\n\n\n\n\n# Gráfico\nfreq_hist(dist_comprimento)"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html",
    "title": "3. Distribuições discretas",
    "section": "",
    "text": "Um modelo probabilístico é um modelo em que, à priori, não é possível definir um resultado particular. Este modelo é especificado por meio de uma distribuição de probabilidade. Geralmente, modelos probabilísticos são utilizados quando se tem um grande número de variáveis influenciando o resultado e estas variáveis não podem ser controladas. Como exemplo, pode-se citar a observação da germinação de uma semente, o lançamento de um dado, onde tenta-se prever o número da face que irá sair, etc."
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#um-exemplo-simples",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#um-exemplo-simples",
    "title": "3. Distribuições discretas",
    "section": "Um exemplo simples",
    "text": "Um exemplo simples\nConsideremos a variável aleatória discreta X como o sexo de um bezerro nascido. Denotando sucesso (1 = fêmea) e fracasso (2 = macho), a probabilidade de sucesso é \\(p = 0,5\\) e a de fracasso \\(q = 1 - q = 0,5\\). Assim, considerando o parto de uma vaca, há 50% de chance de nascimento de uma terneira.\n\nlibrary(DiagrammeR)\nmermaid(\"\n   graph TB\n    Start -->|0,5|A(1)\n    Start -->|0,5|B(0)\n\")\n\n\n\n\n\nConsiderando duas vacas prenhas, com a mesma probabilidade de nascimento de fêmeas, temos então o seguinte cenário.\n\n\n\n\nflowchart\n    Start --> |0,5|A(1)\n    Start --> |0,5|B(0)\n    A --> |0,5|C(1)\n    A --> |0,5|D(0)\n    B --> |0,5|E(1)\n    B --> |0,5|F(0)\n    C --> G(11 = pp)\n    D --> H(10 = pq)\n    E --> I(01 = qp)\n    F --> J(00 = qq)\n\n\n\n\n\n\n\n\nAssim, as probabilidades associadas ao número de nascimentos de bezzeras são dadas por\n\nNenhuma bezerra\n\n\\[\nP(X = 0) = \\left( \\begin{array}{l}2\\\\0\\end{array} \\right) \\times {0,5^0} \\times {0,5^{2 - 0}} = 0,25\n\\]\n\nUma bezerra\n\n\\[\nP(X = 1) = \\left( \\begin{array}{l}2\\\\1\\end{array} \\right) \\times {0,5^1} \\times {0,5^{2 - 1}} = 0,50\n\\]\n\nDuas bezerras\n\n\\[\nP(X = 2) = \\left( \\begin{array}{l}2\\\\2\\end{array} \\right) \\times {0,5^2} \\times {0,5^{2 - 2}} = 0,25\n\\]\nNo software R, a probabilidade de sucesso de um evento para uma variável que segue uma distribuição binomial é computada com a função dbinom().\n\nargs(dbinom)\n\nfunction (x, size, prob, log = FALSE) \nNULL\n\n\n\nx é o vetor de quantiles (sucesso);\nsize é o número de experimentos (repetições);\nprob é a probabilidade de sucesso em cada experimento aleatório.\n\n\nlibrary(tibble)\n\nWarning: package 'tibble' was built under R version 4.2.1\n\ndata.frame(nbez = 0:2,\n           prob = dbinom(0:2, size = 2, prob = 0.5))\n\n  nbez prob\n1    0 0.25\n2    1 0.50\n3    2 0.25\n\n\nA mesma lógica é utilizada para uma situação onde três vacas estão prenhas. Assim, \\(n = 3\\), gera o seguinte cenário.\n\nmermaid(\"\n   graph TB\n    Start --> |0,5|A(1)\n    Start --> |0,5|B(0)\n    A --> |0,5|C(1)\n    A --> |0,5|D(0)\n    B --> |0,5|E(1)\n    B --> |0,5|F(0)\n    C --> |0,5|G(1)\n    C --> |0,5|H(0)\n    D --> |0,5|I(1)\n    D --> |0,5|J(0)\n    E --> |0,5|K(1)\n    E --> |0,5|L(0)\n    F --> |0,5|M(1)\n    F --> |0,5|N(0)\n    G --> O(111 = ppp)\n    H --> P(110 = ppq)\n    I --> Q(101 = pqp)\n    J --> R(100 = pqq)\n    K --> S(011 = qpp)\n    L --> T(010 = qpq)\n    M --> U(001 = qqp)\n    N --> V(000 = qqq)\n\")\n\n\n\n\n\n\ndata.frame(n_femeas = 0:3,\n           prob = dbinom(0:3, size = 3, prob = 0.5))\n\n  n_femeas  prob\n1        0 0.125\n2        1 0.375\n3        2 0.375\n4        3 0.125"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-bezerro",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-bezerro",
    "title": "3. Distribuições discretas",
    "section": "Exercício bezerro",
    "text": "Exercício bezerro\nUm produtor possui quatro vacas prenhas de monta natural. Como está cursando a disciplina de Bioestatística, ele gostaria de calcular probabilidades associadas ao nascimento de bezerras fêmeas.\n\nlibrary(tibble)\nbezerros <- \n  tibble(nbez = 0:4,\n         prob = dbinom(x = 0:4, size = 4, prob = 0.5),\n         prob_ac = cumsum(prob),\n         prob_ac_inv = rev(prob_ac))\nbezerros\n\n# A tibble: 5 × 4\n   nbez   prob prob_ac prob_ac_inv\n  <int>  <dbl>   <dbl>       <dbl>\n1     0 0.0625  0.0625      1     \n2     1 0.25    0.313       0.938 \n3     2 0.375   0.688       0.688 \n4     3 0.25    0.938       0.313 \n5     4 0.0625  1           0.0625\n\n# Gráfico da distribuição\nlibrary(tidyverse)\nggplot(bezerros, aes(nbez, prob))+\n  geom_bar(stat = \"identity\",\n           col = \"black\",\n           size = 0,\n           fill = \"cyan\")+\n  labs(x = \"Número de bezerros fêmeas\",\n       y = \"Probabilidade\")+\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  scale_x_continuous(expand = expansion(mult = c(0, 0))) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-questões-prova",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-questões-prova",
    "title": "3. Distribuições discretas",
    "section": "Exercício questões prova",
    "text": "Exercício questões prova\nConsidere uma prova de estatística com peso 10 contendo 10 questões, cada uma com 5 alternativas. Apenas 1 é correta. Se o aluno tirar uma nota inferior a 4, o aluno está reprovado. Notas entre 4 e 7 fazem com que o aluno fique em exame. Se a nota for superior a 7 o aluno passa. Como João não prestou atenção nas aulas de estatística, ele decidiu “chutar” todas as questões. Calcule as probabilidades que se pede.\n\nProbabilidade de não acertar nenhuma questão\n\ndbinom(x = 0, size = 10, prob = 0.2)\n\n[1] 0.1073742\n\n\n\n\nProbabilidade de ser reprovado\nJoão será reprovado caso acerte menos que quatro questões. Logo, a soma as probabilidades de acertar 0, 1, 2 e 3 questões é esta probabilidade.\n\ndbinom(x = 0:3, size = 10, prob = 0.2) %>% sum()\n\n[1] 0.8791261\n\n\n\n\nProbabilidade de ficar em exame\nJoão ficará em exame caso acerte entre 4 e 7 questões. Logo, a probabilidade de ficar em exame será a soma das probabilidades individuais destes números de questões.\n\ndbinom(x = 4:7, size = 10, prob = 0.2) %>% sum()\n\n[1] 0.120796\n\n\n\n\nPasse na prova\nJoão somente passará na prova, caso acerte mais que sete questões. Valendo-se da propriedade da soma das probabilidades, a probabilidade de João passar na prova é data tanto somando-se as probabilidades de acertar 8, 9 e 10 questões, quanto subtraindo a unidade da probabilidade da soma de acerto de até 7 questões.\n\ndbinom(x = 8:10, size = 10, prob = 0.2) %>% sum()\n\n[1] 7.79264e-05\n\n1 - dbinom(0:7, size = 10, prob = 0.2) |> sum()\n\n[1] 7.79264e-05\n\n\n\n\nGabarite a prova\nA probabilidade de acerto de 10 questões é dada pela probabilidade pontual de exatamente 10 sucessos em 10 tentativas.\n\ndbinom(x = 10, size = 10, prob = 0.2)\n\n[1] 1.024e-07\n\n\n\n\nMostrar código\nprova <- \n  tibble(nques = 0:10,\n         prob = dbinom(x = 0:10, size = 10, prob = 0.2),\n         prob_ac = cumsum(prob))\n\n\nggplot(prova, aes(nques, prob, label = round(prob, 4)))+\n  geom_bar(stat = \"identity\",\n           col = \"black\",\n           fill = \"cyan\")+\n  scale_x_continuous(breaks = c(0:10))+\n  labs(x = \"Número de questões\",\n       y = \"Probabilidade\")+\n  ggtitle(label = \"Probabilidade de acerto em uma prova de 10 questões\",\n          subtitle = \"Cada questão tem 5 alternativas, apenas 1 é correta\")+\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1)))+\n  geom_text(vjust = -1) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\nMostrar código\n# distribuição acumulada\n\nggplot(prova, aes(nques, prob_ac))+\n  geom_path(color = \"red\", size = 1)+\n  labs(x = \"Número de questões\",\n       y = \"Probabilidade acumulada\")+\n  ggtitle(label = \"Probabilidade acumulada de acertar 10 questões 'chutando' todas\",\n          subtitle = \"Cada questão tem 5 alternativas, apenas 1 é correta\")+\n  scale_x_continuous(breaks = c(0:10)) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-germinação-de-sementes",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-germinação-de-sementes",
    "title": "3. Distribuições discretas",
    "section": "Exercício germinação de sementes",
    "text": "Exercício germinação de sementes\nUma empresa produtora de sementes de moranga vende pacotes com 20 sementes cada. O percentual de germinação destas sementes é de 92%. A empresa garante que pacotes que contém menos de 18 sementes germinadas são indenizados na metade do valor de venda. Se você comprou um pacote de sementes desta empresa a probabilidade de ser indenizado é de:\n\ndbinom(0:17, size = 20, prob = 0.92) |> sum()\n\n[1] 0.2120538"
  },
  {
    "objectID": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-nascimento-de-bezerros",
    "href": "FIT5306/FIT5306_03_DIST_DISCRET.html#exercício-nascimento-de-bezerros",
    "title": "3. Distribuições discretas",
    "section": "Exercício nascimento de bezerros",
    "text": "Exercício nascimento de bezerros\n\nA inseminação artificial (IA) é uma das biotecnias da reprodução bovina mais importante e utilizada visando o melhoramento genético do rebanho. O uso de sêmem sexado é uma tecnologia em que os espermatozoides que vão resultar na escolha do sexo que o criador deseja, são separados daqueles que resultariam em machos após a fecundação do óvulo. Ou seja, ao final do processo obtêm-se uma paleta de sêmen com predominância de espermatozoides “fêmeas” ou “Machos”, dependendo da escolha. Portanto, a sexagem de espermatozoides permite maximizar a produção animal, possibilitando maior progresso genético entre as gerações1.\n\nConsidere um lote de 120 vacas inseminadas com sêmem sexado que contenha a probabilidade de 85% de nascimento de fêmeas. Assumindo um nascimento por fêmea, calcule a probabilidade de:\n\nTodos os bezerros nascidos sejam fêmeas\nNeste caso, a probabilidade é dada pela probabilidade pontual de 120 nascimentos de fêmeas.\n\ndbinom(x = 120, size = 120, prob = 0.85)\n\n[1] 3.390557e-09\n\n\n\n\nPelo menos 90% dos bezerros nascidos sejam fêmeas\nNeste caso, precisaríamos de, pelo menos, 108 (120 \\(\\times\\) 0,9) bezerros fêmeas. Então, a probabilidade dessa ocorrência é \\(P(X \\>= 108) + P(X = 109) + ... + P(X = 120)\\)\n\nx <- \n  data.frame(nascimentos = 108:120) |> \n  mutate(prob = dbinom(nascimentos, size = 120, prob = 0.85),\n         acum = cumsum(prob))\nx\n\n   nascimentos         prob       acum\n1          108 3.260600e-02 0.03260600\n2          109 2.034136e-02 0.05294736\n3          110 1.152677e-02 0.06447412\n4          111 5.884537e-03 0.07035866\n5          112 2.679566e-03 0.07303823\n6          113 1.074988e-03 0.07411322\n7          114 3.740456e-04 0.07448726\n8          115 1.105874e-04 0.07459785\n9          116 2.701129e-05 0.07462486\n10         117 5.232956e-06 0.07463009\n11         118 7.539004e-07 0.07463085\n12         119 7.180004e-08 0.07463092\n13         120 3.390557e-09 0.07463092\n\n\n\n\nMulta por ineficiência\nO vendedor do sêmen se comprometeu em pagar uma multa de R$10,00 para cada bezerro macho nascido se a taxa de parição de fêmeas fosse menor que 75%. Qual a probabilidade do produtor receber alguma indenização?\nO produtor somente será indenizado se nascerem 89 ou menos bezerras. Assim, a probabilidade é dada pela soma das probabilidades individuais de 0 até 89\n\ndbinom(x = 0:89, size = 120, prob = 0.85) |> sum()\n\n[1] 0.001409492\n\n# ou pbinom() que retorna a fdp acumulada\npbinom(q = 89, size = 120, prob = 0.85)\n\n[1] 0.001409492\n\n\nAbaixo, é possível identificar a distribuição de probabilidade para o exemplo dado.\n\n\nMostrar código\nbezerros <- \n  tibble(nbez = 0:120,\n         prob = dbinom(x = 0:120, size = 120, prob = 0.85),\n         prob_ac = cumsum(prob))\n\n\n# Gráfico da distribuição\nggplot(bezerros, aes(nbez, prob))+\n  geom_bar(stat = \"identity\",\n           col = \"black\",\n           size = 0.05,\n           fill = \"cyan\")+\n  labs(x = \"Número de bezerros fêmeas\",\n       y = \"Probabilidade\") +\n  ggtitle(label = \"Probabilidade de nascimento de terneiras em 120 partos\",\n          subtitle = \"Sêmen com 85% de probabilidade de nascimento de terneiras\")+\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1)))+\n  scale_x_continuous(breaks = seq(0, 120, 20))\n\n\n\n\n\nMostrar código\n# distribuição acumulada\n\nggplot(bezerros, aes(nbez, prob_ac))+\n  geom_path(color = \"red\", size = 1)+\n  labs(x = \"Número de fêmeas\",\n       y = \"Probabilidade acumulada\")+\n  ggtitle(label = \"Probabilidade acumulada de nascimento de fêmeas\",\n          subtitle = \"Sêmem sexado com 85% de chance de nascimento de fêmeas\")+\n  # scale_x_continuous(breaks = c(0:10)) +\n  theme_grey(base_size = 14) +\n  theme(panel.grid.minor = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_04_DIST_CONT.html",
    "href": "FIT5306/FIT5306_04_DIST_CONT.html",
    "title": "4. Distribuições Contínuas",
    "section": "",
    "text": "A distribuição normal é um modelo bastante útil na estatística, pois sua função densidade de probabilidade (FDP) está associada ao fato de que aproxima de forma bastante satisfatória as curvas de frequências observadas quando se mensura diversas variáveis biológicas (ex., altura, massa, comprimento, etc). Como exemplo, vamos ver a distribuição da massa de mil grãos de híbridos de milho, disponíveis no conjunto de dados data_ge do pacote metan. Neste exemplo, a linha vermelha representa a distribuição normal.\n\n\nMostrar script\nlibrary(tidyverse)\nlibrary(metan)\n\n# tema personalizado\nmy_theme <- \n  theme_gray(base_size = 14) +\n  theme(panel.grid.minor = element_blank())\n# define o tema para todos os gráficos\ntheme_set(my_theme)\n\n\nggplot(data_ge2, aes(TKW)) + \n  geom_histogram(aes(y = ..density..),\n                 bins = 15) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                color = \"red\",\n                size = 1,\n                args = list(\n                  mean = mean(data_ge2$TKW),\n                  sd = sd(data_ge2$TKW)\n                ))\n\n\n\n\n\nVamos ver a distribuição dos valores do comprimento da folha de café, mensurado na primeira aula de bioestatística.\n\n\nMostrar script\nlibrary(rio)\n\n\nWarning: package 'rio' was built under R version 4.2.2\n\n\nMostrar script\n# link dos dados\nlink <- \"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=1453191616\"\n\n# função para importar os dados\ndf <-  \n  import(link, dec = \",\") |> \n  filter(tipo == \"Folha\")\n\nggplot(df, aes(comprimento)) + \n  geom_histogram(aes(y = ..density..),\n                 bins = 10) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                color = \"red\",\n                size = 1,\n                args = list(\n                  mean = mean(df$comprimento),\n                  sd = sd(df$comprimento)\n                ))\n\n\n\n\n\n\n\nA distribuição normal possui dois parâmetros:\n\n\\(\\mu\\), sendo a média;\n\\(\\sigma\\), sendo o desvio padrão.\n\nEstes parâmetros definem a posição e a dispersão do conjunto de dados. Assim, se X se distribui de forma normal e contínua (variável contínua) de \\(-\\infty < x <+\\infty\\), a área total sob a curva do modelo é 1.\nO modelo da função normal possui a seguinte Função Densidade de Probabilidade:\n\\[\n{f}(x) = \\frac{1}{{\\sqrt {2\\pi {\\sigma ^2}} }}{e^{ - \\frac{{{{(x - \\mu )}^2}}}{{2{\\sigma ^2}}}}}-\\infty< x < \\infty\n\\]\nNo exemplo abaixo, é apresentado a distribuição de uma variável aleatória contínua (X) com \\(\\mu = 20\\), e \\(\\sigma = 2\\). Assim, dizemos que \\(X \\sim N(\\mu,\\sigma)\\), ou seja, segue uma distribuição normal com média \\(\\mu = 20\\) e desvio padrão \\(\\sigma = 2\\).\n\n\nMostrar script\nggplot() +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                color = \"red\",\n                size = 1,\n                xlim = c(10, 30),\n                args = list(\n                  mean = 20,\n                  sd = 2\n                )) +\n  labs(y = bquote(f(x)~~\"densidades\"),\n       x = \"x\")\n\n\n\n\n\nAbaixo, pode-se observar a distribuição de variáveis aleatórias contínuas com diferentes valores de parâmetros. No gráfico à esquerda, fixa-se a média e varia-se o desvio padrão. No exemplo central, fixa-se o desvio padrão e varia-se a média. No exemplo à direita, varia-se os dois parâmetros.\n\n\nMostrar código\nget_norm <- function(mu, sd, col = \"blue\"){\n  stat_function(fun=dnorm,\n                geom = \"line\",\n                size = 1,\n                col=col,\n                args = c(mean=mu,sd=sd))\n}\n\np1 <- \n  ggplot(data.frame(x=c(0,30)),aes(x=x)) +\n  get_norm(10, 1) +\n  get_norm(10, 2, \"green\") +\n  get_norm(10, 4, \"red\")\n\np2 <- \n  ggplot(data.frame(x=c(0,30)),aes(x=x)) +\n  get_norm(6, 2) +\n  get_norm(10, 2, \"green\") +\n  get_norm(14, 2, \"red\")\n\np3 <- \n  ggplot(data.frame(x=c(0,30)),aes(x=x)) +\n  get_norm(6, 1) +\n  get_norm(10, 2, \"green\") +\n  get_norm(14, 4, \"red\")\n\narrange_ggplot(p1, p2, p3)\n\n\n\n\n\n\n\n\nA probabilidade estatística de um valor estar no intervalo \\(x_1,x_2\\) é dada pela soma da área abaixo da curva contida no intervalo entre estes dois pontos. Tal área pode ser obtida conforme segue:\n\\[\nP\\left(x_{1}\\le X \\le  x_{2}\\right)=\\int_{x_{1}}^{x_{2}} \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}} d x\n\\]\nConsidere como exemplo, a altura de planta em uma lavoura de milho que segue uma distribuição normal com média 2 e desvio padrão de 0,2. Pergunda-se: qual é a probabilidade de, ao entrar aleatoriamente nesta lavoura ser encontrada uma planta que mede de 1,75 m a 2 m?\n\nSOLUÇÃO: Para resolver este problema, precisamos encontrar a área sombreada na figura abaixo.\n\n\n\nMostrar script\nme <- 2\nsdd <- 0.2\n\nargs <- \n  list(mean = me,\n       sd = sdd)\n\nggplot() +\n  scale_x_continuous(limits = c(1, 3),\n                     breaks = seq(1, 3, by = 0.25)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(1.75, 2),\n                args = args)+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                size = 1,\n                args = args)+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Altura da planta (m)\",\n       y = \"Probabilidade\")\n\n\n\n\n\nPara calcular esta probabilidade, precisamos encontrar a probabilidade associada a cada quantil, utilizando a função pnorm(). Esta função retorna por padrão a probabilidade \\(PX \\\\le x\\). Assim, ao se diminuir a probabilidade de encontrar uma planta com 2 m da probabilidade de encontrar uma planta com até 1,75 m, resolvemos o problema.\n\n# P[X<= 2.0]\n(p2 <- pnorm(q = 2, mean = 2, sd = 0.2))\n\n[1] 0.5\n\n# P[X<= 1.75]\n(p175 <- pnorm(q = 1.75, mean = 2, sd = 0.2))\n\n[1] 0.1056498\n\np2 - p175\n\n[1] 0.3943502\n\n\n\n\n\nO cálculo da integral da distribuição Normal pode ser aproximado pelo método geométrico por soma de retângulos (Ou Soma de Riemann). Este método possibilita calcular a integral definida em dois pontos (ex., \\(x_1\\) e \\(x_2\\)), considerando uma variável com distribuição normal. Assim, a soma das áreas dos retângulos sob a curva da distribuição normal resultarão na probabilidade estatística de um valor estar no intervalo \\(x_1,x_2\\).\n\n\nMostrar script\n##### N = 20\nn <- 20\np <- 0.5\nx <- seq(0, n, 1)\npx <- dbinom(x, n, p)\ndf2 <- data.frame(x, px)\n\n\n# Aproximação\nmedia <- n*p # media\ndesvp <- sqrt(n*p*(1-p)) # desvio padrao\n\nggplot(df2, aes(x = x, y = px)) + \n  geom_bar(stat = \"identity\",\n           width = 1, \n           color = \"black\",\n           size = 0.01,\n           fill = \"salmon\") + \n  scale_y_continuous(expand = c(0.01, 0)) + \n  xlab(\"x\") + \n  ylab(\"px e fx\") +\n  stat_function(aes(x=x),\n                fun=dnorm,\n                geom = \"line\",\n                size=1,\n                col=\"green\",\n                args = c(mean = media, sd = desvp))\n\n\n\n\n\nNo método geométrico, a função f(x) corresponderá a altura de cada retângulo. A base do retângulo (\\(\\Delta\\)), será dada por:\n\\[\n\\Delta=\\frac{x_2-x_1}{n}\n\\]\nonde n representa o número de retângulos no intervalo. Ao multiplicar a altura do retângulo pela sua base, temos a área de cada retângulo. Ao somarmos todas as n áreas, teremos a aproximação da probabilidade. Logo, é fácil notar que quanto maior o valor de n melhor será a aproximação do valor calculado pela integral.\nA função abaixo pode ser utilizada para aproximar a integral da função da distribuição Normal. A função mnorm é a Função Densidade de Probabilidade e é aplicada dentro da função int_norm para encontrar a altura de cada retângulo. Por padrão, 50000 retângulos são utilizados.\n\n# função normal, f(x)\nmnorm <- function(x, m, dp){\n  (1/(dp * sqrt(2 * pi) )) * exp(-((x - m)^2)/(2 * dp ^ 2))\n}\n# integral definida em dois pontos\n# (método geométrico por soma de retângulos)\nint_norm <- function(x1, x2, me, dp, n = 50000){\n  # cria uma sequência com n retangulos de x1 a x2\n  x <- seq(x1, x2, length.out = n)\n  # acha a base da área\n  barea <- (x2 - x1)/n\n  # encontra a altura\n  altrect <- mnorm(x, me, dp)\n  # multiplica a altura pela base e soma\n  sum(altrect * barea)\n}\n\nAbaixo, a função int_norm() é usada para aproximar a probabilidade obtida anteriormente com a função pnorm().\n\nx1 <- 1.75 # x_0\nx2 <- 2    # x_1\nm <- 2     # média\ndp <- 0.2  # desvio padrão\n\n# método geométrico\n(aprox <- int_norm(x1, x2, m, dp))\n\n[1] 0.3943496\n\n(fun_pnorm <- p2 - p175)\n\n[1] 0.3943502\n\nfun_pnorm - aprox\n\n[1] 6.171243e-07\n\n\nNota-se que com 50000 retângulos, a aproximação da probabilidade pelo método geométrico apresentou diferença somente na quinta casa após a vírgula, demonstrando uma aproximação satisfatória. Vejamos o impacto do número de retângulos nesta aproximação. Para isso, vamos criar um gráfico para mostrar como esta aproximação vai melhorando com o aumento no número de retângulos. No exemplo, é simulado de 1 até 200 (apenas para fins didáticos). A linha vermelha horizontal representa a probabilidade compudata com a função pnorm().\n\nx <- NULL\nfor (i in 1:200) {\n  x[i] <- int_norm(x1, x2, m, dp, i)\n}\ndf <- \n  data.frame(x = 1:200,\n             prob = x)\n\nggplot(df, aes(x, prob)) +\n  geom_line() +\n  geom_hline(yintercept = p2 - p175,\n             color = \"red\") +\n  labs(x = \"Números de retângulos\",\n       y = \"Probabilidade aproximada\")\n\n\n\n\n\n\n\nA distribuição Normal Padrão é nada mais que uma distribuição normal com média e desvio padrão fixos (\\(\\mu = 0; \\sigma = 1\\)). Uma vez que estes parâmetros são fixos, sempre que desejamos calcular uma probabilidade pode-se recorrer a uma tabela, onde valores de probabilidade já foram previamente calculados para essa única distribuição.\nPara isso, precisamos definir uma nova variável aleatória Z, chamada de variável aleatória normal padronizada, dada pela função linear Z.\n\\[\nZ = \\frac{X- \\mu}{\\sigma}\n\\]\nOnde X é uma variável aleatória com distribuição normal com média \\(\\mu\\) e \\(\\sigma \\> 0\\).\nComo exemplo, vamos simular uma variável aleatória (X) com \\(n = 300\\) tal que \\(X \\sim N(\\mu = 20; \\sigma = 3)\\).\n\nset.seed(1) # assegura a reprodutibilidade\nX <- round(rnorm(n = 300 , mean = 20, sd = 3), digits = 1)\nhist(X)\n\n\n\n(mu <- mean(X))\n\n[1] 20.102\n\n(sdx <- sd(X))\n\n[1] 2.892973\n\n\nPodemos criar uma função para criar a nova variável Z com base em um vetor numérico da variável original. Neste caso, a chamei de get_z().\n\nget_z <- function(x){\n  (x - mean(x)) / sd(x)\n}\n# obtém o valor Z de X\nZ <- get_z(X)\nhist(Z)\n\n\n\n\nOs valores de Z podem ser interpretados como o número de desvios padrão afastados da média, em uma distribuição normal padrão.\n\n\nMostrar script\nggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"cyan\",\n                xlim = c(-3, 3),\n                alpha = 1) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"green\",\n                xlim = c(-2, 2),\n                alpha = 1) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"salmon\",\n                xlim = c(-1, 1),\n                alpha = 1) +\n  \n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-4, 4), breaks = c(seq(-5, 5, 1))) +\n  scale_y_continuous(expand = expansion(mult = c(0, .5)),\n                     breaks = NULL) +\n  labs(x = \"Z\",\n       y = \"\")+\n  theme_gray(base_size = 16) +\n  theme(panel.grid = element_blank(),\n        panel.background = element_rect(fill = NA))\n\n\n\n\n\nDesta forma, uma tabela contendo a área sobre a curva desta distribuição de Z pode ser utilizada.\n\n\n\n\n\nA primeira decimal da variável Z encontra-se na linha e a segunda decimal na coluna. Como exemplo, a probabilidade de Z ser menor ou igual a -1 é de 0,15866.\n\n# valor exato\npnorm(-1)\n\n[1] 0.1586553\n\n\n\n\n\n\n\n\nNote\n\n\n\nRetomando o exemplo: Considere como exemplo, a altura de planta em uma lavoura de milho. Esta variável segue uma distribuição normal com média 2 e desvio padrão de 0,2. Pergunda-se: qual é a probabilidade de, ao entrar aleatoriamente nesta lavoura ser encontrada uma planta que mede de 1,75 m a 2 m? Neste caso, utilizando a normal padrão, a resolução é dada por:\n\n\n\nme <- 2 # média \nsdd <- 0.2 # desvio padrão\nval1 <- 1.75 # primeiro quantil do intervalo\nval2 <- 2 # segundo quantil do intervalo\n(Z1 <- (val1 - me) / sdd) # Z associado ao primeiro quantil\n\n[1] -1.25\n\n(Z2 <- (val2 - me) / sdd) # Z associado ao segundo quantil\n\n[1] 0\n\n(prob1 <- pnorm(Z1)) # P(Z <= -1,25)\n\n[1] 0.1056498\n\n(prob2 <- pnorm(Z2)) # P(z <= 0)\n\n[1] 0.5\n\nprob2 - prob1 # P(-1,25 <= Z <= 0)\n\n[1] 0.3943502\n\n\nNo exemplo, a área da parte sombreada (probabilidade) é de 0,39455.\n\n\nMostrar script\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(1.2, 2.8)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(1.75, 2),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                ))+\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                )) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original (altura em m)\", y = \"Probabilidade\")\n\npadrao <-\n  ggplot() +\n  scale_x_continuous(limits = c(-4, 4)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z1, Z2))+\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")\n\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA série histórica das vendas de uma determinada fórmula de adubo seguem uma distribuição normal com média 25.000 t e desvio padrão de 2.600 t. Se a empresa fabricante decidir fabricar 30000 toneladas deste adubo para suprir a demanda da safra atual, qual é a probabilidade de que ela não possa atender todas as vendas por estar com a produção esgotada?\n\nR = 0,0272\n\nSOLUÇÃO: encontrar a probabilidade de vender mais que 30000 t.\n\n\nMostrar script\nme <- 25000\nsdd <- 2600\nval <- 30000\n(Z <- (val - me) / sdd)\n\n\n[1] 1.923077\n\n\nMostrar script\n(prob <- 1 - pnorm(Z))\n\n\n[1] 0.0272352\n\n\nMostrar script\n# gráfico da normal padrão\nnormal <-\n  ggplot() +\n  xlim(c(15900, 34100)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(30000, 34100),\n                args = list(\n                  mean = me,\n                  sd = sdd\n                )) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = list(\n                  mean = me,\n                  sd = sdd\n                )) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável original\")\n\n# gráfico da variável original\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z, 3.5)) +\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-3.5, 3.5), breaks = c(seq(-3, 3, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\",\n          subtitle = paste(\"Valor de Z:\", round(Z, 4), \"; Prob área sombreada:\", round(prob, 4)))\narrange_ggplot(normal, padrao, ncol = 1)\n\n\n\n\n\n\n\n\nUma variável aleatória X segue uma distribuição normal com média 100 e desvio padrão 10. Calcule a probabilidade de x estar entre 90 e 110.\n\nR: 0.6826895\n\nRESOLUÇÃO: encontrar os valores de Z associado a 90 e 100, encontrando a área sobre a curva entre estes dois valores.\n\n\nMostrar script\nme <- 100\nsdd <- 10\nval1 <- 90\nval2 <- 110\n(Z1 <- (val1 - me) / sdd)\n\n\n[1] -1\n\n\nMostrar script\n(Z2 <- (val2 - me) / sdd)\n\n\n[1] 1\n\n\nMostrar script\n# probabilidade dos valores estarem a 1 desvio padrão para mais ou menos\npnorm(Z2) - pnorm(Z1)\n\n\n[1] 0.6826895\n\n\nMostrar script\nargs <- list(\n  mean = 100,\n  sd = 10\n)\nnormal <-\n  ggplot() +\n  scale_x_continuous(limits = c(60, 140),\n                     breaks = seq(60, 140, 10)) +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(90, 110),\n                args = args) +\n  stat_function(fun = dnorm,\n                geom = \"line\",\n                args = args) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor original\", y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável original\")\n\npadrao <-\n  ggplot() +\n  stat_function(fun = dnorm,\n                geom = \"area\",\n                fill = \"steelblue\",\n                xlim = c(Z1, Z2)) +\n  stat_function(fun = dnorm,\n                geom = \"line\")+\n  scale_x_continuous(limits = c(-4, 4), breaks = c(seq(-4, 4, 1)))+\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de Z\",\n       y = \"Probabilidade\")+\n  ggtitle(\"Distribuição da variável padronizada\")\n\narrange_ggplot(normal, padrao, ncol = 1)"
  },
  {
    "objectID": "FIT5306/FIT5306_04_DIST_CONT.html#intervalo-de-confiança",
    "href": "FIT5306/FIT5306_04_DIST_CONT.html#intervalo-de-confiança",
    "title": "4. Distribuições Contínuas",
    "section": "Intervalo de confiança",
    "text": "Intervalo de confiança\nA estimação por pontos (ex., média) não nos fornece a ideia da margem de erro cometida ao estimar um determinado parâmetro. Por isso, para verificar se uma dada hipótese \\(H_0\\) (de igualdade) é ou não verdadeira, deve-se utilizar intervalos de confiança ou testes de hipóteses. A construção destes intervalos, e as particularidades dos testes de hipóteses para amostras independentes e dependentes, serão discutidos a seguir. Recomendo como literatura o livro Estatística Básica escrito pelo Prof. Daniel Furtado Ferreira.\nO intervalo de confiança de uma média amostral assumindo uma taxa de erro \\(\\alpha\\) é dado por:\n\\[\nP\\left[ {\\bar X - {t_{\\alpha /2}}\\frac{S}{{\\sqrt n }} \\le \\mu  \\le \\bar X + {t_{\\alpha /2}}\\frac{S}{{\\sqrt n }}} \\right] = 1 - \\alpha\n\\]\nNa expressão acima, \\(\\bar X\\) é a média, \\(S\\) é o desvio padrão e \\(-t \\frac{\\alpha}{2}\\) e \\(+t\\frac{\\alpha}{2}\\) são os quantis inferior e superior, respectivamente, da distribuição t de Student. O intervalo acima indica que o valor do parâmetro (\\(\\mu\\)) tem \\(1 - \\alpha\\) de chance de estar contido no intervalo.\n\nExemplo 1 (altura da turma)\nComo exemplo de motivação, vamos utilizar os dados referentes a altura (em cm) dos alunos da disciplina de Bioestatística e Experimentação Agrícola, mensurada em sala de aula. A amostra é composta por 25observações.\n\nlibrary(rio)\ndf_altura <- \n  import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=1590128876\") |> \n  metan::remove_rows_na() # remove valores faltantes\n\nWarning: Row(s) 1, 2, 3, 5, 8, 10, 15, 22, 26, 27, 28, 31, 32, 33, 34, 40 with\nNA values deleted.\n\nstr(df_altura)\n\n'data.frame':   25 obs. of  4 variables:\n $ id    : int  4 7 11 13 14 20 21 29 30 35 ...\n $ aluno : chr  \"Bruna Waltrich\" \"Danielli Zangalli Kern\" \"Gabriela Araujo Catto\" \"Helena dos Santos Vanderlinde\" ...\n $ crm   : chr  \"xx\" \"xx\" \"xx\" \"xx\" ...\n $ altura: int  156 169 162 180 166 165 164 170 164 158 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:16] 1 2 3 5 8 10 15 22 26 27 ...\n  ..- attr(*, \"names\")= chr [1:16] \"1\" \"2\" \"3\" \"5\" ...\n\n\nComo n = 25, o grau liberdade para encontrar o quantil da distribuição t é 24. O quantil t associado a este Grau Liberdade, considerando \\(\\alpha = 0,05\\) (2,063) é encontrado na tabela da distribuição t observando-se a linha com GL = 24 e a coluna \\(\\alpha = 0.05\\).\n\n\n\n\n\nTamém podemos encontrar este quantil utilizando a função qt(). No próximo código, o quantil (2.5% e 97.5%), a média e o desvio padrão são calculados. Note que\n\n(quantil_t <- qt(c(0.025, 0.975), df = 24))\n\n[1] -2.063899  2.063899\n\n(n <- nrow(df_altura))\n\n[1] 25\n\n(media <- mean(df_altura$altura))\n\n[1] 170.44\n\n(desvpad <- sd(df_altura$altura))\n\n[1] 8.381925\n\n\nDe posse destas informações, podemos calcular o intervalo de confiança (limite inferior, LI e limite superior, LS)\n\\[\nLI = 170,44 - 2,063 \\times \\frac{{8,38}}{{\\sqrt {25} }} = 166,98\n\\]\n\\[\nLS =  170,44 + 2,063 \\times \\frac{{8,38}}{{\\sqrt {25} }} = 173,90\n\\]\nPara facilitar nossos próximos exemplos, vamos criar uma função para computar o intervalo de confiança 95%.\n\nget_ci_t <- function(media, dp, n){\n  quantil_t <- qt(0.975, n - 1)\n  semi_amp <- quantil_t * dp / sqrt(n)\n  message(\n    \"[\", round(media - semi_amp, 3), \" <= mu <= \", round(media + semi_amp, 3), \"]\"\n  )\n  return(semi_amp)\n}\nget_ci_t(media, desvpad, n)\n\n[166.98 <= mu <= 173.9]\n\n\n[1] 3.459889\n\n\n\n\nMostrar script\ndf <- \n  tibble(\n    media = media,\n    desvpad = desvpad,\n    LI = media - get_ci_t(media, desvpad, n),\n    LS = media + get_ci_t(media, desvpad, n)\n  )\n\n\n[166.98 <= mu <= 173.9]\n[166.98 <= mu <= 173.9]\n\n\nMostrar script\ndf\n\n\n# A tibble: 1 × 4\n  media desvpad    LI    LS\n  <dbl>   <dbl> <dbl> <dbl>\n1  170.    8.38  167.  174.\n\n\nMostrar script\n# criar o gráfico com os intervalos\n# média geral\nggplot(df, aes(x = media, y = \"\")) +\n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS),\n                width = 0.1) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  geom_text(aes(x = LS,\n                label = round(LS, 2)),\n            vjust = -1) +\n  geom_text(aes(x = LI,\n                label = round(LI, 2)),\n            vjust = -1) +\n  scale_x_continuous(breaks = seq(166, 175, by = 1), limits = c(166, 175)) +\n  labs(x = \"Altura do aluno (cm)\",\n       y = \"\") + \n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\nA função t.test() pode também ser utilizada para calcular o intervalo de confiança de 95% quando se tem apenas uma amostra.\n\nic <- t.test(df_altura$altura)\nic$conf.int\n\n[1] 166.9801 173.8999\nattr(,\"conf.level\")\n[1] 0.95\n\n\n\n\nExemplo 2 (altura da turma por grupo)\nComo temos dois grupos (xx e xy) o intervalo de confiança para a média pode ser calculado para cada grupo. Neste caso é válido utilizar os intervalos de confiança da média como critério para significância da diferença entre duas médias. Médias onde os intervalos de confiança não se sobrepõe podem ser consideradas significativas na probabilidade de erro considerada para o cálculo do intervalo.\n\n\nMostrar script\nlibrary(tidyverse)\n# média por cromossomo\ndf2 <- \n  df_altura |> \n  group_by(crm) |> \n  summarise(media = mean(altura),\n            desvpad = sd(altura),\n            n = n()) |> \n  mutate(LI = media - get_ci_t(media, desvpad, n),\n         LS = media + get_ci_t(media, desvpad, n))\n\n\n[162.02170.36 <= mu <= 170.134179.974]\n[162.02170.36 <= mu <= 170.134179.974]\n\n\nMostrar script\n# criar o gráfico com os intervalos\n# média por cromossomo\nggplot(df2, aes(x = media, y = crm)) +\n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS,\n                    color = crm),\n                width = 0.1) +\n  geom_point(aes(color = crm),\n             size = 3) +\n  geom_text(aes(x = LS,\n                label = round(LS, 2)),\n            vjust = -1,\n            size = 2.5) +\n  geom_text(aes(x = LI,\n                label = round(LI, 2)),\n            vjust = -1,\n            size = 2.5) +\n  labs(x = \"Altura do aluno (cm)\",\n       y = \"Cromossomo\") + \n  theme(panel.grid.minor = element_blank())\n\n\n\n\n\n\n\nExemplo 3 (peso de frango)\nConsidere um aviário com 15000 frangos. O criador realizou a amostragem de 25 frangos aleatoriamente para realizar uma estimativa da média do peso do lote visando a programação para abate. Após analisar as pesagens coletadas, o produtor encontrou uma média de 2,83 Kg e um desvio padrão de 0,27 Kg. Pergunta-se: Qual o intervalo de 95% para a média estimada?\n\n\nMostrar script\ndf3 <- tibble(\n  media = 2.83,\n  desvpad = 0.27,\n  LI = media - get_ci_t(media, desvpad, n = 25),\n  LS = media + get_ci_t(media, desvpad, n = 25)\n)\n\n\n[2.719 <= mu <= 2.941]\n[2.719 <= mu <= 2.941]\n\n\nMostrar script\nggplot(df3, aes(x = media, y = \"\")) +\n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS),\n                width = 0.1) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  labs(x = \"Peso médio do frango\",\n       y = \"\")\n\n\n\n\n\n\n\nVariação no desvio padrão\nAbaixo, são simuladas 4 amostras de n = 20 com médias igual a 10 e desvios padrões variantes. Note como o intervalo de confiança é menor a medida em que o desvio padrão é mais baixo.\n\n\nMostrar script\ndf4 <- tibble(\n  amostra = paste0(1:4),\n  media = c(10, 10, 10, 10),\n  desvpad = c(1, 4, 6, 8),\n  LI = media - get_ci_t(media, desvpad, n = 20),\n  LS = media + get_ci_t(media, desvpad, n = 20),\n  lab = paste0(\"dp: \", desvpad)\n)\n\n\n[9.5328.1287.1926.256 <= mu <= 10.46811.87212.80813.744]\n[9.5328.1287.1926.256 <= mu <= 10.46811.87212.80813.744]\n\n\nMostrar script\ndf4\n\n\n# A tibble: 4 × 6\n  amostra media desvpad    LI    LS lab  \n  <chr>   <dbl>   <dbl> <dbl> <dbl> <chr>\n1 1          10       1  9.53  10.5 dp: 1\n2 2          10       4  8.13  11.9 dp: 4\n3 3          10       6  7.19  12.8 dp: 6\n4 4          10       8  6.26  13.7 dp: 8\n\n\nMostrar script\n# criar o gráfico com os intervalos\nggplot(df4, aes(x = media, y = amostra)) +\n  geom_vline(xintercept = 10, linetype = 2) + \n  geom_errorbar(aes(xmin = LI,\n                    xmax = LS),\n                width = 0.1) +\n  geom_point(color = \"blue\",\n             size = 3) +\n  scale_x_continuous(breaks = seq(169, 177, by = 1)) +\n  geom_text(aes(label = lab),\n            vjust = -1,\n            hjust = 2) +\n  labs(x = \"Variável hipotética\",\n       y = \"Amostra\")\n\n\n\n\n\n\n\nVariação no tamanho da amostra\n\n\nMostrar script\ndf_t <- tibble(\n  dist = \"t\",\n  n = seq(2, 30, length.out = 200),\n  media = 10,\n  desvpad = 2,\n  UL = media + get_ci_t(media, desvpad, n = n),\n  LL = media - get_ci_t(media, desvpad, n = n)\n)\n\n\n[-7.969-3.041-0.1791.6462.8923.7894.4614.9835.3985.7376.0186.2556.4586.6336.7876.9237.0447.1527.257.3397.427.4947.5637.6267.6847.7397.797.8387.8837.9257.9658.0028.0388.0728.1048.1358.1648.1928.2188.2448.2688.2918.3148.3368.3568.3768.3968.4148.4338.458.4678.4838.4998.5148.5298.5448.5588.5718.5848.5978.618.6228.6348.6458.6578.6688.6798.6898.6998.7098.7198.7298.7388.7478.7568.7658.7738.7828.798.7988.8068.8148.8218.8298.8368.8438.858.8578.8648.8718.8778.8848.898.8968.9028.9088.9148.928.9268.9318.9378.9438.9488.9538.9588.9648.9698.9748.9798.9838.9888.9938.9989.0029.0079.0119.0169.029.0249.0289.0339.0379.0419.0459.0499.0539.0579.069.0649.0689.0729.0759.0799.0829.0869.0899.0939.0969.19.1039.1069.119.1139.1169.1199.1229.1259.1289.1319.1349.1379.149.1439.1469.1499.1529.1549.1579.169.1639.1659.1689.1719.1739.1769.1789.1819.1839.1869.1889.1919.1939.1969.1989.29.2039.2059.2079.219.2129.2149.2169.2189.2219.2239.2259.2279.2299.2319.2339.2359.2379.2399.2419.2439.2459.2479.2499.2519.253 <= mu <= 27.96923.04120.17918.35417.10816.21115.53915.01714.60214.26313.98213.74513.54213.36713.21313.07712.95612.84812.7512.66112.5812.50612.43712.37412.31612.26112.2112.16212.11712.07512.03511.99811.96211.92811.89611.86511.83611.80811.78211.75611.73211.70911.68611.66411.64411.62411.60411.58611.56711.5511.53311.51711.50111.48611.47111.45611.44211.42911.41611.40311.3911.37811.36611.35511.34311.33211.32111.31111.30111.29111.28111.27111.26211.25311.24411.23511.22711.21811.2111.20211.19411.18611.17911.17111.16411.15711.1511.14311.13611.12911.12311.11611.1111.10411.09811.09211.08611.0811.07411.06911.06311.05711.05211.04711.04211.03611.03111.02611.02111.01711.01211.00711.00210.99810.99310.98910.98410.9810.97610.97210.96710.96310.95910.95510.95110.94710.94310.9410.93610.93210.92810.92510.92110.91810.91410.91110.90710.90410.910.89710.89410.8910.88710.88410.88110.87810.87510.87210.86910.86610.86310.8610.85710.85410.85110.84810.84610.84310.8410.83710.83510.83210.82910.82710.82410.82210.81910.81710.81410.81210.80910.80710.80410.80210.810.79710.79510.79310.7910.78810.78610.78410.78210.77910.77710.77510.77310.77110.76910.76710.76510.76310.76110.75910.75710.75510.75310.75110.74910.747]\n[-7.969-3.041-0.1791.6462.8923.7894.4614.9835.3985.7376.0186.2556.4586.6336.7876.9237.0447.1527.257.3397.427.4947.5637.6267.6847.7397.797.8387.8837.9257.9658.0028.0388.0728.1048.1358.1648.1928.2188.2448.2688.2918.3148.3368.3568.3768.3968.4148.4338.458.4678.4838.4998.5148.5298.5448.5588.5718.5848.5978.618.6228.6348.6458.6578.6688.6798.6898.6998.7098.7198.7298.7388.7478.7568.7658.7738.7828.798.7988.8068.8148.8218.8298.8368.8438.858.8578.8648.8718.8778.8848.898.8968.9028.9088.9148.928.9268.9318.9378.9438.9488.9538.9588.9648.9698.9748.9798.9838.9888.9938.9989.0029.0079.0119.0169.029.0249.0289.0339.0379.0419.0459.0499.0539.0579.069.0649.0689.0729.0759.0799.0829.0869.0899.0939.0969.19.1039.1069.119.1139.1169.1199.1229.1259.1289.1319.1349.1379.149.1439.1469.1499.1529.1549.1579.169.1639.1659.1689.1719.1739.1769.1789.1819.1839.1869.1889.1919.1939.1969.1989.29.2039.2059.2079.219.2129.2149.2169.2189.2219.2239.2259.2279.2299.2319.2339.2359.2379.2399.2419.2439.2459.2479.2499.2519.253 <= mu <= 27.96923.04120.17918.35417.10816.21115.53915.01714.60214.26313.98213.74513.54213.36713.21313.07712.95612.84812.7512.66112.5812.50612.43712.37412.31612.26112.2112.16212.11712.07512.03511.99811.96211.92811.89611.86511.83611.80811.78211.75611.73211.70911.68611.66411.64411.62411.60411.58611.56711.5511.53311.51711.50111.48611.47111.45611.44211.42911.41611.40311.3911.37811.36611.35511.34311.33211.32111.31111.30111.29111.28111.27111.26211.25311.24411.23511.22711.21811.2111.20211.19411.18611.17911.17111.16411.15711.1511.14311.13611.12911.12311.11611.1111.10411.09811.09211.08611.0811.07411.06911.06311.05711.05211.04711.04211.03611.03111.02611.02111.01711.01211.00711.00210.99810.99310.98910.98410.9810.97610.97210.96710.96310.95910.95510.95110.94710.94310.9410.93610.93210.92810.92510.92110.91810.91410.91110.90710.90410.910.89710.89410.8910.88710.88410.88110.87810.87510.87210.86910.86610.86310.8610.85710.85410.85110.84810.84610.84310.8410.83710.83510.83210.82910.82710.82410.82210.81910.81710.81410.81210.80910.80710.80410.80210.810.79710.79510.79310.7910.78810.78610.78410.78210.77910.77710.77510.77310.77110.76910.76710.76510.76310.76110.75910.75710.75510.75310.75110.74910.747]\n\n\nMostrar script\ndf_n <- tibble(\n  dist = \"normal\",\n  n = seq(2, 30, length.out = 200),\n  media = 10,\n  desvpad = 2,\n  UL = media + qnorm(0.975) * desvpad / sqrt(n),\n  LL = media - qnorm(0.975) * desvpad / sqrt(n)\n)\ndf_dists <- rbind(df_t, df_n)\n\n# criar o gráfico com os intervalos\nggplot(df_dists, aes(color = dist)) +\n  geom_line(aes(x = n, y = LL), size = 1) +\n  geom_line(aes(x = n, y = UL), size = 1) +\n  scale_x_continuous(breaks = seq(2, 30, by = 2)) +\n  labs(x = \"Tamanho da amostra\",\n       y = \"Intervalo de confiança (95%)\") +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())"
  },
  {
    "objectID": "FIT5306/FIT5306_04_DIST_CONT.html#testes-de-hipóteses",
    "href": "FIT5306/FIT5306_04_DIST_CONT.html#testes-de-hipóteses",
    "title": "4. Distribuições Contínuas",
    "section": "Testes de hipóteses",
    "text": "Testes de hipóteses\nOs testes de hipóteses são utilizados para determinar quais resultados de um estudo científico podem levar à rejeição da hipótese nula (\\(H_0\\)) a um nível de significância pré–estabelecido. Os testes de hipóteses aqui demonstrados tem como objetivo:\n1) verificar se determinada amostra difrere ou não de zero (\\({H_0}:\\mu = 0\\));\n2) Verificar se duas amostras independentes são ou não iguais (\\({H_0}:{\\mu _1} = {\\mu _2}\\));\n2) Verificar se duas amostras dependentes possuem desvios iguais a zero (\\({H_0}:d_i = 0\\)).\n\nTeste de hipótese para uma amostra\nNo caso de uma amostra, a estatística teste (t calculado) é dada por\n\\[\n{t_{c(\\alpha; \\nu)}} = \\frac{{\\bar Y - \\mu }}{{\\frac{{{S_Y}}}{{\\sqrt n }}}}\n\\]\nOnde \\(\\alpha\\) é a probabilidade de erro, \\(\\nu\\) é o grau de liberdade (nº de amostras menos 1), \\(\\bar Y\\) é a média da amostra, \\(S_y\\) é o desvio padrão da amostra e \\(n\\) é o número de amostras.\nVamos retornar ao exemplo da altura da turma. A média da amostragem é de 170,44 cm. Digamos que a altura média dos alunos da UFSC é de 165 cm. Pode-se dizer que a estimativa da altura da turma de Bioestatística difere de 165 cm, considerando uma taxa de erro de 5%?\nPrimeiramente, define-se as hipóteses;\n\\[\n{H_0}:170,44 = 165\n\\]\n\\[\nH_1:170,44 \\ne 165\n\\]\n\naltura <- df_altura$altura\n(dp <- sd(altura))\n\n[1] 8.381925\n\n(media <- mean(altura))\n\n[1] 170.44\n\n(n <- length(altura))\n\n[1] 25\n\n(t_tab <- qt(0.975, df = n - 1))\n\n[1] 2.063899\n\n\n\\[\n{t_c} = \\frac{{170,44 - 165}}{{\\frac{{8,38}}{{\\sqrt {25} }}}}\n\\]\n\\[\n{t_c} = 3,245\n\\]\nComo o t calculado (3,245) é maior que o t tabelado (2,064), rejeita-se a hipótese nula e afirma-se que a estimativa da média da altura da turma difere de 165 cm. Este mesmo teste pode ser realizado com a função t.test().\n\n# t tabelado\nt.test(altura, mu = 165)\n\n\n    One Sample t-test\n\ndata:  altura\nt = 3.2451, df = 24, p-value = 0.003443\nalternative hypothesis: true mean is not equal to 165\n95 percent confidence interval:\n 166.9801 173.8999\nsample estimates:\nmean of x \n   170.44 \n\n\n\n\nTeste de hipóteses para amostras independentes\nNeste tipo de teste de hipótese, o objetivo é comparar se a estimativa da média de um grupo “A” difere estatisticamente da estimativa da média de um grupo “B”. Utilizaremos como amostras os dados da altura dos alunos, onde deseja-se testar a hipótese de diferença entre as médias da altura dos homens (\\(\\bar X_{xx}\\)) e das mulheres (\\(\\bar X_{xx}\\)). Primeiramente, define-se as hipóteses:\n\\[\n{H_0}:\\bar X_{xx} = \\bar X_{xy}\n\\]\n\\[\n{H_1}:\\bar X_{xx} \\ne \\bar X_{xy}\n\\]\n\n\nMostrar script\n#gráfico\nggplot(df_altura, aes(altura, fill = crm)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_manual(values = c(\"green\", \"red\")) +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())\n\n\n\n\n\nNeste caso, a estatística do teste é dada por\n\\[\n{t_c} = \\frac{{\\left( {{{\\bar X}_{xy}} - {{\\bar X}_{xx}}} \\right)}}{{\\sqrt {S_p^2\\left( {\\frac{1}{{{n_{xy}}}} + \\frac{1}{{{n_{xx}}}}} \\right)} }}\n\\]\nOnde\n\\[\nS_p^2 = \\frac{{\\left( {{n_{xy}} - 1} \\right)S_{{xy}}^2 + \\left( {{n_{xx}} - 1} \\right)S_{{xx}}^2}}{{{n_{xy}} + {n_{xx}} - 2}}\n\\]\nOnde \\(\\bar X_{xy}\\), \\(n_{xy}\\) e \\(S^2_{xy}\\) são a média, o tamanho da amostra e a variância para a amostra da altura dos homens; \\(\\bar X_{xx}\\), \\(n_{xx}\\) e \\(S^2_{xx}\\) são a média, o tamanho da amostra e a variância para a amostra da altura das mulheres. Vamos calcular estas estatísticas para os dados em questão. A estatística de teste é então comparada com o t tabelado com 23 (12 + 13 - 2) Graus Liberdade.\n\ndf_altura |> \n  desc_stat(altura,\n            by = crm,\n            stats = c(\"n, mean, var.amo\")) |> \n  as.data.frame()\n\n  crm variable  n     mean var.amo\n1  xx   altura 13 166.0769 45.0769\n2  xy   altura 12 175.1667 57.2424\n\n(t_tab <- qt(0.975, df = 23))\n\n[1] 2.068658\n\n\nCom base nos valores obtidos, a estatística t é obtida com:\n\\[\nS_p^2 = \\frac{{\\left( {12 - 1} \\right)57,242 + \\left( {13 - 1} \\right)45,077}}{{12 + 13 - 2}}\n\\]\n\\[\nS_p^2 = 50,895\n\\]\n\\[\n{t_c} = \\frac{{\\left( {175,167-166,077} \\right)}}{{\\sqrt {50,894\\left( {\\frac{1}{{12}} + \\frac{1}{{13}}} \\right)} }}\n\\]\n\\[\n{t_c} = 3,1825\n\\]\nComo \\(3,18 > 2,064\\), rejeita-se a hipótese \\(H_0\\) e conclui-se que as médias dos dois grupos são estatisticamente distintas. Usando a função t.test(), este teste de hipótese é realizado com:\n\n# testa se as amostras difrem entre si\nt.test(altura ~ crm, data = df_altura, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  altura by crm\nt = -3.1828, df = 23, p-value = 0.004146\nalternative hypothesis: true difference in means between group xx and group xy is not equal to 0\n95 percent confidence interval:\n -14.997666  -3.181821\nsample estimates:\nmean in group xx mean in group xy \n        166.0769         175.1667 \n\n\nO pacote ggstatplot pode ser utilizado para confecionar gráficos que incluem teste de hipóteses.\n\n\nMostrar script\nlibrary(ggstatsplot)\n\nggbetweenstats(df_altura, \n               x = crm,\n               y = altura,\n               plot.type = \"box\",\n               bf.message = FALSE,\n               k = 3, # dígitos\n               var.equal = TRUE)\n\n\n\n\n\n\n\nTeste de hipóteses para amostras dependentes\nAs formas de comparação discutidas acima consideram as amostras como sendo independentes entre si. Em certas ocasiões, um mesmo indivíduo de uma amostra é medido ao longo do tempo ou avaliado antes ou depois da aplicação de um determinado tratamento.\nAssim, nessas ocasiões, é possível avaliar se a diferença média das observações é estatisticamente igual a zero ou não. Se esta diferença for estatisticamente diferente de zero, pode-se afirmar que tal tratamento possui efeito significativo.\nA estatística do teste t para amostras pareadas é dada por\n\\[\n{t_c} = \\frac{{\\bar D}}{{\\frac{{{S_D}}}{{\\sqrt n }}}} \\sim {t_{\\left( {\\alpha ,\\nu } \\right)}}\n\\]\nOnde \\(\\bar D\\) é a média das diferenças e \\(S_D\\) é o desvio padrão das diferenças.\n\nA fim de determinar a eficiência de um medicamento antitérmico, a temperatura corporal (em graus Celsius) de 7 indivíduos foi medida. Em seguida, foi administrado o medicamento e após uma hora a temperatura foi medida novamente.\n\n\npaired <- \n  import(\"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=1507821405\",\n         dec = \",\")\npaired\n\n  INDIVIDUO ANTES DEPOIS DIFERENCA\n1         1  37.5   36.8      -0.7\n2         2  36.0   35.4      -0.6\n3         3  39.0   37.6      -1.4\n4         4  38.0   37.2      -0.8\n5         5  37.8   36.9      -0.9\n6         6  38.5   37.7      -0.8\n7         7  39.3   38.0      -1.3\n\n(mean_dif <- mean(paired$DIFERENCA))\n\n[1] -0.9285714\n\n(dp_dif <- sd(paired$DIFERENCA))\n\n[1] 0.3039424\n\n(n <- length(paired$DIFERENCA))\n\n[1] 7\n\n\nA estatística de teste é dada por:\n\\[\n{t_c} = \\frac{{-0.928 - 0}}{{\\frac{{0,3039}}{{\\sqrt {7} }}}}\n\\]\n\\[\nt_c = -8,079\n\\]\n\nantes <- paired$ANTES\ndepois <- paired$DEPOIS\nt.test(depois, antes, paired = TRUE, var.equal = TRUE)\n\n\n    Paired t-test\n\ndata:  depois and antes\nt = -8.083, df = 6, p-value = 0.0001921\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -1.2096712 -0.6474716\nsample estimates:\nmean difference \n     -0.9285714 \n\n\nNote que o mesmo resultado é obtido ao se realizar um teste para uma amostra utilizando a diferença calculada.\n\nt.test(paired$DIFERENCA, var.equal = TRUE)\n\n\n    One Sample t-test\n\ndata:  paired$DIFERENCA\nt = -8.083, df = 6, p-value = 0.0001921\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1.2096712 -0.6474716\nsample estimates:\n mean of x \n-0.9285714 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html",
    "title": "5. Visualização de dados",
    "section": "",
    "text": "Para reprodução destes exemplos, os seguintes pacotes precisam ser instalados do github\n\n# pacotes para criação de mapas (github)\nremotes::install_github(\"ropensci/rnaturalearthhires\")\nremotes::install_github(\"ricardo-bion/ggradar\")\nremotes::install_github(\"ricardo-bion/ggradar\")\n\nAntes de carregar, verifique se o pacote está instalado.\n\nlibrary(tidyverse)\nlibrary(metan)   \nlibrary(rio)\nlibrary(ggridges)\nlibrary(rnaturalearth)\nlibrary(ggradar)\nlibrary(lubridate)\nlibrary(geobr)\nlibrary(esquisse)\nlibrary(DataExplorer)"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#grãos-de-café",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#grãos-de-café",
    "title": "5. Visualização de dados",
    "section": "Grãos de café",
    "text": "Grãos de café\nOs dados contidos na aba graos do arquivo Atividade caracteres qualitativos e quantitativos serão utilizados. Este arquivo contém dados do comprimento e largura de grãos e folhas de café, amostrados na primeira aula de Bioestatística da turma 2022/01. Para carregar estes dados, utilizamos o seguinte comando.\n\nurl <- \"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=2073179916\"\ndf <- \n  import(url, dec = \",\") |> \n  as_factor(1:3)\nhead(df)\n\n    grupo individuo      cor comprimento largura\n1 Grupo 1         1 vermelho       13.49   16.61\n2 Grupo 1         2 vermelho       11.08   14.23\n3 Grupo 1         3 vermelho       13.35   15.93\n4 Grupo 1         4 vermelho        9.87   14.10\n5 Grupo 1         5    verde       11.61   16.11\n6 Grupo 1         6    verde        9.86   13.87"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação-meteorológica",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação-meteorológica",
    "title": "5. Visualização de dados",
    "section": "Dados da estação meteorológica",
    "text": "Dados da estação meteorológica\n\nurl2 <- \"https://docs.google.com/spreadsheets/d/1JMrkppvv1BdGKVCekzZPsPYCKcgUWjxpuDlWqejc22s/edit#gid=764890920\"\ndf_estacao <-  \n  import(url2, setclass = \"tbl\", dec = \",\") |> \n  as_character(1:4) |> \n  mutate(dia = dmy(dia),\n         m = fct_relevel(factor(m), paste0(1:10)))"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#o-pacote-ggplot2",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#o-pacote-ggplot2",
    "title": "5. Visualização de dados",
    "section": "O pacote ggplot2",
    "text": "O pacote ggplot2\nO ggplot2 é um pacote R para produção de gráficos que diferentemente da maioria dos outros pacotes, apresenta uma profunda gramática baseada no livro The grammar of graphics (Wilkinson 2005)1. Os gráficos originados em ggplot2 são baseados em camadas, e cada gráfico tem três componentes chave: data, os dados de onde o gráfico será criado; aes() (aesthetic mappings), que controla o mapeamento estético e as propriedades visuais do gráfico; e ao menos uma camada que irá descrever como cada observação será renderizada. Camadas são usualmente criadas utilizando uma função geom_()."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#galerias",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#galerias",
    "title": "5. Visualização de dados",
    "section": "Galerias",
    "text": "Galerias\n\nhttps://www.r-graph-gallery.com/portfolio/ggplot2-package/\nhttp://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html\nhttps://r4stats.com/examples/graphics-ggplot2/\nhttp://girke.bioinformatics.ucr.edu/GEN242/pages/mydoc/Rgraphics.html"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#extensões-do-ggplot2",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#extensões-do-ggplot2",
    "title": "5. Visualização de dados",
    "section": "Extensões do ggplot2",
    "text": "Extensões do ggplot2\n\nhttp://www.ggplot2-exts.org/gallery/\nhttps://mode.com/blog/r-ggplot-extension-packages"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#tutoriais-em-português",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#tutoriais-em-português",
    "title": "5. Visualização de dados",
    "section": "Tutoriais em português",
    "text": "Tutoriais em português\n\nhttps://rpubs.com/mnunes/ggplot2\nhttps://analisereal.com/2015/09/19/introducao-ao-ggplot2/\nhttps://timogrossenbacher.ch/2016/12/beautiful-thematic-maps-with-ggplot2-only/\nhttp://recologia.com.br/tag/graficos/\nhttp://rstudio-pubs-static.s3.amazonaws.com/24563_3b7b0a6414824e3b91769a95309380f1.html\nhttp://eduardogutierres.com/inteligencia-geografica-gerando-mapas-em-r/\nhttps://pt.stackoverflow.com/questions/332053/r-mapa-de-cidades-brasileiras"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#meu-primeiro-gráfico-em-ggplot2",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#meu-primeiro-gráfico-em-ggplot2",
    "title": "5. Visualização de dados",
    "section": "Meu primeiro gráfico em ggplot2",
    "text": "Meu primeiro gráfico em ggplot2\nA seguir, vamos discutir os aspcetos básicos para a construção de gráficos utilizando o pacote ggplot2. A função arrange_ggplot() do pacote metan é utilizada aqui para organizar os gráficos em forma de painéis."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#as-camadas-de-um-gráfico-ggplot2",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#as-camadas-de-um-gráfico-ggplot2",
    "title": "5. Visualização de dados",
    "section": "As camadas de um gráfico ggplot2",
    "text": "As camadas de um gráfico ggplot2\nNo ggplot2, os gráficos são construídos camada por camada (ou, layers, em inglês). Neste exemplo, vamos confeccionar um gráfico mostrando a distribuição do comprimento da folha (eixo x) e largura da folha (eixo y).\n\np1 <- \n  ggplot(df, aes(x = comprimento, y = largura)) +\n  geom_point()\np1\n\n\n\n\nEste comando criou um gráfico e armazenou no objeto p1, que será plotado posteriormente. Observe que o primeiro argumento da função é o data frame onde nossos dados foram armazenados. A função aes() descreve como as variáveis são mapeadas (neste caso comprimento no eixo x e largura no eixo y). A função geom_point() definiu que a forma geométrica a ser utilizada é baseada em pontos, gerando, assim, um gráfico de dispersão. Isto é tudo que precisa ser feito para a confecção de um gráfico simples."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#aesthetics-estética",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#aesthetics-estética",
    "title": "5. Visualização de dados",
    "section": "Aesthetics (estética)",
    "text": "Aesthetics (estética)\n\n“O maior valor de uma imagem é quando ela nos obriga a perceber o que nunca esperamos ver.” — John Tukey\n\nAlterar a estética dos gráficos ggplot2 é uma tarefa relativamente simples. No gráfico anterior, os valores do comprimento e largura foram plotados sem nenhum tipo de mapeamento estético. Digamos que marcadores com diferentes cores para cada nível do fator cor poderia nos ajudar a compreender melhor o padrão presente em nossos dados. Vamos confeccionar este gráfico.\n\np2 <- \n  ggplot(df, aes(x = comprimento,\n                 y = largura,\n                 colour = cor)) +\n  geom_point()\np2\n\n\n\n\nAo incluirmos colour = cor dentro da função aes, dizemos ao ggplot que os pontos devem ser mapeados esteticamente (neste caso utilizando cores) para cada nível do fator cor presente em nossos dados. Digamos que em vez de utilizar diferentes cores, a cor do grão do café deveria ser representada por diferentes tipos de marcadores (quadrados, triângulo, etc.) Neste caso, o argumento colour = cor é substituído por shape = cor.\n\n#| out-width: \"100%\"\n#| \np3 <- \n  ggplot(df, aes(x = comprimento, y = largura, shape = cor, color = cor)) +\n  geom_point()\n\n# organizar os gráficos\narrange_ggplot(p1, p2, p3,\n               ncol = 3,\n               tag_levels = list(c(\"p1\", \"p2\", \"p3\")))"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#salvar-gráficos",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#salvar-gráficos",
    "title": "5. Visualização de dados",
    "section": "Salvar gráficos",
    "text": "Salvar gráficos\nA função ggsave() é uma função conveniente para salvar um gráfico. O padrão é salvar a última plotagem exibida, usando o tamanho do dispositivo gráfico atual. Também é possível informar a altura (height) e largura (width). Ele também adivinha o tipo de dispositivo gráfico da extensão. No seguinte exemplo, o gráfico acima é salvo no diretório de trabalho atual com o nome pontos.png, com 5 polegadas de altura e 10 de largura.\n\nggsave(\"pontos.png\",\n       height = 5,\n       width = 10)"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#facet-facetas",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#facet-facetas",
    "title": "5. Visualização de dados",
    "section": "Facet (facetas)",
    "text": "Facet (facetas)\nMapeando os diferentes níveis de cor para diferentes cores, incluímos em um único gráfico os dados de todos osgrupos. Mas, e se nosso objetivo fosse realizar um gráfico para cada grupo? O ggplot2 tem uma poderosa ferramenta para isto: as funções facet_. Ao utilizar estas funções, o conjunto de dados é subdividido e um gráfico é construído para cada um destes subconjuntos. Vamos ver como elas podem nos ajudar em nosso problema.\n\nfac1 <- \n  ggplot(df, aes(x = comprimento,\n                 y = largura,\n                 color = cor)) +\n  geom_point() +\n  facet_wrap(~ grupo)\nfac1\n\n\n\n\nUm painel para cada nível da variável grupo.\n\n\n\n\nNeste exemplo, um gráfico completamente diferente do anterior é gerado com apenas uma simples adição: incluímos uma nova função, facet_wrap(~ grupo). Neste caso, informamos que um gráfico deveria ser realizado para cada grupo."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#theme-temas",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#theme-temas",
    "title": "5. Visualização de dados",
    "section": "Theme (temas)",
    "text": "Theme (temas)\nCada gráfico criado com a função ggplot() tem um tema padrão. Tema, aqui, é toda propriedade relacionada ao aspecto visual do gráfico, que não foi definida na função aes() e que pode ser modificada utilizando a função theme() (veja ?theme). O ggplot2 já conta com alguns temas personalizados para facilitar nosso trabalho. Considerando o exemplo anterior, vamos utilizar a função theme_bw() (preto e branco) e a função theme() para modificar as propriedades visuais do gráfico.\n\nfac2 <- \n  ggplot(df, aes(x = comprimento, y = largura, color = cor)) +\n  geom_point() +\n  facet_wrap(~ grupo) +\n  theme_light() +\n  theme(panel.grid.minor = element_blank(), # remove as linhas do corpo do gráfico\n        # sem bordas entre os painéis\n        panel.spacing = unit(0, \"cm\"),\n        # legenda abaixo do gráfico\n        legend.position = \"bottom\",\n        # modifica o texto dos eixos\n        axis.text = element_text(size = 12, colour = \"black\"),\n        # cor dos marcadores\n        axis.ticks = element_line(colour = \"black\"),\n        # tamanho dos marcadores\n        axis.ticks.length = unit(.2, \"cm\"), \n        #cor da borda\n        panel.border = element_rect(colour = \"black\", fill = NA, size = 0.5))+\n  # título dos eixos\n  labs(x = \"Comprimento do grão (mm)\", # título do eixo x\n       y = \"Largura do grão (mm)\", # título do eixo y\n       color = \"\") # título da legenda\n\narrange_ggplot(fac1, fac2,\n               ncol = 1,\n               tag_levels = list(c(\"f1\", \"f2\")))\n\n\n\n\nGráfico de dispersão considerando a confecção de um gráfico para cada nível de um fator(f1) e modificações na propriedades do tema de um gráfico ggplot2 (f2)\n\n\n\n\nOs argumentos inseridos dentro das função theme() modificaram a aparência do nosso gráfico. Inúmeros outros argumentos são disponíveis, fazendo com que os gráficos originados sejam completamente personalizáveis. Digamos que precisamos confeccionar diversos gráficos e gostaríamos de manter o mesmo tema do gráfico acima. Seria exaustivo e desinteressante informar cada vez estes argumentos para cada gráfico, não? Felizmente, outra poderosa ferramenta proporcionada pelo ggplot2 é a possibilidade de confeccionarmos nossos próprios temas. Para isto, vamos executar o seguinte comando para criar um tema personalizado (my_theme()). Este tema pode então ser aplicado como uma camada adicional a cada gráfico que confecionarmos. Para evitar a necessidade da inclusão deste tema em cada gráfico gerado, iremos definir este tema como padrão utilizando a função theme_set().\n\nmy_theme <- function () {\n  theme_light() %+replace% # permite que os valores informados possam ser sobescritos\n    theme(axis.ticks.length = unit(.2, \"cm\"),\n          axis.text = element_text(size = 12, colour = \"black\"),\n          axis.title = element_text(size = 12, colour = \"black\"),\n          axis.ticks = element_line(colour = \"black\"),\n          panel.border = element_rect(colour = \"black\", fill = NA, size = 0.5),\n          panel.grid.minor =  element_blank())\n}\ntheme_set(my_theme())"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#geoms-geometria",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#geoms-geometria",
    "title": "5. Visualização de dados",
    "section": "Geoms (geometria)",
    "text": "Geoms (geometria)\nAs funções geom_ definem qual forma geométrica será utilizada para a visualização dos dados no gráfico. Até agora, utilizamos a função geom_point()para construir gráficos de dispersão. Basicamente, qualquer outro tipo de gráfico pode ser criado dependendo da função geom_ utilizada. Dentre as diversas disponíveis no pacote ggplot2 as funções geom_ mais utilizadas são:\n\ngeom_abline(): para retas definidas por um intercepto e uma inclinação;\ngeom_hline(): para retas horizontais definidas por um intercept y;\ngeom_vline(): para retas verticais definidas por um intercept x;\ngeom_boxplot(): para boxplots;\ngeom_histogram(): para histogramas de frequência;\ngeom_smooth(): ajusta uma função para o conjunto de dados e mostra uma banda de confiança;\ngeom_density(): para densidades;\ngeom_area(): para áreas;\ngeom_bar(): para barras;\ngeom_errorbar() para barras de erro;\n\nDeste ponto em diante, vamos confeccionar alguns exemplos utilizando algumas destas funções (ou combinações destas funções) incluindo argumentos de mapeamento de estética e temas vistos até agora.\n\nLinhas horizontais, verticais e diagonais\nTrês importantes geometrias são apresentadas a seguir:\n\ngeom_hline() adiciona uma linha horizontal definida por um intercepto em y\ngeom_vline() adiciona uma linha vertical definida por um intercepto em x.\ngeom_abline() adiciona uma linha diagonal definida por um intercepto e uma inclinação.\n\n\ng1 <- \n  ggplot(df, aes(comprimento, largura)) +\n  geom_point()\n\n\n# adiciona linhas horizontais e verticais\ng2 <- \n  g1 +\n  geom_hline(yintercept = mean(df$largura), color = \"blue\") +\n  geom_vline(xintercept = mean(df$comprimento), color = \"red\")\n\narrange_ggplot(g1, g2,\n               ncol = 1,\n               tag_levels = list(c(\"g1\", \"g2\")))\n\n\n\n\n\n\nGráficos do tipo boxplot\n\nbox1 <- \n  ggplot(df, aes(grupo, comprimento)) +\n  geom_boxplot()\n\nbox2 <- \n  ggplot(df, aes(grupo, comprimento)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.1, color = \"salmon\")\n\nbox3 <- \n  ggplot(df, aes(grupo, comprimento, fill = cor)) +\n  geom_boxplot(width = 0.3) + \n  labs(x = \"Grupo\",\n       y = \"Comprimento do grão (mm)\") +\n  theme(legend.position = \"bottom\") +\n  scale_fill_manual(values = c(\"green\", \"red\"))\n\narrange_ggplot((box1 + box2) / box3,\n               tag_levels = list(c(\"b1\", \"b2\", \"b3\")))\n\n\n\n\nGráfico do tipo boxplot combinando mapeamentos estéticos.\n\n\n\n\nCinco estatísticas são mostradas neste boxplot. A mediana (linha horizontal), as caixas inferior e superior (primeiro e terceiro quartil (percentis 25 e 75, respectivamente)). A linha vertical superior se estende da caixa até o maior valor, não maior que $1,5 $ (onde IQR é a amplitude interquartílica). A linha vertical inferior se estende da caixa até o menor valor, de no máximo, $1,5 $. Dados além das linhas horizontais podem ser considerados outliers.\n\n\nGráficos do tipo histograma\nNeste exemplo, utilizaremos os dados de temperatura mínima da estação meteorológica, disponível no data frame df_estacao. O primeiro histograma (p1) mostra os dados gerais desde 01/01/2022. No segundo, um histograma é gerado para cada mês.\n\nh1 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_histogram()\n\nh2 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_histogram(color = \"black\",\n                 fill = \"skyblue\") +\n  facet_wrap(~m) +\n  labs(x = \"Temperatura mínima\",\n       y = \"Horas\")\n\narrange_ggplot(h1, h2,\n               widths = c(1, 1.4),\n               tag_levels = list(c(\"h1\", \"h2\")))\n\n\n\n\nGráfico do tipo histograma\n\n\n\n\nNo histograma (h2), a linha vermelha representa a estimativa da função de probabilidade normal. Para isto, a escala do eixo y foi mudada de contagem para densidade.\n\n\nGráficos de Densidade\nOs gráficos de densidade, têm a mesma interpretação que histogramas, no então são esteticamente mais atraente. Os primeiros dois exemplos nada mais são que a versão densidade dos histogramas apresentados anteriormente.\nNo terceiro exemplo (d3), eu mostro como é possível construir um gráfico de densidade ridges. Gráficos ridges são gráficos de linha parcialmente sobrepostos que criam a impressão de uma cordilheira. Eles podem ser bastante úteis para visualizar mudanças nas distribuições ao longo do tempo ou espaço2.\n\nd1 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_density()\n\nd2 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_density(color = \"black\",\n               fill = \"skyblue\") +\n  facet_wrap(~m, ncol = 5) +\n  labs(x = \"Temperatura média (ºC)\",\n       y = \"Densidade\")\n\nd3 <- \n  ggplot(df_estacao, aes(x = tmed, y = m, fill = stat(x))) +\n  geom_density_ridges_gradient() +\n  scale_fill_viridis_c() +\n  labs(x = \"Temperatura média (ºC)\",\n       y = \"Meses do ano\",\n       fill = \"Temperatura\\nmédia (ºC)\")\n\n# agrupa os gráficos\narrange_ggplot((d1 + d2) / d3,\n               tag_levels = list(c(\"d1\", \"d2\", \"d3\")))\n\n\n\n\nGráfico do tipo densidade\n\n\n\n\n\n\nGráficos de linhas\nO seguinte exemplo mostra a temperatura mínima, média e máxima ao longo dos dias desde 01/01/2022.\nPrimeiro, é preciso obter as temperaturas mínimas, máximas e médias de cada dia. Fazemos isso com a função summarise().\n\nclima_max_min <-\n  df_estacao %>%\n  group_by(dia) %>% \n  summarise(max = max(tmax),\n            min = min(tmin),\n            mean = mean(tmed),\n            precip = sum(prec)) %>% \n  pivot_longer(-dia)\nclima_max_min\n\n# A tibble: 1,152 × 3\n   dia        name   value\n   <date>     <chr>  <dbl>\n 1 2022-01-01 max     28.7\n 2 2022-01-01 min      0  \n 3 2022-01-01 mean    24.0\n 4 2022-01-01 precip   0  \n 5 2022-01-02 max     31.8\n 6 2022-01-02 min     23.4\n 7 2022-01-02 mean    27.1\n 8 2022-01-02 precip   0  \n 9 2022-01-03 max     32.4\n10 2022-01-03 min     24.3\n# … with 1,142 more rows\n\n\n\n# realiza um subset para remover a precipitação\ndf_temp <-  \n  clima_max_min |>  \n  subset(name != \"precip\")\n\n# faz o gráfico de linhas\nggplot(df_temp, aes(dia, value, color = name)) +\n  geom_point() + \n  geom_line() + \n  scale_color_manual(values = c(\"red\", \"green\", \"blue\"),\n                     labels = c(\"Temperatura máxima (ºC)\",\n                                \"Temperatura média (ºC)\",\n                                \"Temperatura mínima (ºC)\"),\n                     guide = \"legend\") + \n  scale_x_date(date_breaks = \"3 week\", # marcação a cada duas semanas\n               date_labels = \"%d/%m/%y\") + # formato dd/mm/aa\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + \n  labs(title = \"Temperaturas máximas, médias e mínimas em 2022\",\n       subtitle = \"Estação - Fazenda Ressacada\",\n       caption = \"Elaboração: Prof. Olivoto\",\n       x = \"Dia do ano\",\n       y = \"Temperatura (ºC)\",\n       color = NULL) # remove o título da legenda\n\n\n\n\n\n\nGráficos do tipo barra\nNo seguinte exemplo, os dados do comprimento do grão de café disponíveis em df são utilizados.\n\nbar1 <- \n  ggplot(df, aes(x = grupo, y = comprimento)) +\n  geom_bar(stat = \"summary\", fun = \"mean\")\n\nbar2 <- \n  ggplot(df, aes(x = grupo, y = comprimento, fill = cor)) +\n  stat_summary(fun = mean,\n               geom = \"bar\",\n               col = \"black\",\n               width = 0.8,\n               position = position_dodge(0.8)) + \n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.2,\n               position = position_dodge(0.8))\n\n\narrange_ggplot(bar1, bar2,\n               widths = c(0.6, 1.2),\n               tag_levels = list(c(\"bar1\", \"bar2\")))\n\n\n\n\nGráfico do tipo barras, com mapeamento estético e barras de erro.\n\n\n\n\nA afirmação de que um gráfico ggplot2 é feito em camadas fica mais evidente aqui. No gráfico bar1, as barras representam as médias geral do comprimento para cada grupo. No segundo gráfico, ao usar fill = cor informamos que as barras devem ser coloridas para cada nível do fator cor. A função stat_summary(), é vista pela primeira vez aqui, foi utilizada no segundo gráfico para substituir a função geom_bar(). Com isto, foi possível incluir as médias (fun = mean e geom = \"bar), bem como as barras de erro (fun.data = mean_se e geom = \"errorbar\").\nUtilizando a função plot_factbars() do pacote metan, um gráfico semelhante pode ser criado com as funções plot_bars() e plot_factbars()\n\nmetan1 <- \n  plot_bars(df,\n            x = grupo,\n            y = comprimento)\nmetan2 <- \n  plot_factbars(df, # dados\n                grupo, cor, # dois fatores\n                resp = comprimento) # eixo y\n\narrange_ggplot(metan1, metan2,\n               widths = c(0.6, 1.2),\n               tag_levels = list(c(\"metan1\", \"metan2\")))\n\n\n\n\n\n\nLinha de regressão (linear)\n\nl1 <-\n  ggplot(df, aes(x = comprimento, y = largura)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + # estima uma regressão linear\n  labs(x = \"Comprimento do grão\",\n       y = \"Largura do grão\")\n\nl2 <-\n  ggplot(df, aes(x = comprimento, y = largura, color = grupo)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F)+\n  labs(x = \"Comprimento do grão\",\n       y = \"Largura do grão\")\n\narrange_ggplot(l1, l2,\n               tag_levels = list(c(\"s1\", \"s2\")),\n               widths = c(1, 1.2))\n\n\n\n\nGráfico de dispersão, combinando pontos e linhas de regressão.\n\n\n\n\n\n\nLinha de regressão (polinomial)\nPara confeccionar um gráfico de regressão polinomial, além do argumento method = \"lm\" (linear model), precisa-se incluir no argumento formula a formula utilizada, neste caso, definida utilizando poly() (polinomial).\n\n#### Polinômio de segundo grau\n\ndado_reg <- tibble(dose = c(15,20,25,30,35,40),\n                   prod = c(65,70,73,75,69,62))\n\nq1 <-\n  ggplot(dado_reg, aes(dose, prod))+\n  geom_point()+\n  stat_smooth(method = \"lm\",\n              formula = \"y ~ poly(x, 1)\",\n              se = FALSE)\n\nq2 <-\n  q1 +\n  stat_smooth(method = \"lm\",\n              formula = \"y ~ poly(x, 2)\",\n              linetype = \"dashed\",\n              color = \"red\",\n              se = FALSE)\n\narrange_ggplot(q1, q2, tag_levels = list(c(\"l1\", \"l2\")))\n\n\n\n\nGráfico de dispersão combinado com inclusão de curvas ajustadas.\n\n\n\n\nUtilizando a função plot_lines() do pacote metan, um gráfico semelhante pode ser criado com\n\nplot_lines(dado_reg,\n           x = dose,\n           y = prod,\n           fit = 2)"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#dados-da-estação",
    "title": "5. Visualização de dados",
    "section": "Dados da estação",
    "text": "Dados da estação\n\nExploração dos dados\n\nplot_intro(df_estacao)\n\n\n\n# Colunas numéricas\nplot_histogram(df_estacao, ncol = 5)\n\n\n\n\n\n\nGráfico da precipitação e temperatura\n\n#| out-width: \"100%\"\n\n\ndf_prec <- \n  clima_max_min |> \n  pivot_wider(names_from = \"name\",\n              values_from = \"value\")\n\nggplot() +\n  geom_bar(df_prec,\n           mapping = aes(x = dia, y = precip * 30 / 100),\n           stat = \"identity\",\n           fill = \"skyblue\") +\n  geom_line(df_prec,\n            mapping = aes(x = dia, y = max, colour = \"red\"),\n            size = 1) +\n  geom_line(df_prec, \n            mapping = aes(x = dia, y = min, colour = \"blue\"),\n            size = 1) +\n  scale_x_date(date_breaks = \"15 days\", date_labels =  \"%d/%m\",\n               expand = expansion(c(0, 0)))+\n  scale_y_continuous(name = expression(\"Temperatura (\"~degree~\"C)\"),\n                     sec.axis = sec_axis(~ . * 100 / 30 , name = \"Precipitação (mm)\")) +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  scale_color_identity(breaks = c(\"red\", \"blue\"),\n                       labels = c(\"Temperatura máxima (ºC)\",\n                                  \"Temperatura mínima (ºC)\"),\n                       guide = \"legend\") +\n  labs(x = \"Dia do ano\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nTemperaturas máximas e mínimas e precipitação observada ao longo dos dias.\n\n\n\n\n\n\nVelocidade média do vento\n\n\nvento_long <-\n  df_estacao %>%\n  select(m, hora, velvent) %>% \n  pivot_longer(-c(m, hora))\nhead(vento_long)\n## # A tibble: 6 × 4\n##   m     hora  name    value\n##   <fct> <chr> <chr>   <dbl>\n## 1 1     00:00 velvent  0   \n## 2 1     01:00 velvent  0   \n## 3 1     02:00 velvent  0   \n## 4 1     03:00 velvent  0   \n## 5 1     04:00 velvent  0   \n## 6 1     05:00 velvent  0.33\n\n\n\n# confeccionar gráfico\nggplot(vento_long, aes(m, value, color = name, group = name )) +\n  stat_summary(geom = \"point\", \n               fun = mean) +\n  stat_summary(geom = \"line\") + \n  stat_summary(geom = \"errorbar\", width = 0.1) +\n  scale_color_manual(values = c(\"red\", \"blue\"),\n                     labels = c(\"Rajada (m/s)\",\n                                \"Velocidade do vento (m/s)\"),\n                     guide = \"legend\") +\n  theme(panel.grid.minor = element_blank(),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 12)) + \n  labs(title = \"Velocidade média mensal do vento em 2022\",\n       subtitle = \"Estação UFSC - Ressacada\",\n       caption = \"Elaboração: Prof. Tiago Olivoto\",\n       x = \"Mês do ano\",\n       y = \"Velocidade (m/s)\")\n\n\n\n\n\n\nDireção do vento\n\n\n# cria uma tabela de frequência transformando a variável quantitativa direção do vento\n# em uma qualitativa \nfreq <- \n  cut(df_estacao$dirvent, breaks = seq(0, 360, by = 45)) |> \n  table() |> \n  as.data.frame() %>% \n  set_names(\"Direção\", \"Dias\") %>% \n  mutate(Direção = paste0(seq(0, 315, by = 45)),\n         Percent = Dias / 3428 * 100) %>% \n  remove_cols(Dias)\nfreq\n##   Direção   Percent\n## 1       0 31.213536\n## 2      45 15.344224\n## 3      90 16.044341\n## 4     135 30.484247\n## 5     180 24.387398\n## 6     225 10.880980\n## 7     270  7.613769\n## 8     315 46.849475\n\n\n# criar um radar plot para mostrar a direção predominante\n# do vento\nggradar(freq %>% transpose_df(),\n        values.radar = c(\"0%\",  \"25.8%\"),\n        grid.max = max(freq$Percent))"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#mapas",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#mapas",
    "title": "5. Visualização de dados",
    "section": "Mapas",
    "text": "Mapas\n\nMapa da américa do sul e Brasil\nO pacote rnaturalearth é uma excelente ferramenta para manter e facilitar a interação com os dados do mapa Natural Earth. Para produção de mapas com o ggplot2, os seguintes pacotes são necessários.\n\n#| out-width: \"100%\"\n\n\n# américa do sul\nlibrary(rnaturalearth)\nlibrary(tidyverse)\nsam <-\n  ne_countries(continent = \"south america\",\n               returnclass = \"sf\",\n               scale = 50)\n\np1 <- \n  ggplot() +\n  geom_sf(data = sam, fill = \"white\") +\n  theme_light() +\n  xlim(c(-90, -35))\n\n# plotar o brasil e destacar santa catarina\nbrazil <- \n  ne_states(country = \"brazil\", returnclass = \"sf\") |> \n  mutate(scat = ifelse(postal == \"SC\", \"SC\", \"Outros\"))\n\np2 <- \n  p1 + \n  geom_sf(data = brazil, aes(fill = scat))\np2\n\n\n\n\n\n\nMapa do Brasil e SC, com municípios\n\nsc <- \n  read_municipality(code_muni = \"SC\",\n                    simplified = FALSE,\n                    showProgress = FALSE) |> \n  mutate(floripa = ifelse(name_muni == \"Florianópolis\",\n                          \"Florianópolis\",\n                          \"Outro\"))\n\nUsing year 2010\n\np3 <-\n  p1 + \n  geom_sf(data = brazil) +\n  geom_sf(data = sc, aes(fill = floripa)) +\n  xlim(c(-55, -47)) +\n  ylim(c(-30, -25)) +\n  labs(title = \"Mapa do brasil destacando o estado de SC\",\n       caption = \"Produzido com os pkgs geobr e rnaturalearth\",\n       fill = \"\") +\n  theme(legend.position = \"bottom\")\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\np3"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#o-pacote-esquisse",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#o-pacote-esquisse",
    "title": "5. Visualização de dados",
    "section": "O pacote esquisse",
    "text": "O pacote esquisse\nO pacote esquisse ajuda a explorar e visualizar dados de forma interativa. Ele é uma interface Shiny para criar gráficos ggplot interativamente usando “arrastar e soltar” para mapear suas variáveis. Pode-se visualizar rapidamente os dados de acordo com seu tipo, exportar para formatos raster (ex., .png, .jpg) ou vetor (ex., .pdf, .eps) e recuperar o código para reproduzir o gráfico.\nPara inciar a criação do gráfico, basta carregar o pacote e executar o comando esquisser(). Uma janela aparecerá, onde será possível importar um conjunto de dados, ou utilizar um conjunto de dados existente no ambiente R.\n\nesquisser()\n\n\nApós selecionar o conjunto de dados, as variáveis existentes ficarão disponíveis para serem mapeadas. Basta clicar e arrastar! Para ter uma maior área de trabalho do pacote, sugere-se definir a opção para que a interface gráfica do pacote seja aberta no navegador. Para isso, rode options(\"esquisse.viewer\" = \"browser\")."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#motivação",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#motivação",
    "title": "5. Visualização de dados",
    "section": "Motivação",
    "text": "Motivação\nA densidade de fluxo de fótons fotossintéticos (PPFD) em níveis subótimos ou superótimos pode modificar o acúmulo de biomassa, composição bromatológica e aparência das culturas. Para isso, Olivoto et al. (2018)3 investigaram o efeito de níveis de radiação no crescimento da chicória (Cichorium endivia L. var. latifolia). Os dados disponíveis na aba FAT_CI (https://docs.google.com/spreadsheets/d/1vpVGdIkggRxmdnwrkllHbVA0TIHN85UK/edit#gid=2056145155) são relativos a duas variáveis, à saber, matéria seca total (MST) e área foliar (AF) de plantas de chicória cultivadas em diferentes níveis de sombreamento (50, 70, e 100), e avaliados aos 21, 28 e 35 dias após o plantio.\n\nConsiderando o link disponível, importe os dados para o software R, salvando-os em um objeto chamado df (preste atenção com o separador decimal!).\n\n\nlibrary(rio)\nlibrary(tidyverse)\nlibrary(metan)\nurl <- \"https://docs.google.com/spreadsheets/d/1vpVGdIkggRxmdnwrkllHbVA0TIHN85UK/edit#gid=2056145155\"\ndf <-  import(url, dec = \",\")\n\nPara lapidar os conhecimentos na construção de gráficos, utilize o pacote ggplot24 e metan5 para solução dos seguintes problemas."
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#problema-1---associação-entre-variáveis",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#problema-1---associação-entre-variáveis",
    "title": "5. Visualização de dados",
    "section": "Problema 1 - Associação entre variáveis",
    "text": "Problema 1 - Associação entre variáveis\n\nConsiderando os dados, construa um gráfico de dispersão com a variável AF no eixo x e a variável MST no eixo y, salve o gráfico em um objeto chamado p1.\n\n\np1 <- \n  ggplot(df, aes(AF, MST)) +\n  geom_point()\n\n\nPara melhor compreender a distribuição dos pontos, realize o mapeamento da variável DAP com diferentes cores.\nAltere a legenda do eixo x e y para ‘Área foliar (cm2)’ e ‘Matéria seca (g)’, respectivamente.\nAplique um tema de sua preferência ao tema utilizando qualquer tema definido por theme_*()6.\nArmazene o gráfico em um objeto chamado p2.\n\n\np2 <- \n  ggplot(df, aes(AF, MST, color = DAP)) +\n  geom_point() +\n  labs(x = \"Área foliar (cm2)\",\n       y = \"Matéria seca (g)\")\n\n\nOrganize os gráficos p1 e p2 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p1, p2)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à associação entre AF e MST.\n\n\nA área foliar e a matéria seca estão positivamente relacionadas, ou seja, há a tendêncida de que o aumento na área foliar venha acompanhado do aumento na matéria seca. No segundo gráfico, é possível identificar que os maiores valores de matéria seca e área foliar foram observados nos 35DAP, e o menores, aos 21DAP.\n\n\nSalve os gráficos em um arquivo chamado dispersão.png, com 3 polegadas de altura e 8 de largura\n\n\nggsave(\"dispersão.png\", width = 8, height = 3)"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#problema-2---variação-dos-dados",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#problema-2---variação-dos-dados",
    "title": "5. Visualização de dados",
    "section": "Problema 2 - Variação dos dados",
    "text": "Problema 2 - Variação dos dados\n\nConfeccione um gráfico do tipo boxplot contendo a variável DAP no eixo x e MST no eixo y. Salve o gráfico em um objeto chamado p3.\n\n\np3 <- \n  ggplot(df, aes(DAP, MST)) +\n  geom_boxplot()\n\n\nPara fazer inferências sobre o fator sombreamento, construa um boxplot semelhante, mas agora mapeando a variável SOM com diferentes cores de preenchimento do boxplot. * Inclua uma linha horizontal que represente a média geral da matéria seca.\nSalve o gráfico em um objeto chamado p4.\n\n\np4 <- \n  ggplot(df, aes(DAP, MST, fill = SOM)) +\n  geom_boxplot() +\n  geom_hline(yintercept = mean(df$MST))\n\n\nOrganize os gráficos p3 e p4 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p3, p4)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à variação da matéria seca total entre os diferentes níveis de radiação dentro de cada dia após o plantio.\n\n\nAos 21DAP foi observada a menor variação entre os níveis de SOM. Aos 28DAP, a diferença entre os níveis de SOM foi mais evidente, onde plantas crescendo em 100R apresentaram um valor mediano de MST maior, mas também a maior variação entre as repetições (comprimento da caixa). Aos 35DAP, a diferença entre as radiações torna-se mais evidente. Também, pode-se observar que as variações entre as repetições do 100R e 50R foram menores se comparado aos 28DAP (menor comprimento da caixa).\n\n\nSalve os boxplots em um arquivo chamado boxplot.png.\n\n\nggsave(\"boxplot.png\")"
  },
  {
    "objectID": "FIT5306/FIT5306_05_DATAVIZ.html#problema-3---médias",
    "href": "FIT5306/FIT5306_05_DATAVIZ.html#problema-3---médias",
    "title": "5. Visualização de dados",
    "section": "Problema 3 - Médias",
    "text": "Problema 3 - Médias\n\nConfeccione um gráfico de barras mostrando a média da variável AF no eixo y para cada dia após o plantio (DAP) no eixo x.\nDefina os limites do eixo y de 0 até 6000.\nSalve o gráfico em um objeto chamado p5.\n\n\nDica: a função plot_bars() do pacote metan pode ser útil.\n\n\np5 <- \n  plot_bars(df,\n            x = DAP,\n            y = AF,\n            y.lim = c(0, 6000))\n\n# versão ggplot2\np5.2 <- \n  ggplot(df, aes(DAP, AF)) +\n  geom_bar(stat = \"summary\") +\n  ylim(c(0, 6000))\n\n\nAssumindo que as médias da AF precisam ser apresentadas para cada combinação de DAP e SOM, mapeie a variável SOM com diferentes cores de preenchimento no gráfico de barras.\nMude os títulos dos eixos x e y para “Dias após o plantio (DAP)” e “Área foliar (cm2)”, respectivamente.\nDefina os limites do eixo y de 0 até 6000.\nArmazene o gráfico em um objeto chamado p6.\nOrganize os gráficos p5 e p6 em um único painel\nSalve os gráficos de barra em uma imagem chamada barras.png.\n\n\nDica: a função plot_factbars() do pacote metan pode ser útil.\n\n\np6 <- \n  plot_factbars(df, DAP, SOM,\n                resp = AF,\n                y.lim = c(0, 6000),\n                xlab = \"Dias após o plantio (DAP)\",\n                ylab = \"Área foliar (cm2)\")\n\n# versão ggplot2\np6.2 <- \n  ggplot(df, aes(DAP, AF, fill = SOM)) +\n  geom_bar(stat = \"summary\",\n           fun = \"mean\",\n           width = 0.7,\n           position = position_dodge()) +\n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.2,\n               position = position_dodge( width = 0.7)) +\n  labs(x = \"Dias após o plantio (DAP)\",\n       y = \"Área foliar (cm2)\") +\n  ylim(c(0, 6000))\n\n\nOrganize os gráficos p5 e p6 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p5, p6)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à área foliar nos diferentes níveis de radiação ao longo dos dias após o plantio.\n\n\nA média da área foliar foi mais semelhante entre os níveis de radiação aos 21DAP. Considerando o erro padrão da média como uma medida de significância, pode-se afirmar que aos 21DAP as médias do 50R e 70R foram estatisticamente iguais. Aos 35DAP, a área foliar das plantas crescendo com 50% de radiação foi menor que àquelas crescendo em pleno sol (100R) e com 70% de radiação (70R).\n\n\nSalve os boxplots em um arquivo chamado barras.png.\n\n\nggsave(\"barras.png\")"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html",
    "title": "6. Amostragem",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.2.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\n\nWarning: package 'tibble' was built under R version 4.2.1\n\n\nWarning: package 'tidyr' was built under R version 4.2.1\n\n\nWarning: package 'readr' was built under R version 4.2.1\n\n\nWarning: package 'purrr' was built under R version 4.2.2\n\n\nWarning: package 'dplyr' was built under R version 4.2.1\n\n\nWarning: package 'stringr' was built under R version 4.2.1\n\n\nWarning: package 'forcats' was built under R version 4.2.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(rio)\n\nWarning: package 'rio' was built under R version 4.2.2\n\ndf <- import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=1590128876\")\ndf\n\n   id                                 aluno crm altura\n1   1                Aline Kliauga Ferrante  xx     NA\n2   2                     André Cuneo Sagaz  xy     NA\n3   3              Beatriz Haensel Teixeira  xx     NA\n4   4                        Bruna Waltrich  xx    156\n5   5       Carlos Eduardo Forcelini Assoni  xy     NA\n6   7                Danielli Zangalli Kern  xx    169\n7  11                 Gabriela Araujo Catto  xx    162\n8   8                 Felipe Ricci Westphal  xy     NA\n9  13         Helena dos Santos Vanderlinde  xx    180\n10 10                   Gabriel Sbardelotto  xy     NA\n11 14               Isabela Martins Ghizoni  xx    166\n12 20        Juliana Eduarda Oliveira Gomes  xx    165\n13 21        Kamilly Vitoria Siqueira Tonet  xx    164\n14 29          Maria Eduarda Wendt Coutinho  xx    170\n15 15        João Pedro dos Santos Angulski  xy     NA\n16 30         Maria Laura Faustino Monteiro  xx    164\n17 35          Rafaela Rodrigues dos Santos  xx    158\n18 37                        Tassie Turcato  xx    165\n19 38         Thalita Maria Gomes Rodrigues  xx    163\n20 39        Wanessa Pedrinha do Nascimento  xx    177\n21  6              Daniel Schmechel Affeldt  xy    169\n22 22                  Leticia Herbert Post  xx     NA\n23  9                 Gabriel Loche Lopasso  xy    188\n24 12            Guilherme Antonio Ferreira  xy    173\n25 16          Joao Pedro Lantyer Marcelino  xy    190\n26 26                Luis Bortoluzzi Sobral  xy     NA\n27 27                   Luiz Paulo da Silva  xy     NA\n28 28              Magalhães Antonio Saxico  xy     NA\n29 17                    João Vitor Germano  xy    166\n30 18           João Vitor Zeferino Madeira  xy    168\n31 31               Mateus Zunino Espindola  xy     NA\n32 32             Matheus de Oliveira Mussi  xy     NA\n33 33 Natacha Micheline de Oliveira da Rosa  xx     NA\n34 34           Pierre Marcel Bruno Boisson  xy     NA\n35 19         José Eduardo Pimentel e Silva  xy    169\n36 23                   Lucas Lopes Ribeiro  xy    175\n37 24                    Lucas Paz Claudino  xy    178\n38 25               Lucas Sodre de Oliveira  xy    174\n39 36              Renan Guilherme da Silva  xy    179\n40 40                 Wesley Castilhos Drun  xy     NA\n41 41                      Wilson Rosa Neto  xy    173\nA função sample_random() retirada do pacote metan pode ser utilizada para amostrar n linhas aleatoriamente do conjunto de dados data. Utilizando prop, uma proporção dos dados é amostrada. Este último é útil ao realizar amostragens estratificadas informando o argumento by, onde cada estrato possui diferentes tamanhos de amostra."
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#aplicação",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#aplicação",
    "title": "6. Amostragem",
    "section": "Aplicação",
    "text": "Aplicação\nVamos considerar uma variável x, distribuida normalmente com média \\(\\bar X = 10\\) e desvio padrão \\(S = 2\\), avaliada em população com N = 10.\n\nset.seed(1)\nN <- 10\ndf2 <- data.frame(id = 1:N,\n                  x = rnorm(n = N, mean = 10, sd = 2))\ndf2\n\n   id         x\n1   1  8.747092\n2   2 10.367287\n3   3  8.328743\n4   4 13.190562\n5   5 10.659016\n6   6  8.359063\n7   7 10.974858\n8   8 11.476649\n9   9 11.151563\n10 10  9.389223\n\n\nConsiderando uma amostragem com n = 3, as 120 amostras possíveis são\n\nn <- 3\namostras <- combn(N, n) |> t()\namostras |> head()\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    1    2    4\n[3,]    1    2    5\n[4,]    1    2    6\n[5,]    1    2    7\n[6,]    1    2    8\n\namostras |> tail()\n\n       [,1] [,2] [,3]\n[115,]    6    8   10\n[116,]    6    9   10\n[117,]    7    8    9\n[118,]    7    8   10\n[119,]    7    9   10\n[120,]    8    9   10"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#médias-amostrais",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#médias-amostrais",
    "title": "6. Amostragem",
    "section": "Médias amostrais",
    "text": "Médias amostrais\nA seguinte função, computa a média das 120 amostras. Assim, obtém-se a distribuição das médias amostrais.\n\nmedias <- NULL\n# abordagem com for-loop\nfor (i in 1:nrow(amostras)) {\n  individ <- amostras[i,]\n  valores <- df2$x[individ]\n  medias <- append(medias, mean(valores))\n}\n\n# criar um data frame com as médias\ndf_medias <- data.frame(amostras) |> mutate(media = medias)\nhead(df_medias)\n\n  X1 X2 X3     media\n1  1  2  3  9.147707\n2  1  2  4 10.768314\n3  1  2  5  9.924465\n4  1  2  6  9.157814\n5  1  2  7 10.029746\n6  1  2  8 10.197009\n\ntail(df_medias)\n\n    X1 X2 X3     media\n115  6  8 10  9.741645\n116  6  9 10  9.633283\n117  7  8  9 11.201023\n118  7  8 10 10.613577\n119  7  9 10 10.505215\n120  8  9 10 10.672478\n\n\nAo computar a média das medias amostrais, obtém-se a média populacional\n\nmed_amostral <- mean(df_medias$media)\nmed_pop <-  mean(df2$x)\n\nidentical(med_amostral, med_pop)\n\n[1] TRUE\n\nggplot(df_medias, aes(x = media)) +\n  geom_histogram(bins = 8, color = \"black\", fill = \"gray\") +\n  geom_vline(xintercept = med_pop, color = \"red\", size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#tamanho-da-amostra-vs-acurácia",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#tamanho-da-amostra-vs-acurácia",
    "title": "6. Amostragem",
    "section": "Tamanho da amostra vs acurácia",
    "text": "Tamanho da amostra vs acurácia\nNo seguinte exemplo, vamos investigar o impacto do tamanho da amostra na acurácia da média. Para isso, serão amostradas aleatoriamente 1:120 médias amostrais do conjunto df_medias e calculado o desvio em relação a média populacional. O processo é repetido nboot vezes utilizando a técnica bootstrap.\n\nnboot <- 200\n\nsamples <- list()\nfor(j in 1:nboot){\n  tmp <- \n    map_dbl(1:nrow(df_medias), function(x){\n      rows <- sample(1:nrow(df_medias), x)\n      mean(df_medias[rows,]$media)\n    })\n  samples[[j]] <- tmp\n}\n\n# cada coluna contém as médias amostrais de um procedimento bootstrap\nsamples <- do.call(cbind, lapply(samples, data.frame))\ncolnames(samples) <- paste0(\"v\", 1:ncol(samples))\n\n# criar dados longo\nsamples_long <- \n  samples |> \n  pivot_longer(everything()) |> \n  mutate(desvio  = value -  mean(df2$x),\n         x = rep(1:nrow(df_medias), each = nboot))\n\n# média dos procedimentos bootstrap\nsamples_mean <- \n  samples_long |> \n  group_by(x) |> \n  summarise(mu = mean(desvio))\n\n\n# criar o gráfico\nggplot(samples_long, aes(x = x,\n                         y = desvio,\n                         group = name)) +\n  geom_line(alpha = 0.1) +\n  geom_line(aes(x = x, y = mu, group = 1),\n            data = samples_mean,\n            color = \"red\") +\n  scale_x_continuous(breaks = seq(0, 120, by = 10)) +\n  theme_bw(base_size = 16) +\n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"Número de médias amostrais incluídas\",\n       y = \"Desvio em relação a média populacional\",\n       title = \"Resultado de 200 procedimentos bootstrap\",\n       caption = glue::glue(\"Média: {round(mean(df2$x), 3)}\"))"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#exemplo-da-altura-da-turma",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#exemplo-da-altura-da-turma",
    "title": "6. Amostragem",
    "section": "Exemplo da altura da turma",
    "text": "Exemplo da altura da turma\n\ndf_turma <- \n  import(\"https://docs.google.com/spreadsheets/d/18aXD_2ISvzB8h8_kgOfSBbr9a9d9pT0QVazt-KjVLRw/edit#gid=1590128876\") |> \n  metan::remove_rows_na()\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\n\nWarning: Row(s) 1, 2, 3, 5, 8, 10, 15, 22, 26, 27, 28, 31, 32, 33, 34, 40 with\nNA values deleted.\n\nlinhas <- sample(1:25, 4)\ndf_turma[linhas,]\n\n   id                         aluno crm altura\n39 36      Renan Guilherme da Silva  xy    179\n24 12    Guilherme Antonio Ferreira  xy    173\n19 38 Thalita Maria Gomes Rodrigues  xx    163\n9  13 Helena dos Santos Vanderlinde  xx    180\n\nset.seed(4)\n\nnboot <- 1000\n\nsamples <- list()\nfor(j in 1:nboot){\n  tmp <- \n    map_dbl(1:nrow(df_turma), function(x){\n      rows <- sample(1:nrow(df_turma), x)\n      mean(df_turma[rows,]$altura)\n    })\n  samples[[j]] <- tmp\n}\n\n# cada coluna contém as médias amostrais de um procedimento bootstrap\nsamples <- do.call(cbind, lapply(samples, data.frame))\ncolnames(samples) <- paste0(\"v\", 1:ncol(samples))\n\n# criar dados longo\nsamples_long <- \n  samples |> \n  pivot_longer(everything()) |> \n  mutate(desvio  = value -  mean(df_turma$altura),\n         x = rep(1:nrow(df_turma), each = nboot))\n\n# média dos procedimentos bootstrap\nsamples_mean <- \n  samples_long |> \n  group_by(x) |> \n  summarise(mu = mean(desvio))\n\n\n# criar o gráfico\nggplot(samples_long, aes(x = x,\n                         y = desvio,\n                         group = name)) +\n  geom_line(alpha = 0.1) +\n  geom_line(aes(x = x, y = mu, group = 1),\n            data = samples_mean,\n            color = \"red\") +\n  scale_x_continuous(breaks = seq(1, nrow(df_turma), by = 1)) +\n  theme_bw(base_size = 16) +\n  theme(panel.grid.minor = element_blank()) +\n  labs(x = \"Número de alunos incluídos na amostra\",\n       y = \"Desvio em relação a média populacional\",\n       title = \"Resultado de 200 procedimentos bootstrap\",\n       caption = glue::glue(\"Média: {round(mean(df_turma$altura), 3)}; N = {nrow(df_turma)}\"))"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#abordagem-paralela",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#abordagem-paralela",
    "title": "6. Amostragem",
    "section": "Abordagem paralela",
    "text": "Abordagem paralela\nQuando o número de amostras cresce bastante, a abordagem for-loop não é computacionalmente eficiente. Assim, uma abordagem utilizando sapply() é mais eficiente. Quando paraleliza-se a função, a eficiência aumenta mais ainda.\n\n# criando uma função para obter a média de um id\nget_mean <- function(df, var, amostras, id){\n  individ <- amostras[id,]\n  mean(df[[var]][individ])\n}\n\n\nN <- 30\nn <- 5\ndf2 <- data.frame(id = 1:N,\n                  x = rnorm(n = N, mean = 10, sd = 2))\namostras2 <- combn(N, n) |> t()\n\n\nsystem.time(\n  medias2 <-\n    map_dbl(1:nrow(amostras2), function(i){\n      get_mean(df2, \"x\", amostras2, id = i)\n    })\n)\n\n\nlibrary(parallel)\nclust <- makeCluster(5)\nclusterExport(clust,\n              varlist = c(\"df2\", \"amostras2\", \"get_mean\"))\nsystem.time(\n  medias3 <-\n    parLapply(clust, 1:nrow(amostras2), function(i){\n      get_mean(df2, \"x\", amostras2, id = i)\n    })\n)\nstopCluster(clust)"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#número-igual-dentro-de-cada-estrato",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#número-igual-dentro-de-cada-estrato",
    "title": "6. Amostragem",
    "section": "Número igual dentro de cada estrato",
    "text": "Número igual dentro de cada estrato\n\nsample_random(df, n = 3, by = crm)\n\n# A tibble: 6 × 4\n     id aluno                          crm   altura\n  <int> <chr>                          <chr>  <int>\n1    39 Wanessa Pedrinha do Nascimento xx       177\n2    35 Rafaela Rodrigues dos Santos   xx       158\n3    29 Maria Eduarda Wendt Coutinho   xx       170\n4    34 Pierre Marcel Bruno Boisson    xy        NA\n5    40 Wesley Castilhos Drun          xy        NA\n6    12 Guilherme Antonio Ferreira     xy       173"
  },
  {
    "objectID": "FIT5306/FIT5306_06_AMOSTRAGEM.html#proporção-da-população-em-cada-estrato",
    "href": "FIT5306/FIT5306_06_AMOSTRAGEM.html#proporção-da-população-em-cada-estrato",
    "title": "6. Amostragem",
    "section": "Proporção da população em cada estrato",
    "text": "Proporção da população em cada estrato\n\nsample_random(df,\n              prop = 0.3,\n              by = crm)\n\n# A tibble: 12 × 4\n      id aluno                           crm   altura\n   <int> <chr>                           <chr>  <int>\n 1     3 Beatriz Haensel Teixeira        xx        NA\n 2    39 Wanessa Pedrinha do Nascimento  xx       177\n 3     1 Aline Kliauga Ferrante          xx        NA\n 4    22 Leticia Herbert Post            xx        NA\n 5     4 Bruna Waltrich                  xx       156\n 6     5 Carlos Eduardo Forcelini Assoni xy        NA\n 7    31 Mateus Zunino Espindola         xy        NA\n 8    18 João Vitor Zeferino Madeira     xy       168\n 9    17 João Vitor Germano              xy       166\n10    24 Lucas Paz Claudino              xy       178\n11    26 Luis Bortoluzzi Sobral          xy        NA\n12    40 Wesley Castilhos Drun           xy        NA"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html",
    "href": "FIT5306/FIT5306_07_DELN.html",
    "title": "7. Análise de Variância",
    "section": "",
    "text": "Tip\n\n\n\n“Muito melhor uma resposta aproximada à pergunta certa, que muitas vezes é vaga, do que uma resposta exata à pergunta errada, que sempre pode ser feita com precisão.” — John Tukey"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#dic",
    "href": "FIT5306/FIT5306_07_DELN.html#dic",
    "title": "7. Análise de Variância",
    "section": "DIC",
    "text": "DIC\nPara realizar a casualização em um experimento de delineamento inteiramente ao acaso, pode-se utilizar a função sketch do pacote agroR. Neste exemplo, simulo a casualização de quatro tratamentos (“C1”, “C2”, “C3” e “C4”) em um ensaio conduzido em delineamento inteiramente casualizado (DIC) com quatro repetições (r).\n\nlibrary(AgroR)\n\nWarning: package 'AgroR' was built under R version 4.2.1\n\n\n\nAttaching package: 'AgroR'\n\n\nThe following object is masked from 'package:dplyr':\n\n    desc\n\nset.seed(1)\ntrats <- c(\"C1\", \"C2\", \"C3\", \"C4\")\nsketch(trats, r = 4)"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#dbc",
    "href": "FIT5306/FIT5306_07_DELN.html#dbc",
    "title": "7. Análise de Variância",
    "section": "DBC",
    "text": "DBC\nPara casualização em DBC, a mesma função sketch é usada. No entanto, utiliza-se o argumento design para indicar que o delineamento é um DBC\n\nset.seed(1)\ntrats <- c(\"C1\", \"C2\", \"C3\", \"C4\")\n# casualização em DBC\nsketch(trats, r = 4, design = \"DBC\")\n\n\n\n# inverte a posição dos blocos\nsketch(trats, r = 4, design = \"DBC\", pos = \"column\")"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#exemplo-de-aplicação",
    "href": "FIT5306/FIT5306_07_DELN.html#exemplo-de-aplicação",
    "title": "7. Análise de Variância",
    "section": "Exemplo de aplicação",
    "text": "Exemplo de aplicação\nNa figura abaixo é mostrado como o DBC pode ser utilizado para considerar fontes de variação conhecida na área experimental. Neste caso, um gradiente de fósforo conhecido é notado no solo, onde maiores valores são observados na parte inferior e menores na parte inferior. Assim, os blocos podem ser alocados de modo que cada tratamento seja casualizado dentro de grupos de unidades experimentais homogêneas (blocos).\n\n\n\nExemplo de casualização em DBC"
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#dados",
    "href": "FIT5306/FIT5306_07_DELN.html#dados",
    "title": "7. Análise de Variância",
    "section": "Dados",
    "text": "Dados\nOs dados utilizados neste exemplo estão na planilha QUALI do conjunto de dados data_R.xlsx. Os próximos códigos carregam o conjunto de dados e criam um gráfico do tipo boxplot para explorar o padrão dos dados.\n\nlibrary(tidyverse)\nlibrary(metan)\nlibrary(rio)\nlibrary(AgroR)\n\nurl <- \"http://bit.ly/df_biostat\"\ndf <- import(url, sheet = \"QUALI\")\nstr(df)\n\n'data.frame':   20 obs. of  3 variables:\n $ BLOCO  : num  1 1 1 1 1 2 2 2 2 2 ...\n $ HIBRIDO: chr  \"NP_1\" \"NP_2\" \"NP_3\" \"NP_4\" ...\n $ RG     : num  8.82 9.12 7.74 6.48 4.06 ...\n\np1 <-\n  ggplot(df, aes(HIBRIDO, RG))+\n  geom_hline(yintercept = mean(df$RG), linetype = \"dashed\")+\n  geom_boxplot()+\n  stat_summary(geom = \"point\", fun = mean, shape = 23) +\n  stat_summary(aes(label = round(after_stat(y), 2),\n                   x = HIBRIDO), \n               fun=mean,\n               geom=\"text\",\n               hjust=-0.3)\n\np2 <- \n  ggplot(df, aes(factor(BLOCO), RG))+\n  geom_hline(yintercept = mean(df$RG), linetype = \"dashed\")+\n  geom_boxplot()+\n  stat_summary(geom = \"point\", fun = mean, shape = 23) +\n  stat_summary(aes(label = round(after_stat(y), 2),\n                   x = BLOCO), \n               fun=mean,\n               geom=\"text\",\n               hjust=-0.3)\n\np1 + p2\n\n\n\n\nAnalizando o boxplot acima é razoável dizer que as médias dos tratamentos são diferentes, principalmente comparando o NP_1 com NP_5. Esta suspeita de diferença, no entanto, deve ser suportada com a realização da análise de variância."
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#anova-em-dic",
    "href": "FIT5306/FIT5306_07_DELN.html#anova-em-dic",
    "title": "7. Análise de Variância",
    "section": "Anova em DIC",
    "text": "Anova em DIC\nNo pacote AgroR, quando os fatores são qualitativos, a análise complementar aplicada é a comparção de médias. A função DIC() do pacote retorna a tabela da ANOVA, a análise de pressupostos (normalidade e homogeneidade) e o teste de comparação de médias.\n\nmod_dic <- with(df, DIC(HIBRIDO, RG))\n\n\n\n\n\n-----------------------------------------------------------------\nNormality of errors\n-----------------------------------------------------------------\n                         Method Statistic     p.value\n Shapiro-Wilk normality test(W)  0.827455 0.002285375\n\n\n-----------------------------------------------------------------\nHomogeneity of Variances\n-----------------------------------------------------------------\n                              Method Statistic   p.value\n Bartlett test(Bartlett's K-squared) 0.9557917 0.9164237\n\n\n-----------------------------------------------------------------\nIndependence from errors\n-----------------------------------------------------------------\n                 Method Statistic      p.value\n Durbin-Watson test(DW) 0.3899192 3.318679e-05\n\n\n-----------------------------------------------------------------\nAdditional Information\n-----------------------------------------------------------------\n\nCV (%) =  23.06\nMStrat/MST =  0.69\nMean =  8.2479\nMedian =  8.0515\nPossible outliers =  No discrepant point\n\n-----------------------------------------------------------------\nAnalysis of Variance\n-----------------------------------------------------------------\n          Df   Sum Sq  Mean.Sq  F value     Pr(F)\ntrat       4 32.62995 8.157488 2.254327 0.1117755\nResiduals 15 54.27888 3.618592                   \n\n\n\n\n-----------------------------------------------------------------\nMultiple Comparison Test\n-----------------------------------------------------------------\n[1] \"H0 is not rejected\"\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nAs funções do pacote AgroR utilizam os dados “anexados” ao ambiente de trabalho, ou seja, um argumento data = . não existe para suas funções. Note que no exemplo acima foi utilizado a função with(qualitativo, DIC(...)). Isto permite acessar variáveis presentes no data frame. Uma outra maneira de realizar esta mesma análise é utilizando a função attach(df), qual carregará o data frame no ambiente R, assim é possível utilizar a função DIC(...). Após realizada a análise, é recomendado executar o comando detach(df) para “limpar” os dados do ambiente de trabalho.\n\n\nA interpretação da significância, ou seja, se as médias de produtividade dos híbridos foram significativamente diferentes a uma determinada probabilidade de erro é feita verificando-se o valor de \"Pr>fc\" na ANOVA. A figura abaixo mostra a distribuição F considerando os graus de liberdade de tratamento e erro \\(F_{4, 15}\\) e nos ajuda a compreender um pouco melhor isto.\n\n\nVeja o código que gerou o gráfico\ndf1 <- 4\ndf2 <- 15\nfcal <- 2.2543\nftab <- 3.055\n\nggplot() +\n  scale_x_continuous(limits = c(0,  6),\n                     breaks = c(0,  fcal, ftab,  6)) +\n  stat_function(fun = df,\n                geom = \"area\",\n                fill = \"red\",\n                xlim = c(fcal, 6),\n                args = list(\n                  df1 = df1,\n                  df2 = 63\n                )) +\n  stat_function(fun = df,\n                geom = \"area\",\n                fill = \"forestgreen\",\n                xlim = c(ftab, 6),\n                args = list(\n                  df1 = df1,\n                  df2 = 63\n                )) +\n  stat_function(fun = df,\n                geom = \"line\",\n                size = 1,\n                args = list(\n                  df1 = df1,\n                  df2 = 63\n                )) +\n  theme_bw(base_size = 16) +\n  theme(panel.grid.minor = element_blank()) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))+\n  labs(x = \"Valor de F\",\n       y = \"Probabilidade acumulada\",\n       title = \"Distribuição F (DF1: 4, DF2: 15)\")\n\n\n\n\n\nDistribuição F com DF1 = 1 e DF2 = 15\n\n\nO valor de F calculado em nosso exemplo foi de 2,2543, o que resulta em uma probabilidade de erro acumulada de 0,1117 (11,17%). Esta probabilidade de erro acumulada está representada pela cor vermelha. Logo, não rejeitou-se a hipótese Para que uma diferença significativa a 5% de probabilidade de erro tivesse sido observada, o valor de F calculado deveria ter sido 3,055 qf(0.05, 4, 15, lower.tail = FALSE), representado neste caso pela cor verde no gráfico.\nConsiderando nosso exemplo, parece razoável dizer que 9,48 t (NP_1) é uma produção maior que 6,28 t (NP_5). Então, é justo perguntar: O que pode ter acontecido para que as médias não tenham sido consideradas diferentes considerando a probabilidade de erro, mesmo tendo fortes indícios de que elas seriam? A primeira opção que nos vem a mente –e que na maioria das vezes é encontrada em artigos científicos– é que as alterações no rendimento de grão observadas fora resultado do acaso; ou seja, neste caso, há a probabilidade de 11,17% de que uma diferença pelo menos tão grande quanto a observada no estudo possa ser gerada a partir de amostras aleatórias se os tratamentos não aferatem a variável resposta. Logo, a recomendação estatística neste caso, seria por optar por qualquer um dos tratamentos. Do ponto de vista prático, sabemos que esta recomendação está totalmente equivocada. Neste ponto surge uma importante (e polêmica) questão: a interpretação do p-valor. Um p-valor de 0,05 não significa que há uma chance de 95% de que determinada hipótese esteja correta. Em vez disso, significa que se a hipótese nula for verdadeira e todas as outras suposições feitas forem válidas, haverá 5% de chance que diferenças ao menos tão grandes quanto as observadas podem ser obtidas de amostras aleatórias. É preciso ter em mente que o p-valor relatado pelos testes é um significado probabilístico, não biológico. Assim, em experimentos biológicos, a interpretação desta estatística deve ser cautelosa, pois um p-valor pode não indicar a importância de uma descoberta. Por exemplo, um medicamento pode ter um efeito estatisticamente significativo nos níveis de glicose no sangue dos pacientes sem ter um efeito terapêutico. Sugerimos a leitura de cinco interessantes artigos relacionados a este assunto (Altman and Krzywinski 2017; Baker 2016; Singh Chawla 2017; Krzywinski and Altman 2013; Nuzzo 2014).\nEm adição à justificativa anterior (as alterações no rendimento de grão observadas fora resultado do acaso), existem pelo menos mais três razões potenciais para a não regeição da hipótese \\(H_0\\) em nosso exemplo:\n\num experimento mal projetado com poder insuficiente para detectar uma diferença (à 5% de erro) entre as médias;\nos tratamentos foram mal escolhidos e não refletiram adequadamente a hipótese inicial do estudo\no experimento foi indevidamente instalado e conduzido sem supervisão adequada, com baixo controle de qualidade sobre os protocolos de tratamento, coleta e análise de dados.\n\nEsta última opção parece ser a mais razoável aqui. É possivel observar no boxplot para o fator bloco que o bloco 4 parece ter uma média superior aos outros blocos. Sabe-ser que no DIC, toda diferença entre as repetições de um mesmo tratamento comporão o erro experimental. Logo, neste exemplo, a área experimental não era homogênea como se pressupunha na instalação do experimento. Isto ficará claro, posteriormente, ao analisarmos o mesmo conjunto de dados, no entanto considerando um DBC."
  },
  {
    "objectID": "FIT5306/FIT5306_07_DELN.html#anova-em-dbc",
    "href": "FIT5306/FIT5306_07_DELN.html#anova-em-dbc",
    "title": "7. Análise de Variância",
    "section": "Anova em DBC",
    "text": "Anova em DBC\n\nwith(df,\n     DBC(HIBRIDO, BLOCO, RG))\n\n\n-----------------------------------------------------------------\nNormality of errors\n-----------------------------------------------------------------\n                         Method Statistic   p.value\n Shapiro-Wilk normality test(W)  0.987223 0.9920259\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered normal\n\n\n\n-----------------------------------------------------------------\nHomogeneity of Variances\n-----------------------------------------------------------------\n                              Method Statistic   p.value\n Bartlett test(Bartlett's K-squared)  7.696982 0.1033304\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, the variances can be considered homogeneous\n\n\n\n-----------------------------------------------------------------\nIndependence from errors\n-----------------------------------------------------------------\n                 Method Statistic   p.value\n Durbin-Watson test(DW)  2.565113 0.7271231\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered independent\n\n\n\n-----------------------------------------------------------------\nAdditional Information\n-----------------------------------------------------------------\n\nCV (%) =  8.2\nMStrat/MST =  0.33\nMean =  8.2479\nMedian =  8.0515\nPossible outliers =  No discrepant point\n\n-----------------------------------------------------------------\nAnalysis of Variance\n-----------------------------------------------------------------\n          Df    Sum Sq    Mean.Sq F value        Pr(F)\ntrat       4 32.629952  8.1574881 17.8475 5.449170e-05\nbloco      3 48.794088 16.2646961 35.5850 2.983658e-06\nResiduals 12  5.484793  0.4570661                     \n\n\nAs the calculated p-value, it is less than the 5% significance level. The hypothesis H0 of equality of means is rejected. Therefore, at least two treatments differ\n\n\n\n\n\n\n-----------------------------------------------------------------\nMultiple Comparison Test\n-----------------------------------------------------------------\n        resp groups\nNP_2 9.48075      a\nNP_1 9.48000      a\nNP_3 8.75075     ab\nNP_4 7.24500     bc\nNP_5 6.28300      c\n\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html",
    "href": "FIT5306/FIT5306_08_DIC.html",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "",
    "text": "library(tidyverse)  # manipulação de dados\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#características",
    "href": "FIT5306/FIT5306_08_DIC.html#características",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Características",
    "text": "Características\n\nUtiliza apenas os princípios de repetição e casualização;\nOs tratamentos são alocados nas parcelas de forma inteiramente casual, sem nenhum tipo de bloqueamento.\nExige que o material experimental e a área experimental sejam uniformes. Ele geralmente é mais utilizado em experimentos nos quais as condições experimentais podem ser bastante controladas (por exemplo em laboratórios);"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#vantagens",
    "href": "FIT5306/FIT5306_08_DIC.html#vantagens",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Vantagens",
    "text": "Vantagens\n\nDelineamento flexível, onde o número de tratamentos e repetições depende apenas da quantidade de parcelas disponíveis na área experimental.\nO número de repetições pode diferir de um tratamento para o outro (experimento não balanceado)\nA análise estatística é simples\nO número de graus de liberdade do erro é o maior possível considerando o número de repetições utilizado."
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#desvantagens",
    "href": "FIT5306/FIT5306_08_DIC.html#desvantagens",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Desvantagens",
    "text": "Desvantagens\n\nExige homogeneidade das condições ambientais\nPode estimar uma variância residual muito alta caso a área experimental apresente heterogeneidade, inflacionando o quadrado médio do erro."
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#modelo-estatístico",
    "href": "FIT5306/FIT5306_08_DIC.html#modelo-estatístico",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Modelo estatístico",
    "text": "Modelo estatístico\nO delineamento inteiramente casualizado (DIC) é um delineamento adequado para áreas uniformes (parcelas são uniformes), onde não há necessidade de controle local (bloqueamento). Neste delineamento, os tratamentos devem ser distribuídos aleatoriamente nas parcelas.\nO modelo do DIC é dado por\n\\[\n{Y_{ij}} = m + {t_i} + {\\varepsilon _{ij}}\n\\]\nOnde m é a média geral do experimento, \\(t_i\\) é o efeito de tratamentos, sendo estimado por \\(\\hat t_i = \\bar Y_{i.} - \\bar Y_{..}\\) com a seguinte restrição: \\(\\sum_i \\hat t_i = 0 ~~~~\\forall_i\\) (leia-se, o somatório dos efeitos de tratamento é zero para todo tratamento \\(i\\)). \\(\\epsilon_{ij}\\) é o erro experimental estimado por \\(\\hat e_{ij} = Y_{ij} - m - \\hat t_i\\) onde \\({e_{ij}}\\sim NID(0,{\\sigma ^2})\\)."
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#análise-de-variância-1",
    "href": "FIT5306/FIT5306_08_DIC.html#análise-de-variância-1",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Análise de variância",
    "text": "Análise de variância\nA análise de variância é computada no software R utilizando a função aov(). Considerando o Delineamento Inteiramente Casualizado (DIC), a única fonte de variação incluída no modelo é tratamento, neste caso, RAD.\n\nanova <- aov(MST ~ RAD, data = df_dic)\nsummary(anova)\n##             Df Sum Sq Mean Sq F value   Pr(>F)    \n## RAD          2  45.06  22.529   25.22 0.000205 ***\n## Residuals    9   8.04   0.893                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_08_DIC.html#comparação-de-médias",
    "href": "FIT5306/FIT5306_08_DIC.html#comparação-de-médias",
    "title": "8. Delineamento Inteiramente Casualizado",
    "section": "Comparação de médias",
    "text": "Comparação de médias\nEm sequência a ANOVA, quando o efeito de tratamento é significativo, teste de Tukey (5% de erro) pode ser utilizado para comparação das médias. Este teste realiza todas as combinações possíveis entre as médias (por isso o nome comparação múltipla de medias), comparando se a diferença entre duas médias é maior ou menor que uma diferença mínima significativa (DMS). Esta DMS é calculada pela seguinte fórmula \\(DMS = q \\times \\sqrt{QME/r}\\), onde q é um valor tabelado, considerando o número de tratamentos e o GL do erro; QME é o quadrado médio do erro; e r é o número de repetições (ou blocos).\n\n\n\n\n\n\nTip\n\n\n\nA fórmula da DMS descrita acima é utilizada apenas se (e somente se) o número de repetições de todos os tratamentos é igual. Caso algum tratamento apresente um número inferir de repetições, fato comumente observado em experimentos de campo devido a presença de parcelas perdidas, a DMS deste par de médias em específico deve ser corrigida. Geralmente, as análises complementares são realizadas quando a ANOVA indica significância para um determinado fator de variação, no entanto, o teste Tukey pode revelar diferença entre as médias, mesmo quando o teste F não indicar essa diferença. Isto pode ser observado, principalmente quando a probabilidade de erro for muito próxima de 5%, por exemplo, Pr>Fc = 0.0502. A recíproca também é verdadeira. O teste Tukey pode indicar que as médias não diferem, se Pr>Fc = 0.0492, por exemplo.\n\n\nO valor de q pode ser encontrado na seguinte tabela:\n\n\n\n\n\nPara este caso, considerando 3 e 9 como o número de tratamentos e o GL do erro, respectivamente, o valor de q é 3,95, que aplicado na fórmula resulta em \\(DMS = 3,95 \\times \\sqrt{0,893/4}=1,866\\). Logo, a diferença mínima entre duas médias para que estas sejam significativamente diferentes (5% de erro), deve ser de 1,866.\nPodemos realizar a comparação par-a-par utilizando a função pwpm() do pacote emmeans.\n\nmedias <- emmeans(anova, ~ RAD)\npwpm(medias)\n\n        50     70    100\n50  [11.2] 0.0061 0.0002\n70   -2.79 [14.0] 0.0428\n100  -4.72  -1.93 [15.9]\n\nRow and column labels: RAD\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nUma alternativa é o Pairwise P-value plot exibindo todos os P-values em comparações de pares. Cada comparação está associada a um segmento de linha vertical que une as posições de escala das duas médias que estão sendo comparadas e cuja posição horizontal é determinada pelo P-valor dessa comparação. Esta técnica não é indicada quando muitas comparações estão sendo testadas.\n\npwpp(medias)\n\n\n\n\nPairwise P-value plot\n\n\n\n\nOutra maneira de representar comparações graficamente por meio do argumento de comparações em plot.emm(). Nesta abordagem, a avaliação da significância das médias de dois tratamentos é dada pela sobreposição das flechas de cada tratamento. Se dois tratamentos apresentam setas que se sobrepoem (considerando o eixo x), assume-se que estes tratamentos são estatisticamente diferentes um do outro.\n\nplot(medias,\n     CIs = FALSE, # remove os intervalos de confiança das médias\n     comparisons = TRUE) # insere setas para comparação de médias (Tukey)\n\n\n\n\nComparações entre pares de médias com base no teste Tukey"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html",
    "href": "FIT5306/FIT5306_09_DBC.html",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "",
    "text": "library(tidyverse)  # manipulação de dados\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA\nlibrary(ExpDes.pt)"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#características",
    "href": "FIT5306/FIT5306_09_DBC.html#características",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Características",
    "text": "Características\n\nUtiliza apenas os princípios de repetição e casualização;\nOs tratamentos são alocados nas parcelas de forma inteiramente casual, sem nenhum tipo de bloqueamento.\nExige que o material experimental e a área experimental sejam uniformes. Ele geralmente é mais utilizado em experimentos nos quais as condições experimentais podem ser bastante controladas (por exemplo em laboratórios);"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#vantagens",
    "href": "FIT5306/FIT5306_09_DBC.html#vantagens",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Vantagens",
    "text": "Vantagens\n\nControla as diferenças que ocorrem nas condições ambientais, de um bloco para outro;\nPode haver heterogeneidade conhecida na área, desde que a alocação dos blocos seja feita de forma correta\nA variação entre blocos é isolada, logo, reduzindo a variância residual"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#desvantagens",
    "href": "FIT5306/FIT5306_09_DBC.html#desvantagens",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Desvantagens",
    "text": "Desvantagens\n\nDevido a inclusão de mais uma fonte de variação no modelo, há uma redução nos graus de liberdade do erro.\nComo exige-se homogeneidade dentro dos blocos, o número de tratamentos pode ficar limitado, visto que quanto maior é o bloco, mais difícil manter a sua homogeneidade."
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#casualização",
    "href": "FIT5306/FIT5306_09_DBC.html#casualização",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Casualização",
    "text": "Casualização\nPara realizar a casualização em um experimento em DBC, pode-se utilizar a função sketch do pacote agroR. Neste exemplo, simulo a casualização de três tratamentos em um ensaio conduzido em delineamento de blocos completos casualizados com quatro repetições (r). Apenas para fins didáticos, é apresentada também a casualização em DIC.\n\ntrats <- c(\"50\", \"70\", \"100\")\n\n# casualização em DIC\nset.seed(1)\nsketch(trats, r = 4, pos = \"line\")\n\n\n\n# casualização em DBC\nsketch(trats, r = 4, design = \"DBC\", pos = \"line\")"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#modelo-estatístico",
    "href": "FIT5306/FIT5306_09_DBC.html#modelo-estatístico",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Modelo estatístico",
    "text": "Modelo estatístico\nO modelo do DBC é dado por\n\\[\n{Y_{ij}} = m + {b_j} + {t_i} + {\\varepsilon _{ij}}\n\\]\nOnde \\(m\\) é a média geral do experimento, \\(b_j\\) é o efeito de bloco, \\(t_i\\) é o efeito de tratamentos e \\(\\epsilon_{ij}\\) é o erro experimental."
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#análise-de-variância-1",
    "href": "FIT5306/FIT5306_09_DBC.html#análise-de-variância-1",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Análise de variância",
    "text": "Análise de variância\nA análise de variância é computada no software R utilizando a função aov(). Considerando o Delineamento de Blocos Casualizados (DBC), as duas fontes de variação incluídas no modelo são a de tratamento (RAD) e bloco (REP).\n\nanova <- aov(MST ~ RAD + REP, data = df_dbc)\nsummary(anova)\n##             Df Sum Sq Mean Sq F value   Pr(>F)    \n## RAD          2  45.06  22.529  138.78 9.47e-06 ***\n## REP          3   7.07   2.356   14.51  0.00371 ** \n## Residuals    6   0.97   0.162                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#comparação-de-médias",
    "href": "FIT5306/FIT5306_09_DBC.html#comparação-de-médias",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Comparação de médias",
    "text": "Comparação de médias\nA análise de variância revelou efeito de tratamento significativo. Nesse caso, segue-se realizando uma análise de comparação múltipla de médias. Podemos realizar a comparação par-a-par utilizando a função pwpm() do pacote emmeans. Neste exemplo, o teste Tukey é utilizado.\n\nmedias_dbc <- emmeans(anova, ~ RAD)\npwpm(medias_dbc)\n\n        50     70    100\n50  [11.2] 0.0002 <.0001\n70   -2.79 [14.0] 0.0012\n100  -4.72  -1.93 [15.9]\n\nRow and column labels: RAD\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nNeste exemplo, utilizaremos a função emmeans para realizar a comparação de médias pelo teste Tukey. Nesta abordagem, a avaliação da significância das médias de dois tratamentos é dada pela sobreposição das flechas de cada tratamento. Se dois tratamentos apresentam setas que se sobrepõem (considerando o eixo x), assume-se que estes tratamentos são estatisticamente diferentes um do outro.\nApenas para fins de comparação, incluirei a comparação de médias considerando o modelo DIC. Observe que a redução da estimativa do erro experimental considerando o delineamento DBC fez com que ficasse mais fácil encontrar diferenças entre os tratamentos.\n\nanova_dic <- aov(MST ~ RAD, data = df_dbc)\nmedias_dic <- emmeans(anova_dic, ~ RAD)\n\nmedias_dbc <- emmeans(anova, ~ RAD)\n\nplot_dic <- \n  plot(medias_dic,\n       xlab = \"Matéria seca total (g)\",\n       ylab = \"Tratamentos\",\n       CIs = FALSE, # remove os intervalos de confiança das médias\n       comparisons = TRUE) # insere setas para comparação de médias (Tukey)\n\nplot_dbc <- \n  plot(medias_dbc,\n       xlab = \"Matéria seca total (g)\",\n       ylab = \"Tratamentos\",\n       CIs = FALSE, # remove os intervalos de confiança das médias\n       comparisons = TRUE) # insere setas para comparação de médias (Tukey)\n\narrange_ggplot(plot_dic,\n               plot_dbc,\n               ncol = 1,\n               tag_levels = \"a\")\n\n\n\n\nComparações entre pares de médias com base no teste Tukey considerando o delineamento inteiramente casualizado (a) e o delineamento de blocos casualizados (b)"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#criação-de-gráficos",
    "href": "FIT5306/FIT5306_09_DBC.html#criação-de-gráficos",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Criação de gráficos",
    "text": "Criação de gráficos\n\nmedias <- \n  plot_bars(df_dbc, RAD, MST,\n            lab.bar = c(\"c\", \"b\", \"a\"))\nmedias2 <- \n  plot_bars(df_dbc, RAD, MST,\n            plot_theme = theme_bw(),\n            lab.bar = c(\"c\", \"b\", \"a\"),\n            values = TRUE,\n            width.bar = 0.6,\n            y.expand = 0.2)\n\narrange_ggplot(medias, medias2, tag_levels = \"a\")"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#pacote-agror",
    "href": "FIT5306/FIT5306_09_DBC.html#pacote-agror",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Pacote AgroR",
    "text": "Pacote AgroR\nNo pacote agroR, a análise de variância neste delineamento pode ser realizada com a função DBC().\n\n\nwith(df_dbc,\n     DBC(RAD, REP, MST))\n\n\n\n## \n## -----------------------------------------------------------------\n## Normality of errors\n## -----------------------------------------------------------------\n##                          Method Statistic   p.value\n##  Shapiro-Wilk normality test(W) 0.9445588 0.5592776\n## \n## \n## -----------------------------------------------------------------\n## Homogeneity of Variances\n## -----------------------------------------------------------------\n##                               Method Statistic   p.value\n##  Bartlett test(Bartlett's K-squared) 0.4182676 0.8112867\n## \n## \n## -----------------------------------------------------------------\n## Independence from errors\n## -----------------------------------------------------------------\n##                  Method Statistic   p.value\n##  Durbin-Watson test(DW)  1.521488 0.1169862\n## \n## \n## -----------------------------------------------------------------\n## Additional Information\n## -----------------------------------------------------------------\n## \n## CV (%) =  2.94\n## MStrat/MST =  0.9\n## Mean =  13.7232\n## Median =  13.5946\n## Possible outliers =  No discrepant point\n## \n## -----------------------------------------------------------------\n## Analysis of Variance\n## -----------------------------------------------------------------\n##           Df     Sum Sq    Mean.Sq   F value        Pr(F)\n## trat       2 45.0579657 22.5289828 138.78145 9.473392e-06\n## bloco      3  7.0667049  2.3555683  14.51061 3.707071e-03\n## Residuals  6  0.9740055  0.1623343                       \n## \n## \n## -----------------------------------------------------------------\n## Multiple Comparison Test\n## -----------------------------------------------------------------\n##         resp groups\n## 100 15.94093      a\n## 70  14.00834      b\n## 50  11.22022      c"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#dados",
    "href": "FIT5306/FIT5306_09_DBC.html#dados",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "Dados",
    "text": "Dados\n\nurl <- \"https://docs.google.com/spreadsheets/d/1vpVGdIkggRxmdnwrkllHbVA0TIHN85UK/edit#gid=1486281449\"\ndf_maize <-  import(url, dec = \",\")\n\ntabela <- \n  df_maize %>% \n  make_mat(HIBRIDO, BLOCO, RG) %>% \n  row_col_sum()\n\ntabela\n\n             B1     B2    B3     B4 row_sums\nNP_1      8.820  9.360  7.98 11.760   37.920\nNP_2      9.123  7.860  8.82 12.120   37.923\nNP_3      7.740  8.123  7.92 11.220   35.003\nNP_4      6.480  6.720  6.12  9.660   28.980\nNP_5      4.060  5.180  5.90  9.992   25.132\ncol_sums 36.223 37.243 36.74 54.752  164.958"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#r-base",
    "href": "FIT5306/FIT5306_09_DBC.html#r-base",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "R base",
    "text": "R base\n\nmod_hib <- aov(RG ~ HIBRIDO + BLOCO, data = df_maize)\nmed_hib <- emmeans(mod_hib, ~HIBRIDO)\npwpm(med_hib)\n\n         NP_1     NP_2     NP_3     NP_4   NP_5\nNP_1   [9.48]   1.0000   0.5666   0.0040 0.0002\nNP_2 -0.00075   [9.48]   0.5657   0.0040 0.0002\nNP_3  0.72925  0.73000   [8.75]   0.0533 0.0018\nNP_4  2.23500  2.23575  1.50575   [7.24] 0.3168\nNP_5  3.19700  3.19775  2.46775  0.96200 [6.28]\n\nRow and column labels: HIBRIDO\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nplot(med_hib, comparisons = TRUE, CIs = FALSE)"
  },
  {
    "objectID": "FIT5306/FIT5306_09_DBC.html#agror",
    "href": "FIT5306/FIT5306_09_DBC.html#agror",
    "title": "9. Delineamento de Blocos Completos Casualizados",
    "section": "AgroR",
    "text": "AgroR\n\nwith(df_maize,\n     DBC(HIBRIDO, BLOCO, RG))\n\n\n-----------------------------------------------------------------\nNormality of errors\n-----------------------------------------------------------------\n                         Method Statistic   p.value\n Shapiro-Wilk normality test(W)  0.987223 0.9920259\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered normal\n\n\n\n-----------------------------------------------------------------\nHomogeneity of Variances\n-----------------------------------------------------------------\n                              Method Statistic   p.value\n Bartlett test(Bartlett's K-squared)  7.696982 0.1033304\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, the variances can be considered homogeneous\n\n\n\n-----------------------------------------------------------------\nIndependence from errors\n-----------------------------------------------------------------\n                 Method Statistic   p.value\n Durbin-Watson test(DW)  2.565113 0.7271231\n\n\nAs the calculated p-value is greater than the 5% significance level, hypothesis H0 is not rejected. Therefore, errors can be considered independent\n\n\n\n-----------------------------------------------------------------\nAdditional Information\n-----------------------------------------------------------------\n\nCV (%) =  8.2\nMStrat/MST =  0.33\nMean =  8.2479\nMedian =  8.0515\nPossible outliers =  No discrepant point\n\n-----------------------------------------------------------------\nAnalysis of Variance\n-----------------------------------------------------------------\n          Df    Sum Sq    Mean.Sq F value        Pr(F)\ntrat       4 32.629952  8.1574881 17.8475 5.449170e-05\nbloco      3 48.794088 16.2646961 35.5850 2.983658e-06\nResiduals 12  5.484793  0.4570661                     \n\n\nAs the calculated p-value, it is less than the 5% significance level. The hypothesis H0 of equality of means is rejected. Therefore, at least two treatments differ\n\n\n\n\n\n\n-----------------------------------------------------------------\nMultiple Comparison Test\n-----------------------------------------------------------------\n        resp groups\nNP_2 9.48075      a\nNP_1 9.48000      a\nNP_3 8.75075     ab\nNP_4 7.24500     bc\nNP_5 6.28300      c\n\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html",
    "href": "FIT5306/FIT5306_10_FAT.html",
    "title": "10. Experimentos Fatoriais",
    "section": "",
    "text": "library(tidyverse)\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(emmeans)    # comparação de médias\nlibrary(AgroR)      # casualização e ANOVA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#casualização",
    "href": "FIT5306/FIT5306_10_FAT.html#casualização",
    "title": "10. Experimentos Fatoriais",
    "section": "Casualização",
    "text": "Casualização\n\nDelineamento Inteiramente Casualizado\n\nsketch(trat= c(\"A1\", \"A2\"),\n       trat1 = c(\"B1\", \"B2\", \"B3\"),\n       design = \"FAT2DIC\",\n       r = 4)\n\n\n\n\n\n\nDelineamento de Blocos Casualizados\n\nsketch(trat= c(\"A1\", \"A2\"),\n       trat1 = c(\"B1\", \"B2\", \"B3\"),\n       design = \"FAT2DBC\",\n       r = 4)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#tipos-de-interação",
    "href": "FIT5306/FIT5306_10_FAT.html#tipos-de-interação",
    "title": "10. Experimentos Fatoriais",
    "section": "Tipos de interação",
    "text": "Tipos de interação\n\nAusência de interação\n\n# sem interação\ndfsi <- tribble(\n  ~GEN, ~FONTEN, ~RG,\n  \"Híbrido 1\",\"Ureia\",   5.7,\n  \"Híbrido 1\",\"Nitrato\", 6.8,\n  \"Híbrido 2\",\"Ureia\",   8.2,\n  \"Híbrido 2\",\"Nitrato\", 9.3)\n\np1 <-\n  plot_factbars(dfsi, GEN, FONTEN, resp = RG,\n                ylab = expression(paste(\"RG (Mg \",ha^-1, \")\")),\n                y.expand = 0.2,\n                size.text = 16,\n                values = TRUE,\n                errorbar = F,\n                xlab = \"Híbrido\",\n                legend.position = c(0.2, 0.89)) +\n  ggtitle(\"Ausência de interação\")\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\np1\n\n\n\n\nDe posse dos dados, vamos construir uma tabela dupla entrada com os valores totais e outra com os valores médios. Os efeitos da interação são calculados como…\n\nmat_dfsi <- make_mat(dfsi, GEN, FONTEN, RG)\nmat_dfsi\n\n          Nitrato Ureia\nHíbrido 1     6.8   5.7\nHíbrido 2     9.3   8.2\n\n# tabela dupla entrada (totais)\nmat_dfsi |> \n  row_col_sum()\n\n          Nitrato Ureia row_sums\nHíbrido 1     6.8   5.7     12.5\nHíbrido 2     9.3   8.2     17.5\ncol_sums     16.1  13.9     30.0\n\n# tabela dupla entrada (totais)\nmat_dfsi |> \n  row_col_mean()\n\n          Nitrato Ureia row_means\nHíbrido 1    6.80  5.70      6.25\nHíbrido 2    9.30  8.20      8.75\ncol_means    8.05  6.95      7.50\n\n# soma de quadrados do fator GEN\nrowSums(mat_dfsi) ^ 2\n\nHíbrido 1 Híbrido 2 \n   156.25    306.25 \n\nmodsi <- aov(RG ~ GEN * FONTEN, data = dfsi)\nsummary(modsi)\n\n            Df Sum Sq Mean Sq\nGEN          1   6.25    6.25\nFONTEN       1   1.21    1.21\nGEN:FONTEN   1   0.00    0.00\n\n\n\n\nInteração simples (quantitativa)\n\n# interação simples\ndf_is <- tribble(\n  ~GEN, ~FONTEN, ~RG,\n  \"Híbrido 1\",\"Ureia\",   4.5,\n  \"Híbrido 1\",\"Nitrato\", 1.9,\n  \"Híbrido 2\",\"Ureia\",   11,\n  \"Híbrido 2\",\"Nitrato\", 5.3)\n\n\np2 <-\n  plot_factbars(df_is, GEN, FONTEN, resp = RG,\n                ylab = expression(paste(\"RG (Mg \",ha^-1, \")\")),\n                y.expand = 0.2,\n                size.text = 16,\n                errorbar = F,\n                values = TRUE,\n                xlab = \"Híbrido\",\n                legend.position = c(0.2, 0.89)) +\n  ggtitle(\"Interação simples\")\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\np2\n\n\n\n\n\n\nInteração complexa (qualitativa)\n\n# interação complexa\ndf_ic <- tribble(\n  ~GEN, ~FONTEN, ~RG,\n  \"Híbrido 1\",\"Ureia\",   4.1,\n  \"Híbrido 1\",\"Nitrato\", 1.4,\n  \"Híbrido 2\",\"Ureia\",   6.2,\n  \"Híbrido 2\",\"Nitrato\", 8.4)\n\np3 <-\n  plot_factbars(df_ic, GEN, FONTEN, resp = RG,\n                ylab = expression(paste(\"RG (Mg \",ha^-1, \")\")),\n                y.expand = 0.2,\n                size.text = 16,\n                errorbar = F,\n                values = TRUE,\n                xlab = \"Híbrido\",\n                legend.position = c(0.2, 0.89)) +\n  ggtitle(\"Interação complexa\")\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\nWarning in qt(level/2 + 0.5, n() - 1): NaNs produzidos\n\np3"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#modelo-estatístico",
    "href": "FIT5306/FIT5306_10_FAT.html#modelo-estatístico",
    "title": "10. Experimentos Fatoriais",
    "section": "Modelo estatístico",
    "text": "Modelo estatístico\nVamos considerar como exemplo, um experimento que avaliou a influencia de dois fatores, digamos \\(\\alpha\\) e \\(\\tau\\), em uma determinada variável resposta. O modelo estatístico considerado neste tipo de experimento é:\n\\[\n{y_{ijk}} = {\\rm{ }}\\mu {\\rm{ }} + {\\rm{ }}\\mathop \\beta \\nolimits_{k}  + \\mathop \\alpha \\nolimits_i  + \\mathop \\tau \\nolimits_j  + \\mathop {(\\alpha \\tau )}\\nolimits_{ij}  + {\\rm{ }}\\mathop \\varepsilon \\nolimits_{ijk}\n\\]\nonde \\({y_{ijk}}\\) é o valor observado da combinação do i-ésimo nível do fator \\(\\alpha\\) com o j-ésimo nível do fator \\(\\tau\\) no k-ésimo bloco; \\(\\mu\\) é a média geral; \\(\\mathop \\beta \\nolimits_{k}\\) é o efeito do bloco k; \\(\\mathop \\alpha \\nolimits_i\\) é o efeito do i-ésimo nível de \\(\\alpha\\) ; \\(\\mathop \\tau \\nolimits_j\\) é o efeito do j-ésimo nível de \\(\\tau\\) ; \\(\\mathop {(\\alpha \\tau )}\\nolimits_{ij}\\) é o efeito da interação do i-ésimo nível de \\(\\alpha\\) com o j-ésimo nível de \\(\\tau\\); e \\(\\mathop \\varepsilon \\nolimits_{ijk}\\) é o erro aleatório associado a \\({y_{ijk}}\\), assumindo \\(\\mathop \\varepsilon \\nolimits_{ijk} \\mathop \\cap \\limits^{iid} N(0,\\mathop \\sigma \\nolimits^2 )\\).\nBasicamente, estes fatores podem ser divididos em dois tipos: qualitativos e quantitativos. Um fator qualitativo é, como o nome já diz, relacionado a qualidade, ou seja, diferentes em tipo, mas não em quantidade. Como exemplo, podemos citar cultivares, defensivos agrícolas, práticas de manejo, etc. Um fator quantitativo, por outro lado, é caracterizado pela quantidade utilizada no experimento. Podemos citar, por exemplo, doses de adubação. Cabe ressaltar que o termo fatorial não indica um delineamento experimental, mas uma forma de arranjo de tratamentos na área parcela. Estes experimentos podem ser conduzidos tanto em DIC quanto DBC. Assim, em cada repetição/bloco, o tratamento a ser aplicado é a combinação dos níveis dos dois fatores."
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#conjunto-de-dados",
    "href": "FIT5306/FIT5306_10_FAT.html#conjunto-de-dados",
    "title": "10. Experimentos Fatoriais",
    "section": "Conjunto de dados",
    "text": "Conjunto de dados\nO conjunto de dados utilizado neste exemplo é adaptado de OLIVOTO et al. (2016) sendo oriundo de um experimento que testou o efeito de diferentes parcelamentos de nitrogênio (N) associado ao uso de enxofre (S) na produtividade, componentes do rendimento e qualidade reológica da farinha de trigo.\n\nOLIVOTO, T. et al. Sulfur and nitrogen effects on industrial quality and grain yield of wheat. Revista de Ciências Agroveterinárias, v. 15, n. 1, p. 24–33, 2016. Disponível em: https://doi.org/10.5965/223811711512016024\n\nOs tratamentos consistiram da combinação de três níveis de parcelamento de N (DA: 100% no duplo anel; AF+DA: 50% no afilhamento + 50% no duplo anel; DA+ES: 50% no afilhamento + 50% no espigamento) e dois níveis de enxofre (S+: com enxofre; S-: sem enxofre).\nPara fins didáticos, a extensibilidade da massa (L, mm) é utilizada. Para importação, utiliza-se a função import() do pacote rio. A função as_factor converte as primeiras três colunas para fator.\n\nurl <- \"https://bit.ly/df_biostat\"\ndf_fat <- \n  import(url, sheet = \"FAT1_CI2\", setclass = \"tbl\") |>\n  as_factor(1:3)\n\nNo seguinte gráfico, apresento as médias observadas da extensibilidade nos diferentes tratamentos.\n\nplot_factbars(df_fat, ENX, NIT, resp = L)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#verificação-de-outliers",
    "href": "FIT5306/FIT5306_10_FAT.html#verificação-de-outliers",
    "title": "10. Experimentos Fatoriais",
    "section": "Verificação de outliers",
    "text": "Verificação de outliers\nA função inspect do pacote metan é utilizada para inspecionar o conjunto de dados. Com esta função, é possível identificar possíveis outliers, bem como valores faltantes.\n\ninspect(df_fat, plot = TRUE)\n## # A tibble: 4 × 10\n##   Variable Class   Missing Levels Valid_n   Min Median   Max Outlier Text \n##   <chr>    <chr>   <chr>   <chr>    <int> <dbl>  <dbl> <dbl>   <dbl> <lgl>\n## 1 ENX      factor  No      2           24    NA   NA      NA      NA NA   \n## 2 NIT      factor  No      3           24    NA   NA      NA      NA NA   \n## 3 REP      factor  No      4           24    NA   NA      NA      NA NA   \n## 4 L        numeric No      -           24    67   78.5    96       0 NA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#estatística-descritiva",
    "href": "FIT5306/FIT5306_10_FAT.html#estatística-descritiva",
    "title": "10. Experimentos Fatoriais",
    "section": "Estatística descritiva",
    "text": "Estatística descritiva\nA função desc_stat() do pacote metan computa estatísticas descritivas para a variável L.\n\ndesc_stat(df_fat)\n## # A tibble: 1 × 10\n##   variable    cv   max  mean median   min sd.amo    se  ci.t n.valid\n##   <chr>    <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>\n## 1 L         10.5    96  80.4   78.5    67   8.43  1.72  3.56      24"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#análise-de-variância",
    "href": "FIT5306/FIT5306_10_FAT.html#análise-de-variância",
    "title": "10. Experimentos Fatoriais",
    "section": "Análise de variância",
    "text": "Análise de variância\n\nManual\n\nmat_df_fat <- make_mat(df_fat, ENX, NIT, L, fun = sum)\nmat_df_fat\n\n   AF+DA  DA DA+ES\nS-   297 316   310\nS+   286 373   347\n\n# total dos blocos\ntbloco <- sum_by(df_fat, REP) |> pull()\n\nI <- nlevels(df_fat$ENX)\nJ <- nlevels(df_fat$NIT)\nK <- nlevels(df_fat$REP)\n\n# fator de correção\nC <- sum(df_fat$L) ^ 2  / (I*J*K)\n# soma de quadrado total\nsqtot <- sum(df_fat$L ^ 2) - C\n# soma de quadrado de bloco\nsqbloco <- sum(tbloco ^ 2) / (I*J) - C\n# soma de quadrados de ENX (a)\nsqa <- sum(rowSums(mat_df_fat) ^ 2)  / (J * K) -  C\n# soma de quadrados de NIT (b)\nsqb <- sum(colSums(mat_df_fat) ^ 2)  / (I * K) -  C\n# soma de quadrados da interação (a x b)\nsqab <- sum(mat_df_fat ^ 2)  / K -  C - sqa - sqb\n# soma de quadrado do erro\nsqerr <- sqtot - sqa - sqb - sqab - sqbloco\n\n\n# montar a tabela\nFV <- c(\"BLOCO\", \"ENX\", \"NIT\", \"ENX*NIT\", \"ERRO\", \"TOTAL\")\nGL <- c(3, 1, 2, 2, 15, 23)\nSQ <- c(sqbloco, sqa, sqb, sqab, sqerr, sqtot)\nQM <- SQ / GL\nFC <- QM / QM[5]\nFC[5:6] <- NA\n\ndata.frame(FV = FV, GL = GL, SQ = SQ, QM = QM, FC = FC)\n\n       FV GL         SQ         QM         FC\n1   BLOCO  3   10.45833   3.486111  0.1779889\n2     ENX  1  287.04167 287.041667 14.6553680\n3     NIT  2  739.00000 369.500000 18.8654092\n4 ENX*NIT  2  305.33333 152.666667  7.7946391\n5    ERRO 15  293.79167  19.586111         NA\n6   TOTAL 23 1635.62500  71.114130         NA\n\n\nA análise de variância é computada no software R utilizando a função aov(). Considerando o Delineamento de Blocos Casualizados (DBC), as três fontes de variação incluídas no modelo são a de enxofre (ENX), nitrogênio (NIT) e bloco (REP). Note que todos os termos (efeito principal e interação) podem ser declarados quando se utiliza ENX*NIT; também é possível indicar termos específicos no modelo.\n\n# opção 1\nanova <- aov(L ~ ENX*NIT + REP, data = df_fat)\n# modelo idêntico, indicando os termos explicitamente\nanova <- aov(L ~ ENX + NIT + ENX:NIT + REP, data = df_fat)\nsummary(anova)\n##             Df Sum Sq Mean Sq F value   Pr(>F)    \n## ENX          1  287.0   287.0  14.655  0.00165 ** \n## NIT          2  739.0   369.5  18.865 8.04e-05 ***\n## REP          3   10.5     3.5   0.178  0.90965    \n## ENX:NIT      2  305.3   152.7   7.795  0.00477 ** \n## Residuals   15  293.8    19.6                     \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#comparação-de-médias",
    "href": "FIT5306/FIT5306_10_FAT.html#comparação-de-médias",
    "title": "10. Experimentos Fatoriais",
    "section": "Comparação de médias",
    "text": "Comparação de médias\nA análise de variância revelou efeito significativo da interação. Nesse caso, segue-se comparando as médias do fator nitrogênio dentro de cada nível do fator enxofre e do enxofre dentro de cada nível do fator nitrogênio. Para isso, utilizo o pacote emmeans (teste Tukey). Nesta abordagem, a avaliação da significância das médias de dois tratamentos é dada pela sobreposição das flechas de cada tratamento. Se dois tratamentos apresentam setas que se sobrepõem (considerando o eixo x), assume-se que estes tratamentos são estatisticamente diferentes um do outro.\n\nmedias_fat <- emmeans(anova, ~ NIT | ENX)\nplot(medias_fat,\n     CIs = FALSE, # remove os intervalos de confiança das médias\n     comparisons = TRUE) # insere setas para comparação de médias (Tukey)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#pacote-agror",
    "href": "FIT5306/FIT5306_10_FAT.html#pacote-agror",
    "title": "10. Experimentos Fatoriais",
    "section": "Pacote AgroR",
    "text": "Pacote AgroR\nNo pacote agroR, a análise de variância neste delineamento pode ser realizada com a função FAT2DBC().\n\nwith(df_fat,\n     FAT2DBC(ENX, NIT, REP, L))\n## \n## -----------------------------------------------------------------\n## Normality of errors\n## -----------------------------------------------------------------\n##                          Method Statistic    p.value\n##  Shapiro-Wilk normality test(W)  0.922206 0.06536118\n## \n## \n## -----------------------------------------------------------------\n## Homogeneity of Variances\n## -----------------------------------------------------------------\n##                               Method Statistic  p.value\n##  Bartlett test(Bartlett's K-squared)  2.459752 0.782544\n## \n## \n## -----------------------------------------------------------------\n## Independence from errors\n## -----------------------------------------------------------------\n##                  Method Statistic    p.value\n##  Durbin-Watson test(DW)  1.682362 0.04036279\n## \n## \n## -----------------------------------------------------------------\n## Additional Information\n## -----------------------------------------------------------------\n## \n## CV (%) =  5.51\n## Mean =  80.375\n## Median =  78.5\n## Possible outliers =  No discrepant point\n## \n## -----------------------------------------------------------------\n## Analysis of Variance\n## -----------------------------------------------------------------\n##               Df    Sum Sq    Mean.Sq    F value        Pr(F)\n## Fator1         1 287.04167 287.041667 14.6553680 1.645485e-03\n## Fator2         2 739.00000 369.500000 18.8654092 8.038974e-05\n## bloco          3  10.45833   3.486111  0.1779889 9.096501e-01\n## Fator1:Fator2  2 305.33333 152.666667  7.7946391 4.774361e-03\n## Residuals     15 293.79167  19.586111                        \n## \n## -----------------------------------------------------------------\n## \n## Significant interaction: analyzing the interaction\n## \n## -----------------------------------------------------------------\n## \n## -----------------------------------------------------------------\n## Analyzing  F1  inside of each level of  F2\n## -----------------------------------------------------------------\n##                        Df Sum Sq Mean Sq F value    Pr(>F)    \n## bloco                   3  10.46    3.49  0.1780 0.9096501    \n## Fator2                  2 739.00  369.50 18.8654 8.039e-05 ***\n## Fator2:Fator1           3 592.38  197.46 10.0815 0.0006909 ***\n##   Fator2:Fator1: AF+DA  1  15.13   15.13  0.7722 0.3933874    \n##   Fator2:Fator1: DA     1 406.12  406.12 20.7354 0.0003805 ***\n##   Fator2:Fator1: DA+ES  1 171.12  171.12  8.7371 0.0098160 ** \n## Residuals              15 293.79   19.59                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## -----------------------------------------------------------------\n## Analyzing  F2  inside of the level of  F1\n## -----------------------------------------------------------------\n## \n##                     Df  Sum Sq Mean Sq F value    Pr(>F)    \n## bloco                3   10.46    3.49  0.1780  0.909650    \n## Fator1               1  287.04  287.04 14.6554  0.001645 ** \n## Fator1:Fator2        4 1044.33  261.08 13.3300 7.897e-05 ***\n##   Fator1:Fator2: S-  2   47.17   23.58  1.2041  0.327368    \n##   Fator1:Fator2: S+  2  997.17  498.58 25.4560 1.508e-05 ***\n## Residuals           15  293.79   19.59                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n## \n## -----------------------------------------------------------------\n## Final table\n## -----------------------------------------------------------------\n##      AF+DA      DA   DA+ES\n## S- 74.2 aA 79.0 bA 77.5 bA\n## S+ 71.5 aB 93.2 aA 86.8 aA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#casualização-1",
    "href": "FIT5306/FIT5306_10_FAT.html#casualização-1",
    "title": "10. Experimentos Fatoriais",
    "section": "Casualização",
    "text": "Casualização\n\nsketch(trat= c(\"A1\", \"A2\"),\n       trat1 = c(\"B1\", \"B2\", \"B3\"),\n       design = \"PSUBDBC\",\n       r = 4)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#análise-de-variância-1",
    "href": "FIT5306/FIT5306_10_FAT.html#análise-de-variância-1",
    "title": "10. Experimentos Fatoriais",
    "section": "Análise de variância",
    "text": "Análise de variância\nConsiderando o mesmo conjunto de dados do exemplo anterior e assumindo que o enxofre estava casualizado nas parcelas principais e o nitrogênio nas subparcelas, a análise de variância no software R é computada conforme segue\n\nanova_psub <- aov(L ~ ENX*NIT + Error(REP/ENX), data = df_fat)\nsummary(anova_psub)\n\n\nError: REP\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  3  10.46   3.486               \n\nError: REP:ENX\n          Df Sum Sq Mean Sq F value Pr(>F)  \nENX        1 287.04  287.04   18.94 0.0224 *\nResiduals  3  45.46   15.15                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n          Df Sum Sq Mean Sq F value   Pr(>F)    \nNIT        2  739.0   369.5  17.855 0.000253 ***\nENX:NIT    2  305.3   152.7   7.377 0.008142 ** \nResiduals 12  248.3    20.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#pacote-agror-1",
    "href": "FIT5306/FIT5306_10_FAT.html#pacote-agror-1",
    "title": "10. Experimentos Fatoriais",
    "section": "Pacote AgroR",
    "text": "Pacote AgroR\nNo pacote agroR, a análise de variância neste delineamento pode ser realizada com a função PSUBDBC().\n\nwith(df_fat,\n     PSUBDBC(ENX, NIT, REP, L))\n## \n## -----------------------------------------------------------------\n## Normality of errors\n## -----------------------------------------------------------------\n##                          Method Statistic    p.value\n##  Shapiro-Wilk normality test(W)  0.922206 0.06536118\n## \n## \n## \n## -----------------------------------------------------------------\n## Homogeneity of Variances\n## -----------------------------------------------------------------\n## Plot\n##                               Method Statistic   p.value\n##  Bartlett test(Bartlett's K-squared) 0.6768708 0.4106663\n## \n## \n## ----------------------------------------------------\n## Split-plot\n##                               Method Statistic   p.value\n##  Bartlett test(Bartlett's K-squared)  1.817323 0.4030634\n## \n## \n## ----------------------------------------------------\n## Interaction\n##                               Method Statistic  p.value\n##  Bartlett test(Bartlett's K-squared)  2.459752 0.782544\n## \n## \n## -----------------------------------------------------------------\n## Additional Information\n## -----------------------------------------------------------------\n## \n## CV1 (%) =  4.84\n## CV2 (%) =  5.66\n## Mean =  80.375\n## Median =  78.5\n## \n## -----------------------------------------------------------------\n## Analysis of Variance\n## -----------------------------------------------------------------\n##         Df Sum Sq    Mean Sq    F value    Pr(>F) \n## F1       1 287.04167 287.041667 18.9431714 0.022  \n## Block    3  10.45833   3.486111  0.2300642 0.871  \n## Error A  3  45.45833  15.152778                   \n## F2       2 739.00000 369.500000 17.8550336 p<0.001\n## F1 x F2  2 305.33333 152.666667  7.3771812 0.008  \n## Error B 12 248.33333  20.694444                   \n## -----------------------------------------------------------------\n## Significant interaction: analyzing the interaction\n## -----------------------------------------------------------------\n## Analyzing  F1  inside of each level of  F2\n## -----------------------------------------------------------------\n##                      GL       SQ        QM        Fc  p.value\n## F1 : F2 AF+DA   1.00000  15.1250  15.12500  0.802506 0.384898\n## F1 : F2 DA      1.00000 406.1250 406.12500 21.548268 0.000343\n## F1 : F2 DA+ES   1.00000 171.1250 171.12500  9.079587 0.008963\n## Combined error 14.57876 274.7691  18.84722                   \n## \n## -----------------------------------------------------------------\n## Analyzing  F2  inside of the level of  F1\n## -----------------------------------------------------------------\n##             GL        SQ        QM        Fc  p.value\n## F2 : F1 S-   2  47.16667  23.58333  1.139597 0.352262\n## F2 : F1 S+   2 997.16667 498.58333 24.092617  6.3e-05\n## Error b     12 248.33333  20.69444\n\n\n\n## \n## -----------------------------------------------------------------\n## Final table\n## -----------------------------------------------------------------\n##      AF+DA      DA   DA+ES\n## S- 74.2 aA 79.0 bA 77.5 bA\n## S+ 71.5 aB 93.2 aA 86.8 aA"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#experimento1",
    "href": "FIT5306/FIT5306_10_FAT.html#experimento1",
    "title": "10. Experimentos Fatoriais",
    "section": "Coberturas de solo e doses de nitrogênio (efeito na massa de cobertura de inverno)",
    "text": "Coberturas de solo e doses de nitrogênio (efeito na massa de cobertura de inverno)\nO delineamento experimental utilizado foi o delineamento de blocos casualizados com parcelas subdivididas em esquema fatorial 4x2 com quatro repetições. quatro espécies: aveia preta cv. BRS 139 (Neblina), com densidade de 120 kg ha\\(^{-1}\\) de semente; triticale cv. BRS SATURNO, com densidade de 160 kg ha\\(^{-1}\\) de semente e centeio cv. BRS PROGRESSO, com densidade de 160 kg ha\\(^{-1}\\) de semente, além do pousio, com presença de diferentes plantas que se desenvolvem nesta época (três espécies de gramíneas); com dois manejos de nitrogênio (com ou sem N em cobertuta). Os tratamentos foram alocados na área experimental em formato de parcelas subdivididas. Na parcela principal foram alocadas as espécies nas subparcela o manejo de nitrogênio. Nas parcelas que receberam N utilizou-se como fonte a ureia (45% de N) na dose de 100 kg ha\\(^{-1}\\).\n\nPacotes e dados\nAssumindo que todos estão instalados, é só carregar com\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\ndf_cobmassa <- import(url, sheet = \"COBERTURA_N_MASSA\", setclass = \"tbl\")\ndf_cobmassa <- as_factor(df_cobmassa, 1:3)\n\n# Apenas para mostrar a estrutura dos dados\ndf_cobmassa\n\n# A tibble: 32 × 6\n   NITROGENIO ESPECIE     REP       MV    MS   MSR\n   <fct>      <fct>       <fct>  <dbl> <dbl> <dbl>\n 1 Sem N      Aveia Preta 1     17939. 3640.  53.2\n 2 Sem N      Aveia Preta 2     20738. 4190. 709. \n 3 Sem N      Aveia Preta 3     37780  6958. 688  \n 4 Sem N      Aveia Preta 4     15448  3055.  98  \n 5 Sem N      Centeio     1     30836. 7001. 347. \n 6 Sem N      Centeio     2     22246  5540  246. \n 7 Sem N      Centeio     3     12422  3330. 169. \n 8 Sem N      Centeio     4     15220. 3797. 213. \n 9 Sem N      Triticale   1     14700. 2989. 268. \n10 Sem N      Triticale   2     19146. 3652. 399. \n# … with 22 more rows\n\n\n\n\nEstatistica descritiva\n\ndesc_stat(df_cobmassa, stats = c(\"min, mean, max\"))\n\n# A tibble: 3 × 4\n  variable    min   mean    max\n  <chr>     <dbl>  <dbl>  <dbl>\n1 MS       1576.   5053.  7573.\n2 MSR        53.2   373.   738 \n3 MV       6413.  25210. 45076.\n\n\n\n\nANOVA\nO modelo considerado para este exemplo de parcela subdivididas é o seguinte\n\\[\n{y_{ijk}} = {\\rm{ }}\\mu {\\rm{ }} + {\\rm{ }}\\mathop \\alpha \\nolimits_i + \\mathop \\beta \\nolimits_{k} + \\mathop \\eta \\nolimits_{ik}  +\\mathop \\tau \\nolimits_j  + \\mathop {(\\alpha \\tau )}\\nolimits_{ij}  + {\\rm{ }}\\mathop \\varepsilon \\nolimits_{ijk}\n\\]\nonde \\({y_{ijk}}\\) é a variável resposta observada; \\(\\mu\\) é a média geral; \\(\\mathop \\alpha \\nolimits_i\\) é o efeito do \\(i\\)-ésimo nível do fator espécie de cobertura ; \\(\\mathop \\beta \\nolimits_{k}\\) é o efeito do bloco \\(k\\); \\(\\mathop \\eta \\nolimits_{ik}\\) é o erro de parcela, mais conhecido como erro a; \\(\\mathop \\tau \\nolimits_j\\) é o efeito do \\(j\\)-ésimo nível do fator nitrogênio; \\(\\mathop {(\\alpha \\tau )}\\nolimits_{ij}\\) é o efeito da interação do \\(i\\)-ésimo nível do fator espécie com o \\(j\\)-ésimo nível do fator nitrogênio; e \\(\\mathop \\varepsilon \\nolimits_{ijk}\\) é o erro da subparcela, mais conhecido como erro b.\n\nMassa verde (MV) por ha\nANOVA\n\nwith(df_cobmassa,\n     psub2.dbc(fator1 = ESPECIE,\n               fator2 = NITROGENIO,\n               bloco = REP,\n               resp = MV,\n               fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1 (parcela):  ESPECIE \nFATOR 2 (subparcela):  NITROGENIO \n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL         SQ        QM      Fc  Pr(>Fc)    \nESPECIE             3  416543558 138847853  1.2283 0.354965    \nBloco               3   77123097  25707699  0.2274 0.875004    \nErro a              9 1017377902 113041989                     \nNITROGENIO          1  743336547 743336547 20.7774 0.000657 ***\nESPECIE*NITROGENIO  3   86334790  28778264  0.8044 0.515204    \nErro b             12  429314110  35776176                     \nTotal              31 2770030005                               \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n------------------------------------------------------------------------\nCV 1 = 42.17338 %\nCV 2 = 23.72551 %\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis   Medias\n1 Aveia Preta 30469.15\n2     Centeio 24084.35\n3      Pousio 20441.70\n4   Triticale 25846.80\n------------------------------------------------------------------------\nNITROGENIO\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    Com N   30030.17 \n b   Sem N   20390.83 \n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo somente foi observado efeito significativo para o fator nitrogênio, prossegue-se com a comparação de médias para o efeito de N, conforme resultado do Teste Tukey acima. Neste gráfico, as barras mostram a média e as barras de erro, o erro padrão da média. Apenas para apresentação, incluo também a média do fator cobertura de solo, sem as letras pois o seu efeito não foi significativo, segundo a ANOVA.\n\npn_mv <- \n  plot_bars(df_cobmassa,\n            x = NITROGENIO,\n            y = MV,\n            lab.bar = c(\"a\", \"b\"),\n            xlab = \"Aplicação de Nitrogênio (N)\",\n            ylab = \"Matéria verde (kg/ha)\")\n\npcob_mv <- \n  plot_bars(df_cobmassa,\n            x = ESPECIE,\n            y = MV,\n            xlab = \"Espécies\",\n            ylab = \"Matéria verde (kg/ha)\") +\n  geom_hline(yintercept = mean(df_cobmassa$MV))\n\n# organiza os gráficos\narrange_ggplot(pn_mv, pcob_mv)\n\n\n\n\n\n\nMassa seca (MS) por ha\nANOVA\n\nwith(df_cobmassa,\n     psub2.dbc(fator1 = ESPECIE,\n               fator2 = NITROGENIO,\n               bloco = REP,\n               resp = MS,\n               fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1 (parcela):  ESPECIE \nFATOR 2 (subparcela):  NITROGENIO \n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL       SQ       QM     Fc Pr(>Fc)  \nESPECIE             3 11614132  3871377 1.0190 0.42877  \nBloco               3  1466451   488817 0.1287 0.94066  \nErro a              9 34191281  3799031                 \nNITROGENIO          1 14139498 14139498 8.1851 0.01433 *\nESPECIE*NITROGENIO  3  1476172   492057 0.2848 0.83542  \nErro b             12 20729720  1727477                 \nTotal              31 83617255                          \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n------------------------------------------------------------------------\nCV 1 = 38.57428 %\nCV 2 = 26.01163 %\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis  Medias\n1 Aveia Preta 5402.25\n2     Centeio 5647.55\n3      Pousio 4065.85\n4   Triticale 5095.85\n------------------------------------------------------------------------\nNITROGENIO\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    Com N   5717.6 \n b   Sem N   4388.15 \n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo somente foi observado efeito significativo para o fator nitrogênio, prossegue-se com a comparação de médias para o efeito de N, conforme resultado do Teste Tukey acima. Apenas para apresentação, incluo também a média do fator cobertura de solo, sem as letras pois o seu efeito não foi significativo, segundo a ANOVA.\n\npn_ms <- \n  plot_bars(df_cobmassa,\n            x = NITROGENIO,\n            y = MS,\n            lab.bar = c(\"a\", \"b\"),\n            xlab = \"Aplicação de Nitrogênio (N)\",\n            ylab = \"Matéria seca (kg/ha)\")\n\npcob_ms <- \n  plot_bars(df_cobmassa,\n            x = ESPECIE,\n            y = MS,\n            xlab = \"Espécies\",\n            ylab = \"Matéria seca (kg/ha)\") +\n  geom_hline(yintercept = mean(df_cobmassa$MS))\n\n# organiza os gráficos\narrange_ggplot(pn_ms, pcob_ms)\n\n\n\n\n\n\nMassa seca de raiz (MSR) por ha\nANOVA\n\nwith(df_cobmassa,\n     psub2.dbc(fator1 = ESPECIE,\n               fator2 = NITROGENIO,\n               bloco = REP,\n               resp = MSR,\n               fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1 (parcela):  ESPECIE \nFATOR 2 (subparcela):  NITROGENIO \n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL      SQ     QM      Fc  Pr(>Fc)    \nESPECIE             3  160868  53623  0.9543 0.454941    \nBloco               3  217735  72578  1.2916 0.335534    \nErro a              9  505724  56192                     \nNITROGENIO          1  141512 141512 21.4205 0.000582 ***\nESPECIE*NITROGENIO  3   44728  14909  2.2568 0.134138    \nErro b             12   79277   6606                     \nTotal              31 1149844                            \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n------------------------------------------------------------------------\nCV 1 = 63.48783 %\nCV 2 = 21.76891 %\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis Medias\n1 Aveia Preta  405.7\n2     Centeio  365.6\n3      Pousio  264.4\n4   Triticale  457.8\n------------------------------------------------------------------------\nNITROGENIO\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    Com N   439.875 \n b   Sem N   306.875 \n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo somente foi observado efeito significativo para o fator nitrogênio, prossegue-se com a comparação de médias para o efeito de N, conforme resultado do Teste Tukey acima. Apenas para apresentação, incluo também a média do fator cobertura de solo, sem as letras pois o seu efeito não foi significativo, segundo a ANOVA.\n\npn_msr <- \n  plot_bars(df_cobmassa,\n            x = NITROGENIO,\n            y = MSR,\n            lab.bar = c(\"a\", \"b\"),\n            xlab = \"Aplicação de Nitrogênio (N)\",\n            ylab = \"Massa seca de raiz (kg/ha)\")\n\npcob_msr <- \n  plot_bars(df_cobmassa,\n            x = ESPECIE,\n            y = MSR,\n            xlab = \"Espécies\",\n            ylab = \"Massa seca de raiz (kg/ha)\") +\n  geom_hline(yintercept = mean(df_cobmassa$MSR))\n\n# organiza os gráficos\narrange_ggplot(pn_msr, pcob_msr)"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#coberturas-de-solo-e-doses-de-nitrogênio-efeito-na-cultura-da-soja",
    "href": "FIT5306/FIT5306_10_FAT.html#coberturas-de-solo-e-doses-de-nitrogênio-efeito-na-cultura-da-soja",
    "title": "10. Experimentos Fatoriais",
    "section": "Coberturas de solo e doses de nitrogênio (efeito na cultura da soja)",
    "text": "Coberturas de solo e doses de nitrogênio (efeito na cultura da soja)\nOs tratamentos e delineamentos são descritos no exemplo anterior. Aqui, são analisados os dados observados na cultura da soja, semeada na resteva de cada tratamento (combinação de N e espécies de cobertura)\n\nPacotes e dados\nAssumindo que todos estão instalados, é só carregar com\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\ndf_cobsoja <- import(url, sheet = \"COBERTURA_N_SOJA\", setclass = \"tbl\")\ndf_cobsoja <- as_factor(df_cobsoja, 1:3)\n\n# Apenas para mostrar a estrutura dos dados\ndf_cobsoja\n\n# A tibble: 32 × 7\n   ESPECIE     NITROGENIO REP      NL   NGL   MMG    RG\n   <fct>       <fct>      <fct> <dbl> <dbl> <dbl> <dbl>\n 1 Aveia Preta Sem N      R1     30    2.25   180 3547.\n 2 Aveia Preta Sem N      R2     40.8  2.55   190 4117.\n 3 Aveia Preta Sem N      R3     34.6  2.6    170 3381.\n 4 Aveia Preta Sem N      R4     37.6  2.52   160 3733.\n 5 Centeio     Sem N      R1     38.6  2.15   180 3819.\n 6 Centeio     Sem N      R2     40.6  2.1    170 1739.\n 7 Centeio     Sem N      R3     37.6  2.48   180 3928.\n 8 Centeio     Sem N      R4     38    2.39   150 3339.\n 9 Triticale   Sem N      R1     35.6  2.46   210 4400 \n10 Triticale   Sem N      R2     32.2  2.42   200 4378.\n# … with 22 more rows\n\n\n\n\nEstatistica descritiva\n\ndesc_stat(df_cobsoja, stats = c(\"min, mean, max\"))\n\n# A tibble: 4 × 4\n  variable    min    mean     max\n  <chr>     <dbl>   <dbl>   <dbl>\n1 MMG      150     178.    210   \n2 NGL        1.97    2.43    2.82\n3 NL        22.6    38.6    53.2 \n4 RG       675    3288.   4861.  \n\n\n\n\nANOVA\nO modelo considerado é descrito no exemplo anterior.\n\nVariável número de legumes por planta (NL)\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = NL,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL      SQ QM     Fc   Pr>Fc\nBloco               3   18.72  6 0.1640 0.91940\nESPECIE             3  148.99  5 1.3051 0.29904\nNITROGENIO          1    2.76  3 0.0726 0.79027\nESPECIE*NITROGENIO  3  430.67  2 3.7724 0.02607\nResiduo            21  799.15  4               \nTotal              31 1400.30  1               \n------------------------------------------------------------------------\nCV = 16 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.5520582 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\n\n\nInteracao significativa: desdobrando a interacao\n------------------------------------------------------------------------\n\nDesdobrando  ESPECIE  dentro de cada nivel de  NITROGENIO \n------------------------------------------------------------------------\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                         GL         SQ        QM     Fc  Pr.Fc\nBloco                     3   18.72375   6.24125  0.164 0.9194\nNITROGENIO                1    2.76125   2.76125 0.0726 0.7903\nESPECIE:NITROGENIO Com N  3  513.04000 171.01333 4.4939 0.0138\nESPECIE:NITROGENIO Sem N  3   66.62750  22.20917 0.5836 0.6323\nResiduo                  21  799.14625  38.05458              \nTotal                    31 1400.29875  45.17093              \n------------------------------------------------------------------------\n\n\n\n ESPECIE  dentro do nivel  Com N  de  NITROGENIO \n------------------------------------------------------------------------\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    1   44.65 \na    2   43.55 \nab   4   36.55 \n b   3   30.65 \n------------------------------------------------------------------------\n\n\n ESPECIE  dentro do nivel  Sem N  de  NITROGENIO \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  35.75\n2      2  38.70\n3      3  41.30\n4      4  37.30\n------------------------------------------------------------------------\n\n\n\nDesdobrando  NITROGENIO  dentro de cada nivel de  ESPECIE \n------------------------------------------------------------------------\n------------------------------------------------------------------------\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                               GL         SQ        QM     Fc  Pr.Fc\nBloco                           3   18.72375   6.24125  0.164 0.9194\nESPECIE                         3  148.99375  49.66458 1.3051  0.299\nNITROGENIO:ESPECIE Aveia Preta  1  158.42000 158.42000  4.163 0.0541\nNITROGENIO:ESPECIE Centeio      1   47.04500  47.04500 1.2363 0.2788\nNITROGENIO:ESPECIE Pousio       1  226.84500 226.84500  5.961 0.0236\nNITROGENIO:ESPECIE Triticale    1    1.12500   1.12500 0.0296 0.8651\nResiduo                        21  799.14625  38.05458              \nTotal                          31 1400.29875  45.17093              \n------------------------------------------------------------------------\n\n\n\n NITROGENIO  dentro do nivel  Aveia Preta  de  ESPECIE \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  44.65\n2      2  35.75\n------------------------------------------------------------------------\n\n\n NITROGENIO  dentro do nivel  Centeio  de  ESPECIE \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  43.55\n2      2  38.70\n------------------------------------------------------------------------\n\n\n NITROGENIO  dentro do nivel  Pousio  de  ESPECIE \n------------------------------------------------------------------------\nTeste de Tukey\n------------------------------------------------------------------------\nGrupos Tratamentos Medias\na    2   41.3 \n b   1   30.65 \n------------------------------------------------------------------------\n\n\n NITROGENIO  dentro do nivel  Triticale  de  ESPECIE \n\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1      1  36.55\n2      2  37.30\n------------------------------------------------------------------------\n\n\nGRÁFICO\nComo não a houve diferença para os efeitos principais (ESPECIE E NITROGÊNIO) mas deu interação entre estes fatores, vamos apresentar um gráfico mostrando essa interação. No gráfico, letras maiúsculas comparam as espécies dentro de cada manejo de N e minúsculas comparam o manejo de N dentro de cada espécie. As barras mostram a média e as barras de erro, o erro padrão da média.\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = NL,\n              lab.bar = c(\"Aa\", \"Aa\", \"Aa\", \"Aa\", \"Bb\", \"Aa\", \"ABa\", \"Aa\"),\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"Número de legumes por planta\")\n\n\n\n\n\n\nVariável número de grãos por legume (NGL)\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = NGL,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL      SQ QM     Fc    Pr>Fc\nBloco               3 0.19640  5 2.3475 0.101764\nESPECIE             3 0.14872  4 1.7776 0.182257\nNITROGENIO          1 0.08405  6 3.0138 0.097208\nESPECIE*NITROGENIO  3 0.14872  3 1.7776 0.182257\nResiduo            21 0.58565  2                \nTotal              31 1.16355  1                \n------------------------------------------------------------------------\nCV = 6.88 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.3640228 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis  Medias\n1 Aveia Preta 2.42250\n2     Centeio 2.32875\n3      Pousio 2.44375\n4   Triticale 2.52000\n------------------------------------------------------------------------\nNITROGENIO\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis Medias\n1  Com N 2.4800\n2  Sem N 2.3775\n------------------------------------------------------------------------\n\n\n\nCOMO NÃO DEU DIFERENÇA SIGNIFICATIVA PARA NENHUM FATOR, PODE-SE APENAS APRESENTAR O GRÁFICO, MAS SEM DISCUTIR DIFERENÇAS ENTRE OS TRATAMENTOS/N\n\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = NGL,\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"Número de grãos por legume\")\n\n\n\n\n\n\nVariável massa de mil grãos (MMG)\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = MMG,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL     SQ QM     Fc   Pr>Fc\nBloco               3 3409.4  2 6.5107 0.00275\nESPECIE             3 1309.4  5 2.5004 0.08733\nNITROGENIO          1   28.1  4 0.1611 0.69218\nESPECIE*NITROGENIO  3  209.4  6 0.3998 0.75454\nResiduo            21 3665.6  3               \nTotal              31 8621.9  1               \n------------------------------------------------------------------------\nCV = 7.4 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.858878 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis Medias\n1 Aveia Preta 176.25\n2     Centeio 171.25\n3      Pousio 188.75\n4   Triticale 177.50\n------------------------------------------------------------------------\nNITROGENIO\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis  Medias\n1  Com N 177.500\n2  Sem N 179.375\n------------------------------------------------------------------------\n\n\n\nCOMO NÃO DEU DIFERENÇA SIGNIFICATIVA PARA NENHUM FATOR, PODE-SE APENAS APRESENTAR O GRÁFICO, MAS SEM DISCUTIR DIFERENÇAS ENTRE OS TRATAMENTOS/N\n\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = MMG,\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"Massa de mil grãos (g)\")\n\n\n\n\n\n\nVariável RG\nANOVA\n\nwith(df_cobsoja,\n     fat2.dbc(fator1 = ESPECIE,\n              fator2 = NITROGENIO,\n              bloco = REP,\n              resp = RG,\n              fac.names = c(\"ESPECIE\", \"NITROGENIO\"))\n)\n\n------------------------------------------------------------------------\nLegenda:\nFATOR 1:  ESPECIE \nFATOR 2:  NITROGENIO \n------------------------------------------------------------------------\n\n\nQuadro da analise de variancia\n------------------------------------------------------------------------\n                   GL       SQ QM      Fc   Pr>Fc\nBloco               3  9602221  4 1.97873 0.14806\nESPECIE             3   219192  6 0.04517 0.98689\nNITROGENIO          1   461200  5 0.28512 0.59897\nESPECIE*NITROGENIO  3  3950128  2 0.81400 0.50045\nResiduo            21 33969089  3                \nTotal              31 48201830  1                \n------------------------------------------------------------------------\nCV = 38.68 %\n\n------------------------------------------------------------------------\nTeste de normalidade dos residuos (Shapiro-Wilk)\nvalor-p:  0.1875762 \nDe acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais.\n------------------------------------------------------------------------\n\nInteracao nao significativa: analisando os efeitos simples\n------------------------------------------------------------------------\nESPECIE\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n       Niveis   Medias\n1 Aveia Preta 3368.403\n2     Centeio 3305.556\n3      Pousio 3150.000\n4   Triticale 3327.778\n------------------------------------------------------------------------\nNITROGENIO\nDe acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n------------------------------------------------------------------------\n  Niveis   Medias\n1  Com N 3167.882\n2  Sem N 3407.986\n------------------------------------------------------------------------\n\n\n\nCOMO NÃO DEU DIFERENÇA SIGNIFICATIVA PARA NENHUM FATOR, PODE-SE APENAS APRESENTAR O GRÁFICO, MAS SEM DISCUTIR DIFERENÇAS ENTRE OS TRATAMENTOS/N\n\n\nplot_factbars(df_cobsoja, ESPECIE, NITROGENIO,\n              resp = RG,\n              y.expand = 0.1,\n              xlab = \"Espécie\",\n              ylab = \"RG (kg/ha)\")"
  },
  {
    "objectID": "FIT5306/FIT5306_10_FAT.html#doses-de-nitrogênio-x-híbridos-de-milho",
    "href": "FIT5306/FIT5306_10_FAT.html#doses-de-nitrogênio-x-híbridos-de-milho",
    "title": "10. Experimentos Fatoriais",
    "section": "Doses de Nitrogênio x híbridos de milho",
    "text": "Doses de Nitrogênio x híbridos de milho\n\nSem interação significativa\nO conjunto de dados utilizado neste exemplo será o FAT2_SI. Como já de conhecimento prévio, a interação não é significativa neste exemplo.\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\nFAT2_SI <- import(url, sheet = \"FAT2_SI\", setclass = \"tbl\")\nFAT2_SI\n\n# A tibble: 40 × 4\n   BLOCO HIBRIDO DOSEN    RG\n   <dbl> <chr>   <dbl> <dbl>\n 1     1 NUPEC_1     0  6.9 \n 2     1 NUPEC_1    25  7.44\n 3     1 NUPEC_1    50  7.65\n 4     1 NUPEC_1    75  7.5 \n 5     1 NUPEC_1   100  7.03\n 6     1 NUPEC_2     0  6.68\n 7     1 NUPEC_2    25  7.14\n 8     1 NUPEC_2    50  7.26\n 9     1 NUPEC_2    75  7.03\n10     1 NUPEC_2   100  6.69\n# … with 30 more rows\n\n\nA função fat2.rdb()é utilizada neste exemplo. Como o fator DOSEN é quantitativo, precisamos informar isto no argumento quali da função.\n\nwith(FAT2_SI, \n     fat2.dbc(fator1 =  HIBRIDO,\n              fator2 =  DOSEN,\n              bloco = BLOCO,\n              resp =  RG,\n              quali = c(TRUE, FALSE),\n              fac.names = c(\"HIBRIDO\", \"DOSE\")))\n\nComo a interação não foi significativa, proceder-se-a a comparação de médias dos dois híbridos considerando a média de todas as doses de nitrogênio, e o ajuste de apenas uma regressão para os dois híbridos. Como o grau do polinômio significativo foi quadrático, declararmos fit = 2 na função plot_lines() do pacote metan.\n\nh <- plot_bars(FAT2_SI, HIBRIDO, RG,\n               width.bar = 0.5,\n               lab.bar = c(\"a\", \"b\"))\nd <- plot_lines(FAT2_SI, DOSEN, RG,\n                fit = 2,\n                col = FALSE,\n                xlab = \"Doses de nitrogênio\",\n                ylab = \"Rendimento de grãos (Mg/ha)\") +\n  geom_text(aes(0, 6.5, label=(paste(expression(\"y = 6,8326 + 0,0012x - 0,0003x\"^2*\"  R\" ^2*\" = 0,99 \")))),\n            hjust = 0,\n            col = \"black\",\n            parse = TRUE) \narrange_ggplot(h, d, tag_levels = list(c(\"h\", \"d\")), widths = c(1, 3))\n\n\n\n\n\n\n\n\n\n\nCom interação significativa\nO conjunto de dados utilizado neste exemplo será o FAT2_CI. Neste exemplo já sabe-se que a interação híbrido x dose de N é significativa.\n\nlibrary(rio) # importar e exportar arquivos\nlibrary(ExpDes.pt) # fazer anova\nlibrary(metan) # gráficos\nlibrary(tidyverse) # manipulação de dados e gráficos\n\n# dados\nurl <- \"https://bit.ly/df_biostat\"\nFAT2_CI <- import(url, sheet = \"FAT2_CI\", setclass = \"tbl\")\nFAT2_CI\n\n# A tibble: 40 × 4\n   BLOCO HIBRIDO DOSEN    RG\n   <dbl> <chr>   <dbl> <dbl>\n 1     1 NUPEC_1     0 11.2 \n 2     1 NUPEC_1    25 12.4 \n 3     1 NUPEC_1    50 13   \n 4     1 NUPEC_1    75 12.5 \n 5     1 NUPEC_1   100 11.4 \n 6     1 NUPEC_2     0  9.22\n 7     1 NUPEC_2    25  9.70\n 8     1 NUPEC_2    50 10.1 \n 9     1 NUPEC_2    75 10.9 \n10     1 NUPEC_2   100 11.4 \n# … with 30 more rows\n\n\n\nwith(FAT2_CI, \n     fat2.dbc(fator1 =  HIBRIDO,\n              fator2 =  DOSEN,\n              bloco = BLOCO,\n              resp =  RG,\n              quali = c(TRUE, FALSE),\n              fac.names = c(\"HIBRIDO\", \"DOSE\")))\n## ------------------------------------------------------------------------\n## Legenda:\n## FATOR 1:  HIBRIDO \n## FATOR 2:  DOSE \n## ------------------------------------------------------------------------\n## \n## \n## Quadro da analise de variancia\n## ------------------------------------------------------------------------\n##              GL     SQ QM      Fc   Pr>Fc\n## Bloco         3  0.119  3    1.29 0.29725\n## HIBRIDO       1 40.076  6 1306.48 0.00000\n## DOSE          4  8.436  4   68.75 0.00000\n## HIBRIDO*DOSE  4  9.814  5   79.98 0.00000\n## Residuo      27  0.828  2                \n## Total        39 59.272  1                \n## ------------------------------------------------------------------------\n## CV = 1.56 %\n## \n## ------------------------------------------------------------------------\n## Teste de normalidade dos residuos (Shapiro-Wilk)\n## valor-p:  0.03477145 \n## ATENCAO: a 5% de significancia, os residuos nao podem ser considerados normais!\n## ------------------------------------------------------------------------\n## \n## \n## \n## Interacao significativa: desdobrando a interacao\n## ------------------------------------------------------------------------\n## \n## Desdobrando  HIBRIDO  dentro de cada nivel de  DOSE \n## ------------------------------------------------------------------------\n## ------------------------------------------------------------------------\n## Quadro da analise de variancia\n## ------------------------------------------------------------------------\n##                  GL       SQ       QM       Fc  Pr.Fc\n## Bloco             3  0.11891  0.03964   1.2921 0.2972\n## DOSE              4  8.43556  2.10889  68.7499      0\n## HIBRIDO:DOSE 0    1 11.10618 11.10618 362.0622      0\n## HIBRIDO:DOSE 25   1 14.34872 14.34872 467.7692      0\n## HIBRIDO:DOSE 50   1 17.81448 17.81448  580.753      0\n## HIBRIDO:DOSE 75   1  6.55582  6.55582 213.7201      0\n## HIBRIDO:DOSE 100  1  0.06444  0.06444   2.1008 0.1587\n## Residuo          27  0.82822  0.03067                \n## Total            39 59.27234  1.51980                \n## ------------------------------------------------------------------------\n## \n## \n## \n##  HIBRIDO  dentro do nivel  0  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     11.56 \n##  b    NUPEC_2     9.2035 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  25  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     12.595 \n##  b    NUPEC_2     9.9165 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  50  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     12.935 \n##  b    NUPEC_2     9.9505 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  75  de  DOSE \n## ------------------------------------------------------------------------\n## Teste de Tukey\n## ------------------------------------------------------------------------\n## Grupos Tratamentos Medias\n## a     NUPEC_1     12.625 \n##  b    NUPEC_2     10.8145 \n## ------------------------------------------------------------------------\n## \n## \n##  HIBRIDO  dentro do nivel  100  de  DOSE \n## \n## De acordo com o teste F, as medias desse fator sao estatisticamente iguais.\n## ------------------------------------------------------------------------\n##    Niveis  Medias\n## 1 NUPEC_1 11.5465\n## 2 NUPEC_2 11.3670\n## ------------------------------------------------------------------------\n## \n## \n## \n## Desdobrando  DOSE  dentro de cada nivel de  HIBRIDO \n## ------------------------------------------------------------------------\n## ------------------------------------------------------------------------\n## Quadro da analise de variancia\n## ------------------------------------------------------------------------\n##                      GL       SQ       QM        Fc  Pr.Fc\n## Bloco                 3  0.11891  0.03964    1.2921 0.2972\n## HIBRIDO               1 40.07604 40.07604 1306.4809      0\n## DOSE:HIBRIDO NUPEC_1  4  6.79944  1.69986   55.4156      0\n## DOSE:HIBRIDO NUPEC_2  4 11.44973  2.86243   93.3155      0\n## Residuo              27  0.82822  0.03067                 \n## Total                39 59.27234  1.51980                 \n## ------------------------------------------------------------------------\n## \n## \n## \n##  DOSE  dentro do nivel  NUPEC_1  de  HIBRIDO \n## ------------------------------------------------------------------------\n## Ajuste de modelos polinomiais de regressao\n## ------------------------------------------------------------------------\n## \n## Modelo Linear\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0  12.2517     0.0678    180.6175    0   \n## b1  0.00001     0.0011     0.0108  0.9914 \n## ------------------------------------------\n## \n## R2 do modelo linear\n## --------\n## 0.000001\n## --------\n## \n## Analise de variancia do modelo linear\n## ===================================================\n##                      GL   SQ     QM    Fc   valor.p\n## ---------------------------------------------------\n## Efeito linear        1    0      0      0   0.99144\n## Desvios de Regressao 3  6.7994 2.2665 73.89    0   \n## Residuos             27 0.8282 0.0307              \n## ---------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo quadratico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0  11.5550     0.0824    140.2044    0   \n## b1   0.0557     0.0039    14.2760     0   \n## b2  -0.0006     0.00004   -14.8843    0   \n## ------------------------------------------\n## \n## R2 do modelo quadratico\n## --------\n## 0.999458\n## --------\n## \n## Analise de variancia do modelo quadratico\n## ====================================================\n##                      GL   SQ     QM     Fc   valor.p\n## ----------------------------------------------------\n## Efeito linear        1    0      0      0    0.99144\n## Efeito quadratico    1  6.7958 6.7958 221.54    0   \n## Desvios de Regressao 2  0.0037 0.0018  0.06  0.94178\n## Residuos             27 0.8282 0.0307               \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo cubico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0  11.5623     0.0869    132.9870    0   \n## b1   0.0536     0.0088     6.0633     0   \n## b2  -0.0005     0.0002    -2.2190  0.0351 \n## b3 -0.000000       0      -0.2654  0.7927 \n## ------------------------------------------\n## \n## R2 do modelo cubico\n## --------\n## 0.999775\n## --------\n## \n## Analise de variancia do modelo cubico\n## ====================================================\n##                      GL   SQ     QM     Fc   valor.p\n## ----------------------------------------------------\n## Efeito linear        1    0      0      0    0.99144\n## Efeito quadratico    1  6.7958 6.7958 221.54    0   \n## Efeito cubico        1  0.0022 0.0022  0.07  0.79271\n## Desvios de Regressao 1  0.0015 0.0015  0.05  0.82509\n## Residuos             27 0.8282 0.0307               \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## \n##  DOSE  dentro do nivel  NUPEC_2  de  HIBRIDO \n## ------------------------------------------------------------------------\n## Ajuste de modelos polinomiais de regressao\n## ------------------------------------------------------------------------\n## \n## Modelo Linear\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0   9.2054     0.0678    135.7082    0   \n## b1   0.0209     0.0011    18.8680     0   \n## ------------------------------------------\n## \n## R2 do modelo linear\n## --------\n## 0.953756\n## --------\n## \n## Analise de variancia do modelo linear\n## ====================================================\n##                      GL   SQ      QM     Fc  valor.p\n## ----------------------------------------------------\n## Efeito linear        1  10.9202 10.9202 356     0   \n## Desvios de Regressao 3  0.5295  0.1765  5.75 0.00354\n## Residuos             27 0.8282  0.0307              \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo quadratico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0   9.2781     0.0824    112.5776    0   \n## b1   0.0151     0.0039     3.8624  0.0006 \n## b2   0.0001     0.00004    1.5534  0.1320 \n## ------------------------------------------\n## \n## R2 do modelo quadratico\n## --------\n## 0.960221\n## --------\n## \n## Analise de variancia do modelo quadratico\n## ====================================================\n##                      GL   SQ      QM     Fc  valor.p\n## ----------------------------------------------------\n## Efeito linear        1  10.9202 10.9202 356     0   \n## Efeito quadratico    1  0.0740  0.0740  2.41 0.13196\n## Desvios de Regressao 2  0.4555  0.2277  7.42 0.0027 \n## Residuos             27 0.8282  0.0307              \n## ----------------------------------------------------\n## ------------------------------------------------------------------------\n## \n## Modelo cubico\n## ==========================================\n##    Estimativa Erro.padrao    tc    valor.p\n## ------------------------------------------\n## b0   9.2414     0.0869    106.2918    0   \n## b1   0.0256     0.0088     2.8956  0.0074 \n## b2  -0.0002     0.0002    -1.0496  0.3032 \n## b3  0.000002       0       1.3271  0.1956 \n## ------------------------------------------\n## \n## R2 do modelo cubico\n## --------\n## 0.964939\n## --------\n## \n## Analise de variancia do modelo cubico\n## =====================================================\n##                      GL   SQ      QM     Fc   valor.p\n## -----------------------------------------------------\n## Efeito linear        1  10.9202 10.9202  356     0   \n## Efeito quadratico    1  0.0740  0.0740  2.41  0.13196\n## Efeito cubico        1  0.0540  0.0540  1.76  0.1956 \n## Desvios de Regressao 1  0.4014  0.4014  13.09 0.00121\n## Residuos             27 0.8282  0.0307               \n## -----------------------------------------------------\n## ------------------------------------------------------------------------\n\nA análise de indicou efeitos significativos tanto para os efeitos principais, quanto para a interação. Assim, as análises complementares realizadas foram (i) a comparação das médias pelo teste Tukey em cada nível da dose de N; e (ii) uma regressão polinomial ajustada para cada híbrido. Por padrão, o máximo grau do polinômio ajustado é 3 (modelo cúbico).\n\nComparação das médias dos híbridos em cada dose de nitrogênio.\n\nAs comparações de médias são apresentadas como saída da função fat2.dbc() após a análise de variância. Neste momento, utilizaremos a função plot_factbars() pacote metan** para plotar as médias dos híbridos em cada dose de nitrogênio. A apresentação gráfica de resultados, mesmo considerando médias, é uma alternativa interessante à tabela, pois permite uma interpretação mais clara e intuitiva dos resultados.\n\nplot_factbars(FAT2_CI, DOSEN, HIBRIDO,\n              resp = RG,\n              xlab = \"Doses de nitrogênio\",\n              ylab = expression(paste(\"Rendimento de grãos (Mg ha\"^-1,\")\")),\n              palette = \"Greys\",\n              lab.bar = c(\"a\", \"b\", # 0\n                          \"a\", \"b\", # 25\n                          \"a\", \"b\", # 50\n                          \"a\", \"b\", # 75\n                          \"a\", \"a\")) # 100\n\n\n\n\nGráfico das médias dos híbridos em cada dose de nitrogênio.\n\n\n\n\n\nAjuste de regressão para cada híbrido\n\nNo exemplo anterior, apresentamos as médias dos híbridos em cada dose de nitrogênio. Agora, criaremos um gráfico com o grau do polinômio significativo ajustado de cada híbrido. O grau a ser ajustado deve ser identificado na saída da ANOVA . Para fins didáticos apresento as equações que serão utilizadas.\nNUPEC_1: modelo quadrático \\(y = 11,555 + 0,05575\\times x -0,0005574\\times x^2, R^2 = 0.999\\)\nNUPEC_2: modelo linear \\(y = 9,2054 + 0,0209\\times x, R^2 = 0.986\\)\nUtilizando uma equação, é possível estimar a produtividade para uma dose de nitrogênio específica não testada, desde que ela esteja dentro do intervalo estudado. Para isto, basta substituir o x na equação pela dose a ser testada. Por exemplo, para estimar qual seria a produtividade do híbrido NUPEC_2 se tivéssemos aplicado 60 kg de N ha\\(^{-1}\\) basta resolver: \\(y = 9,2054 + 0,0209\\times 60\\), resultando em \\(y \\approx 10.5\\) Mg ha\\(^{-1}\\). A interpretação deste resultado, no entanto, deve ser cautelosa. Inconscientemente, concluiríamos que a produtividade do híbrido aumentaria 0,0209 Mg ha\\(^{-1}\\) a cada kg de nitrogênio aplicado por hectare. Este fato, no entanto, não é observado na prática. Por exemplo, a produtividade não irá aumentar infinitamente a medida em que se aumenta a dose de nitrogênio aplicado. A única conclusão válida, neste caso, é que a produtividade aumenta linearmente até 100 kg de N ha\\(^{-1}\\). Este resultado se deu em virtude de as doses testadas não terem sido o suficiente para identificar um outro comportamento na variável testada. Nestes casos, indica-se para estudos futuros aumentar o número de doses. Quando não se conhece o intervalo de dose em que a variável em estudo apresenta uma resposta explicável, estudos pilotos podem ser realizados. Neste caso, testar-se-iam o mesmo número de tratamentos (número de doses), no entanto com um intervalo maior entre as doses (por exemplo, 0, 100, 200, 300 e 400 kg de N ha\\(^{-1}\\). Possivelmente, nesta amplitude, o comportamento da produtividade não seria linear, pois em uma determinada dose, a produtividade estabilizaria.\nO ponto em X (dose) em que a produtividade é máxima é chamado de máxima eficiência técnica (MET) e pode ser estimado por:\n\\[\nMET = \\frac{{ - {\\beta _1}}}{{2 \\times {\\beta _2}}}\n\\]\nSubstituindo com os parâmetros estimados, temos:\n\\[\nMET = \\frac{{ - 0,05575}}{{2 \\times  -0,0005574}} = 50\n\\]\n\nx_met <- -0.05575 / (2 * -0.0005574)\nx_met\n\n[1] 50.00897\n\n\nLogo, a dose que proporciona a máxima produtividade para o híbrido NUPEC_1 é aproximadamente 50 kg de N ha\\(^{-1}\\). Assim para sabermos qual é esta produtividade estimada, basta substituir o x da equação por 50, resultando em \\(y_{máx}\\) = 12,949 Mg ha\\(^{-1}\\).\n\ny_met <- 11.555 + 0.05575 * 50 - 0.0005574 * 50^2\n\nOutro ponto importante que é possível de estimar utilizando uma equação de segundo grau, é a máxima eficiência econômica (MEE), ou seja, a dose máxima, neste caso de nitrogênio, em que é possível aplicar obtendo-se lucro. Este ponto é importante, pois a partir de uma certa dose, os incrementos em produtividade não compensariam o preço pago pelo nitrogênio aplicado. Este ponto pode ser facilmente estimado por:\n\\[\nMEE = MET + \\frac{u}{{2 \\times \\beta_2 \\times m}}\n\\]\nonde u e m são os preços do nitrogênio e do milho em grão, respectivamente, na mesma unidade utilizada para a estimativa da equação (neste caso, preço do nitrogênio por kg e preço do milho por tonelada). Considerando o preço de custo do nitrogênio como R$ 5,00 por kg e o preço de venda do milho a R$ 1300,00 por tonelada, substituindo-se na formula obtém-se:\n\\[\nMEE = 50 + \\frac{{5}}{{2 \\times (-0,0005574) \\times 1300}} \\approx 46\n\\]\nAssim, a dose máxima de nitrogênio que em que os incrementos de produtividade são lucrativos é de \\(\\approx 48\\) Kg ha\\(^{-1}\\).\n\nx_mee <- x_met + (5 / (2 * -0.0005574 * 1300))\nx_mee\n\n[1] 46.55889\n\n# predito na mee\n\ny_mee <- 11.555 + 0.05575 * x_mee - 0.0005574 * x_mee^2\ny_mee\n\n[1] 12.94237\n\n\nSemelhante ao exemplo das médias nas doses de nitrogênio, utilizaremos a função plot_factlines() para plotar, agora, uma regressão ajustada para cada híbrido. Os argumentos a serem informados são os seguintes: .data, o conjunto de dados (neste caso FAT2_CI); x e y, as colunas dos dados correspondentes aos eixos x e y do gráfico, respectivamente; group a coluna que contém os níveis dos fatores em que as regressões serão ajustadas; fit um vetor de comprimento igual ao número de níveis da coluna informada em group. O número indicado em cada posição do vetor, corresponde ao grau do polinômio ajustado (máximo grau ajustado = 4). Em nosso exemplo, utilizaremos fit = c(2, 1) para ajustar uma regressão quadrática para o híbrido NUPEC_1 e uma regressão linear para o híbrido NUPEC_2.\n\nplot_factlines(FAT2_CI, DOSEN, RG,\n               group = HIBRIDO,\n               fit = c(2, 1)) +\n  # Linhas e ponto da MET\n  geom_segment(aes(x = x_met,\n                   y = y_met,\n                   xend = x_met,\n                   yend = 8.5),\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_segment(aes(x = 0,\n                   y = y_met,\n                   xend = x_met,\n                   yend = y_met),\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_point(aes(x = x_met, y = y_met), shape = 19, size = 3, color = \"blue\") +\n  # Linhas e ponto da MEE\n  geom_segment(aes(x = x_mee,\n                   y = y_mee,\n                   xend = x_mee,\n                   yend = 8.5),\n               linetype = 2,\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_segment(aes(x = 0,\n                   y = y_mee,\n                   xend = x_mee,\n                   yend = y_mee),\n               linetype = 2,\n               color = \"black\",\n               show.legend = FALSE) +\n  geom_point(aes(x = x_mee, y = y_mee), shape = 17, size = 3, color = \"blue\") +\n  # Equações no gráfico\n  geom_text(aes(0, 11,\n                label=(\n                  paste(\n                    expression(\"y = 11.555 + 0.05575x - 0.0005574x\"^2*\"  R\" ^2*\" = 0,999\"))\n                )\n  ),\n  hjust = 0,\n  size = 5,\n  col = \"black\",\n  parse = TRUE) + \n  geom_text(aes(0, 8.5,\n                label=(\n                  paste(\n                    expression(\"y = 9.2054 + 0.0209x R\" ^2*\" = 0,95\"))\n                )\n  ),\n  hjust = 0,\n  size = 5,\n  col = \"black\",\n  parse = TRUE) \n\n\n\n\nObservando-se a figura acima, é possível identificar o comportamento quadrático da variável resposta do híbrido NUPEC_1. Para este híbrido, houve um incremento positivo na produtividade até um ponto, posteriormente observa-se que a produtividade tendeu a reduzir. Uma explicação biológica para esta redução seria que o excesso de nitrogênio aplicado proporcionou um alto vigor vegetativo as plantas, podendo ter ocorrido competição entre as plantas por água, luz e outros nutrientes, ou até mesmo tombamento das plantas.\nFree website hit counter"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html",
    "href": "FIT5306/FIT5306_11_REG.html",
    "title": "11. Regressão e correlação",
    "section": "",
    "text": "library(tidyverse)\nlibrary(metan)      # estatísticas descritivas\nlibrary(rio)        # importação/exportação de dados\nlibrary(AgroR)\nlibrary(broom)"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#introdução",
    "href": "FIT5306/FIT5306_11_REG.html#introdução",
    "title": "11. Regressão e correlação",
    "section": "Introdução",
    "text": "Introdução\nA análise de regressão tem como objetivo verificar como uma variável independente (x) influencia a resposta de uma variável dependente (y). A análise de regressão é amplamente utilizada nas ciências agrárias. O modelo mais simples de regressão linear é a de primeiro grau, descrita conforme o modelo a seguir:\n\\[\nY_i = {\\beta _0} + {\\beta _1}x + \\varepsilon_i  \n\\]\nOnde \\(Y_i\\) é o valor observado da variável dependente no i-ésimo nível da variável independente; \\(x_i\\) é o valor do i-ésimo nível da variável independente, \\(\\beta_0\\) é o intercepto (valor que a reta predita intercepta o eixo y quando x é igual a zero); \\(\\beta_1\\) é a inclinação da reta (quantas unidades mudam em y a cada unidade alterada em x) e \\(\\varepsilon\\) é o desvio."
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#o-problema",
    "href": "FIT5306/FIT5306_11_REG.html#o-problema",
    "title": "11. Regressão e correlação",
    "section": "O problema",
    "text": "O problema\n\n\n\n\n\n\nNote\n\n\n\nNo seguinte exemplo é apresentado o valor do rendimento de grãos de um certo híbrido de milho (eixo y) em função da dose de N (eixo x).\n\nx <- seq(0, 150, by = 25)\ny <- c(8.6, 8.9, 9.5, 9.9, 10, 10.2, 10.5)\ndf <- data.frame(x = x, y = y)\n\n# plotar os valores\nggplot(df, aes(x, y)) +\n  geom_point(size = 4, color = \"red\") + \n  geom_smooth(se = FALSE, method = \"lm\") +\n  scale_x_continuous(breaks = x) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y= \"Rendimento de grãos (t/ha)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nO problema consiste em obter o valor de \\(\\beta_0\\) e \\(\\beta_1\\) de melhor ajuste para a equação, de modo que a soma de quadrado dos desvios (diferença entre os pontos observados e a reta de predição) seja mínima. Assim, adota-se o critério de obter a solução que minimiza soma dos quadrados dos resídulos (\\(\\sum\\nolimits_{i = 1}^n {{e_i}^2}\\)), método conhecido como Método dos Mínimos Quadrados\n\\[\n{b_1} = \\frac{{S{P_{xy}}}}{{S{Q_x}}}\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\n\\[\n{b_0} = \\bar y - {b_1} \\times \\bar x\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\nOnde\n\\[\nS{P_{xy}} = \\sum\\limits_{i = 1}^n {{x_i}{y_i}}  - \\frac{{\\left( {\\sum\\limits_{i = 1}^n {{x_i}} } \\right)\\left( {\\sum\\limits_{i = 1}^n {{y_i}} } \\right)}}{n}\n\\tag{1}\\]\n\\[\n\\\\S{Q_x} = \\sum\\limits_{i = 1}^n {x_i^2}  - \\frac{{{{\\left( {\\sum\\limits_{i = 1}^n {x_i^{}} } \\right)}^2}}}{n}\n\\tag{2}\\]\n\\[\n\\\\S{Q_y} = \\sum\\limits_{i = 1}^n {y_i^2}  - \\frac{{{{\\left( {\\sum\\limits_{i = 1}^n {y_i^{}} } \\right)}^2}}}{n}\n\\tag{3}\\]\nDe posse deste valor pode ser obtidas as somas de quadrados:\n\\[\nS{Q_{total}} = S{Q_y}\n\\]\n\\[\nS{Q_{reg}} = \\frac{{S{P_{xy}}^2}}{{S{Q_x}}}\n\\]\n\\[\nS{Q_{erro}} = S{Q_{total}} - S{Q_{reg}}\n\\]"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#estimação-dos-coeficientes",
    "href": "FIT5306/FIT5306_11_REG.html#estimação-dos-coeficientes",
    "title": "11. Regressão e correlação",
    "section": "Estimação dos coeficientes",
    "text": "Estimação dos coeficientes\nNo seguinte exemplo, são calculados as somas de x e y, as somas de \\(x^2\\) e \\(y^2\\) e também as somas de \\(x\\times y\\) .\n\ndf2 <- \n  mutate(df,\n         x2 = x ^ 2,\n         y2 = y ^ 2,\n         xy = x * y)\ndf2\n\n    x    y    x2     y2     xy\n1   0  8.6     0  73.96    0.0\n2  25  8.9   625  79.21  222.5\n3  50  9.5  2500  90.25  475.0\n4  75  9.9  5625  98.01  742.5\n5 100 10.0 10000 100.00 1000.0\n6 125 10.2 15625 104.04 1275.0\n7 150 10.5 22500 110.25 1575.0\n\n# número de pontos\n(n <- length(x))\n\n[1] 7\n\n# soma de xi\n(sum_xi <- sum(x))\n\n[1] 525\n\n# soma de xi ao quadrado\n(sum_xi2 <- sum(x ^ 2))\n\n[1] 56875\n\n# soma de yi\n(sum_yi <- sum(y))\n\n[1] 67.6\n\n# soma de yi ao quadrado\n(sum_yi2 <- sum(y ^ 2))\n\n[1] 655.72\n\n# soma de xi * yi\n(sum_xiyi <- sum(x * y))\n\n[1] 5290\n\n\nNote que estas mesmas somas podem ser obtidas facilmente utilizando duas outras abordagens. A primeira usando a função colSums() e outra a função apply().\n\ncolSums(df2)\n\n       x        y       x2       y2       xy \n  525.00    67.60 56875.00   655.72  5290.00 \n\napply(df2, 2, sum)\n\n       x        y       x2       y2       xy \n  525.00    67.60 56875.00   655.72  5290.00 \n\n\nDe posse destes valores é possível computar a soma de produtos de x e y , bem como suas somas de quadrados.\n\n# soma de produtos de X e Y\n(SPxy <- sum_xiyi - (sum_xi * sum_yi) / n)\n\n[1] 220\n\n# soma de quadrados de X\n(SQx <- sum_xi2 - (sum_xi ^2) / n)\n\n[1] 17500\n\n# soma de quadrados de Y\n(SQy <- sum_yi2 - (sum_yi ^ 2) / n)\n\n[1] 2.897143\n\n# computar o b1\n(b1 <- SPxy / SQx)\n\n[1] 0.01257143\n\n# computar o b0\n(b0 <- mean(y) - b1 * mean(x))\n\n[1] 8.714286"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#regressão-ajustada-e-tabela-anova",
    "href": "FIT5306/FIT5306_11_REG.html#regressão-ajustada-e-tabela-anova",
    "title": "11. Regressão e correlação",
    "section": "Regressão ajustada e tabela ANOVA",
    "text": "Regressão ajustada e tabela ANOVA\nA equação ajustada é então \\(y = 8,7142 + 0,01257x\\). As somas de quadrados de regressão e resídulo são dadas à seguir\n\n# soma de quadrado total\n(SQtot <- SQy)\n\n[1] 2.897143\n\n(SQreg <- SPxy ^ 2 / SQx)\n\n[1] 2.765714\n\n(SQerro <- SQtot - SQreg)\n\n[1] 0.1314286\n\n\nPode-se ainda obter a análise da variância da regressão, cujo esquema é apresentado a seguir na Tabela.\n\nFV <- c(\"Regressão\", \"Desvio\", \"Total\")\nGL <- c(1, n - 2, n - 1)\nSQ <- c(SQreg, SQerro, SQtot)\nQM <- SQ / GL\nFC <- c(QM[[1]] / QM[[3]], NA, NA)\ndata.frame(FV, GL, SQ, QM, FC) |> knitr::kable()\n\n\n\n\nFV\nGL\nSQ\nQM\nFC\n\n\n\n\nRegressão\n1\n2.7657143\n2.7657143\n5.727811\n\n\nDesvio\n5\n0.1314286\n0.0262857\nNA\n\n\nTotal\n6\n2.8971429\n0.4828571\nNA"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#grau-de-ajuste-do-modelo",
    "href": "FIT5306/FIT5306_11_REG.html#grau-de-ajuste-do-modelo",
    "title": "11. Regressão e correlação",
    "section": "Grau de ajuste do modelo",
    "text": "Grau de ajuste do modelo\nA proporção da variação de y que é explicada pelos níveis de x é conhecido como coeficiente de determinação (\\(R^2\\)) e é calculado por:\n\\[\nR^2 = \\frac{SQ_{reg}}{SQ_{tot}}\n\\]\n\n(R2 <- SQreg / SQtot)\n\n[1] 0.9546351\n\n\nPode-se ainda obter o (\\(R^2\\)) ajustado (\\(R^2_{adj}\\)) . O \\(R^2_{adj}\\) pode ser usado quando desejar comparar modelos que têm diferentes números de preditores. O (\\(R^2\\)) sempre aumenta quando você adiciona um preditor ao modelo, mesmo quando não existe uma verdadeira melhoria ao modelo. O valor de (\\(R^2_{adj}\\)) ajustado o número de preditores no modelo para ajudá-lo a escolher o modelo correto1, sendo calculado por:\n\\[\nR^2_{adj} = 1 -\\frac{(n - 1)(1 -  R^2)}{n - p}\n\\] Sendo que para a regressão linear simples estima-se 2 parâmetros (\\(\\beta_0\\) e \\(\\beta_1\\)).\n\nR2adj <- 1 - ((n - 1)*(1 - R2)) / (n - 2)\nR2adj\n\n[1] 0.9455621"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#valores-preditos-e-resíduos",
    "href": "FIT5306/FIT5306_11_REG.html#valores-preditos-e-resíduos",
    "title": "11. Regressão e correlação",
    "section": "Valores preditos e resíduos",
    "text": "Valores preditos e resíduos\nOs valores preditos são obtidos substituindo-se o x da equação pelo valor de x testado. Como o R trabalha de forma vetorizada, podemos facilmente obter os valores preditos para cada elemento de x com:\n\n(pred <- b0 + b1 * x)\n\n[1]  8.714286  9.028571  9.342857  9.657143  9.971429 10.285714 10.600000\n\n\nOs desvios são computados como a diferença entre o valor observado e o valor predito. Assim, pode calculá-los com:\n\n(desvios <- y - pred)\n\n[1] -0.11428571 -0.12857143  0.15714286  0.24285714  0.02857143 -0.08571429\n[7] -0.10000000\n\n\nFica fácil identificar estes desvios plotando-os no gráfico abaixo.\n\n# gráfico base\nggplot(df, aes(x, y)) +\n  geom_segment(aes(x = x,\n                   y = y,\n                   xend = x,\n                   yend = pred)) +\n  geom_point(size = 4, color = \"red\") + \n  geom_smooth(se = FALSE, method = \"lm\") +\n  scale_x_continuous(breaks = x) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y= \"Rendimento de grãos (t/ha)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nA soma de quadrado dos desvios obtida anteriormente pode ser obtida aqui também, ao somarmos o quadrado dos desvios.\n\nsum(desvios ^ 2)\n\n[1] 0.1314286"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#a-função-lm",
    "href": "FIT5306/FIT5306_11_REG.html#a-função-lm",
    "title": "11. Regressão e correlação",
    "section": "A função lm()",
    "text": "A função lm()\nNo R, a função lm() (linear model) pode ser utilizada para ajustar a equação linear. Para isso, utiliza-se uma fórmula to tipo y ~ x (ou seja, y em função de x). Note que y e x são os nomes das variáveis presentes no data frame, informado no argumento data.\n\n# ajustar modelo de regressão linear\nmod <- lm(y ~ x, data = df)\n\n# coeficientes\nsummary(mod)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n       1        2        3        4        5        6        7 \n-0.11429 -0.12857  0.15714  0.24286  0.02857 -0.08571 -0.10000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 8.714286   0.110472   78.88  6.2e-09 ***\nx           0.012571   0.001226   10.26 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1621 on 5 degrees of freedom\nMultiple R-squared:  0.9546,    Adjusted R-squared:  0.9456 \nF-statistic: 105.2 on 1 and 5 DF,  p-value: 0.0001513\n\n# Análise de variância\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: y\n          Df  Sum Sq Mean Sq F value    Pr(>F)    \nx          1 2.76571 2.76571  105.22 0.0001513 ***\nResiduals  5 0.13143 0.02629                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nConferindo os resultados\n\n\n\nCompare os valores obtidos no cálculo passo-a-passo com os valores dos coeficientes obtidos com a função summary(mod) e anova(mod). Os valores conferem?\n\n\nNo código abaixo é criado um novo conjunto de dados, contendo os valores preditos e os resíduos.\n\n# valores preditos\npred <- \n  df %>% \n  mutate(predito = predict(mod),\n         residual = y - predito)\npred\n\n    x    y   predito    residual\n1   0  8.6  8.714286 -0.11428571\n2  25  8.9  9.028571 -0.12857143\n3  50  9.5  9.342857  0.15714286\n4  75  9.9  9.657143  0.24285714\n5 100 10.0  9.971429  0.02857143\n6 125 10.2 10.285714 -0.08571429\n7 150 10.5 10.600000 -0.10000000\n\n\nOs valores preditos são obtidos ao substituir o x da equação pelo valor utilizado. Pode-se criar uma função para retornar os valores preditos utilizando um modelo ajustado e o valor de x desejado. No seguinte exemplo, o valor de y quando x é 75 é calculado e plotado no gráfico.\n\n# modelo ajustado o valor predito para x = 75\n# função auxiliar\npred_linear <- function(mod, x){\n  b0 <- coef(mod)[[1]]\n  b1 <- coef(mod)[[2]]\n  pred <- b0 + b1 * x\n  return(pred)\n}\n\npred_75 <- pred_linear(mod, 75)\npred_75\n\n[1] 9.657143\n\nggplot(df, aes(x, y)) +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  geom_segment(aes(x = 75, y = 8.5, xend = 75, yend = pred_75)) +\n  geom_segment(aes(x = 0, y = pred_75, xend = 75, yend = pred_75)) +\n  geom_point(aes(x = 75, y = pred_75), color = \"blue\", size = 4) +\n  geom_point(size = 4, color = \"red\") + \n  scale_x_continuous(breaks = x) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y= \"Rendimento de grãos (t/ha)\",\n       title = \"Reta predita para o modelo de regressão\",\n       subtitle = \"O ponto azul representa o RG predito com 75 kg/ha de N\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#regressão-linear-com-repetições",
    "href": "FIT5306/FIT5306_11_REG.html#regressão-linear-com-repetições",
    "title": "11. Regressão e correlação",
    "section": "Regressão linear com repetições",
    "text": "Regressão linear com repetições\n\nurl <- \"https://bit.ly/df_biostat\"\ndf_reg <- import(url, sheet = \"REG_DEL_DATA\", setclass = \"tbl\")\n\n\n# anova em DBC\ndf_factors <- df_reg %>% as_factor(1:2)\nanova <- aov(RG ~ DOSEN + BLOCO, data = df_factors)\ntidy(anova) %>% as.data.frame()\n\n       term df      sumsq     meansq statistic      p.value\n1     DOSEN  4 14.8617548 3.71543870  116.2335 1.737670e-09\n2     BLOCO  3  0.1568282 0.05227605    1.6354 2.333476e-01\n3 Residuals 12  0.3835836 0.03196530        NA           NA\n\n# regressão\nreg <- lm(RG ~ DOSEN, data = df_reg)\ntidy(reg) %>% as.data.frame()\n\n         term estimate   std.error statistic      p.value\n1 (Intercept) 8.434550 0.078237590 107.80687 9.383071e-27\n2       DOSEN 0.024222 0.001277614  18.95877 2.419233e-13\n\n# anova da regressão\nanova_reg <- aov(reg)\ntidy(anova_reg) %>% as.data.frame() %>% slice(1)\n\n   term df    sumsq   meansq statistic      p.value\n1 DOSEN  1 14.66763 14.66763   359.435 2.419233e-13\n\n# pontos plotados\nggplot(df_reg, aes(DOSEN, RG)) +\n  geom_point(color = \"red\") +\n  stat_summary(geom = \"point\",\n               fun = mean,\n               shape = 23) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y = \"Rendimento de grãos (t/ha)\") +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#polinômio-de-segundo-grau",
    "href": "FIT5306/FIT5306_11_REG.html#polinômio-de-segundo-grau",
    "title": "11. Regressão e correlação",
    "section": "Polinômio de segundo grau",
    "text": "Polinômio de segundo grau\nA regressão polinomial de segundo grau (que também é linear!) é uma outra opção muito útil para analisar dados que apresentem comportamento de parábola, por vezes observado em ensaios que testam dosagens de algum produto/fertilizante, etc. Neste tipo, um parâmetro a mais é adicionado ao modelo, ficando na forma:\n\\[\nY_i = {\\beta _0} + {\\beta _1}x + {\\beta _2}x^2 + \\varepsilon_i  \n\\]\nComo motivação, utilizaremos os dados abaixo. Para ajustar um modelo polinomial, utilizamos a função poly() e informamos o grau do polinômio desejado. É válido lembrar, que o grau máximo possível de polinômio é dado pelo número de níveis da variável independente/preditora menos 1.\n\nDOSEN <- c(0, 50, 100, 150, 200, 250)\nRG    <- c(7.1, 7.3, 7.66, 7.71, 7.62, 7.6)\ndf2 <- data.frame(DOSEN = DOSEN, RG = RG)\n\n# modelo de regressão\nmod2 <- lm(RG ~ poly(DOSEN, 2, raw = TRUE), data = df2)\nsummary(mod2)\n\n\nCall:\nlm(formula = RG ~ poly(DOSEN, 2, raw = TRUE), data = df2)\n\nResiduals:\n       1        2        3        4        5        6 \n 0.02500 -0.08243  0.07371  0.02343 -0.06329  0.02357 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  7.075e+00  7.013e-02 100.882 2.15e-06 ***\npoly(DOSEN, 2, raw = TRUE)1  7.184e-03  1.319e-03   5.445   0.0122 *  \npoly(DOSEN, 2, raw = TRUE)2 -2.071e-05  5.066e-06  -4.089   0.0264 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.07738 on 3 degrees of freedom\nMultiple R-squared:  0.9389,    Adjusted R-squared:  0.8982 \nF-statistic: 23.06 on 2 and 3 DF,  p-value: 0.0151\n\n# valores preditos\npred2 <- \n  df2 %>% \n  mutate(predito = predict(mod2),\n         residual = RG - predito)\npred2\n\n  DOSEN   RG  predito    residual\n1     0 7.10 7.075000  0.02500000\n2    50 7.30 7.382429 -0.08242857\n3   100 7.66 7.586286  0.07371429\n4   150 7.71 7.686571  0.02342857\n5   200 7.62 7.683286 -0.06328571\n6   250 7.60 7.576429  0.02357143\n\n# gráfico base\np1 <-\n  ggplot(df2, aes(DOSEN, RG)) +\n  geom_point(size = 4, color = \"red\") + \n  geom_smooth(se = FALSE,\n              method = \"lm\",\n              formula = y ~ poly(x, 2)) +\n  scale_x_continuous(breaks = DOSEN) +\n  labs(x = \"Dose de N (Kg/ha)\",\n       y = \"Rendimento de grãos (t/ha)\")\np1\n\n\n\n\nO ponto em X (dose de N) em que a produtividade é máxima é chamado de máxima eficiência técnica (MET) e pode ser estimado por:\n\\[\nMET = \\frac{{ - {\\beta _1}}}{{2 \\times {\\beta _2}}}\n\\]\nSubstituindo com os parâmetros estimados, temos:\n\\[\nMET = \\frac{{ - 0,007184}}{{2 \\times  -2,071^{-05}}} \\approx 173,4\n\\]\nNo R, podemos criar uma função auxiliar para calcular o ponto de MET.\n\n# máxima eficiência técnica\n# mod é o modelo quadrático ajustado\nmet <- function(mod){\n  b1 <- coef(mod)[[2]]\n  b2 <- coef(mod)[[3]]\n  res <- -b1 / (2 * b2)\n  return(res)\n}\n\nx_met <- met(mod2)\nx_met\n\n[1] 173.4138\n\n\nEm nosso exemplo, o ponto em x (dose de N) que proporciona o máximo rendimento predito é 173,413. Assim para sabermos qual é este rendimento estimado, basta substituir o x da equação por 173,4: \\(y = 7,075 + 0,007184\\times 173,413 -2,071^{-05}\\times 173,413^2 \\approx 7,70\\)\nUma função auxiliar para predição de y em um determinado valor de x considerando um modelo quadrático ajustado é fornecida abaixo.\n\n# valor predito para x = MET\n# função auxiliar\npred_quad <- function(mod, x){\n  b0 <- coef(mod)[[1]]\n  b1 <- coef(mod)[[2]]\n  b2 <- coef(mod)[[3]]\n  pred <- b0 + b1 * x + b2 * x ^ 2\n  return(pred)\n}\npred_met <- pred_quad(mod2, x = x_met)\npred_met\n\n[1] 7.697927\n\n\nOutro ponto importante que é possível de estimar utilizando uma equação de segundo grau, é a máxima eficiência econômica (MEE), ou seja, a dose máxima, neste caso de nitrogênio, em que é possível aplicar obtendo-se lucro. Este ponto é importante, pois a partir de uma certa dose, os incrementos em produtividade não compensariam o preço pago pelo nitrogênio aplicado. Este ponto pode ser facilmente estimado por:\n\\[\nMEE = MET + \\frac{u}{{2 \\times \\beta_2 \\times m}}\n\\]\nonde u e m são os preços do nitrogênio e do milho em grão, respectivamente, na mesma unidade utilizada para a estimativa da equação (neste caso, preço do nitrogênio por kg e preço do milho por tonelada). Considerando o preço de custo do nitrogênio como R 3 por kg e o preço de venda do milho a 1,300 por tonelada, substituindo-se na formula obtêm-se:\n\\[\nMEE = 173,41 + \\frac{{3,0}}{{2 \\times (-2,071^{-05}) \\times 1.300}} \\approx 117\n\\]\n\nmee <- function(mod, px, py){\n  x_met <- met(mod)\n  mee <- x_met + px / (2 * coef(mod)[[3]] * py)\n  return(mee)\n}\n\nx_mee <- mee(mod2, 3, 1300)\nx_mee\n\n[1] 117.7109\n\n\nAssim, a dose máxima de nitrogênio que em que os incrementos de produtividade são lucrativos é de \\(\\approx 117\\) Kg ha\\(^{-1}\\), em um rendimento estimado de \\(\\approx\\) 7,63 Mg ha\\(^{-1}\\).\n\n# Máxima eficiência econõmica (y)\nrg_mee <- pred_quad(mod2, x = x_mee)\nrg_mee\n\n[1] 7.633655\n\n\nDe posse das informações, um gráfico elaborado, que deveria ser apresentado em todo trabalho deste tipo pode ser confeccionado com a função plot_lines() do pacote metan combinado com algumas funções do pacote ggplot2. Sugiro a leitura do capítulo 8 deste material para mais informações sobre confecção de gráficos no R.\n\np1 +\n  labs(title = \"Equação quadrática\",\n       subtitle = \"Trigângulo e cículo representam os pontos de MME e MET, respectivamente\",\n       caption = \"MME = Máxima eficiência econômica\\n MET = máxima eficiência técnica\") +\n  # Linhas e ponto da MET\n  geom_segment(aes(x = x_met, y = pred_met, xend = x_met, yend = 6.7)) +\n  geom_segment(aes(x = 0, y = pred_met, xend = x_met, yend = pred_met)) +\n  geom_point(aes(x = x_met, y = pred_met), shape = 19, size = 3, color = \"blue\") +\n  # Linhas e ponto da MEE\n  geom_segment(aes(x = x_mee, y = rg_mee, xend = x_mee, yend = 6.7), linetype = 2) +\n  geom_segment(aes(x = 0, y = rg_mee, xend = x_mee, yend = rg_mee), linetype = 2) +\n  geom_point(aes(x = x_mee, y = rg_mee), shape = 17, size = 3, color = \"blue\") +\n  # Equação no gráfico\n  geom_text(aes(0, 7.9,\n                label=(\n                  paste(\n                    expression(\"y = 7.075 + 0.007184x - 2,071e\"^{-5}*\"x\"^2*\"  R\" ^2*\" = 0,938 \"))\n                )\n  ),\n  hjust = 0,\n  size = 5,\n  col = \"black\",\n  parse = TRUE)"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#exercício",
    "href": "FIT5306/FIT5306_11_REG.html#exercício",
    "title": "11. Regressão e correlação",
    "section": "Exercício",
    "text": "Exercício\n\nDados\n\nNeste exemplo, serão utilizados dados de produtividade de grãos de milho (Kg /ha) de acordo com diferentes doses de dejeto suíno (m3/ha) aplicadas na cultura do milho2.\n\n\nurl <- \"https://bit.ly/df_biostat\"\nreg_ex <- import(url, sheet = \"REG_EXERCICIO\", setclass = \"tbl\")\nreg_ex\n\n# A tibble: 4 × 2\n   DOSE    RG\n  <dbl> <dbl>\n1    20  7.09\n2    30  7.37\n3    40  8.28\n4    50  8.32\n\n\n\n\nCálculo dos coeficientes (manual)\n\nAjuste o modelo de regressão linear da forma \\(y_i = \\beta_0 + \\beta_1x_i\\), apresentando o valor dos parâmetros \\(\\beta_0\\) e \\(\\beta_1\\).\n\n\n(x <- reg_ex$DOSE)\n\n[1] 20 30 40 50\n\n(y <- reg_ex$RG)\n\n[1] 7.09 7.37 8.28 8.32\n\n# número de pontos\n(n <- length(x))\n\n[1] 4\n\n# médias\n(mx <- mean(x))\n\n[1] 35\n\n(my <- mean(y))\n\n[1] 7.765\n\n# soma de x\n(sumx <- sum(x))\n\n[1] 140\n\n# soma de y\n(sumy <- sum(y))\n\n[1] 31.06\n\n# soma de x * y\n(sumxy <- sum(x * y))\n\n[1] 1110.1\n\n# soma de x ao quadrado\n(sumx2 <- sum(x ^ 2))\n\n[1] 5400\n\n# soma de y ao quadrado\n(sumy2 <- sum(y ^ 2))\n\n[1] 242.3658\n\n# soma de produtos xy (SPxy)\n(SPxy <- sumxy - (sumx * sumy / n))\n\n[1] 23\n\n# soma de quadrados de x SQx\n(SQx <- sumx2 - sumx ^ 2 / n)\n\n[1] 500\n\n# soma de quadrados de y\n(SQy <- sumy2 - sumy ^ 2 / n)\n\n[1] 1.1849\n\n## coeficientes\n# b1\n(b1 <- SPxy / SQx)\n\n[1] 0.046\n\n# b0\n(b0 <- my - mx * b1)\n\n[1] 6.155\n\n# equação: y = 6150 + 6,15x\n\n\nInterprete o valor dos coeficientes, indicando sua aplicação prática.\n\n\n\n\n\n\n\nInterpretação dos coeficientes\n\n\n\nO intercept indica ….\no coeficiente angular…\n\n\n\nCalcule o valor do coeficiente de determinação (R2) do modelo ajustado e interprete os resultados\n\n\n################## SOMAS DE QUADRADOS DA REGRESSÃO E R2 ############\n\n# soma de quadrado total\n(SQtot <- SQy)\n\n[1] 1.1849\n\n# soma de quadrados da regressão\n(SQreg <- SPxy ^ 2 / (SQx))\n\n[1] 1.058\n\n# soma de quadrados do resíduo\n(SQres <- SQtot - SQreg)\n\n[1] 0.1269\n\n# coeficiente de determinação\n(R2 <- SQreg / SQtot)\n\n[1] 0.8929024\n\n\n\nRealize a predição da produtividade para uma dose de dejeto aplicado de 35 metros cúbicos por ha.\n\n\n# y predito com x = 35\n(yx35 <- b0 + b1 * 35)\n\n[1] 7.765\n\n\n\nAjuste a regressão no software R utilizando a função lm(). Após, construa um gráfico de dispersão com a reta de predição do modelo.\n\n\nreg <- lm(RG ~ DOSE, data = reg_ex)\n# coeficientes e R2\nsummary(reg)\n\n\nCall:\nlm(formula = RG ~ DOSE, data = reg_ex)\n\nResiduals:\n     1      2      3      4 \n 0.015 -0.165  0.285 -0.135 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  6.15500    0.41390  14.871  0.00449 **\nDOSE         0.04600    0.01126   4.083  0.05506 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2519 on 2 degrees of freedom\nMultiple R-squared:  0.8929,    Adjusted R-squared:  0.8394 \nF-statistic: 16.67 on 1 and 2 DF,  p-value: 0.05506\n\n# anova\nanova(reg)\n\nAnalysis of Variance Table\n\nResponse: RG\n          Df Sum Sq Mean Sq F value  Pr(>F)  \nDOSE       1 1.0580 1.05800  16.674 0.05506 .\nResiduals  2 0.1269 0.06345                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nGráfico\n\n\nMostrar código\nlibrary(ggpmisc) # adiciona a equação no gráfico\n\n\nWarning: package 'ggpmisc' was built under R version 4.2.2\n\n\nCarregando pacotes exigidos: ggpp\n\n\nWarning: package 'ggpp' was built under R version 4.2.1\n\n\n\nAttaching package: 'ggpp'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\n\nMostrar código\np1 <-\n  ggplot(reg_ex, aes(DOSE, RG)) +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  geom_point(size = 4, color = \"blue\") +\n  stat_poly_eq(formula = y ~ x,\n               aes(label = paste(..eq.label.., ..rr.label.., sep = \"~~~~\")),\n               coef.digits = 5) +\n  labs(x = expression(Doses~de~dejeto~(m^3~ha^{-1})),\n       y = expression(Rendimento~de~grãos~(t~ha^{-1})),\n       title = \"Rendimento de grãos em função da dose de dejeto\")\n\np2 <-\n  ggplot(reg_ex, aes(DOSE, RG)) +\n    geom_abline(intercept = b0,\n              slope = b1,\n              color = \"red\") +\n  geom_smooth(se = FALSE, method = \"lm\") +\n  geom_point(size = 4, color = \"blue\") +\n  stat_poly_eq(formula = y ~ x,\n               aes(label = paste(..eq.label.., ..rr.label.., sep = \"~~~~\")),\n               coef.digits = 5) +\n  labs(x = expression(Doses~de~dejeto~(m^3~ha^{-1})),\n       y = expression(Rendimento~de~grãos~(t~ha^{-1})),\n       title = expression(Compreendendo~o~intercept~(beta[0]))) +\n  scale_x_continuous(limits = c(0, 50),\n                     expand = expansion(c(0, 0.05))) +\n  scale_y_continuous(limits = c(6, 9),\n                     breaks = c(6, 6.155, 7, 8, 9)) +\n  theme(panel.grid.minor = element_blank())\n\np1 + p2\n\n\nWarning: The dot-dot notation (`..eq.label..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(eq.label)` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nValores preditos\nPara obter os valores preditos, precisamos considerar os parâmetros estimados da regressão linear, substituindo o x pelos valores observados de x. Felizmente, a vetorização proporcionada pelo R, nos facilita este procedimento, bastando realizar o seguinte comando\n\n(pred <- b0 + b1 * x)\n\n[1] 7.075 7.535 7.995 8.455\n\n\nOs valores preditos também podem ser obtidos com a função predict(), informando o modelo ajustado\n\n(pred2 <- predict(reg))\n\n    1     2     3     4 \n7.075 7.535 7.995 8.455 \n\n\n\n\nResiduais\nOs resíduos são obtidos pela diferença entre os valores observados e os preditos pelo modelo ajustado. Para isso, utilizamos o seguinte comando:\n\n(res <- y - pred)\n\n[1]  0.015 -0.165  0.285 -0.135\n\n# o mesmo com a função residuals()\n(res2 <- residuals(reg))\n\n     1      2      3      4 \n 0.015 -0.165  0.285 -0.135 \n\n\nApenas para fins de comprovação, observe que a soma de quadrado do resíduo obtida anteriormente pode ser calculada agora como:\n\n(sqres2 <- sum(res ^ 2))\n\n[1] 0.1269\n\n\nPor fim, é possível mutar o conjunto de dados incluindo os valores preditos e residuais.\n\nmutate(reg_ex,\n       predito = pred,\n       residual = res)\n\n# A tibble: 4 × 4\n   DOSE    RG predito residual\n  <dbl> <dbl>   <dbl>    <dbl>\n1    20  7.09    7.07   0.0150\n2    30  7.37    7.53  -0.165 \n3    40  8.28    7.99   0.285 \n4    50  8.32    8.45  -0.135"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#cálculo-do-coeficiente-de-correlação",
    "href": "FIT5306/FIT5306_11_REG.html#cálculo-do-coeficiente-de-correlação",
    "title": "11. Regressão e correlação",
    "section": "Cálculo do coeficiente de correlação",
    "text": "Cálculo do coeficiente de correlação\nUtilizando o método dos mínimos quadrados, a correlação entre duas variáveis (x e y) é dada por:\n\\[\nr = \\frac{SP_{xy}}{\\sqrt{SQ_x\\times SQ_y}}\n\\]\nAs definições de \\(SP_{xy}\\), \\(SQ_{x}\\) e \\(SQ_{y}\\) foram apresentadas nas Equações Equation 1, Equation 2 e Equation 3, respectivamente.\nA significância da correlação (r) é testada utilizando um teste t com \\(t_{\\alpha(n-2)}\\) graus liberdade. As hipóteses são:\n\\[\n{H_0}:r = 0\n\\]\n\\[\n{H_1}:r \\ne 0\n\\]\nO valor de t calculado é dado por:\n\\[\n{t_0} = r\\sqrt {\\frac{{n - 2}}{{1 - {r^2}}}}\n\\]\nPor fim, compara-se o t calculado com o tabelado ao nível \\(\\alpha\\) de significância de erro (teste bilateral), com n menos dois graus liberdade.\n\\[\n{t_0} > {t_{\\alpha (n - 2)}} = r \\ne 0\n\\]"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#a-função-cor-do-r",
    "href": "FIT5306/FIT5306_11_REG.html#a-função-cor-do-r",
    "title": "11. Regressão e correlação",
    "section": "A função cor() do R",
    "text": "A função cor() do R\nUtilizando a função do R cor() é possível obter o coeficiente de correlação entre duas variáveis, por exemplo, APLA e AIES do seguinte conjunto de dados:\n\nurl <- \"https://bit.ly/df_biostat\"\ndf_mat <- \n  import(url, sheet = \"maize\", setclass = \"tbl\") |> \n  select(APLA:MGRA)\n\n# correlação de pearson (APLA e AIES)\ncor(df_mat$APLA, df_mat$AIES)\n\n[1] 0.8407699\n\n\nUma matriz de correlação também pode ser calculada informando um data frame de variáveis numéricas\n\n# Matriz gráfica de correlação\ncor(df_mat)\n\n          APLA      AIES      CESP      DIES      MGRA\nAPLA 1.0000000 0.8407699 0.2349817 0.4693013 0.5096475\nAIES 0.8407699 1.0000000 0.2080551 0.4588893 0.4649353\nCESP 0.2349817 0.2080551 1.0000000 0.3985263 0.6763286\nDIES 0.4693013 0.4588893 0.3985263 1.0000000 0.7649486\nMGRA 0.5096475 0.4649353 0.6763286 0.7649486 1.0000000\n\n\nUsando a função corr_plot() do pacote metan, é possível obter uma matriz mista (gráfico e número), contendo a distribuição dos pontos e o coeficiente de correlação entre as variáveis.\n\n# Matriz gráfica de correlação\ncorr_plot(df_mat)"
  },
  {
    "objectID": "FIT5306/FIT5306_11_REG.html#exercício-1",
    "href": "FIT5306/FIT5306_11_REG.html#exercício-1",
    "title": "11. Regressão e correlação",
    "section": "Exercício",
    "text": "Exercício\n\nDados\n\nNeste exemplo, serão utilizados dados referentes ao número de grãos (NGRA) e massa de grãos (MGRA) observados em 15 espigas de milho (n = 15).\n\n\nurl <- \"https://bit.ly/df_biostat\"\ncor_ex <- import(url, sheet = \"COR_EXERCICIO\", setclass = \"tbl\")\n\n(x <- cor_ex$NGRA)\n\n [1] 519 522 624 670 518 547 670 546 444 611 557 702 443 430 481\n\n(y <- cor_ex$MGRA)\n\n [1] 173.5 213.5 221.1 261.5 220.1 177.8 250.8 192.0 193.5 255.6 245.9 207.4\n[13] 185.3 166.6 202.4\n\n(n <- length(x))\n\n[1] 15\n\n\n\n\nMétodo dos mínimos quadrados\n\n(xy <- x * y)\n\n [1]  90046.5 111447.0 137966.4 175205.0 114011.8  97256.6 168036.0 104832.0\n [9]  85914.0 156171.6 136966.3 145594.8  82087.9  71638.0  97354.4\n\n(x2 <- x ^ 2)\n\n [1] 269361 272484 389376 448900 268324 299209 448900 298116 197136 373321\n[11] 310249 492804 196249 184900 231361\n\n(y2 <- y ^ 2)\n\n [1] 30102.25 45582.25 48885.21 68382.25 48444.01 31612.84 62900.64 36864.00\n [9] 37442.25 65331.36 60466.81 43014.76 34336.09 27755.56 40965.76\n\n# soma de xy\n(somxy <- sum(xy))\n\n[1] 1774528\n\n# soma de x\n(somx <- sum(x))\n\n[1] 8284\n\n# soma de y\n(somy <- sum(y))\n\n[1] 3167\n\n# soma de x2\n(somx2 <- sum(x2))\n\n[1] 4680690\n\n# soma de y2\n(somy2 <- sum(y2))\n\n[1] 682086\n\n# adiciona as colunas nos dados originais usando mutate()\ncor_ex <-\n  mutate(cor_ex,\n         xy = xy,\n         x2 = x2,\n         y2 = y2)\ndata.frame(cor_ex)\n\n   NGRA  MGRA       xy     x2       y2\n1   519 173.5  90046.5 269361 30102.25\n2   522 213.5 111447.0 272484 45582.25\n3   624 221.1 137966.4 389376 48885.21\n4   670 261.5 175205.0 448900 68382.25\n5   518 220.1 114011.8 268324 48444.01\n6   547 177.8  97256.6 299209 31612.84\n7   670 250.8 168036.0 448900 62900.64\n8   546 192.0 104832.0 298116 36864.00\n9   444 193.5  85914.0 197136 37442.25\n10  611 255.6 156171.6 373321 65331.36\n11  557 245.9 136966.3 310249 60466.81\n12  702 207.4 145594.8 492804 43014.76\n13  443 185.3  82087.9 196249 34336.09\n14  430 166.6  71638.0 184900 27755.56\n15  481 202.4  97354.4 231361 40965.76\n\n# soma de produtos xy\n(sxy <- somxy - (somx * somy / n))\n\n[1] 25499.77\n\n# soma de quadrados de x\n(sx <- somx2 - somx ^ 2 / n)\n\n[1] 105712.9\n\n# soma de quadrados de y\n(sy <- somy2 - somy ^ 2 / n)\n\n[1] 13426.77\n\n# coeficiente de correlaçao\n(r <- sxy / (sqrt(sx * sy)))\n\n[1] 0.6768405\n\n# t calculado\n(tc <- r * sqrt((n - 2) / (1 - r ^ 2)))\n\n[1] 3.315153\n\n# t tabelado (cauda direita) = 2.16\n# como é bicaudal, considera-se 0.05 / 2\nqt(0.025, df = 13, lower.tail = FALSE)\n\n[1] 2.160369\n\n\n\n\nFunção cor e cor.test()\n\n# somente calcula o r\ncor(x, y)\n\n[1] 0.6768405\n\n# computa o r e realiza o teste de hipótese\ncor.test(x, y)\n\n\n    Pearson's product-moment correlation\n\ndata:  x and y\nt = 3.3152, df = 13, p-value = 0.005583\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2519252 0.8829624\nsample estimates:\n      cor \n0.6768405 \n\n\nFree website hit counter"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html",
    "href": "RGV410046/RGV410046_00_ABOUT.html",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "",
    "text": "Bem-vindo ao material de apoio da disciplina RGV410046 (Introdução à linguagem R de programação)! Esta página contém os dados e scripts R necessários para aplicação prática dos conteúdos vistos na disciplina."
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "21/11/2022",
    "text": "21/11/2022\n\nIntrodução à disciplina\nInstalação do R e Rstudio\nIntrodução ao R\n\nScript\nPacotes\nFóruns e materiais de apoio\n\nExercício (encontrar pacotes)"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section-1",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section-1",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "23/11/2022",
    "text": "23/11/2022\n\nDinâmica aula anterior\nTipos de dados\nNumérico\nLógico\nCaractere\nEstrutura de dados;\n\nVetor\nMatriz\nData frame\nTibbles\nArray\n\nLógica de programação\n\nBase\nTidyverse\n\nExercício (lógica de programação)"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section-2",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section-2",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "24/11/2022",
    "text": "24/11/2022\n\nImportação de dados (pc, repositório)\ndados tidy\nConversão de dados\nExercício descrição dos dados, arrumar tipo de dados\nExportação de dados"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section-3",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section-3",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "25/11/2022",
    "text": "25/11/2022\n\nManipulação de dados\nLonger (dados errados, para arrumar)\nWider\nSeparate\nUnite\nrename"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section-4",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section-4",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "28/11/2022",
    "text": "28/11/2022\n\nSeleção de dados\nselect\nfilter\nslice\narrange\n(dados próprios para o dia 1)"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section-5",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section-5",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "30/11/2022",
    "text": "30/11/2022\n\nMutação de dados\nmutate\nacross\ngroup_by"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section-6",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section-6",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "01/12/2022",
    "text": "01/12/2022\n\nResumo de dados\nsummarise\nacross\ngroup_by"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#section-7",
    "href": "RGV410046/RGV410046_00_ABOUT.html#section-7",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "02/12/2022",
    "text": "02/12/2022\n\no básico do ggplot2\nFechamento da disciplina"
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#código-fonte",
    "href": "RGV410046/RGV410046_00_ABOUT.html#código-fonte",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "Código fonte",
    "text": "Código fonte\nO código fonte deste material pode ser encontrado neste repositório GitHub. Para informar qualquer problema, por favor, crie um pull request."
  },
  {
    "objectID": "RGV410046/RGV410046_00_ABOUT.html#licença",
    "href": "RGV410046/RGV410046_00_ABOUT.html#licença",
    "title": "RGV410046 - Introdução à linguagem R de programação",
    "section": "Licença",
    "text": "Licença\nEste material é distribuído nos termos da licença CC BY-NC-SA 4.0\nO resumo legível da licença afirma que você tem o direito de:\n\nCompartilhar — copiar e redistribuir o material em qualquer suporte ou formato\nAdaptar — remixar, transformar, e criar a partir do material\nAtribuição — Você deve dar o crédito apropriado, prover um link para a licença e indicar se mudanças foram feitas. Você deve fazê-lo em qualquer circunstância razoável, mas de nenhuma maneira que sugira que o licenciante apoia você ou o seu uso.\nDe acordo com os termos seguintes\n\nNão Comercial — Você não pode usar o material para fins comerciais.\nCompartilhaIgual — Se você remixar, transformar, ou criar a partir do material, tem de distribuir as suas contribuições sob a mesma licença que o original.\nSem restrições adicionais — Você não pode aplicar termos jurídicos ou medidas de caráter tecnológico que restrinjam legalmente outros de fazerem algo que a licença permita.\n\n\nFree website hit counter"
  },
  {
    "objectID": "RGV410046/RGV410046_01_INTRO.html",
    "href": "RGV410046/RGV410046_01_INTRO.html",
    "title": "1. O software R",
    "section": "",
    "text": "O artigo R: A Language for Data Analysis and Graphics1, escrito pelos desenvolvedores da linguagem George Ross Ihaka e Robert Clifford Gentleman, marca o início de uma nova era no processamento e análise de dados: o desenvolvimento do software R.\n\n\n\nCriadores do 2\n\n\nO R é uma linguagem e ambiente estatístico que traz muitas vantagens para o usuário, embora elas não sejam tão obvias inicialmente:\n\nO R é um Software Livre (livre no sentido de liberdade) distribuído sob a Licença Pública Geral3, podendo ser livremente copiado, distribuído, e instalado em diversos computadores livremente. Isso contrasta com softwares comerciais, que têm licenças altamente restritivas, que não permitem que cópias sejam distribuídas ou instaladas em mais de um computador sem a devida licença (que obviamente é paga!);\nA grande maioria dos Softwares livres são grátis, e o R não é uma exceção;\nOs códigos-fontes R estão disponíveis para os usuários, e atualmente são gerenciados por um grupo chamado R Development Core Team4. A vantagem de ter o código aberto é que falhas podem ser detectadas e rapidamente corrigidas. Este sistema de revisão depende da participação dos usuários. Em contraste, em muitos pacotes comerciais, as falhas não são corrigidas até o lançamento da próxima versão, o que pode levar vários anos;\nO R fornece um interface de entrada por linha de comando (ELC).\n\nNo software R, todos os comandos são digitados e o mouse é pouco usado. Pode parecer antigo, pouco amigável ou até pobre em recursos visuais, mas isso faz com que nos deparemos com o melhor recurso do R: a sua flexibilidade. Para usuários familiarizados, a linguagem do R se torna clara e simples. Com poucos comandos, funções poderosas podem ser5 e o usuário é sempre consciente do que foi pedido através da ELC (Meus dados, minhas análises!). Isso contrasta com pacotes que possuem uma interface amigável (point-and-click), mas que escondem a dinâmica dos cálculos e, potencialmente, os seus erros. Finalmente, o R fornece uma ampla variedade de procedimentos estatísticos básicos ou que exigem grande esforço computacional (modelagem linear e não linear, testes estatísticos clássicos, análise de séries temporais, classificação, agrupamento, etc.) e recursos gráficos elegantes. Um dos pontos fortes de R é a facilidade com que gráficos de qualidade podem ser produzidos, incluindo símbolos matemáticos e fórmulas, quando necessário. O software R está disponível em uma ampla variedade de plataformas UNIX e sistemas similares (incluindo FreeBSD e Linux), Windows e MacOS."
  },
  {
    "objectID": "RGV410046/RGV410046_01_INTRO.html#meu-primeiro-script",
    "href": "RGV410046/RGV410046_01_INTRO.html#meu-primeiro-script",
    "title": "1. O software R",
    "section": "Meu primeiro script",
    "text": "Meu primeiro script\nO primero passo é criar um novo script, seguindo os seguintes passos: File > New File > R script ou utilizando o atalho Ctrl+Shift+N. Para salvar um script, devemos clicar no botão com o símbolo de disquete (R/RStudio), escolher o nome do arquivo e o diretório onde o arquivo será armazenado no seu computador. Algumas importantes dicas:\n\nEscolha sempre um nome sem caracteres especiais (ex., ç, ã, é, etc.)\nEscolha sempre um nome curto ou abreviado, que identifique a finalidade das linhas de comando escritas (ex., dftese)\nEvite espaços se o nome do arquivo for composto. Para isso, use um uderscore ‘_’(ex., df_tese)"
  },
  {
    "objectID": "RGV410046/RGV410046_01_INTRO.html#diretório-de-trabalho",
    "href": "RGV410046/RGV410046_01_INTRO.html#diretório-de-trabalho",
    "title": "1. O software R",
    "section": "Diretório de trabalho",
    "text": "Diretório de trabalho\nAntes de iniciar as análises, recomenda-se escolher um diretório onde devem estar os inputs (dados) e para onde serão enviados os outputs (gráficos, arquivos .txt, .xlsx, etc). Para selecionar o diretório, basta seguir o caminho Session > Set Working Directory > Choosing diretory ou utilizar as teclas de atalho Ctrl+Shift+H.\n\n\n\nSelecionando um diretório"
  },
  {
    "objectID": "RGV410046/RGV410046_01_INTRO.html#atribuições",
    "href": "RGV410046/RGV410046_01_INTRO.html#atribuições",
    "title": "1. O software R",
    "section": "Atribuições",
    "text": "Atribuições\nOs comandos elementares podem ser divididos em expressões e atribuições. Por exemplo, podemos estar interessados em resolver a seguinte expressão \\(10+15=25\\).\n\n10 + 15\n\n[1] 25\n\n\nNo console quando passamos pelo comando, o R avalia a função e retorna o resultado. Caso queiramos armazenar este resultado em algum objeto, usamos a atribuição <- (Alt + -) que é utilizada no formato objeto <- operacao. Considerano o mesmo caso anterior, um objeto soma é criado com\n\nsoma <- 10 + 15"
  },
  {
    "objectID": "RGV410046/RGV410046_01_INTRO.html#operadores-matemáticos",
    "href": "RGV410046/RGV410046_01_INTRO.html#operadores-matemáticos",
    "title": "1. O software R",
    "section": "Operadores matemáticos",
    "text": "Operadores matemáticos\nConhecendo estes comandos elementares, podemos passar para as operações matemáticas mais utilizadas e que são cruciais na linguagem de programação. No R, estas operações são baseadas em símbolos ou funções que se assemelham à maioria dos outros softwares estatísticos.\n\n1 + 1 # Soma\n\n[1] 2\n\n2 - 1 # Subtração\n\n[1] 1\n\n2 * 2 # Multiplicação\n\n[1] 4\n\n1 + 2 * 2 ^ 2 # Eleva ao quadrado, multiplica e soma\n\n[1] 9\n\n((1 + 2) * 2) ^ 2 # Soma, multiplica e eleva ao quadrado\n\n[1] 36\n\nsqrt(4) # Raiz quadrada\n\n[1] 2\n\n4^2 # Potência\n\n[1] 16\n\nlog(10) # Por default, o logarítimo é de base e (logarítimo natural)\n\n[1] 2.302585\n\nlog(100, 10) # Logarítimo de base 10\n\n[1] 2\n\nexp(100) # exponencial\n\n[1] 2.688117e+43"
  },
  {
    "objectID": "RGV410046/RGV410046_01_INTRO.html#álgebra-de-matrizes",
    "href": "RGV410046/RGV410046_01_INTRO.html#álgebra-de-matrizes",
    "title": "1. O software R",
    "section": "Álgebra de matrizes",
    "text": "Álgebra de matrizes\nPara multiplicação de matrizes utiliza-se %*% ao envéz de *. Note a diferença no exemplo abaixo.\n\n(x <- matrix(1:4, ncol = 2))\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n(y <- matrix(5:8, ncol = 2))\n\n     [,1] [,2]\n[1,]    5    7\n[2,]    6    8\n\n\nO resultado da multiplicação da matriz x e y é dado por:\n\\[\n    \\left( {\\begin{array}{*{20}{c}}{1 \\cdot 5 + 3 \\cdot 6}&{1 \\cdot 7 + 3 \\cdot 8}\\\\{2 \\cdot 5 + 4 \\cdot 6}&{2 \\cdot 7 + 4 \\cdot 8}\\end{array}} \\right) = \\left( {\\begin{array}{*{20}{c}}{23}&{31}\\\\{34}&{46}\\end{array}} \\right)\n\\]\n\nx * y # Errado\n\n     [,1] [,2]\n[1,]    5   21\n[2,]   12   32\n\nx %*% y # Certo\n\n     [,1] [,2]\n[1,]   23   31\n[2,]   34   46\n\n\nA função t() é utilizada para transposição de matrizes e solve() para inversão de matrizes. Vamos resolver o seguinte sistema de equações utilizando estes operadores.\n\\[\n\\begin{array}{l}{x_1} + 2{x_2} = 4\\\\{x_1} - {x_2} = 1\\end{array}\n\\]\nMatricialmente o sistema acima é dado por:\n\\[\n\\left[ {\\begin{array}{*{20}{c}}{\\begin{array}{*{20}{l}}1\\\\1\\end{array}}&{\\begin{array}{*{20}{c}}2\\\\{ - 1}\\end{array}}\\end{array}} \\right]\\left[ {\\begin{array}{*{20}{c}}{{x_1}}\\\\{{x_2}}\\end{array}} \\right] = \\left[ {\\begin{array}{*{20}{c}}4\\\\1\\end{array}} \\right]\n\\]\nEsse sistema de equações é representado por \\({\\bf{AX}} = {\\bf{c}}\\) e tem como solução \\({\\bf{X = }}{{\\bf{A}}^{{\\bf{ - 1}}}}{\\bf{c}}\\)\n\n(A <- matrix(c(1, 1, 2, -1), ncol = 2))\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    1   -1\n\n# Transposta de A\nt(A)\n\n     [,1] [,2]\n[1,]    1    1\n[2,]    2   -1\n\n# resolução do sistema de equações\n(Ainv <- solve(A)) # Obtém a inversa generalizada de A\n\n          [,1]       [,2]\n[1,] 0.3333333  0.6666667\n[2,] 0.3333333 -0.3333333\n\n(c <- c(4, 1)) # Vetor C\n\n[1] 4 1\n\n(X <- Ainv %*% c)\n\n     [,1]\n[1,]    2\n[2,]    1\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote que o mesmo resultado anterior pode ser obtido sem a necessidade de atribuição, ao declarar todas as operações em um único comando\n\nsolve(matrix(c(1, 1, 2, -1), ncol = 2)) %*% c(4, 1)\n\n     [,1]\n[1,]    2\n[2,]    1\n\n\n\n\nA função det() é utilizada para calcular o determinante de uma matriz e função eigen() para calcular calcular autovalores e autovetores\n\n(X <- matrix(c(1, 2, 5, 3, 4, 5, 6, 1, 9), ncol = 3))\n\n     [,1] [,2] [,3]\n[1,]    1    3    6\n[2,]    2    4    1\n[3,]    5    5    9\n\n(detX <- det(X))\n\n[1] -68\n\n\n\n(av <- eigen(X))\n\neigen() decomposition\n$values\n[1] 12.980067  2.854933 -1.835000\n\n$vectors\n           [,1]       [,2]       [,3]\n[1,] -0.4785227  0.2342735 -0.9165278\n[2,] -0.2017392 -0.8386325  0.2624173\n[3,] -0.8545861  0.4917432  0.3018507\n\nav$values # Extrai os autovalores\n\n[1] 12.980067  2.854933 -1.835000\n\n\n\nav$vectors # Extrai os autovetores\n\n           [,1]       [,2]       [,3]\n[1,] -0.4785227  0.2342735 -0.9165278\n[2,] -0.2017392 -0.8386325  0.2624173\n[3,] -0.8545861  0.4917432  0.3018507\n\n\nA função diag() extrai a diagonal de uma matriz ou cria uma matriz onde a diagonal são os elementos declarados. Os próximos comandos extraem a diagonal de X e criam uma matriz identidade, com 3 linhas e 3 colunas.\n\ndiag(X)\n\n[1] 1 4 9\n\ndiag(x = 1, nrow = 3, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1"
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html",
    "title": "2. Introdução à programação R",
    "section": "",
    "text": "Neste material, serão vistos conceitos importantes envolvidos na programação R que envolvem o conhecimento dos tipos de objetos, estruturas de dados e lógica de programação."
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#estuturas-de-dados",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#estuturas-de-dados",
    "title": "2. Introdução à programação R",
    "section": "Estuturas de dados",
    "text": "Estuturas de dados\nExistem quatro tipos principais de estruturas de dados, que podem ser interpretadas como: logical, integer, double e character (que contém cadeias de caracteres). Vetores do tipo integer e double são conhecidos como vetores numéricos. Cada um dos quatro tipos primários possui uma sintaxe especial para criar um valor individual, um escalar. A função c() combina valores que formam vetores1. Abaixo, é demonstrado como vetores podem ser criados utilizando c(). Note que o código é dado entre parênteses (...) para que o valor seja armazenado no ambiente ao mesmo tempo em que é impresso no console.\n\nVetores do tipo double\nVetores do tipo double podem ser especificadas em formato decimal (0.1234) ou científico (1.23e4).\n\n(x1 <- 1) # Escalar \n\n[1] 1\n\n(x2 <- c(1, 2, 3.5)) # Vetor\n\n[1] 1.0 2.0 3.5\n\ntypeof(x2)\n\n[1] \"double\"\n\n\n\n\nVetores do tipo integer\nVetores do tipo integer são escritos de forma semelhante aos double, mas devem ser seguidos por L (1234L, 1e4L ou 0xcafeL) e não podem conter valores fracionados.\n\n(x3 <- c(1L,2L,3L)) # Vetor\n\n[1] 1 2 3\n\ntypeof(x3)\n\n[1] \"integer\"\n\n\n\n\nVetores do tipo character\nVetores do tipo character são cercadas por ” e contém texto, tais como (\"dia\") ou ’ ('noite').\n\n(x4 <- c(\"um\",\"dois\",\"três\")) # Vetor com caracteres\n\n[1] \"um\"   \"dois\" \"três\"\n\ntypeof(x4)\n\n[1] \"character\"\n\n\n\n\nVetores do tipo logical\nVetores do tipo logical podem ser escritos por extenso (TRUE ou FASLSE) ou abreviados (T ou F).\n\n(x5 <- c(TRUE, FALSE)) # Vetor logical\n\n[1]  TRUE FALSE\n\ntypeof(x5)\n\n[1] \"logical\"\n\n\n\n\n\nOs vetores foram armazenados em x1, x2, x3 e x4 e ficaram armazenados como valores na área de trabalho como valores (values). Para que os valores sejam mostrados basta digitar no console onde os vetores foram armazenados. Vetores também podem ser criados utilizando as funções rep() e seq(), conforme mostrado abaixo.\n\n(x6 <- rep(5, 10))\n\n [1] 5 5 5 5 5 5 5 5 5 5\n\n(x7 <- seq(1, 5))\n\n[1] 1 2 3 4 5\n\n(x8 <- seq(1, 5, by = 0.5))\n\n[1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\n(x9 <- seq(2, 20, by = 2))\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n\nAgora, objserve o seu ambiente de trabalho. Lá você pode ver os objetos que foram criados.\n\nVocÇe também pode ser combinar as funções c(), rep() e seq() para criar vetores mais complexos, como mostrado abaixo.\n\nrep(c(1, 3, 6), each = 4)     # repete números de uma sequência\n\n [1] 1 1 1 1 3 3 3 3 6 6 6 6\n\nseq(1:5)                      # cria uma sequência\n\n[1] 1 2 3 4 5\n\nrep(seq(1:5), length.out= 15) # define o tamanho da saída\n\n [1] 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n\n\nUtilizando colchtes [] é possível selecionar um (ou um conjunto) de elementos de um vetor. Por exemplo:\n\nx8[1]            # Seleciona o primeiro elemento do vetor \n\n[1] 1\n\nx8[4]            #  Seleciona o quarto elemento do vetor \n\n[1] 2.5\n\nx8[c(1, 4, 8)]   # Seleciona o primeiro, o quarto e o oitavo elemento\n\n[1] 1.0 2.5 4.5\n\nx8[1:4]          # armazena uma sequência de elementos (primeiro ao quarto)\n\n[1] 1.0 1.5 2.0 2.5\n\n\nEm adição ao uso de [], as funções first(), last() e nth() do pacote dplyr são utilizadas para selecionar o primeiro, o último e o i-ésimo elemento de um vetor. A principal vantagem é que você pode fornecer um vetor secundário opcional que define a ordem e fornecer um valor padrão a ser usado quando a entrada for menor que o esperado.\n\nx <- runif(100, 0, 100)\nlibrary(tidyverse)\nfirst(x)\n\n[1] 32.50094\n\nlast(x)\n\n[1] 72.24972\n\nnth(x, 23)\n\n[1] 50.49352\n\n\n\n\n\n\n\n\nUsamos <- ou = para associação de nomes a objetos?\n\n\n\nMuitos usuários utilizam o símbolo da igualdade “=” para associarmos nomes aos objetos, algo que o ambiente R compreenderá. Contudo, o uso da igualdade deverá em R ser usado apenas para a utilização em argumentos de uma função e não para associação de nomes a objetos. Para mais detalhes, execute o comando ?assignOps."
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#matrizes",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#matrizes",
    "title": "2. Introdução à programação R",
    "section": "Matrizes",
    "text": "Matrizes\nAs matrizes são um conjunto de valores (ou variáveis) dispostos em linhas e colunas, e que formam um corpo delimitado por [ ]. As matrizes são geralmente representadas genericamente por \\({{\\boldsymbol{A}}_{{\\boldsymbol{MxN}}}}\\), onde M e N represetam os números de linhas e colunas da matriz, respectivamente. As matrizes podem ser facilmente construídas utilizando a função matrix(). Alternativamente, as funções cbind() e rbind() também podem ser utilizadas. A primeira função adiciona colunas as matrizes, enquanto que a segunda adiciona linhas. Veremos mais tarde que estas funções podem ser combinadas com outras funções para construção de dataframes.\n\n## Usando cbind()\ncbind(c(1,2,3,4,5))                # Uma coluna com 5 elementos cada \n\n     [,1]\n[1,]    1\n[2,]    2\n[3,]    3\n[4,]    4\n[5,]    5\n\ncbind(c(1,2,3,4,5),c(6,7,8,9,10))  # 2 colunas de 5 elementos\n\n     [,1] [,2]\n[1,]    1    6\n[2,]    2    7\n[3,]    3    8\n[4,]    4    9\n[5,]    5   10\n\n\n\n## Usando rbind()\nrbind(c(1,2,3,4,5)) # 1 linha com 5 elementos cada\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    2    3    4    5\n\nrbind(c(1,2,3,4,5),c(6,7,8,9,10)) # 2 linhas com 5 elementos cada\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    2    3    4    5\n[2,]    6    7    8    9   10\n\n\nCom a função matrix() podemos podemos criar matrizes. Para isso, alguns argumentos devem ser declarados. Na função matrix(data = NA, nrow = 1, ncol = 1, byrow = FALSE,dimnames = NULL), os argumentos que devemos inicialmente conhecer são o nrow, ncol e byrow. O primeiro indica o número de linhas da matriz, o segundo a número de colunas e o terceiro indica como a matriz é preenchida. Por default, byrow é FALSE, indicando que as matrizes são preenchidas por colunas. Se TRUE, o preenchimento ocorre por linhas.\n\n## Usando matrix\n(x9 <- matrix(1:15, nrow = 5, ncol = 3))\n\n     [,1] [,2] [,3]\n[1,]    1    6   11\n[2,]    2    7   12\n[3,]    3    8   13\n[4,]    4    9   14\n[5,]    5   10   15\n\nclass(x9)\n\n[1] \"matrix\" \"array\" \n\ntypeof(x9)\n\n[1] \"integer\"\n\n(x10 <- matrix(1:15, nrow = 5, ncol = 3, byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n[4,]   10   11   12\n[5,]   13   14   15\n\n\nPara selecionar elementos, linhas e colunas da matriz com [ ] utiliza-se um sistema de coordenadas:\n\nx9[2, 3] # seleciona o elemento que está na linha 2 e coluna 3\n\n[1] 12\n\nx9[, 2] # \",\" indica que todas as linhas serão selecionadas na coluna 2\n\n[1]  6  7  8  9 10\n\nx9[1, ] # \",\" indica que todas as colunas serão selecionadas na linha 1\n\n[1]  1  6 11\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote que matrizes ficam armazenadas no ambiente glogal em “Data”, não “Values”."
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#data-frame",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#data-frame",
    "title": "2. Introdução à programação R",
    "section": "Data Frame",
    "text": "Data Frame\nA função data.frame() cria estruturas cujas colunas podem ser valores numéricos ou caracteres. É uma estrutura muito utilizada em funções do software R.\n\nx10 <- data.frame(arvore = paste0(\"O\", 1:5),\n                  altura = c(4, 4.6, 3.8, 5, 4.1))\nclass(x10)\n\n[1] \"data.frame\"\n\nprint(x10)\n\n  arvore altura\n1     O1    4.0\n2     O2    4.6\n3     O3    3.8\n4     O4    5.0\n5     O5    4.1\n\n# o mesmo sistema de coordenadas pode ser utilizado com data.frames\nx10[1, ]\n\n  arvore altura\n1     O1      4"
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#tibbles",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#tibbles",
    "title": "2. Introdução à programação R",
    "section": "Tibbles",
    "text": "Tibbles\nUm tibble ou tbl_df, é uma versão moderna do data.frame. Tibbles são datas frames que não alteram nomes ou tipos de variáveis, possuindo um método print() aprimorado, que facilita o uso com grandes conjuntos de dados contendo objetos complexos. Você pode forçar um objeto de classe data.frame a um de classe tibble utilizando as_tibble() ou criar um a partir de vetores individuais com tibble(). A função tibble(), diferente de data.frame() permite que você se refira às variáveis que você acabou de criar. É possível, também, que um tibble tenha nomes de colunas que não sejam nomes de variáveis R válidos. Por exemplo, elas podem não começar com uma letra ou podem conter caracteres incomuns como um espaço. Para se referir a essas variáveis, você precisa cercá-las com ` `. Neste documento, a estrutura de dados padrão a ser utilizada será tibble.\n\n# Convertendo um dataframe a um tibble\ntbl_x10 <- as_tibble(x10)\nclass(tbl_x10)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nprint(tbl_x10)\n\n# A tibble: 5 × 2\n  arvore altura\n  <chr>   <dbl>\n1 O1        4  \n2 O2        4.6\n3 O3        3.8\n4 O4        5  \n5 O5        4.1\n\n\n\n# Tentando criar um dataframe\ndata.frame(x = 1:5,\n           y = 2:6,\n           z = x ^ 2 + y)\n\n\n# Criando um tibble\ntib1 <- \n  tibble(x = 1:5,\n         y = 2:6,\n         z = x ^ 2 + y)\n\ntib1[, 1]\n\n# A tibble: 5 × 1\n      x\n  <int>\n1     1\n2     2\n3     3\n4     4\n5     5"
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#lista",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#lista",
    "title": "2. Introdução à programação R",
    "section": "Lista",
    "text": "Lista\nNo exemplo abaixo, será armazenado em uma lista um objeto de cada class. Posteriomente, será selecionado o terceiro objeto\n\nlist1 <- list(x2, x9, x10)\nlist1[[3]]\n\n  arvore altura\n1     O1    4.0\n2     O2    4.6\n3     O3    3.8\n4     O4    5.0\n5     O5    4.1"
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#funções",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#funções",
    "title": "2. Introdução à programação R",
    "section": "Funções",
    "text": "Funções\nUma das melhores maneiras de tornar o código mais eficiente é escrever funções. As funções são a base da linguagem R. Através de argumentos que são indicados em funtion(), uma expressão (ou série de expressões) é resolvida e um valor (ou um conjunto de valores) é retornado. As funções permitem automatizar tarefas comuns de uma maneira mais poderosa e geral do que ‘copiar e colar’. Escrever uma função tem três grandes vantagens sobre o uso de copiar e colar:\n\nVocê pode dar a uma função um nome evocativo que torne seu código mais fácil de entender.\nÀ medida que os requisitos mudam, você só precisa atualizar o código em um local, em vez de vários.\nVocê elimina a chance de cometer erros acidentais ao copiar e colar (ex., atualizar um nome de variável em um local, mas não em outro).\n\nConsidere escrever uma função sempre que ‘copiar e colar’ um bloco de código mais de duas vezes. Quando uma função é armazenada no ambiente de trabalho, basta digitar o nome como o qual aquela função foi gravada. Os argumentos podem ser inseridos na ordem em que aparecem na função, sem especificar a qual argumento aquele valor pertence. No caso em que a inserção dos argumentos é diferente da ordem em que aparecem na função, é preciso identificar a qual argumento aquele valor pertente. Note que é possível combinar valores numéricos e texto como argumentos e/ou resultados de funções. Veja alguns exemplos.\n\n# EXEMPLO 1:\n# resolve a função 2x+1\n\nfun1 <- function(x){  # x é o único argumento da função\n  a <- 2 * x + 1\n  return(a) # retorna a\n}\nfun1(2)\n\n[1] 5\n\nfun1(x = 2) # explicita o ragumento\n\n[1] 5\n\n# EXEMPLO 2\n# função para elevar ao quadrado ou cubo\n# inclui condicionantes\nelevar <- function(x, eleva = \"quadrado\"){\n  if(!eleva %in% c(\"quadrado\", \"cubo\")){\n    stop(\"O argumento eleva = \",eleva, \" deve ser ou 'quadrado' ou 'cubo'\")\n  }\n  if(eleva == \"quadrado\"){\n    valor <- ifelse(x^2 >= 1000,\n                    paste(\"O resultado (\",x^2,\") tem mais que 3 dígitos\"),\n                    paste(\"O resultado (\",x^2,\") tem menos que 3 dígitos\"))\n  }\n  if(eleva == \"cubo\"){\n    valor <- ifelse(x^3 >= 1000,\n                    paste(\"O resultado (\",x^3,\") tem mais que 3 dígitos\"),\n                    paste(\"O resultado (\",x^3,\") tem menos que 3 dígitos\"))\n  }\n  \n  return(valor)\n}\n\nelevar(2)                       # usa o valor dos argumentos \n\n[1] \"O resultado ( 4 ) tem menos que 3 dígitos\"\n\nelevar(3, \"cubo\")               # argumentos na sequência que eles aparecem\n\n[1] \"O resultado ( 27 ) tem menos que 3 dígitos\"\n\nelevar(eleva = \"cubo\", x = 15)  # mudar a ordem dos argumentos\n\n[1] \"O resultado ( 3375 ) tem mais que 3 dígitos\"\n\n# EXEMPLO 3: fórmula de Bháskara\n# Encontrar as raízes de uma equação de segundo grau\n# Plotar a curva\nbhaskara <- function(a, b, c, plot = TRUE){ \n  # argumentos a, b e c são \n  dentro_raiz <- b^2 - 4 * a * c\n  if(dentro_raiz < 0){\n    stop(\"Sem solução real\")\n  }\n  delta <- sqrt(dentro_raiz)\n  x1 <- (-b + delta) / (2 * a)\n  x2 <- (-b - delta) / (2 * a)\n  minx <- min(x1, x2)\n  min_exp <- ifelse(minx < 0, minx + minx * 0.2, minx - minx * 0.2)\n  maxx <- max(x1, x2)\n  \n  # checa se precisa plotar\n  if(isTRUE(plot)){\n    # plot.new()\n    # curva\n    curve(a * x^2 + b * x + c, \n          xlim = c(min_exp,\n                   maxx + maxx * 0.2))\n    # pontos nas raízes\n    points(x = c(x1, x2),\n           y = c(0, 0),\n           col = \"black\",\n           pch = 19)\n    # linha no zero\n    abline(h=0, lty=2)\n  }\n  \n  # calcula o x e y do vértice\n  x_vert <- round(-b / (2*a), 3)\n  print(paste0(\"x: \", x_vert))\n  y_vert <- round(a * x_vert^2 + b * x_vert + c , 3)\n  print(paste0(\"y: \", y_vert))\n  \n  # plota os pontos do vértice\n  points(x = x_vert,\n         y = y_vert,\n         col = \"red\",\n         pch = 19)\n  # retorna as raízes\n  print(paste0(\"Raízes: S{\", x1, \";\", x2, \"}\"))\n}\n\nbhaskara(1, -2, -3)\n\n\n\n\n[1] \"x: 1\"\n[1] \"y: -4\"\n[1] \"Raízes: S{3;-1}\"\n\nbhaskara(-1, 4, -3)\n\n\n\n\n[1] \"x: 2\"\n[1] \"y: 1\"\n[1] \"Raízes: S{1;3}\""
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#operador-pipe",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#operador-pipe",
    "title": "2. Introdução à programação R",
    "section": "Operador pipe",
    "text": "Operador pipe\nPipes são uma ferramenta poderosa para expressar claramente uma sequência de várias operações. Em resumo, o operador pipe fornece o resultado do lado esquerdo (LHS) do operador como o primeiro argumento do lado direito (RHS). O pipe %>% vem do pacote magrittr e faz parte da família de pacotes tidyverse, que serão explorados no decorrer deste material. O objetivo do pipe é ajudá-lo a escrever código de uma maneira que seja mais fácil de ler e entender. A partir da versão 4.1.0, o R contém um pipe nativo |>. Sutis diferenças são observadas, mas não é nosso objetivo aqui entrar neste universo. Para maiores detalhes veja o vídeo abaixo.\n\nVocê consegue habilitar o pipe nativo no Rstudio, indo em Tools > Global Options > Code e selecionar a caixa indicada abaixo.\n\nPara ver por que o pipe é tão útil, vamos explorar algumas maneiras de escrever o mesmo código. Para isso, considere as seguintes (e simples) operações.\n\n\nCrie uma função que computa o quadrado do desvio de cada termo em relação à média.\nCrie um vetor com 10 dados aleatórios de uma distribuição normal com média 10 e desvio padrão 2, utilizando rnorm().\nEleve o vetor numérico ao quadrado\nSome os valores\ndivida por n - 1\nArmazene no objeto var_amo\n\n\n\n# função para computar o quadrado dos desvios\nquadrado_desvio <- function(x){\n  (x - mean(x))^2\n}\n\n\nset.seed(1) # garante reprodutibilidade\n(x <- rnorm(n = 10, mean = 10, sd = 2))\n\n [1]  8.747092 10.367287  8.328743 13.190562 10.659016  8.359063 10.974858\n [8] 11.476649 11.151563  9.389223\n\n(quad_desv <- quadrado_desvio(x))\n\n [1] 2.30223930 0.01058452 3.74679043 8.56238918 0.15571704 3.63032940\n [7] 0.50474281 1.46953515 0.78704779 0.76594412\n\n(soma_quad_desv <- sum(quad_desv))\n\n[1] 21.93532\n\n(var_amo <- sum(soma_quad_desv) / 9)\n\n[1] 2.437258\n\n\nNote que a mesma operação pode ser realizada se você aninhar as funções.\n\n(var_amo <- sum(sum(quadrado_desvio(x))) / 9)\n\n[1] 2.437258\n\n\nAgora, utilizando o pipe, note como o código fica muito mais claro, pois as indicações são feitas na ordem em que elas precisam ser executadas.\n\nvar_amo <- \n  x |> \n  quadrado_desvio() |> \n  sum() / 9\nvar_amo\n\n[1] 2.437258\n\n\n\n\n\n\n\n\nTip\n\n\n\nSe você ainda não percebeu, acabamos de reproduzir o que a função nativa do R var() faz para computar a variância amostral.\n\nvar(x)\n\n[1] 2.437258"
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#loops",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#loops",
    "title": "2. Introdução à programação R",
    "section": "Loops",
    "text": "Loops\nReescrever um código muitas vezes por necessidade de repetir um determinado procedimento seria bastante trabalhoso, além de precisarmos de mais tempo para isso e estarmos mais propensos à erros, como por exemplo, esquecer de trocar o nome de uma variável, ou um coeficiente. Por isso, o R tem algumas funções que fazem essas repetições para nós. Isso é muito comum e pode ser facilmente implementado pela função for(), while() e repeat().\n\nfor()\nA função for() repete o código indicado dentro de {} n vezes, sendo n o comprimento da sequência dentro dos parênteses.\n\nj <- 5\nfor (i in 1:j){\n  k <- i * 2\n  print(k)\n}\n\n[1] 2\n[1] 4\n[1] 6\n[1] 8\n[1] 10\n\n\n\n\nwhile()\nA função while() (que significa enquanto) repete o código dentro de {} enquanto alguma condição for verdadeira. Isso é útil, por exemplo, para ser aplicada em um modelo que contém um algoritmo iterativo que necessita de convergência. O modo é iterado infinitas vezes até a convergência ser atingida, ou até uma condição (por exemplo, após um número máximo de iterações) ser atingida.\n\ni <- 1\nwhile (i <= 5){\n  print(i * 2)\n  i <- i + 1\n}\n\n[1] 2\n[1] 4\n[1] 6\n[1] 8\n[1] 10\n\n\nNote que os dois últimos exemplos apresentam o mesmo resultado: o R vai retornar uma sequência i sendo i = 1:5, onde cada número será o resultado da multiplicação \\(i \\times 2\\). No caso while(), precisamos mudar o valor de i para que a sequência continue até que a condição (i <= 5) for verdadeira. Em adição, precisamos declarar a variável (i = 1) antes para que o R possa testar a condição expressa dentro dos parênteses. No caso do for(), a sequência progride sem precisarmos fazer isso manualmente.\n\n\nrepeat()\nNo último exemplo, utilizando repeat(), o R repetirá o código dentro de {} sem condições. Com isso, precisamos utilizar a combinação das funções if() e break() para informar ao programa quando o código deve parar de ser repetido.\n\ni <- 1\nrepeat {\n  print(i * 2)\n  i <- i + 1\n  if(i > 5){\n    break()\n  }\n}\n\n[1] 2\n[1] 4\n[1] 6\n[1] 8\n[1] 10\n\n\n\n\n\nImprimir números no console foi uma boa maneira de conhecermos como o procedimento for-loop funciona no R. Em resumo: podemos chegar no mesmo resultado utilziando três abordagens distintas. Mas vamos dar um pouco mais de aplicabilidade aos procedimentos for-loop. Imagine que temos este simples data.frame:\n\ndf <- data.frame(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10),\n  e = rnorm(10)\n)\ndf\n\n             a           b           c          d          e\n1   1.51178117  0.91897737  1.35867955 -0.1645236  0.3981059\n2   0.38984324  0.78213630 -0.10278773 -0.2533617 -0.6120264\n3  -0.62124058  0.07456498  0.38767161  0.6969634  0.3411197\n4  -2.21469989 -1.98935170 -0.05380504  0.5566632 -1.1293631\n5   1.12493092  0.61982575 -1.37705956 -0.6887557  1.4330237\n6  -0.04493361 -0.05612874 -0.41499456 -0.7074952  1.9803999\n7  -0.01619026 -0.15579551 -0.39428995  0.3645820 -0.3672215\n8   0.94383621 -1.47075238 -0.05931340  0.7685329 -1.0441346\n9   0.82122120 -0.47815006  1.10002537 -0.1123462  0.5697196\n10  0.59390132  0.41794156  0.76317575  0.8811077 -0.1350546\n\n\nAgora, imagine que você quer computar a média de cada variável. Você poderia fazer isso copiando e colando 5 vezes o código.\n\nmean(df$a)\n\n[1] 0.248845\n\nmean(df$b)\n\n[1] -0.1336732\n\nmean(df$c)\n\n[1] 0.1207302\n\nmean(df$d)\n\n[1] 0.1341367\n\nmean(df$e)\n\n[1] 0.1434569\n\n\nUsando o for loop, teríamos um vetor de médias, com o seguinte código\n\noutput <- NULL                 # 1. output\nfor (i in 1:ncol(df)) {        # 2. Sequência\n  output[i] <- mean(df[[i]])   # 3. o que é executado dentro de cada loop\n}\noutput\n\n[1]  0.2488450 -0.1336732  0.1207302  0.1341367  0.1434569\n\n\nBem, neste exemplo, as duas abordagens têm 5 linhas de programação e realmente parece que o loop foi um tanto quanto mais “difícil” de implementar. Sua vantagem, no entanto, aparece quando muitas colunas estão disponíveis. Neste caso, se um conjunto de dados com 100 variáveis precisa ser analizado, as mesmas cinco linhas de programação são utilizadas."
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#família-apply",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#família-apply",
    "title": "2. Introdução à programação R",
    "section": "Família apply",
    "text": "Família apply\nNativamente, o R contém uma família de funções vetorizadas que minimizam sua necessidade de criar loops explicitamente. Essas funções aplicarão uma função especificada a um objeto de dados e sua principal diferença está na classe de objeto na qual a função é aplicada (lista vs. matriz, etc.) e na classe de objeto que será retornada da função.\n\napply()\nA função apply() é mais frequentemente usada para aplicar uma função às linhas ou colunas (margens) de matrizes ou data.frames. Note como montante de código para computar a média de cada coluna de df é drasticamente reduzido utilizando apply().\n\napply(df, 1, mean) # média das linhas\n\n [1]  0.80460408  0.04076075  0.17581582 -0.96611130  0.22239302  0.15136957\n [7] -0.11378305 -0.17236625  0.38009399  0.50421435\n\napply(df, 2, mean) # média das colunas\n\n         a          b          c          d          e \n 0.2488450 -0.1336732  0.1207302  0.1341367  0.1434569 \n\n\n\n\nlapply()\nA função lapply() faz a seguinte série simples de operações:\n\nFaz um loop em uma lista, iterando sobre cada elemento dessa lista;\nAplica uma função a cada elemento da lista (uma função que você especifica)\nRetorna uma lista (o l é para “lista”).\n\n\nlapply(df, mean)\n\n$a\n[1] 0.248845\n\n$b\n[1] -0.1336732\n\n$c\n[1] 0.1207302\n\n$d\n[1] 0.1341367\n\n$e\n[1] 0.1434569\n\n\n\n\nsapply()\nA função sapply() se comporta de maneira semelhante a lapply(); a única diferença está no valor retornado. sapply() tentará simplificar o resultado, se possível.\n\nsapply(df, mean)\n\n         a          b          c          d          e \n 0.2488450 -0.1336732  0.1207302  0.1341367  0.1434569"
  },
  {
    "objectID": "RGV410046/RGV410046_02_PROGRAMACAO.html#família-map_",
    "href": "RGV410046/RGV410046_02_PROGRAMACAO.html#família-map_",
    "title": "2. Introdução à programação R",
    "section": "Família map_*()",
    "text": "Família map_*()\nO padrão de fazer um loop sobre um vetor, fazer algo em cada elemento e salvar os resultados é tão comum que o pacote purrr fornece uma família de funções para fazer isso por você. Existe uma função para cada tipo de saída:\n\nmap() retorna uma lista.\nmap_lgl() retorna um vetor lógico.\nmap_int() retorna um vetor de números inteiros.\nmap_dbl() retorna um vetor double.\nmap_chr() retorna um vetor de caracteres.\n\n\nlibrary(purrr)\n\nmap(df, mean) # retorna uma lista\n\n$a\n[1] 0.248845\n\n$b\n[1] -0.1336732\n\n$c\n[1] 0.1207302\n\n$d\n[1] 0.1341367\n\n$e\n[1] 0.1434569\n\nmap_dbl(df, mean) # retorna um vetor double\n\n         a          b          c          d          e \n 0.2488450 -0.1336732  0.1207302  0.1341367  0.1434569"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html",
    "href": "RGV410046/RGV410046_03_DADOS.html",
    "title": "3. Dados",
    "section": "",
    "text": "# meu computador (mudar de acordo)\nsetwd(\"E:/Desktop/UFSC/aulas/classes/RGV410046/data\")"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#funções-r-base",
    "href": "RGV410046/RGV410046_03_DADOS.html#funções-r-base",
    "title": "3. Dados",
    "section": "Funções R base",
    "text": "Funções R base\nA função read.table() lê um arquivo em formato de tabela (.txt, .csv) e cria um data frame a partir dele.\n\n(dados <- read.table(\"df_txt.txt\", header = TRUE))\n(dados <- read.table(\"df_csv.csv\", header = TRUE, sep = \";\"))\n# Argumento header = TRUE indica a existência de cabeçalho"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#rstudio",
    "href": "RGV410046/RGV410046_03_DADOS.html#rstudio",
    "title": "3. Dados",
    "section": "Rstudio",
    "text": "Rstudio\nA forma mais comum do pesquisador digitar seus dados é através de planilhas eletrônicas do Excel. Para carregar esses dados, basta ir em Import Dataset na área de trabalho. O passo a passo está descrito abaixo:\n\n\n\nImportando dados de planilhas eletrônicas do Excel - Passo 1\n\n\n\n\n\nImportando dados de planilhas eletrônicas do Excel - Passo 2\n\n\n\n\n\nImportando dados de planilhas eletrônicas do Excel - Passo 3"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#do-excel",
    "href": "RGV410046/RGV410046_03_DADOS.html#do-excel",
    "title": "3. Dados",
    "section": "Do excel",
    "text": "Do excel\n\nUm arquivo\n\n# primeira planilha do excel\ndf_excel <- import(\"df_excel.xlsx\")\ndf_excel\n\n   RAD REP AF_M2       AF      MST\n1   50   1  5.02 5016.429 12.30785\n2   50   2  3.65 3648.359 10.73315\n3   50   3  3.93 3925.333 10.86140\n4   50   4  4.71 4705.269 10.97850\n5   70   1  6.12 6118.425 15.75180\n6   70   2  5.61 5614.233 13.30495\n7   70   3  5.11 5109.944 13.88435\n8   70   4  4.98 4975.857 13.09225\n9  100   1  5.46 5464.528 16.92240\n10 100   2  5.55 5551.951 14.93085\n11 100   3  5.72 5723.849 16.12900\n12 100   4  5.87 5869.697 15.78145\n\n# uma planilha específica\n# converter para tibble\ndf_excel2 <- \n  import(\"df_excel.xlsx\",\n         sheet = \"traits\",\n         setclass = \"tbl\")\ndf_excel2\n\n# A tibble: 12 × 2\n      AF   MST\n   <dbl> <dbl>\n 1 5016.  12.3\n 2 3648.  10.7\n 3 3925.  10.9\n 4 4705.  11.0\n 5 6118.  15.8\n 6 5614.  13.3\n 7 5110.  13.9\n 8 4976.  13.1\n 9 5465.  16.9\n10 5552.  14.9\n11 5724.  16.1\n12 5870.  15.8\n\n\n\n\nVários arquivos\n\n(padrao <- list.files(pattern = \"df_excel\"))\n\n[1] \"df_excel.xlsx\"  \"df_excel2.xlsx\" \"df_excel3.xlsx\"\n\ndf_lista <- import_list(file = padrao)\nstr(df_lista)\n\nList of 3\n $ df_excel :'data.frame':  12 obs. of  5 variables:\n  ..$ RAD  : num [1:12] 50 50 50 50 70 70 70 70 100 100 ...\n  ..$ REP  : num [1:12] 1 2 3 4 1 2 3 4 1 2 ...\n  ..$ AF_M2: num [1:12] 5.02 3.65 3.93 4.71 6.12 5.61 5.11 4.98 5.46 5.55 ...\n  ..$ AF   : num [1:12] 5016 3648 3925 4705 6118 ...\n  ..$ MST  : num [1:12] 12.3 10.7 10.9 11 15.8 ...\n  ..- attr(*, \"filename\")= chr \"df_excel.xlsx\"\n $ df_excel2:'data.frame':  12 obs. of  5 variables:\n  ..$ RAD  : num [1:12] 50 50 50 50 70 70 70 70 100 100 ...\n  ..$ REP  : num [1:12] 1 2 3 4 1 2 3 4 1 2 ...\n  ..$ AF_M2: num [1:12] 5.02 3.65 3.93 4.71 6.12 5.61 5.11 4.98 5.46 5.55 ...\n  ..$ AF   : num [1:12] 5016 3648 3925 4705 6118 ...\n  ..$ MST  : num [1:12] 12.3 10.7 10.9 11 15.8 ...\n  ..- attr(*, \"filename\")= chr \"df_excel2.xlsx\"\n $ df_excel3:'data.frame':  12 obs. of  5 variables:\n  ..$ RAD  : num [1:12] 50 50 50 50 70 70 70 70 100 100 ...\n  ..$ REP  : num [1:12] 1 2 3 4 1 2 3 4 1 2 ...\n  ..$ AF_M2: chr [1:12] \"5,02\" \"3,65\" \"3,93\" \"4,71\" ...\n  ..$ AF   : chr [1:12] \"5016,43\" \"3648,36\" \"3925,33\" \"4705,27\" ...\n  ..$ MST  : chr [1:12] \"12,31\" \"10,73\" \"10,86\" \"10,98\" ...\n  ..- attr(*, \"filename\")= chr \"df_excel3.xlsx\"\n\ndf_lista_bind <- import_list(file = padrao, rbind = TRUE)\ndf_lista_bind\n\n   RAD REP AF_M2         AF      MST          _file\n1   50   1  5.02 5016.42875 12.30785  df_excel.xlsx\n2   50   2  3.65  3648.3589 10.73315  df_excel.xlsx\n3   50   3  3.93 3925.33325  10.8614  df_excel.xlsx\n4   50   4  4.71  4705.2685  10.9785  df_excel.xlsx\n5   70   1  6.12  6118.4251  15.7518  df_excel.xlsx\n6   70   2  5.61 5614.23305 13.30495  df_excel.xlsx\n7   70   3  5.11 5109.94435 13.88435  df_excel.xlsx\n8   70   4  4.98 4975.85695 13.09225  df_excel.xlsx\n9  100   1  5.46   5464.528  16.9224  df_excel.xlsx\n10 100   2  5.55 5551.95115 14.93085  df_excel.xlsx\n11 100   3  5.72 5723.84875   16.129  df_excel.xlsx\n12 100   4  5.87 5869.69745 15.78145  df_excel.xlsx\n13  50   1  5.02 5016.42875 12.30785 df_excel2.xlsx\n14  50   2  3.65  3648.3589 10.73315 df_excel2.xlsx\n15  50   3  3.93 3925.33325  10.8614 df_excel2.xlsx\n16  50   4  4.71  4705.2685  10.9785 df_excel2.xlsx\n17  70   1  6.12  6118.4251  15.7518 df_excel2.xlsx\n18  70   2  5.61 5614.23305 13.30495 df_excel2.xlsx\n19  70   3  5.11 5109.94435 13.88435 df_excel2.xlsx\n20  70   4  4.98 4975.85695 13.09225 df_excel2.xlsx\n21 100   1  5.46   5464.528  16.9224 df_excel2.xlsx\n22 100   2  5.55 5551.95115 14.93085 df_excel2.xlsx\n23 100   3  5.72 5723.84875   16.129 df_excel2.xlsx\n24 100   4  5.87 5869.69745 15.78145 df_excel2.xlsx\n25  50   1  5,02    5016,43    12,31 df_excel3.xlsx\n26  50   2  3,65    3648,36    10,73 df_excel3.xlsx\n27  50   3  3,93    3925,33    10,86 df_excel3.xlsx\n28  50   4  4,71    4705,27    10,98 df_excel3.xlsx\n29  70   1  6,12    6118,43    15,75 df_excel3.xlsx\n30  70   2  5,61    5614,23    13,30 df_excel3.xlsx\n31  70   3  5,11    5109,94    13,88 df_excel3.xlsx\n32  70   4  4,98    4975,86    13,09 df_excel3.xlsx\n33 100   1  5,46    5464,53    16,92 df_excel3.xlsx\n34 100   2  5,55    5551,95    14,93 df_excel3.xlsx\n35 100   3  5,72    5723,85    16,13 df_excel3.xlsx\n36 100   4  5,87    5869,70    15,78 df_excel3.xlsx"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#planilha-separada-por-vírgulas",
    "href": "RGV410046/RGV410046_03_DADOS.html#planilha-separada-por-vírgulas",
    "title": "3. Dados",
    "section": "Planilha separada por vírgulas",
    "text": "Planilha separada por vírgulas\n\ndf_csv <- import(\"df_csv.csv\")\ndf_csv\n\n   RAD REP AF_M2      AF   MST\n1   50   1  5.02 5016.43 12.31\n2   50   2  3.65 3648.36 10.73\n3   50   3  3.93 3925.33 10.86\n4   50   4  4.71 4705.27 10.98\n5   70   1  6.12 6118.43 15.75\n6   70   2  5.61 5614.23 13.30\n7   70   3  5.11 5109.94 13.88\n8   70   4  4.98 4975.86 13.09\n9  100   1  5.46 5464.53 16.92\n10 100   2  5.55 5551.95 14.93\n11 100   3  5.72 5723.85 16.13\n12 100   4  5.87 5869.70 15.78"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#arquivos-de-texto",
    "href": "RGV410046/RGV410046_03_DADOS.html#arquivos-de-texto",
    "title": "3. Dados",
    "section": "Arquivos de texto",
    "text": "Arquivos de texto\n\ndf_txt <- import(\"df_txt.txt\")\ndf_txt\n\n   RAD REP AF_M2      AF   MST\n1   50   1  5.02 5016.43 12.31\n2   50   2  3.65 3648.36 10.73\n3   50   3  3.93 3925.33 10.86\n4   50   4  4.71 4705.27 10.98\n5   70   1  6.12 6118.43 15.75\n6   70   2  5.61 5614.23 13.30\n7   70   3  5.11 5109.94 13.88\n8   70   4  4.98 4975.86 13.09\n9  100   1  5.46 5464.53 16.92\n10 100   2  5.55 5551.95 14.93\n11 100   3  5.72 5723.85 16.13\n12 100   4  5.87 5869.70 15.78"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#google-sheets",
    "href": "RGV410046/RGV410046_03_DADOS.html#google-sheets",
    "title": "3. Dados",
    "section": "Google sheets",
    "text": "Google sheets\n\nurl <- \"https://docs.google.com/spreadsheets/d/1b-Sj9l-VwJ-Oy-hFx7j8twsA5oC6-Fr9ukllywfim0E\"\ndf_gsheet <- import(url, dec = \",\")\ndf_gsheet\n\n   RAD REP AF_M2      AF   MST\n1   50   1  5.02 5016.43 12.31\n2   50   2  3.65 3648.36 10.73\n3   50   3  3.93 3925.33 10.86\n4   50   4  4.71 4705.27 10.98\n5   70   1  6.12 6118.43 15.75\n6   70   2  5.61 5614.23 13.30\n7   70   3  5.11 5109.94 13.88\n8   70   4  4.98 4975.86 13.09\n9  100   1  5.46 5464.53 16.92\n10 100   2  5.55 5551.95 14.93\n11 100   3  5.72 5723.85 16.13\n12 100   4  5.87 5869.70 15.78"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#spss",
    "href": "RGV410046/RGV410046_03_DADOS.html#spss",
    "title": "3. Dados",
    "section": "SPSS",
    "text": "SPSS\nO arquivo \".sav\" de exemplo foi baixado deste site\n\ndf_spss <- import(\"df_spss.sav\", setclass = \"tbl\")\ndf_spss\n\n# A tibble: 306 × 59\n   IDnumber   age   sex workstat increg incmnth incwk housing living homepay\n      <dbl> <dbl> <dbl>    <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl>   <dbl>\n 1 20160186    19     2        3      1       0   0         2      1       1\n 2 20160011    17     2        0      0       0   0         2      1       1\n 3 20160081    18     2        3      1     300  69.2       2      1       1\n 4 20160155    18     2        0      0       0   0         2      1       1\n 5 20160182    19     2        0      1     600 138.        2      1       4\n 6 20160027    17     2        0      0       0   0         2      1       4\n 7 20160188    19     2        0      0       0   0         2      1      99\n 8 20160013    17     2        0      0       0   0         2      1       1\n 9 20160214    20     2        0      1    1500 346.        3      2       4\n10 20160216    20     2        3      1     400  92.3       3      2       1\n# … with 296 more rows, and 49 more variables: homecost <dbl>,\n#   homecostwk <dbl>, mobile <dbl>, mobilepay <dbl>, mobilecost <dbl>,\n#   mobilecostwk <dbl>, transport <dbl>, food <dbl>, entertain <dbl>,\n#   privhlth <dbl>, fs_illness <dbl>, fs_accident <dbl>, fs_death <dbl>,\n#   fs_mtlillness <dbl>, fs_disability <dbl>, fs_divsep <dbl>,\n#   fs_nogetjob <dbl>, fs_lossofjob <dbl>, fs_alcdrug <dbl>, fs_witviol <dbl>,\n#   fs_absvcrim <dbl>, fs_police <dbl>, fs_gambling <dbl>, famstress <dbl>, …"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#dbf",
    "href": "RGV410046/RGV410046_03_DADOS.html#dbf",
    "title": "3. Dados",
    "section": "DBF",
    "text": "DBF\nO arquivo \".dbf\" de exemplo foi baixado deste site\n\ndf_dbf <- import(\"df_dbf.dbf\", setclass = \"tbl\")\ndf_dbf\n\n# A tibble: 67 × 15\n      ID CATCOUNT AGRPCOUNT PGRPCO…¹ ORDER CODE  NAME  THUMB…² IMAGE PRICE  COST\n   <int>    <int>     <int>    <int> <int> <chr> <chr> <chr>   <chr> <dbl> <dbl>\n 1    87        2         0        0    87 1     Asso… graphi… grap…   0     0  \n 2    26        3         0        0    26 CPKG  Chri… graphi… grap…   0    29.0\n 3    27        3         0        0    27 CHOC  Choc… graphi… grap…   0    29.0\n 4    28        3         0        0    28 PAST… Past… graphi… grap…   0    29.0\n 5    29        2         0        0    29 CKR-… Chec… graphi… grap…  15.8  15.8\n 6    30        3         0        0    30 C     Chri… graphi… grap…   0    32.0\n 7    31        3         0        0    31 TBC01 Truf… graphi… grap…  19.2  19.2\n 8    32        2         0        0    32 BD01  Bisc… graphi… grap…  28.8  28.8\n 9    33        1         0        0    33 DS02  Dres… graphi… grap…  24.0  24.0\n10    34        1         0        0    34 AB01  Apri… graphi… grap…  38.0  38.0\n# … with 57 more rows, 4 more variables: DESC <chr>, WEIGHT <dbl>,\n#   TAXABLE <lgl>, ACTIVE <lgl>, and abbreviated variable names ¹​PGRPCOUNT,\n#   ²​THUMBNAIL"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#ods",
    "href": "RGV410046/RGV410046_03_DADOS.html#ods",
    "title": "3. Dados",
    "section": "ODS",
    "text": "ODS\n\ndf_ods <- import(\"df_ods.ods\")\n\nLoading required namespace: readODS\n\ndf_ods\n\n   RAD REP AF_M2       AF      MST\n1   50   1  5.02 5016.429 12.30785\n2   50   2  3.65 3648.359 10.73315\n3   50   3  3.93 3925.333 10.86140\n4   50   4  4.71 4705.269 10.97850\n5   70   1  6.12 6118.425 15.75180\n6   70   2  5.61 5614.233 13.30495\n7   70   3  5.11 5109.944 13.88435\n8   70   4  4.98 4975.857 13.09225\n9  100   1  5.46 5464.528 16.92240\n10 100   2  5.55 5551.951 14.93085\n11 100   3  5.72 5723.849 16.12900\n12 100   4  5.87 5869.697 15.78145"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#rdata",
    "href": "RGV410046/RGV410046_03_DADOS.html#rdata",
    "title": "3. Dados",
    "section": "Rdata",
    "text": "Rdata\n\ndf_rdata <- readRDS(\"df_r.RData\")\ndf_rdata\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP\n1      H1     I     3.002   1.878\n2      H1    II     2.974   1.834\n3      H1   III     2.814   1.674\n4      H2     I     2.104   0.910\n5      H2    II     2.120   1.034\n6      H2   III     1.924   1.018\n7      H3     I     2.132   1.052\n8      H3    II     2.126   1.012\n9      H3   III     2.182   0.992"
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#mesmos-dados-diferentes-formas",
    "href": "RGV410046/RGV410046_03_DADOS.html#mesmos-dados-diferentes-formas",
    "title": "3. Dados",
    "section": "Mesmos dados, diferentes formas",
    "text": "Mesmos dados, diferentes formas\nNesta seção você aprenderá organizar dados no R no formato tidy. Colocar seus dados nesse formato requer algum trabalho inicial, mas esse trabalho compensa a longo prazo. Aqui, um foco especial será dado nas funções do pacote tidyr e do pacote metan. Se você quiser saber mais sobre a teoria por tras dos dados tidy, poderá apreciar o artigo Tidy Data.\nVocê pode representar os mesmos dados várias maneiras. O exemplo abaixo mostra os mesmos dados organizados de quatro maneiras diferentes. Cada conjunto de dados mostra os mesmos valores de duas variáveis (ALT_ESP, ALT_PLANT) mensuradas em três híbridos (HIBRIDO), considerando três repetições (BLOCOS).\n\ndf <- import_list(\"examples_data.xlsx\")\ndf$df1\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP\n1      H1     I     3.002   1.878\n2      H1    II     2.974   1.834\n3      H1   III     2.814   1.674\n4      H2     I     2.104   0.910\n5      H2    II     2.120   1.034\n6      H2   III     1.924   1.018\n7      H3     I     2.132   1.052\n8      H3    II     2.126   1.012\n9      H3   III     2.182   0.992\n\ndf$df2\n\n   HIBRIDO BLOCO  VARIAVEL VALOR\n1       H1     I ALT_PLANT 3.002\n2       H1     I   ALT_ESP 1.878\n3       H1    II ALT_PLANT 2.974\n4       H1    II   ALT_ESP 1.834\n5       H1   III ALT_PLANT 2.814\n6       H1   III   ALT_ESP 1.674\n7       H2     I ALT_PLANT 2.104\n8       H2     I   ALT_ESP 0.910\n9       H2    II ALT_PLANT 2.120\n10      H2    II   ALT_ESP 1.034\n11      H2   III ALT_PLANT 1.924\n12      H2   III   ALT_ESP 1.018\n13      H3     I ALT_PLANT 2.132\n14      H3     I   ALT_ESP 1.052\n15      H3    II ALT_PLANT 2.126\n16      H3    II   ALT_ESP 1.012\n17      H3   III ALT_PLANT 2.182\n18      H3   III   ALT_ESP 0.992\n\ndf$df3\n\n  HIBRIDO ALT_ESP_I ALT_ESP_II ALT_ESP_III ALT_PLANT_I ALT_PLANT_II\n1      H1     1.878      1.834       1.674       3.002        2.974\n2      H2     0.910      1.034       1.018       2.104        2.120\n3      H3     1.052      1.012       0.992       2.132        2.126\n  ALT_PLANT_III\n1         2.814\n2         1.924\n3         2.182\n\ndf$df4\n\n  HIBRIDO      name     I    II   III\n1      H1 ALT_PLANT 3.002 2.974 2.814\n2      H1   ALT_ESP 1.878 1.834 1.674\n3      H2 ALT_PLANT 2.104 2.120 1.924\n4      H2   ALT_ESP 0.910 1.034 1.018\n5      H3 ALT_PLANT 2.132 2.126 2.182\n6      H3   ALT_ESP 1.052 1.012 0.992\n\n\nEssas são todas representações dos mesmos dados, mas são completamente diferentes do ponto de vista de uso.\n\n\n\n\n\n\nO que não fazer\n\n\n\nVamos assumir que queiramos computar a média da variável ALT_PLANT. Observe os quatro exemplos abaixo e veja qual está correto.\n\nmean(df$df1$ALT_PLANT)\n\n[1] 2.375333\n\nmean(df$df2$value)\n\nWarning in mean.default(df$df2$value): argumento não é numérico nem lógico:\nretornando NA\n\n\n[1] NA\n\nmean(df$df3$ALT_PLANT_I)\n\n[1] 2.412667\n\nmean(df$df4$I)\n\n[1] 1.846333\n\n\n\n\nUm conjunto de dados tidy é um conjunto de dados onde as três regras à seguir são respeitadas:\n\nCada variável deve ter sua própria coluna.\nCada observação deve ter sua própria linha.\nCada valor deve ter sua própria célula.\n\nA Figura à seguir mostra as regras visualmente.\n\n\n\nAdaptado de https://r4ds.had.co.nz/tidy-data.html#tidy-data-1\n\n\nApós vermos estas regras, percebemos que dos quatro conjuntos apresentados anteriormente, apenas df é tidy. Ao usarmos conjuntos de dados tidy vamos poder aproveitar uma das belezas do R: a possibilidade de aplicar funções à vetores, que neste caso nada mais são do que os valores presentes em cada coluna."
  },
  {
    "objectID": "RGV410046/RGV410046_03_DADOS.html#padão-padrão-padrão",
    "href": "RGV410046/RGV410046_03_DADOS.html#padão-padrão-padrão",
    "title": "3. Dados",
    "section": "Padão, padrão, padrão!",
    "text": "Padão, padrão, padrão!\n\nFormatar strings\nUm dos maiores equívocos cometidos ao trabalhar com conjuntos de dados e que pode impactar significativamente análises posteriores é a falta de padrão de nomenclatura, tanto em variáveis como string de caracteres. Por exemplo, suponha que tenhamos uma string de caracteres str = c(\"Env1\", \"env 1\", \"env.1\"), para representar três observações do ambiente “env 1”. Por definição, str deve representar um nível único, mas na verdade tem três níveis.\n\nstr <- c(\"Env1\", \"env 1\", \"env.1\")\nstr |> factor() |> levels()\n\n[1] \"env 1\" \"env.1\" \"Env1\" \n\n\nA função tidy_strings() do pacote metan pode ser usada para organizar strings de caracteres colocando todas as palavras em maiúsculas, substituindo qualquer espaço, tabulação, caracteres de pontuação por _ e colocando _ entre maiúsculas e minúsculas.\n\n(tidy_str <- tidy_strings(str))\n\n[1] \"ENV_1\" \"ENV_1\" \"ENV_1\"\n\ntidy_str |> factor() |> levels()\n\n[1] \"ENV_1\"\n\n\nExcelente! Agora temos o nível único que deveríamos ter antes.\n\n\nFormatar nomes de colunas\nO mesmo princípio visto anteriormente se aplica aos nomes das colunas. Como exemplo motivador, vamos utilziar o conjunto de dados messy.\n\nmessy <- df$messy\nnames(messy)\n\n[1] \"env\" \"Gen\" \"b 1\" \"B2\"  \"b.3\"\n\n\nObserve que o nome das colunas do conjunto de dados messy não segue nenhum padrão. São observados letras minúsculas e maiúsculas, espaços e pontuações. Note o que a presença de espaços resulta na seleção de variáveis.\n\nmessy$env\nmessy$b 1\n\n# espaços requerem código adicional\nmessy$`b 1`\n\nError: <text>:2:9: unexpected numeric constant\n1: messy$env\n2: messy$b 1\n           ^\n\n\nPara formatar os nomes de colunas, podemos utilizar a função tidy_colnames() do pacote metan.\n\nmessy <- tidy_colnames(messy)\nnames(messy)\n\n[1] \"ENV\" \"GEN\" \"B_1\" \"B_2\" \"B_3\"\n\n\n\n\nPreencher valores\nObserve o seguinte conjunto de dados\n\nNa hora da coleta de dados é muito comum observar células mescladas em conjuntos de dados. Observe o que acontece quando estes dados são importados para o software R.\n\n(mesclado <- df$fill)\n\n   AMB HIBRIDO BLOCO ALT_PLANT\n1   A1      H1     I     3.002\n2   A1      H1    II     2.974\n3   A1      H1   III     2.814\n4   A1      H2     I     2.104\n5   A1      H2    II     2.120\n6   A1      H2   III     1.924\n7   A2      H1     I     3.002\n8   A2      H1    II     2.974\n9   A2      H1   III     2.814\n10  A2      H2     I     2.104\n11  A2      H2    II     2.120\n12  A2      H2   III     1.924\n\n\nA função fill() do pacote tidyr pode ser utilizada para preencher valores faltantes. Ela preenche os valores ausentes nas colunas selecionadas. Isso é útil no formato de saída comum em que os valores não são repetidos e são registrados apenas quando são alterados. Par\n\n(preenchido <- fill(mesclado, AMB, HIBRIDO))\n\n   AMB HIBRIDO BLOCO ALT_PLANT\n1   A1      H1     I     3.002\n2   A1      H1    II     2.974\n3   A1      H1   III     2.814\n4   A1      H2     I     2.104\n5   A1      H2    II     2.120\n6   A1      H2   III     1.924\n7   A2      H1     I     3.002\n8   A2      H1    II     2.974\n9   A2      H1   III     2.814\n10  A2      H2     I     2.104\n11  A2      H2    II     2.120\n12  A2      H2   III     1.924"
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html",
    "title": "4. Manipulação de Dados",
    "section": "",
    "text": "# meu computador (mudar de acordo)\nsetwd(\"E:/Desktop/UFSC/aulas/classes/RGV410046/data\")"
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#longer",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#longer",
    "title": "4. Manipulação de Dados",
    "section": "Longer",
    "text": "Longer\n\n(df_wide <- import(\"examples_data.xlsx\", sheet = \"feijao\"))\n\n  UE BLOCO ADUBACAO   P1   P2   P3   P4   P5\n1  1     1       AO 16.0 17.0 19.0 15.0 17.0\n2  2     1       AQ 21.5 17.0 13.5 14.0 15.0\n3  3     1       SA 13.0 16.5 11.5 14.5 12.5\n4  4     2       AQ 15.0 14.0 13.0 16.0 16.0\n5  5     2       AO 14.0 17.0 18.0 16.0 14.0\n6  6     2       SA 15.0 14.0 16.0 16.0 13.0\n7  7     3       AO 17.0 17.0 11.0 16.0 15.0\n8  8     3       SA 17.0 16.0 14.0 17.0 12.0\n9  9     3       AQ 16.0 17.0 14.0 16.0 12.0\n\n\nPara organizar um conjunto de dados como esse, precisamos dinamizar as colunas problemáticas em duas novas colunas (variável e valor) utilizando a função pivot_longer().\n\n\n\nExemplo da função pivot_longer(). Fonte: https://github.com/rstudio/cheatsheets/blob/main/tidyr.pdf\n\n\nPara realizar essa operação, precisamos de três parâmetros (além do conjunto de dados)\n\ncols: o conjunto de colunas cujos nomes são valores, não variáveis. Neste exemplo, essas são as colunas P1, P2, P3, P4 e P5.\nnames_to: O nome da variável para a qual mover os nomes das colunas. Aqui será \"PLANTA\".\nvalues_to: O nome da variável para a qual mover os valores da coluna. Aqui será \"ALTURA\".\n\n\nlong <- \n  pivot_longer(df_wide,\n               cols = P1:P5,\n               names_to = \"PLANTA\",\n               values_to = \"AP\")\nlong\n\n# A tibble: 45 × 5\n      UE BLOCO ADUBACAO PLANTA    AP\n   <dbl> <dbl> <chr>    <chr>  <dbl>\n 1     1     1 AO       P1      16  \n 2     1     1 AO       P2      17  \n 3     1     1 AO       P3      19  \n 4     1     1 AO       P4      15  \n 5     1     1 AO       P5      17  \n 6     2     1 AQ       P1      21.5\n 7     2     1 AQ       P2      17  \n 8     2     1 AQ       P3      13.5\n 9     2     1 AQ       P4      14  \n10     2     1 AQ       P5      15  \n# … with 35 more rows\n\n\n\n\n\n\n\n\ntidyselect style notation\n\n\n\nA seleção de variáveis no universo tidy é prioritariamente suportada pelo pacote tidyselect. Isso significa que a seleção de variáveis pode ser realizada com base em seus nomes, posições, ou propriedades.\n\n# seleciona variáveis que contém uma determinada string\npivot_longer(df_wide,\n             cols = starts_with(\"P\"),\n             names_to = \"PLANTA\",\n             values_to = \"ALTURA\") |> \n  print(n = 3)\n\n# A tibble: 45 × 5\n     UE BLOCO ADUBACAO PLANTA ALTURA\n  <dbl> <dbl> <chr>    <chr>   <dbl>\n1     1     1 AO       P1         16\n2     1     1 AO       P2         17\n3     1     1 AO       P3         19\n# … with 42 more rows\n\n# seleciona variáveis por sua posição\npivot_longer(df_wide,\n             cols = 4:8,\n             names_to = \"PLANTA\",\n             values_to = \"ALTURA\") |> \n  print(n = 3)\n\n# A tibble: 45 × 5\n     UE BLOCO ADUBACAO PLANTA ALTURA\n  <dbl> <dbl> <chr>    <chr>   <dbl>\n1     1     1 AO       P1         16\n2     1     1 AO       P2         17\n3     1     1 AO       P3         19\n# … with 42 more rows\n\n\n\n\nApós a modificação, as colunas são descartadas e obtemos as colunas de planta e altura. Assim, vemos que pivot_longer() torna os conjuntos de dados mais longos aumentando o número de linhas e diminuindo o número de colunas."
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#wider",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#wider",
    "title": "4. Manipulação de Dados",
    "section": "Wider",
    "text": "Wider\nUma outra forma comum de dados que não seguem o formato tidy é quando observações estão espalhadas por várias linhas. Observe os dados abaixo.\n\n(dflong <- import(\"examples_data.xlsx\", sheet = \"df2\"))\n\n   HIBRIDO BLOCO  VARIAVEL VALOR\n1       H1     I ALT_PLANT 3.002\n2       H1     I   ALT_ESP 1.878\n3       H1    II ALT_PLANT 2.974\n4       H1    II   ALT_ESP 1.834\n5       H1   III ALT_PLANT 2.814\n6       H1   III   ALT_ESP 1.674\n7       H2     I ALT_PLANT 2.104\n8       H2     I   ALT_ESP 0.910\n9       H2    II ALT_PLANT 2.120\n10      H2    II   ALT_ESP 1.034\n11      H2   III ALT_PLANT 1.924\n12      H2   III   ALT_ESP 1.018\n13      H3     I ALT_PLANT 2.132\n14      H3     I   ALT_ESP 1.052\n15      H3    II ALT_PLANT 2.126\n16      H3    II   ALT_ESP 1.012\n17      H3   III ALT_PLANT 2.182\n18      H3   III   ALT_ESP 0.992\n\n\nNeste caso, duas variáveis (ALT_PLANT e ALT_ESP) estão espalhadas pelas linhas. Para lidar com esse problema, utilizamos a função pivot_wider() que é o oposto de pivot_longer().\n\n\n\nExemplo da função pivot_wider(). Fonte: https://github.com/rstudio/cheatsheets/blob/main/tidyr.pdf\n\n\nPara arrumarmos os dados em dflong utilizamos pivot_wider() de maneira similar à pivot_longer(). Desta vez, no entanto, precisamos apenas de dois parâmetros:\n\nnames_from: A coluna da qual obter nomes de variáveis. Aqui, é \"VARIAVEL\".\nvalues_from: A coluna da qual obter valores. Aqui é \"VALOR\".\n\n\nwider <- \n   dflong |> \n     pivot_wider(names_from = VARIAVEL,\n                 values_from = VALOR)\nwider\n\n# A tibble: 9 × 4\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP\n  <chr>   <chr>     <dbl>   <dbl>\n1 H1      I          3.00   1.88 \n2 H1      II         2.97   1.83 \n3 H1      III        2.81   1.67 \n4 H2      I          2.10   0.91 \n5 H2      II         2.12   1.03 \n6 H2      III        1.92   1.02 \n7 H3      I          2.13   1.05 \n8 H3      II         2.13   1.01 \n9 H3      III        2.18   0.992\n\n\n\n\n\n\n\n\nMúltiplos nomes e/ou valores\n\n\n\nEm alguns casos será necessário realizar a o mesmo processo anterior, mas utilizando múltiplas variáveis em names_from e/ou values_from. Aqui, também são mostrados alguns argumentos adicionais que permitem um bom nível de controle sobre como as variáveis são combinadas.\n\nwider2 <- \n  dflong |> \n    pivot_wider(names_from = c(VARIAVEL, BLOCO),\n                values_from = VALOR,\n                names_sep = \".\")\nwider2\n\n# A tibble: 3 × 7\n  HIBRIDO ALT_PLANT.I ALT_ESP.I ALT_PLANT.II ALT_ESP.II ALT_PLANT.III ALT_ESP.…¹\n  <chr>         <dbl>     <dbl>        <dbl>      <dbl>         <dbl>      <dbl>\n1 H1             3.00      1.88         2.97       1.83          2.81      1.67 \n2 H2             2.10      0.91         2.12       1.03          1.92      1.02 \n3 H3             2.13      1.05         2.13       1.01          2.18      0.992\n# … with abbreviated variable name ¹​ALT_ESP.III"
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#r-base",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#r-base",
    "title": "4. Manipulação de Dados",
    "section": "R base",
    "text": "R base\n\nlong1 <- long\nnames(long1)[c(1, 2)] <- c(\"PARCELA\", \"REP\")\nnames(long1)\n\n[1] \"PARCELA\"  \"REP\"      \"ADUBACAO\" \"PLANTA\"   \"AP\""
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#dplyr-rename",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#dplyr-rename",
    "title": "4. Manipulação de Dados",
    "section": "dplyr rename()",
    "text": "dplyr rename()\nA função rename() do pacote dplyr altera os nomes de variáveis individuais usando a sintaxe nome_novo = nome_antigo.\n\nrename(long,\n       PARCELA = UE,\n       REP = BLOCO) |> \n  names()\n\n[1] \"PARCELA\"  \"REP\"      \"ADUBACAO\" \"PLANTA\"   \"AP\""
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#dplyr-rename_with",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#dplyr-rename_with",
    "title": "4. Manipulação de Dados",
    "section": "dplyr rename_with()",
    "text": "dplyr rename_with()\nUma outra alternativa é rename_with(), que renomeia colunas usando uma função.\n\nrename_with(long, tolower) |> names()\n\n[1] \"ue\"       \"bloco\"    \"adubacao\" \"planta\"   \"ap\""
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#metan-add_prefix-e-add_suffix",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#metan-add_prefix-e-add_suffix",
    "title": "4. Manipulação de Dados",
    "section": "metan add_prefix() e add_suffix()",
    "text": "metan add_prefix() e add_suffix()\nPrefixos e sufixos são extremamente úteis na manipulação de dados, pois permitem que select helpers possam ser utilizados na seleção de variáveis, que será visto no próximo tópico. Aqui, vamos ver como prefixos e sufixos podem ser adicionados à nomes das variáveis.\n\nlong |> \n  add_prefix(UE:PLANTA, prefix = \"Fct\") |> \n  names()\n\n[1] \"Fct_UE\"       \"Fct_BLOCO\"    \"Fct_ADUBACAO\" \"Fct_PLANTA\"   \"AP\"          \n\n# utilizando select helper\nlong |> \n  add_suffix(starts_with(\"A\"), suffix = \"a\") |> \n  select(contains(\"_a\")) |> \n  names()\n\n[1] \"ADUBACAO_a\" \"AP_a\""
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#junções-com-mutação",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#junções-com-mutação",
    "title": "4. Manipulação de Dados",
    "section": "Junções com mutação",
    "text": "Junções com mutação\n\nleft_join(): inclui todas as linhas em x.\nright_join(): inclui todas as linhas em y.\ninner_join(): inclui todas as linhas em x e y.\nfull_join(): inclui todas as linhas em x ou y.\n\nSe uma linha em x corresponder a várias linhas em y, todas as linhas em y serão retornadas uma vez para cada linha correspondente em x.\n\n\n\nFonte: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf\n\n\nVamos à um exemplo prático!\n\ndf1 <- import(\"examples_data.xlsx\", sheet = \"df1\")\n# computar a média para cada híbrido\n# renomear as variáveis\ndf2 <- \n  mean_by(df1, HIBRIDO) |> \n  rename(AP_M = ALT_PLANT, AE_M = ALT_ESP)\n\n# remove alguns níveis para mostrar as diferenças nas funções\ndf1 <- df1 |> filter(HIBRIDO != \"H2\")\ndf2 <- df2 |> filter(HIBRIDO != \"H3\")\n\ndf1\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP\n1      H1     I     3.002   1.878\n2      H1    II     2.974   1.834\n3      H1   III     2.814   1.674\n4      H3     I     2.132   1.052\n5      H3    II     2.126   1.012\n6      H3   III     2.182   0.992\n\ndf2\n\n# A tibble: 2 × 3\n  HIBRIDO  AP_M  AE_M\n  <chr>   <dbl> <dbl>\n1 H1       2.93 1.80 \n2 H2       2.05 0.987\n\n\n\n# todas as linhas de df1\ndf1 |> left_join(df2)\n\nJoining, by = \"HIBRIDO\"\n\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP AP_M     AE_M\n1      H1     I     3.002   1.878 2.93 1.795333\n2      H1    II     2.974   1.834 2.93 1.795333\n3      H1   III     2.814   1.674 2.93 1.795333\n4      H3     I     2.132   1.052   NA       NA\n5      H3    II     2.126   1.012   NA       NA\n6      H3   III     2.182   0.992   NA       NA\n\n# todas as linhas de df2\n# suprima a mensagem informando por qual coluna(s) juntar\ndf1 |> right_join(df2, by = \"HIBRIDO\")\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP     AP_M      AE_M\n1      H1     I     3.002   1.878 2.930000 1.7953333\n2      H1    II     2.974   1.834 2.930000 1.7953333\n3      H1   III     2.814   1.674 2.930000 1.7953333\n4      H2  <NA>        NA      NA 2.049333 0.9873333\n\n# todas as linhas de df1 e df2\ndf1 |> inner_join(df2)\n\nJoining, by = \"HIBRIDO\"\n\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP AP_M     AE_M\n1      H1     I     3.002   1.878 2.93 1.795333\n2      H1    II     2.974   1.834 2.93 1.795333\n3      H1   III     2.814   1.674 2.93 1.795333\n\n# todas as linhas de df1 ou df2\ndf1 |> full_join(df2, keep = TRUE)\n\nJoining, by = \"HIBRIDO\"\n\n\n  HIBRIDO.x BLOCO ALT_PLANT ALT_ESP HIBRIDO.y     AP_M      AE_M\n1        H1     I     3.002   1.878        H1 2.930000 1.7953333\n2        H1    II     2.974   1.834        H1 2.930000 1.7953333\n3        H1   III     2.814   1.674        H1 2.930000 1.7953333\n4        H3     I     2.132   1.052      <NA>       NA        NA\n5        H3    II     2.126   1.012      <NA>       NA        NA\n6        H3   III     2.182   0.992      <NA>       NA        NA\n7      <NA>  <NA>        NA      NA        H2 2.049333 0.9873333"
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#junções-com-filtragem",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#junções-com-filtragem",
    "title": "4. Manipulação de Dados",
    "section": "Junções com filtragem",
    "text": "Junções com filtragem\nAs duas seguintes funções de filtragem filtram linhas de x com base na presença ou ausência de correspondências em y:\n\nsemi_join() retorna todas as linhas de x com uma correspondência em y.\nanti_join() retorna todas as linhas de x sem uma correspondência em y.\n\n\n\n\nFonte: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf\n\n\n\n# linhas de df1 que estão em df2\ndf1 |> semi_join(df2)\n\nJoining, by = \"HIBRIDO\"\n\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP\n1      H1     I     3.002   1.878\n2      H1    II     2.974   1.834\n3      H1   III     2.814   1.674\n\n# linhas de df1 que NÃO estão em df2\ndf1 |> anti_join(df2)\n\nJoining, by = \"HIBRIDO\"\n\n\n  HIBRIDO BLOCO ALT_PLANT ALT_ESP\n1      H3     I     2.132   1.052\n2      H3    II     2.126   1.012\n3      H3   III     2.182   0.992"
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#operações-com-conjuntos-vetores",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#operações-com-conjuntos-vetores",
    "title": "4. Manipulação de Dados",
    "section": "Operações com conjuntos (vetores)",
    "text": "Operações com conjuntos (vetores)\nOperações com conjuntos são importantes na análise de dados. Por exemplo, se um determinado genótipo foi selecionado nos ambientes A, B e C, então, este determinado genótipo é a interseção dos ambientes A, B e C. Tanto o R-base quanto o pacote dplyr fornecem funções para operações com conjuntos, mas funcionam com dois conjuntos de uma vez apenas.\n\n(A <- letters[1:4])\n\n[1] \"a\" \"b\" \"c\" \"d\"\n\n(B <- letters[2:5])\n\n[1] \"b\" \"c\" \"d\" \"e\"\n\n(C <- letters[3:7])\n\n[1] \"c\" \"d\" \"e\" \"f\" \"g\"\n\n(D <- letters[1:12])\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\"\n\nset_lits <- list(A = A, B = B, C = C, D = D)\n\n# intersecção de A, B (dplyr)\nintersect(A, B)\n\n[1] \"b\" \"c\" \"d\"\n\n# intersecção de A, B e C (dplyr)\nintersect(intersect(A, B), C)\n\n[1] \"c\" \"d\"\n\n\nObserve que para computar interseções/uniões/diferenças com mais de dois conjuntos precisamos chamar (ex., intersect()) várias vezes O pacote metan fornece um grupo de funções set_*() que supera esse problema\n\n# Intersecção de A e B\nset_intersect(A, B)\n\n[1] \"b\" \"c\" \"d\"\n\n# Intersecção de A, B e C\nset_intersect(A, B, C)\n\n[1] \"c\" \"d\"\n\n# União de todos os conjuntos\n# Todas as funções entendem um objeto de classe lista\n\nset_union(set_lits)\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\"\n\n# Intersecção de todos os conjuntos\nset_intersect(set_lits)\n\n[1] \"c\" \"d\"\n\n\n\n\n\n\n\n\nDiagrama de Venn\n\n\n\nUm diagrama de Venn é um estilo de diagrama amplamente utilizado que mostra a relação lógica entre conjuntos usando curvas fechadas simples desenhadas em um plano para representar conjuntos. Muitas vezes, essas curvas são círculos ou elipses. Para mostrar as relações entre os conjuntos A, B, C e D, usamos a função venn_plot() do pacote metan.\n\nvenn_plot(set_lits, show_elements = TRUE)"
  },
  {
    "objectID": "RGV410046/RGV410046_04_MANIPULACAO.html#operações-com-conjuntos-data-frames",
    "href": "RGV410046/RGV410046_04_MANIPULACAO.html#operações-com-conjuntos-data-frames",
    "title": "4. Manipulação de Dados",
    "section": "Operações com conjuntos (data frames)",
    "text": "Operações com conjuntos (data frames)\nNesta seção será demonstrado como é possivel utilizar operações de cojuntos como interseção e união. É esperado que as entradas x e y tenham as mesmas variáveis. Para isto, vamos criar dois novos conjuntos de dados fictícios.\n\ndfi1 <- data.frame(gen = c(\"A\", \"B\", \"C\"),\n                   y = c(2, 3, 1))\ndfi2 <- data.frame(gen = c(\"B\", \"C\", \"D\"),\n                   y = c(3, 1, 4))\n\nset_intersect(dfi1, dfi2)\n\n  gen y\n1   B 3\n2   C 1\n\nset_difference(dfi1, dfi2)\n\n  gen y\n1   A 2\n\nset_union(dfi1, dfi2)\n\n  gen y\n1   A 2\n2   B 3\n3   C 1\n4   D 4\n\n\nFree website hit counter"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html",
    "href": "RGV410046/RGV410046_05_SELECAO.html",
    "title": "5. Seleção e filtragem",
    "section": "",
    "text": "# meu computador (mudar de acordo)\nsetwd(\"E:/Desktop/UFSC/aulas/classes/RGV410046/data\")"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html#selecionar-colunas",
    "href": "RGV410046/RGV410046_05_SELECAO.html#selecionar-colunas",
    "title": "5. Seleção e filtragem",
    "section": "Selecionar colunas",
    "text": "Selecionar colunas\n\n\n\n\n\nA função select() do pacote dplyr pode ser usada para selecionar colunas de um conjunto de dados com base em seu nome (por exemplo, a:f seleciona todas as colunas de a à esquerda a f à direita). Você também pode usar funções de predicado como is.numeric para selecionar variáveis com base em suas propriedades. As seleções do Tidyverse implementam um dialeto R onde os operadores facilitam a seleção de variáveis:\n\n: para selecionar um intervalo de variáveis consecutivas.\n! para tomar o complemento de um conjunto de variáveis.\n& e | para selecionar a interseção ou a união de dois conjuntos de variáveis.\nc() para combinar seleções.\n\n\nCom base em seus nomes\n\nmaize <- \n  import(\"examples_data.xlsx\",\n         sheet = \"maize\",\n         setclass = \"tbl\")\n# para evitar uma saída longa\ndf <- maize |> slice(1:5)\n\n# lista de nomes\ndf |> select(AMB, HIB, REP)\n\n# A tibble: 5 × 3\n  AMB   HIB   REP  \n  <chr> <chr> <chr>\n1 A1    H1    I    \n2 A1    H1    I    \n3 A1    H1    I    \n4 A1    H1    I    \n5 A1    H1    I    \n\n# sequência de nomes\ndf |> select(AMB:REP)\n\n# A tibble: 5 × 3\n  AMB   HIB   REP  \n  <chr> <chr> <chr>\n1 A1    H1    I    \n2 A1    H1    I    \n3 A1    H1    I    \n4 A1    H1    I    \n5 A1    H1    I    \n\n# vector de posições\ndf |> select(1:3)\n\n# A tibble: 5 × 3\n  AMB   HIB   REP  \n  <chr> <chr> <chr>\n1 A1    H1    I    \n2 A1    H1    I    \n3 A1    H1    I    \n4 A1    H1    I    \n5 A1    H1    I    \n\n# negar a seleção\ndf |> select(!c(AMB:REP))\n\n# A tibble: 5 × 7\n  APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n       <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1       2.45       2.39  16.9  52.1  228.  375.    NA\n2       2.5        1.43  14.4  50.7  187.  437.   427\n3       2.69       1.52  16.5  54.7  230.  464.   497\n4       2.8        1.64  16.8  52.0  213.  408.   523\n5       2.62       1.55  15.9  51.6  224.  406.   551\n\n\n\n\nCom base na classe\nA função where() aplica uma função a todas as variáveis e seleciona aquelas para as quais a função retorna TRUE. Assim, podemos selecionar facilmente colunas com base em sua classe\n\n# seleciona variáveis numéricas\ndf |> select(where(is.numeric))\n\n# A tibble: 5 × 7\n  APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n       <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1       2.45       2.39  16.9  52.1  228.  375.    NA\n2       2.5        1.43  14.4  50.7  187.  437.   427\n3       2.69       1.52  16.5  54.7  230.  464.   497\n4       2.8        1.64  16.8  52.0  213.  408.   523\n5       2.62       1.55  15.9  51.6  224.  406.   551\n\n# seleciona variáveis não numéricas\ndf |> select(!where(is.numeric))\n\n# A tibble: 5 × 3\n  AMB   HIB   REP  \n  <chr> <chr> <chr>\n1 A1    H1    I    \n2 A1    H1    I    \n3 A1    H1    I    \n4 A1    H1    I    \n5 A1    H1    I    \n\n\n\n\nSelect helpers\nEssas funções permitem selecionar variáveis com base em seus nomes.\n\nstarts_with(): começa com um prefixo\n\n\ndf |> select(starts_with(\"C\"))\n\n# A tibble: 5 × 1\n   CESP\n  <dbl>\n1  16.9\n2  14.4\n3  16.5\n4  16.8\n5  15.9\n\n\n\nends_with(): termina com um prefixo\n\n\ndf |> select(ends_with(\"S\"))\n\n# A tibble: 5 × 1\n   DIES\n  <dbl>\n1  52.1\n2  50.7\n3  54.7\n4  52.0\n5  51.6\n\n# variáveis que começam com M e terminam com A\ndf |> select(starts_with(\"M\") & ends_with(\"A\"))\n\n# A tibble: 5 × 1\n   MGRA\n  <dbl>\n1  228.\n2  187.\n3  230.\n4  213.\n5  224.\n\n# variáveis que começam com M ou terminam com A\ndf |> select(starts_with(\"M\") | ends_with(\"A\"))\n\n# A tibble: 5 × 3\n   MGRA   MMG  NGRA\n  <dbl> <dbl> <dbl>\n1  228.  375.    NA\n2  187.  437.   427\n3  230.  464.   497\n4  213.  408.   523\n5  224.  406.   551\n\n\n\ncontains(): contém uma string literal\n\nSe as variáveis no conjunto de dados tiverem um padrão com diferenças entre um grupo de variáveis, podemos usar o código a seguir para selecionar variáveis com um padrão.\n\ndf |> select(contains(\"PLANT\"))\n\n# A tibble: 5 × 2\n  APLA_PLANT AIES_PLANT\n       <dbl>      <dbl>\n1       2.45       2.39\n2       2.5        1.43\n3       2.69       1.52\n4       2.8        1.64\n5       2.62       1.55\n\n\n\nmatches(): corresponde a uma expressão regular\n\nSeleções mais sofisticadas podem ser feitas usando matches(). Supondo que gostaríamos de selecionar as variáveis que começam com “A” e tem a segunda letra entre “A” e “M”, usaríamos algo como\n\ndf |> select(matches(\"^A[A-M]\"))\n\n# A tibble: 5 × 2\n  AMB   AIES_PLANT\n  <chr>      <dbl>\n1 A1          2.39\n2 A1          1.43\n3 A1          1.52\n4 A1          1.64\n5 A1          1.55\n\n\n\none_of(): variáveis no vetor de caracteres.\n\n\nvars <- c(\"TESTE\", \"CESP\", \"NGRA\", \"NAO_TEM\")\ndf |> select(one_of(vars))\n\nWarning: Unknown columns: `TESTE`, `NAO_TEM`\n\n\n# A tibble: 5 × 2\n   CESP  NGRA\n  <dbl> <dbl>\n1  16.9    NA\n2  14.4   427\n3  16.5   497\n4  16.8   523\n5  15.9   551\n\n\n\neverything(): todas as variáveis.\n\n\ndf |> select(everything())\n\n# A tibble: 5 × 10\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A1    H1    I           2.45       2.39  16.9  52.1  228.  375.    NA\n2 A1    H1    I           2.5        1.43  14.4  50.7  187.  437.   427\n3 A1    H1    I           2.69       1.52  16.5  54.7  230.  464.   497\n4 A1    H1    I           2.8        1.64  16.8  52.0  213.  408.   523\n5 A1    H1    I           2.62       1.55  15.9  51.6  224.  406.   551"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html#extrair-colunas",
    "href": "RGV410046/RGV410046_05_SELECAO.html#extrair-colunas",
    "title": "5. Seleção e filtragem",
    "section": "Extrair colunas",
    "text": "Extrair colunas\nNo R base, para extrair colunas de um data frame usamos $. A função pull() é semelhante a $, mas é mais fácil de ser utilizada com pipes. Para seleção, podemos especificar uma variável como:\n\num nome de variável literal\num inteiro positivo, dando a posição contando a partir da esquerda\num inteiro negativo, dando a posição contando a partir da direita.\nO padrão retorna a última coluna (supondo que seja a coluna que você criou mais recentemente).\n\nNote a diferença.\n\ndf$MGRA\n\n[1] 228.3716 186.6627 230.3904 213.4960 223.6949\n\n# padrão é a última coluna\ndf |> pull()\n\n[1]  NA 427 497 523 551\n\n# selecionar variável com base no nome\ndf |> pull(MGRA)\n\n[1] 228.3716 186.6627 230.3904 213.4960 223.6949\n\n# selecionar variável com base na sua posição\ndf |> pull(5)\n\n[1] 2.39 1.43 1.52 1.64 1.55"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html#realocar-colunas",
    "href": "RGV410046/RGV410046_05_SELECAO.html#realocar-colunas",
    "title": "5. Seleção e filtragem",
    "section": "Realocar colunas",
    "text": "Realocar colunas\nPara reordenar colunas em um data frame, podemos utilizar a função relocate() do pacote dplyr. Ela altera as posições das colunas, usando a mesma sintaxe que select() para facilitar a movimentação de blocos de colunas de uma só vez.\n\nrelocate(.data, ..., .before = NULL, .after = NULL)\n\nNesta função, as variáveis em … são movidas para antes de .before ou depois de .after.\n\ndf |> relocate(NGRA, .before = APLA_PLANT)\n\n# A tibble: 5 × 10\n  AMB   HIB   REP    NGRA APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG\n  <chr> <chr> <chr> <dbl>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A1    H1    I        NA       2.45       2.39  16.9  52.1  228.  375.\n2 A1    H1    I       427       2.5        1.43  14.4  50.7  187.  437.\n3 A1    H1    I       497       2.69       1.52  16.5  54.7  230.  464.\n4 A1    H1    I       523       2.8        1.64  16.8  52.0  213.  408.\n5 A1    H1    I       551       2.62       1.55  15.9  51.6  224.  406.\n\ndf |> relocate(contains(\"_PLANT\"), .after = last_col())\n\n# A tibble: 5 × 10\n  AMB   HIB   REP    CESP  DIES  MGRA   MMG  NGRA APLA_PLANT AIES_PLANT\n  <chr> <chr> <chr> <dbl> <dbl> <dbl> <dbl> <dbl>      <dbl>      <dbl>\n1 A1    H1    I      16.9  52.1  228.  375.    NA       2.45       2.39\n2 A1    H1    I      14.4  50.7  187.  437.   427       2.5        1.43\n3 A1    H1    I      16.5  54.7  230.  464.   497       2.69       1.52\n4 A1    H1    I      16.8  52.0  213.  408.   523       2.8        1.64\n5 A1    H1    I      15.9  51.6  224.  406.   551       2.62       1.55\n\ndf |> relocate(where(is.numeric), .before = where(is.character))\n\n# A tibble: 5 × 10\n  APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA AMB   HIB   REP  \n       <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr> <chr> <chr>\n1       2.45       2.39  16.9  52.1  228.  375.    NA A1    H1    I    \n2       2.5        1.43  14.4  50.7  187.  437.   427 A1    H1    I    \n3       2.69       1.52  16.5  54.7  230.  464.   497 A1    H1    I    \n4       2.8        1.64  16.8  52.0  213.  408.   523 A1    H1    I    \n5       2.62       1.55  15.9  51.6  224.  406.   551 A1    H1    I"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html#selecionar-linhas-com-base-em-seus-valores",
    "href": "RGV410046/RGV410046_05_SELECAO.html#selecionar-linhas-com-base-em-seus-valores",
    "title": "5. Seleção e filtragem",
    "section": "Selecionar linhas com base em seus valores",
    "text": "Selecionar linhas com base em seus valores\nUtilizando a função filter() é possivel filtrar as linhas de um conjunto de dados com base no valor de suas variáveis. No primeiro exemplo, selecionaremos as linhas onde o valor da variável MGRA é maior que 280.\n\nmaize %>% \n  filter(MGRA > 280)\n\n# A tibble: 4 × 10\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A1    H6    I           2.92       1.64  18    56.0  289.  393.   734\n2 A1    H10   I           2.92       1.61  20.3  55.4  283.  441.   641\n3 A1    H13   II          2.47       1.28  15.3  53.0  291.  417.   698\n4 A4    H10   I           2.65       1.47  14    50.3  287.  275.   493\n\n\nNo segundo exemplo, selecionaremos apenas as linhas onde a MGRA é maior que 220 OU a APLA é menor que 1.3 OU o NGRA é maior que 820.\n\nmaize %>% \n  filter(MGRA > 280 | APLA_PLANT < 1.3 | NGRA > 820)\n\n# A tibble: 13 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H6    I           2.92       1.64  18    56.0 289.   393.   734\n 2 A1    H10   I           2.92       1.61  20.3  55.4 283.   441.   641\n 3 A1    H13   II          2.47       1.28  15.3  53.0 291.   417.   698\n 4 A2    H8    II          1.03       0.69  10.8  44.8  94.8  277.   342\n 5 A2    H10   III         1.09       0.92  15    47.6 166.   299.   555\n 6 A2    H13   I           0          1.26  15.1  51.4 173.   375.   462\n 7 A3    H2    III         0          1.25  17.8  51.6 196.   348.   562\n 8 A3    H5    II          0          0.95  14.4  49.7 135.   213.   635\n 9 A3    H10   I           1.04       0.71  14.8  45.5 112.   265.   423\n10 A3    H11   I           1          0.65  14.5  43.6 120.   210.   571\n11 A4    H8    I           2.65       1.67  18    50   277.   251.   903\n12 A4    H8    I           2.95       1.7   18.6  52.9 249.   302.   824\n13 A4    H10   I           2.65       1.47  14    50.3 287.   275.   493\n\n\nNo último exemplo, selecionaremos apenas as linhas onde MGRA é maior que é maior que 220 E a APLA é menor que 2.\n\nmaize %>% \n  filter(MGRA > 220 & APLA_PLANT < 2)\n\n# A tibble: 1 × 10\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A1    H6    II          1.97       1.63  17.1  54.7  230.  375.   614\n\n\nIsto é aproximadamente equivalente ao seguinte código R base.\n\nmaize[maize$MGRA > 220 & maize$APLA_PLANT < 2, ]\n\nVocê também pode usar filter() para remover grupos inteiros. Por exemplo, o código a seguir elimina todas as linhas que contém o híbrido “H1”.\n\nmaize |> filter(HIB != \"H1\")\n\n# A tibble: 720 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H2    I           2.45       1.24  17.7  54.7 255.   422.   604\n 2 A1    H2    I           2.41       1.32  15    50.5 198.   369.   537\n 3 A1    H2    I           2.62       1.16  10    47.5  94.5  380.   249\n 4 A1    H2    I          NA          1.18  16.1  52.3 213.   331.   643\n 5 A1    H2    I           2.65       1.21  16.6  53.2 228.   409.   558\n 6 A1    H2    II          2.95       1.55  14.5  49.2 178.   258.   689\n 7 A1    H2    II          2.95       1.39  15.5  54.7 233.   284.   818\n 8 A1    H2    II          2.92       1.4   14    46.7 174.   288.   602\n 9 A1    H2    II          2.86       1.34  16.1  55.3 273.   356.   767\n10 A1    H2    II          2.84       1.35  15.5  51.6 204.   335.   607\n# … with 710 more rows\n\n# seleciona somente os híbridos H1 e H2\nmaize |> filter(HIB  %in%  c(\"H1\", \"H2\"))\n\n# A tibble: 120 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    I           2.45       2.39  16.9  52.1 228.   375.    NA\n 2 A1    H1    I           2.5        1.43  14.4  50.7 187.   437.   427\n 3 A1    H1    I           2.69       1.52  16.5  54.7 230.   464.   497\n 4 A1    H1    I           2.8        1.64  16.8  52.0 213.   408.   523\n 5 A1    H1    I           2.62       1.55  15.9  51.6 224.   406.   551\n 6 A1    H1    II          2.12       1.8   15    51.4 203.   383.   529\n 7 A1    H1    II          3.15       1.78  10.9  NA    75.2  256.   294\n 8 A1    H1    II          2.97       1.84  15    53.4 204.   387.   528\n 9 A1    H1    II          3.1        1.78  13.6  50.8 187.   348.   538\n10 A1    H1    II          3.02       1.6   16.3  53.9 250.   430.   582\n# … with 110 more rows"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html#selecionar-linhas-com-base-em-sua-posição",
    "href": "RGV410046/RGV410046_05_SELECAO.html#selecionar-linhas-com-base-em-sua-posição",
    "title": "5. Seleção e filtragem",
    "section": "Selecionar linhas com base em sua posição",
    "text": "Selecionar linhas com base em sua posição\nA função slice() permite indexar linhas por seus locais (inteiros). Ele permite selecionar, remover e duplicar linhas. Ele é acompanhado por vários auxiliares para casos de uso comuns:\n\nslice_head() e slice_tail() selecionam a primeira ou a última linha.\nslice_sample() seleciona linhas aleatoriamente.\nslice_min() e slice_max() selecionam linhas com valores mais altos ou mais baixos de uma variável.\n\n\n# selciona as primeiras três linhas\nmaize |> slice(1:3)\n\n# A tibble: 3 × 10\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A1    H1    I           2.45       2.39  16.9  52.1  228.  375.    NA\n2 A1    H1    I           2.5        1.43  14.4  50.7  187.  437.   427\n3 A1    H1    I           2.69       1.52  16.5  54.7  230.  464.   497\n\n# cinco linhas aleatórias\nmaize |> slice_sample(n = 5)\n\n# A tibble: 5 × 10\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A1    H9    I          NA          1.76  11.9  51.0  125.  423.   295\n2 A1    H6    I           2.91       1.47  17.1  57.3  280.  420.   665\n3 A2    H2    II          3.06       1.91  15    54.4  198.  501.   396\n4 A4    H2    II          2.7        1.52  16.8  50.0  203.  363.   559\n5 A1    H13   III         3.06       1.93  14.4  54.0  183.  382.   478\n\n# dois menores valores de MGRA\nmaize |> slice_min(n = 2, MGRA)\n\n# A tibble: 2 × 10\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A1    H9    III         2.72       1.54  11    42.8  58.5  295.   198\n2 A2    H8    I           1.92       0.63  12.1  39.7  59.5  243.   245\n\n# maior valor de NGRA\nmaize |> slice_max(n = 1, NGRA)\n\n# A tibble: 1 × 10\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 A4    H8    I           2.65       1.67    18    50  277.  251.   903"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html#ordenar-linhas-com-base-em-seus-valores",
    "href": "RGV410046/RGV410046_05_SELECAO.html#ordenar-linhas-com-base-em-seus-valores",
    "title": "5. Seleção e filtragem",
    "section": "Ordenar linhas com base em seus valores",
    "text": "Ordenar linhas com base em seus valores\nA função arrange() é utilizada para ordenar as linhas de um tibble (ou data.frames) com base em uma expressão envolvendo suas variáveis.\n\n# ordena as linhas com base na variável CESP (crescente)\nmaize |> arrange(CESP)\n\n# A tibble: 780 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H9    I          NA          1.51 0.800  54.0 224.   420.   533\n 2 A1    H8    I           2.6        1.4  5.9    52.2 225.   383.   588\n 3 A3    H8    III         1.86       0.96 7.5    40.8  73.0  293.   249\n 4 A1    H5    II          2.83       1.82 8.2    43.2  94.6  326.   290\n 5 A4    H3    II          2.37       1.12 8.2    47.4  96.0  256.   375\n 6 A2    H9    I           2.02       1.11 8.7    46.7  61.2  312.   196\n 7 A4    H3    II          2.22       1.02 8.9    41.6  77.8  218.   357\n 8 A3    H1    III         2.45       1.29 9      51.0  78.9  503.   157\n 9 A2    H3    I           2.82       1.87 9.3    47.2 105.   294.   358\n10 A1    H2    III         2.86       1.52 9.4    51.2  91.0  225.   405\n# … with 770 more rows\n\n# ordena as linhas com base na variável CESP (decrescente)\nmaize |> arrange(desc(CESP))\n\n# A tibble: 780 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A4    H7    III         2.6        1.37  20.4  52    253.  408.   620\n 2 A1    H10   I           2.92       1.61  20.3  55.4  283.  441.   641\n 3 A3    H1    I           2          1.05  19.9  53.3  253.  444.   570\n 4 A1    H10   III         2.29       1.15  19.8  55.9  276.  411.   671\n 5 A3    H2    II          2.08       0.93  19.6  52.9  220.  384.   574\n 6 A3    H9    III         2.07       1     19.6  48.2  190.  307.   617\n 7 A4    H8    III         2.6        1.5   19.5  56.1  264.  402.   657\n 8 A2    H6    III         3.18       1.62  19.2  53.0  270.  382.   708\n 9 A4    H7    III         2.76       1.54  19.2  54.1  254.  417.   610\n10 A1    H9    I           2.69       1.8   19    52.4  226.  428.   529\n# … with 770 more rows\n\n\nAo combinar a função group_by() com arrange() é possível realizar o ordenamento para cada nível de um determinado fator. No exemplo abaixo, a variável APLA é ordenada de maneira crescente para cada híbrido.\n\nmaize %>%\n  group_by(HIB) %>%\n  arrange(MGRA, .by_group = TRUE)\n\n# A tibble: 780 × 10\n# Groups:   HIB [13]\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    II          3.15       1.78  10.9  NA    75.2  256.   294\n 2 A3    H1    III         2.45       1.29   9    51.0  78.9  503.   157\n 3 A3    H1    I           2.13       1.05  11.6  47.0  89.5  300.   298\n 4 A3    H1    II          2.18       1.04  13    46.6 103.   351.   293\n 5 A3    H1    II          2.08       0.94  12    47.6 103.   334.   309\n 6 A3    H1    I           2.07       1.05  13.2  47.9 110.   293.   377\n 7 A3    H1    II          1.93       0.93  13    50.0 120.   276.   433\n 8 A2    H1    III         3.11       1.9   13    50.8 131.   402.   325\n 9 A4    H1    I           2.3        1.25  13.1  50.0 140.   230.   609\n10 A3    H1    II          2.39       1.21  14    50.2 144.   331.   435\n# … with 770 more rows"
  },
  {
    "objectID": "RGV410046/RGV410046_05_SELECAO.html#outras-funções-úteis",
    "href": "RGV410046/RGV410046_05_SELECAO.html#outras-funções-úteis",
    "title": "5. Seleção e filtragem",
    "section": "Outras funções úteis",
    "text": "Outras funções úteis\nAlgumas funções do pacote metan podem ser úteis para trabalhar com dados faltantes. Abaixo, alguns exemplos são mostrados.\n\n# seleciona linhas com NA\nmaize |> select_rows_na()\n\nWarning: Rows(s) with NAs: 1, 7, 19, 124, 125, 257, 258, 259, 318, 319, 549,\n550, 551, 552\n\n\n# A tibble: 14 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT   CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    I           2.45       2.39 16.9    52.1 228.   375.    NA\n 2 A1    H1    II          3.15       1.78 10.9    NA    75.2  256.   294\n 3 A1    H2    I          NA          1.18 16.1    52.3 213.   331.   643\n 4 A1    H9    I          NA          1.76 11.9    51.0 125.   423.   295\n 5 A1    H9    I          NA          1.51  0.800  54.0 224.   420.   533\n 6 A2    H5    I          NA          1.45 16.4    47.5 187.   306.   610\n 7 A2    H5    I          NA          1.42 16.9    47.4 192.   382.   504\n 8 A2    H5    I          NA          1.55 14      48.3 163.   355.   458\n 9 A2    H9    I          NA          0.83 13.2    41.8 114.   218.   521\n10 A2    H9    I          NA          1.1  14.2    43.9 119.   186.   640\n11 A3    H11   II          2.3        1    NA      45.1  99.8  303.   329\n12 A3    H11   II          2.12       1.03 NA      47.8 104.   276.   375\n13 A3    H11   III         2.4        1.3  NA      49.6 125.   277.   451\n14 A3    H11   III         2.58       1.28 NA      46.8 177.   338.   523\n\n# remove linhas com NA\nmaize |> remove_rows_na()\n\nWarning: Row(s) 1, 7, 19, 124, 125, 257, 258, 259, 318, 319, 549, 550, 551, 552\nwith NA values deleted.\n\n\n# A tibble: 766 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    I           2.5        1.43  14.4  50.7  187.  437.   427\n 2 A1    H1    I           2.69       1.52  16.5  54.7  230.  464.   497\n 3 A1    H1    I           2.8        1.64  16.8  52.0  213.  408.   523\n 4 A1    H1    I           2.62       1.55  15.9  51.6  224.  406.   551\n 5 A1    H1    II          2.12       1.8   15    51.4  203.  383.   529\n 6 A1    H1    II          2.97       1.84  15    53.4  204.  387.   528\n 7 A1    H1    II          3.1        1.78  13.6  50.8  187.  348.   538\n 8 A1    H1    II          3.02       1.6   16.3  53.9  250.  430.   582\n 9 A1    H1    III         2.69       1.52  15.6  49.5  195.  369.   529\n10 A1    H1    III         2.6        1.68  14.3  48.9  172.  344.   500\n# … with 756 more rows\n\n# substitu NA por 0\nmaize |> replace_na()\n\n# A tibble: 780 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    I           2.45       2.39  16.9  52.1 228.   375.     0\n 2 A1    H1    I           2.5        1.43  14.4  50.7 187.   437.   427\n 3 A1    H1    I           2.69       1.52  16.5  54.7 230.   464.   497\n 4 A1    H1    I           2.8        1.64  16.8  52.0 213.   408.   523\n 5 A1    H1    I           2.62       1.55  15.9  51.6 224.   406.   551\n 6 A1    H1    II          2.12       1.8   15    51.4 203.   383.   529\n 7 A1    H1    II          3.15       1.78  10.9   0    75.2  256.   294\n 8 A1    H1    II          2.97       1.84  15    53.4 204.   387.   528\n 9 A1    H1    II          3.1        1.78  13.6  50.8 187.   348.   538\n10 A1    H1    II          3.02       1.6   16.3  53.9 250.   430.   582\n# … with 770 more rows\n\n# substitui NA pela média da coluna (cuidado!!!)\nmaize |> replace_na(replacement = \"colmean\")\n\n# A tibble: 780 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    I           2.45       2.39  16.9  52.1 228.   375.  512.\n 2 A1    H1    I           2.5        1.43  14.4  50.7 187.   437.  427 \n 3 A1    H1    I           2.69       1.52  16.5  54.7 230.   464.  497 \n 4 A1    H1    I           2.8        1.64  16.8  52.0 213.   408.  523 \n 5 A1    H1    I           2.62       1.55  15.9  51.6 224.   406.  551 \n 6 A1    H1    II          2.12       1.8   15    51.4 203.   383.  529 \n 7 A1    H1    II          3.15       1.78  10.9  49.5  75.2  256.  294 \n 8 A1    H1    II          2.97       1.84  15    53.4 204.   387.  528 \n 9 A1    H1    II          3.1        1.78  13.6  50.8 187.   348.  538 \n10 A1    H1    II          3.02       1.6   16.3  53.9 250.   430.  582 \n# … with 770 more rows"
  },
  {
    "objectID": "RGV410046/RGV410046_06_MUTACAO.html",
    "href": "RGV410046/RGV410046_06_MUTACAO.html",
    "title": "6. Mutação",
    "section": "",
    "text": "# meu computador (mudar de acordo)\nsetwd(\"E:/Desktop/UFSC/aulas/classes/RGV410046/data\")"
  },
  {
    "objectID": "RGV410046/RGV410046_06_MUTACAO.html#geral",
    "href": "RGV410046/RGV410046_06_MUTACAO.html#geral",
    "title": "6. Mutação",
    "section": "Geral",
    "text": "Geral\n\n\n\nFonte: https://dplyr.tidyverse.org/index.html\n\n\nA função mutate() é utilizada quando se deseja adicionar novas variáveis no conjunto de dados. Estas variáveis são funções de variáveis existentes. Como exemplo, vamos criar uma nova variável chamada CD no conjunto de dados maize, qual será a razão entre CESP e DIES. Note que a função adiciona a nova variável após a última variável origina e mantém todas as demais. Você pode controlar a posição da nova variável criada utilizando os argumentos .before e .after (assim como na função relocate()) e quais variáveis são mantidas utilizando o argumento .keep.\n\n# padrão: nova variável inserida na última posição\nmaize %>% mutate(CD = CESP/DIES)\n\n# A tibble: 780 × 11\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA     CD\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n 1 A1    H1    I           2.45       2.39  16.9  52.1 228.   375.    NA  0.324\n 2 A1    H1    I           2.5        1.43  14.4  50.7 187.   437.   427  0.284\n 3 A1    H1    I           2.69       1.52  16.5  54.7 230.   464.   497  0.302\n 4 A1    H1    I           2.8        1.64  16.8  52.0 213.   408.   523  0.323\n 5 A1    H1    I           2.62       1.55  15.9  51.6 224.   406.   551  0.308\n 6 A1    H1    II          2.12       1.8   15    51.4 203.   383.   529  0.292\n 7 A1    H1    II          3.15       1.78  10.9  NA    75.2  256.   294 NA    \n 8 A1    H1    II          2.97       1.84  15    53.4 204.   387.   528  0.281\n 9 A1    H1    II          3.1        1.78  13.6  50.8 187.   348.   538  0.267\n10 A1    H1    II          3.02       1.6   16.3  53.9 250.   430.   582  0.302\n# … with 770 more rows\n\n# posição da nova variável\nmaize %>% mutate(CD = CESP/DIES, \n                 .after = DIES)\n\n# A tibble: 780 × 11\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES     CD  MGRA   MMG  NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    I           2.45       2.39  16.9  52.1  0.324 228.   375.    NA\n 2 A1    H1    I           2.5        1.43  14.4  50.7  0.284 187.   437.   427\n 3 A1    H1    I           2.69       1.52  16.5  54.7  0.302 230.   464.   497\n 4 A1    H1    I           2.8        1.64  16.8  52.0  0.323 213.   408.   523\n 5 A1    H1    I           2.62       1.55  15.9  51.6  0.308 224.   406.   551\n 6 A1    H1    II          2.12       1.8   15    51.4  0.292 203.   383.   529\n 7 A1    H1    II          3.15       1.78  10.9  NA   NA      75.2  256.   294\n 8 A1    H1    II          2.97       1.84  15    53.4  0.281 204.   387.   528\n 9 A1    H1    II          3.1        1.78  13.6  50.8  0.267 187.   348.   538\n10 A1    H1    II          3.02       1.6   16.3  53.9  0.302 250.   430.   582\n# … with 770 more rows\n\n# mantém somente as utilizadas no cálculo\nmaize %>% mutate(CD = CESP/DIES,\n                 .keep = \"used\")\n\n# A tibble: 780 × 3\n    CESP  DIES     CD\n   <dbl> <dbl>  <dbl>\n 1  16.9  52.1  0.324\n 2  14.4  50.7  0.284\n 3  16.5  54.7  0.302\n 4  16.8  52.0  0.323\n 5  15.9  51.6  0.308\n 6  15    51.4  0.292\n 7  10.9  NA   NA    \n 8  15    53.4  0.281\n 9  13.6  50.8  0.267\n10  16.3  53.9  0.302\n# … with 770 more rows\n\n# mantém as não utilizadas\nmaize %>% mutate(CD = CESP/DIES,\n                 .keep = \"unused\")\n\n# A tibble: 780 × 9\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  MGRA   MMG  NGRA     CD\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl>  <dbl>\n 1 A1    H1    I           2.45       2.39 228.   375.    NA  0.324\n 2 A1    H1    I           2.5        1.43 187.   437.   427  0.284\n 3 A1    H1    I           2.69       1.52 230.   464.   497  0.302\n 4 A1    H1    I           2.8        1.64 213.   408.   523  0.323\n 5 A1    H1    I           2.62       1.55 224.   406.   551  0.308\n 6 A1    H1    II          2.12       1.8  203.   383.   529  0.292\n 7 A1    H1    II          3.15       1.78  75.2  256.   294 NA    \n 8 A1    H1    II          2.97       1.84 204.   387.   528  0.281\n 9 A1    H1    II          3.1        1.78 187.   348.   538  0.267\n10 A1    H1    II          3.02       1.6  250.   430.   582  0.302\n# … with 770 more rows\n\n# mantém somente a variável criada\nmaize %>% mutate(CD = CESP/DIES,\n                 .keep = \"none\")\n\n# A tibble: 780 × 1\n       CD\n    <dbl>\n 1  0.324\n 2  0.284\n 3  0.302\n 4  0.323\n 5  0.308\n 6  0.292\n 7 NA    \n 8  0.281\n 9  0.267\n10  0.302\n# … with 770 more rows"
  },
  {
    "objectID": "RGV410046/RGV410046_06_MUTACAO.html#mutação-por-grupos",
    "href": "RGV410046/RGV410046_06_MUTACAO.html#mutação-por-grupos",
    "title": "6. Mutação",
    "section": "Mutação por grupos",
    "text": "Mutação por grupos\n\n\n\n\n\nA função group_by() pode ser utilizada para realizar mutação dentro de cada nível de uma ou mais variáveis categóricas. Para este exemplo, vamos criar uma variável (rank) que será o rankeamento das observações dentro de cada híbrido com base na MGRA (em ordem decrescente).\n\nmaize |> \n  group_by(HIB) |> \n  mutate(rank = rank(desc(MGRA)))\n\n# A tibble: 780 × 11\n# Groups:   HIB [13]\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA  rank\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1 A1    H1    I           2.45       2.39  16.9  52.1 228.   375.    NA     8\n 2 A1    H1    I           2.5        1.43  14.4  50.7 187.   437.   427    33\n 3 A1    H1    I           2.69       1.52  16.5  54.7 230.   464.   497     7\n 4 A1    H1    I           2.8        1.64  16.8  52.0 213.   408.   523    15\n 5 A1    H1    I           2.62       1.55  15.9  51.6 224.   406.   551     9\n 6 A1    H1    II          2.12       1.8   15    51.4 203.   383.   529    22\n 7 A1    H1    II          3.15       1.78  10.9  NA    75.2  256.   294    60\n 8 A1    H1    II          2.97       1.84  15    53.4 204.   387.   528    21\n 9 A1    H1    II          3.1        1.78  13.6  50.8 187.   348.   538    31\n10 A1    H1    II          3.02       1.6   16.3  53.9 250.   430.   582     5\n# … with 770 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nO ranqueamento acima foi obtido com base no ranqueamento, utilizando a função slice_min(). Execute o código abaixo e veja o que acontece.\n\nmaize |> \n  group_by(HIB) |> \n  slice_max(MGRA, n = 2)\n\n\n\nEm alguns casos, um agrupamento específico onde cada linha é considerada um grupo pode ser útil. Isto pode ser realizado com a função rowwise(). Como group_by(), rowwise() não faz nada sozinha; apenas muda a forma como os outros verbos (ex., mutate, summarise funcionam). Por exemplo, compare os resultados de mutate() no código a seguir:\n\ndf <- tibble(x = 1:2, y = 3:4, z = 5:6)\n# sem rowise()\ndf |> mutate(m = sum(c(x, y, z)))\n\n# A tibble: 2 × 4\n      x     y     z     m\n  <int> <int> <int> <int>\n1     1     3     5    21\n2     2     4     6    21\n\n# com rowise()\ndf |>\n  rowwise() |> \n  mutate(soma = sum(c(x, y, z)))\n\n# A tibble: 2 × 4\n# Rowwise: \n      x     y     z  soma\n  <int> <int> <int> <int>\n1     1     3     5     9\n2     2     4     6    12\n\n# mesmo resultado\n# utilizando semântica tidyselect \ndf |>\n  rowwise() |> \n  mutate(soma = sum(c_across(x:z)))\n\n# A tibble: 2 × 4\n# Rowwise: \n      x     y     z  soma\n  <int> <int> <int> <int>\n1     1     3     5     9\n2     2     4     6    12"
  },
  {
    "objectID": "RGV410046/RGV410046_06_MUTACAO.html#mutação-de-várias-variáveis",
    "href": "RGV410046/RGV410046_06_MUTACAO.html#mutação-de-várias-variáveis",
    "title": "6. Mutação",
    "section": "Mutação de várias variáveis",
    "text": "Mutação de várias variáveis\n\n\n\nFonte: https://dplyr.tidyverse.org/reference/across.html\n\n\nEm alguns casos, deseja-se aplicar a mesma função de mutação (ou resumo) à várias variáveis. A função across() facilita a aplicação da mesma transformação a várias colunas, permitindo que você use a semântica select() dentro de funções como summarise() e mutate(). Como exemplo de aplicação, vamos criar uma função para rescalar uma variável para uma amplitude 0-1 e aplicar essa função à todas as colunas numéricas do conjunto maize.\n\n# função para rescalar\nrescale <- function(x) {\n  rng <- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\n# aplica a função rescale() a todas as colunas numéricas\nmaize %>% mutate(across(where(is.numeric), rescale))\n\n# A tibble: 780 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP   DIES   MGRA   MMG   NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl>\n 1 A1    H1    I          0.742      1     0.821  0.674 0.730  0.596 NA    \n 2 A1    H1    I          0.758      0.492 0.694  0.611 0.551  0.742  0.370\n 3 A1    H1    I          0.815      0.540 0.801  0.786 0.739  0.805  0.463\n 4 A1    H1    I          0.848      0.603 0.816  0.670 0.666  0.674  0.497\n 5 A1    H1    I          0.794      0.556 0.770  0.652 0.710  0.669  0.534\n 6 A1    H1    II         0.642      0.688 0.724  0.645 0.620  0.615  0.505\n 7 A1    H1    II         0.955      0.677 0.515 NA     0.0717 0.314  0.194\n 8 A1    H1    II         0.9        0.709 0.724  0.728 0.627  0.624  0.504\n 9 A1    H1    II         0.939      0.677 0.653  0.620 0.553  0.532  0.517\n10 A1    H1    II         0.915      0.582 0.791  0.752 0.825  0.726  0.575\n# … with 770 more rows\n\n# aplica a função rescale() para algumas colunas\nmaize %>% mutate(across(MGRA:NGRA, rescale))\n\n# A tibble: 780 × 10\n   AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES   MGRA   MMG   NGRA\n   <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>\n 1 A1    H1    I           2.45       2.39  16.9  52.1 0.730  0.596 NA    \n 2 A1    H1    I           2.5        1.43  14.4  50.7 0.551  0.742  0.370\n 3 A1    H1    I           2.69       1.52  16.5  54.7 0.739  0.805  0.463\n 4 A1    H1    I           2.8        1.64  16.8  52.0 0.666  0.674  0.497\n 5 A1    H1    I           2.62       1.55  15.9  51.6 0.710  0.669  0.534\n 6 A1    H1    II          2.12       1.8   15    51.4 0.620  0.615  0.505\n 7 A1    H1    II          3.15       1.78  10.9  NA   0.0717 0.314  0.194\n 8 A1    H1    II          2.97       1.84  15    53.4 0.627  0.624  0.504\n 9 A1    H1    II          3.1        1.78  13.6  50.8 0.553  0.532  0.517\n10 A1    H1    II          3.02       1.6   16.3  53.9 0.825  0.726  0.575\n# … with 770 more rows\n\n\nTambém é possível utilizar a semântica select() dentro de across(). Isso significa que select helpers podem ser utilizados. No exemplo abaixo apenas as variáveis que contém \"_PLANT\" são mutadas, sendo que os valores destas variáveis são divididos por 2.\n\n# usando select helpers\n# divide o valor da variável pela metade\n# atribui um sufixo para as novas variáveis\n# seleciona apenas as utilizadas\nmaize %>%\n  mutate(across(contains(\"_PLANT\"), ~.x / 2,\n                .names = \"{.col}_metade\"),\n         .after = AIES_PLANT,\n         .keep = \"used\")\n\n# A tibble: 780 × 4\n   APLA_PLANT AIES_PLANT APLA_PLANT_metade AIES_PLANT_metade\n        <dbl>      <dbl>             <dbl>             <dbl>\n 1       2.45       2.39              1.23             1.20 \n 2       2.5        1.43              1.25             0.715\n 3       2.69       1.52              1.34             0.76 \n 4       2.8        1.64              1.4              0.82 \n 5       2.62       1.55              1.31             0.775\n 6       2.12       1.8               1.06             0.9  \n 7       3.15       1.78              1.58             0.89 \n 8       2.97       1.84              1.48             0.92 \n 9       3.1        1.78              1.55             0.89 \n10       3.02       1.6               1.51             0.8  \n# … with 770 more rows"
  },
  {
    "objectID": "RGV410046/RGV410046_06_MUTACAO.html#mutação-condicional",
    "href": "RGV410046/RGV410046_06_MUTACAO.html#mutação-condicional",
    "title": "6. Mutação",
    "section": "Mutação condicional",
    "text": "Mutação condicional\nÉ muito comum comum que condicionantes sejam necessárias quando alguma nova variável for criada. Abaixo, um pequeno exemplo contendo notas de 10 alunos é utilizado.\n\nset.seed(5)\nnotas <- \n  data.frame(aluno = paste0(\"Aluno\", 1:10),\n             nota = runif(10, 3, 10) |> round(1))\nnotas\n\n     aluno nota\n1   Aluno1  4.4\n2   Aluno2  7.8\n3   Aluno3  9.4\n4   Aluno4  5.0\n5   Aluno5  3.7\n6   Aluno6  7.9\n7   Aluno7  6.7\n8   Aluno8  8.7\n9   Aluno9  9.7\n10 Aluno10  3.8\n\n\nOs objetivos aqui são:\n\nCriar uma nova variável em notas contendo a classe que tal aluno foi classificado dependendo de sua nota, com as seguintes condições:\n\nNota menor que 4: reprovado\nNota de 4 a menos que 7: exame\nNota igual ou maior que 7: aprovado\n\nOrdenar as notas em ordem decrescente (do maior para o menor).\n\n\nifelse() com R base\nA função ifelse() retorna um valor com a mesma forma de test que é preenchido com elementos selecionados de yes ou no, dependendo se o elemento de test é TRUE ou FALSE. Para criação da nova coluna baseado nas notas em notas, utiliza-se a seguinte abordagem. Note que como temos três classes (aprovado, reprovado ou exame) e ifelse() somente retorna duas dependendo se o teste é TRUE ou FALSE, precisamos aninhar ifelse()s.\n\nclasse <- \n  transform(notas,\n            condicao = ifelse(nota < 4,\n                           yes = \"reprovado\", \n                           no = ifelse(nota >= 4 & nota < 7,\n                                       yes = \"exame\",\n                                       no = \"aprovado\")))\nclasse[order(classe$nota, decreasing = TRUE), ]\n\n     aluno nota  condicao\n9   Aluno9  9.7  aprovado\n3   Aluno3  9.4  aprovado\n8   Aluno8  8.7  aprovado\n6   Aluno6  7.9  aprovado\n2   Aluno2  7.8  aprovado\n7   Aluno7  6.7     exame\n4   Aluno4  5.0     exame\n1   Aluno1  4.4     exame\n10 Aluno10  3.8 reprovado\n5   Aluno5  3.7 reprovado\n\n\n\n\ncase_when() com dplyr\ncase_when() pode ser vista como uma versão vetorizada de ifelse() que permite que você avalie várias instruções. Se nenhum caso corresponder, NA será retornado. Esta função é particularmente útil dentro da função mutate() quando você quer criar uma nova variável que depende de uma combinação complexa de variáveis existentes.\nA função é baseada em uma sequência de fórmulas de dois lados. O lado esquerdo (LHS) determina o teste; O lado direito (RHS) fornece o valor de substituição.\n\nnotas |> \n  mutate(condicao = case_when(\n    nota < 4 ~ \"reprovado\",\n    between(nota, 4, 6.99999999) ~ \"exame\", # mesmo que nota >= 4 & nota < 7\n    TRUE ~ \"aprovado\" # TRUE: o que não foi incluso nas duas avaliações anteriores\n  )) |> \n  arrange(desc(nota))\n\n     aluno nota  condicao\n1   Aluno9  9.7  aprovado\n2   Aluno3  9.4  aprovado\n3   Aluno8  8.7  aprovado\n4   Aluno6  7.9  aprovado\n5   Aluno2  7.8  aprovado\n6   Aluno7  6.7     exame\n7   Aluno4  5.0     exame\n8   Aluno1  4.4     exame\n9  Aluno10  3.8 reprovado\n10  Aluno5  3.7 reprovado\n\n\nNeste exemplo, o conjunto de dados maize é utilizado para mostrar como uma variável qualitativa nominal pode ser criada utilizando a função case_when(). A nova variável será criada dependendo dos valores de APLA, AIES ou CESP. Ao agrupar pela nova variável categórica criada e utilizar a função slice_sample(), um exemplo de cada nível é amostrado aleatoriamente.\n\nset.seed(10)\n\nmaize %>% \n  mutate(\n    CASO = case_when(\n      MGRA > 280 | APLA_PLANT < 1.3 | NGRA > 820 ~  \"Selecionar\",\n      APLA_PLANT > 2.3 ~ \"Alto\",\n      MGRA < 130 ~ \"Pouco produtivo\",\n      TRUE ~ \"Outro\"\n    )\n  ) |> \n  group_by(CASO) |> \n  slice_sample(n = 1)\n\n# A tibble: 4 × 11\n# Groups:   CASO [4]\n  AMB   HIB   REP   APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA CASO    \n  <chr> <chr> <chr>      <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>   \n1 A1    H10   III         3.11       1.86  15.5  50.2 194.   405.   479 Alto    \n2 A3    H2    II          2.04       0.92  14.7  47.2 130.   362.   360 Outro   \n3 A3    H9    I           2.24       1.17  13    42.6  92.6  384.   241 Pouco p…\n4 A3    H2    III         0          1.25  17.8  51.6 196.   348.   562 Selecio…\n\n\n\n\n\n\n\n\nAbordagem R base\n\n\n\nO seguinte exemplo realiza o mesmo procedimento de criação da variável categórica utilizando as funções R base transform() e ifelse().\n\nmilho2 <- \ntransform(maize, \n          CASO = ifelse(MGRA > 280 | APLA_PLANT < 1.3 | NGRA > 820, \"Selecionar\",\n                        ifelse(APLA_PLANT > 2.3, \"Alto\",\n                               ifelse(MGRA < 130, \"Pouco produtivo\",\n                                      \"Outro\"))))\n# cria uma lista onde cada elemento é um nível de CASO\ncasos <- split(milho2, milho2$CASO)\n\n# percorre a lista e amostra uma linha aleatória de cada uma\n# junta com rbind()\n\nset.seed(10)\ndo.call(rbind,\n  lapply(casos, function(x){\n    x[sample(nrow(x), 1), ]\n  })\n)\n\n                AMB HIB REP APLA_PLANT AIES_PLANT CESP  DIES      MGRA      MMG\nAlto             A1 H10 III       3.01       1.64 17.0 54.27 210.78954 419.0647\nOutro            A3  H3   I       2.28       1.19 14.3 51.62 162.09701 305.2674\nPouco produtivo  A3  H9  II       1.80       0.58 12.4 42.47  73.97816 271.9785\nSelecionar       A3  H2 III       0.00       1.25 17.8 51.57 195.59343 348.0310\n                NGRA            CASO\nAlto             503            Alto\nOutro            531           Outro\nPouco produtivo  272 Pouco produtivo\nSelecionar       562      Selecionar\n\n\n\n\nFree website hit counter"
  },
  {
    "objectID": "RGV410046/RGV410046_07_RESUMO.html",
    "href": "RGV410046/RGV410046_07_RESUMO.html",
    "title": "7. Sintetização",
    "section": "",
    "text": "# meu computador (mudar de acordo)\nsetwd(\"E:/Desktop/UFSC/aulas/classes/RGV410046/data\")"
  },
  {
    "objectID": "RGV410046/RGV410046_07_RESUMO.html#uma-variável-uma-estatística",
    "href": "RGV410046/RGV410046_07_RESUMO.html#uma-variável-uma-estatística",
    "title": "7. Sintetização",
    "section": "Uma variável, uma estatística",
    "text": "Uma variável, uma estatística\nDiversos verbos do pacote dplyr podem ser utilizados para resumir conjuntos de dados. Iniciaremos com a função count() para contar valores que se repetem em uma determinada variável. Por exemplo, é possível identificar qual é o valor de NGRA que mais se repete utilizando\n\nmaize |> count(NGRA, sort = TRUE)\n\n# A tibble: 367 × 2\n    NGRA     n\n   <dbl> <int>\n 1   419     8\n 2   513     8\n 3   503     7\n 4   528     7\n 5   529     7\n 6   538     7\n 7   451     6\n 8   481     6\n 9   493     6\n10   530     6\n# … with 357 more rows\n\n\nPara identificar quais os valores distintos de NGRA foram observados a função distinct() é usada.\n\nmaize |> distinct(NGRA)\n\n# A tibble: 367 × 1\n    NGRA\n   <dbl>\n 1    NA\n 2   427\n 3   497\n 4   523\n 5   551\n 6   529\n 7   294\n 8   528\n 9   538\n10   582\n# … with 357 more rows"
  },
  {
    "objectID": "RGV410046/RGV410046_07_RESUMO.html#uma-variável-diversas-estatísticas",
    "href": "RGV410046/RGV410046_07_RESUMO.html#uma-variável-diversas-estatísticas",
    "title": "7. Sintetização",
    "section": "Uma variável, diversas estatísticas",
    "text": "Uma variável, diversas estatísticas\nUtilizando a função summarise() é possível criar uma ou mais variáveis escalares resumindo as variáveis de um data frame existente. Como resultado, uma linha e várias colunas é retornada. O seguinte código calcula a média global e o desvio padrão amostral da variável MGRA eretorna o n utilizado na estimativa.\n\nmaize %>% \n  summarise(MGRA_mean = mean(MGRA),\n            MGRA_sd = sd(MGRA),\n            n = n())\n\n# A tibble: 1 × 3\n  MGRA_mean MGRA_sd     n\n      <dbl>   <dbl> <int>\n1      173.    47.6   780\n\n\nMuitas vezes é necessário computar uma determinada função (como a média) para cada nível de uma variável categórica. Continuamos no mesmo exemplo anterior, mas agora neste caso, o objetivo é calcular a média da MGRA para cada híbrido. Utilizando a função group_by() antes da função summarise() uma linha de resultado para cada nível do fator híbrido é retornado.\n\nmaize %>% \n  group_by(HIB) %>%\n  summarise(MGRA_mean = mean(MGRA),\n            MGRA_sd = sd(MGRA),\n            n = n())\n\n# A tibble: 13 × 4\n   HIB   MGRA_mean MGRA_sd     n\n   <chr>     <dbl>   <dbl> <int>\n 1 H1         184.    43.9    60\n 2 H10        164.    50.1    60\n 3 H11        167.    40.6    60\n 4 H12        157.    45.1    60\n 5 H13        180.    44.3    60\n 6 H2         187.    46.0    60\n 7 H3         169.    48.2    60\n 8 H4         184.    35.7    60\n 9 H5         184.    41.1    60\n10 H6         188.    52.7    60\n11 H7         171.    44.0    60\n12 H8         160.    53.8    60\n13 H9         153.    55.2    60"
  },
  {
    "objectID": "RGV410046/RGV410046_07_RESUMO.html#diversas-variáveis-uma-estatística",
    "href": "RGV410046/RGV410046_07_RESUMO.html#diversas-variáveis-uma-estatística",
    "title": "7. Sintetização",
    "section": "Diversas variáveis, uma estatística",
    "text": "Diversas variáveis, uma estatística\nAté aqui vimos como a média (global ou para cada híbrido) da MGRA pode ser calculada. Quase sempre, no entanto, quando calculamos a média (ou qualquer outra medida) em um conjunto de dados, queremos fazê-la para todas (ou algumas) variáveis numéricas dos dados. Implementar isto com dplyr é relativamente fácil. Para isto, é utilizada a função across() que aplica uma função (ou um conjunto de funções) a um conjunto de colunas. Veremos como across() pode ser utilizada para calcular a média para as variáveis numéricas do conjunto maize. No exemplo abaixo, where() aplica uma função (neste caso is.numeric()) a todas as variáveis e seleciona aquelas para as quais a função retorna TRUE. Assim, a média somente é calculada para as variáveis numéricas.\n\nmaize %>% \n  summarise(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 1 × 7\n  APLA_PLANT AIES_PLANT  CESP  DIES  MGRA   MMG  NGRA\n       <dbl>      <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1       2.47       1.34  15.2  49.5  173.  339.  512.\n\n\nFunções próprias podem ser aplicadas dentro da função summarise() para computar uma estatística personalizada. Como exemplo, vamos criar uma função chamada se que retornará o erro padrão da média e aplicá-la a todas as variáveis que iniciam \"M\", para cada nível do fator AMB.\n\nse <- function(x){\n  return(sd(x, na.rm = TRUE) / sqrt(length(x)))\n}\n\nmaize %>% \n  group_by(AMB) %>%\n  summarise(across(starts_with(\"M\"), se, .names = \"{.col}_se\"))\n\n# A tibble: 4 × 3\n  AMB   MGRA_se MMG_se\n  <chr>   <dbl>  <dbl>\n1 A1       3.23   4.16\n2 A2       3.38   4.86\n3 A3       2.79   4.42\n4 A4       3.12   4.20"
  },
  {
    "objectID": "RGV410046/RGV410046_07_RESUMO.html#diversas-variáveis-diversas-estatísticas",
    "href": "RGV410046/RGV410046_07_RESUMO.html#diversas-variáveis-diversas-estatísticas",
    "title": "7. Sintetização",
    "section": "Diversas variáveis, diversas estatísticas",
    "text": "Diversas variáveis, diversas estatísticas\nSe desejamos computar mais de uma estatística para variáveis específicas, então o próximo código nos ajudará. Note que para aplicar mais de uma função é necessário criar uma lista com o nome das funções. Neste caso, os sufixos _m e _sd representam a média e o desvio padrão, respectivamente. Faremos isso para cada nível da variável HIB.\n\nmaize %>%\n  group_by(HIB) |> \n  summarise(across(starts_with(\"M\"), list(m = mean, sd = sd)))\n\n# A tibble: 13 × 5\n   HIB   MGRA_m MGRA_sd MMG_m MMG_sd\n   <chr>  <dbl>   <dbl> <dbl>  <dbl>\n 1 H1      184.    43.9  365.   53.7\n 2 H10     164.    50.1  320.   67.6\n 3 H11     167.    40.6  333.   53.8\n 4 H12     157.    45.1  316.   55.5\n 5 H13     180.    44.3  340.   60.6\n 6 H2      187.    46.0  356.   59.0\n 7 H3      169.    48.2  346.   61.8\n 8 H4      184.    35.7  346.   55.0\n 9 H5      184.    41.1  341.   60.3\n10 H6      188.    52.7  363.   57.2\n11 H7      171.    44.0  345.   56.3\n12 H8      160.    53.8  322.   71.2\n13 H9      153.    55.2  311.   82.8"
  },
  {
    "objectID": "RGV410046/RGV410046_07_RESUMO.html#quick-tips",
    "href": "RGV410046/RGV410046_07_RESUMO.html#quick-tips",
    "title": "7. Sintetização",
    "section": "Quick tips",
    "text": "Quick tips\n\nmy_quantile <- function(x, probs) {\n  tibble::tibble(x = quantile(x, probs), probs = probs)\n}\nmtcars %>%\n  group_by(cyl) %>%\n  summarise(my_quantile(disp, c(0.25, 0.75)))\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 6 × 3\n# Groups:   cyl [3]\n    cyl     x probs\n  <dbl> <dbl> <dbl>\n1     4  78.8  0.25\n2     4 121.   0.75\n3     6 160    0.25\n4     6 196.   0.75\n5     8 302.   0.25\n6     8 390    0.75\n\nmaize %>%\n   group_by(HIB) %>%\n  summarise(my_quantile(MGRA, c(0.25, 0.75)))\n\n`summarise()` has grouped output by 'HIB'. You can override using the `.groups`\nargument.\n\n\n# A tibble: 26 × 3\n# Groups:   HIB [13]\n   HIB       x probs\n   <chr> <dbl> <dbl>\n 1 H1     162.  0.25\n 2 H1     211.  0.75\n 3 H10    131.  0.25\n 4 H10    199.  0.75\n 5 H11    144.  0.25\n 6 H11    193.  0.75\n 7 H12    121.  0.25\n 8 H12    186.  0.75\n 9 H13    146.  0.25\n10 H13    211.  0.75\n# … with 16 more rows\n\n\nFree website hit counter"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html",
    "title": "8. Visualização de dados",
    "section": "",
    "text": "# meu computador (mudar de acordo)\nsetwd(\"E:/Desktop/UFSC/aulas/classes/RGV410046/data\")"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#grãos-café",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#grãos-café",
    "title": "8. Visualização de dados",
    "section": "Grãos café",
    "text": "Grãos café\nOs dados contidos na aba cafe do arquivo examples_data.xlsx serão utilizados. Este arquivo contém dados do comprimento e largura (mm) de grãos de café, amostrados por diferentes grupos de alunos da disciplina de Bioestatística e Experimentação Agrícola e classificados em diferentes cores. Para carregar estes dados, utilizamos o seguinte comando.\n\ndf <- \n  import(\"examples_data.xlsx\",\n         sheet = \"cafe\",\n         setclass = \"tbl\") |> \n  as_factor(1:3)\ndf\n\n# A tibble: 47 × 5\n   grupo   individuo cor      comprimento largura\n   <fct>   <fct>     <fct>          <dbl>   <dbl>\n 1 Grupo 1 1         vermelho       13.5     16.6\n 2 Grupo 1 2         vermelho       11.1     14.2\n 3 Grupo 1 3         vermelho       13.4     15.9\n 4 Grupo 1 4         vermelho        9.87    14.1\n 5 Grupo 1 5         verde          11.6     16.1\n 6 Grupo 1 6         verde           9.86    13.9\n 7 Grupo 1 7         verde           9.84    12.4\n 8 Grupo 1 8         verde          10.7     14.8\n 9 Grupo 1 9         verde           9.98    13.2\n10 Grupo 1 10        verde          10.3     13  \n# … with 37 more rows"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#dados-da-estação-meteorológica",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#dados-da-estação-meteorológica",
    "title": "8. Visualização de dados",
    "section": "Dados da estação meteorológica",
    "text": "Dados da estação meteorológica\nOs dados contidos em estacao_fazenda.csv contém informações de variáveis climáticas obtidas em sensores automáticos com leituras horárias, do dia 01/01/2022 a 28/11/2022, totalizando 7957 observações. Estes dados serão utilizados ainda neste material, na sessão Section 4.12.\n\ndf_estacao <-  \n  import(\"estacao_fazenda.csv\", setclass = \"tbl\") |>\n  mutate(dia = dmy(dia),\n         m = fct_relevel(factor(m), paste0(1:10))) # reordena os meses\ndf_estacao\n\n# A tibble: 7,957 × 13\n   dia        m     hora   prec  tmax  tmed  tmin urmax urmed urmin dirvent\n   <date>     <fct> <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>\n 1 2022-01-01 1     00:00     0  21.2  20.6  20.2   100  99.5  99.0     0  \n 2 2022-01-01 1     01:00     0  20.5  19.8  19.4   100  99.9  99.6     0  \n 3 2022-01-01 1     02:00     0  19.7  19.4  19.0   100 100.   99.9     0  \n 4 2022-01-01 1     03:00     0  20.0  19.2  18.7   100 100   100       0  \n 5 2022-01-01 1     04:00     0  20.5  20.2  19.8   100 100   100       0  \n 6 2022-01-01 1     05:00     0  20.7  20.2  19.9   100 100   100      79.8\n 7 2022-01-01 1     06:00     0  20.2  19.7  19.1   100 100   100       0  \n 8 2022-01-01 1     07:00     0  20.0  19.5  19.1   100 100   100       0  \n 9 2022-01-01 1     08:00     0  22.1  21.2   0     100  99.3   0       0  \n10 2022-01-01 1     09:00     0  26.0  24.3  22.1   100  89.0  78.6   287. \n# … with 7,947 more rows, and 2 more variables: velvent <dbl>, rajada <dbl>"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#o-pacote-ggplot2",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#o-pacote-ggplot2",
    "title": "8. Visualização de dados",
    "section": "O pacote ggplot2",
    "text": "O pacote ggplot2\nO ggplot2 é um pacote R para produção de gráficos que diferentemente da maioria dos outros pacotes, apresenta uma profunda gramática baseada no livro The grammar of graphics (Wilkinson 2005)1. Os gráficos originados em ggplot2 são baseados em camadas, e cada gráfico tem três componentes chave: data, os dados de onde o gráfico será criado; aes() (aesthetic mappings), que controla o mapeamento estético e as propriedades visuais do gráfico; e ao menos uma camada que irá descrever como cada observação será renderizada. Camadas são usualmente criadas utilizando uma função geom_()."
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#galerias",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#galerias",
    "title": "8. Visualização de dados",
    "section": "Galerias",
    "text": "Galerias\n\nhttps://www.r-graph-gallery.com/portfolio/ggplot2-package/\nhttp://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html\nhttps://r4stats.com/examples/graphics-ggplot2/\nhttp://girke.bioinformatics.ucr.edu/GEN242/pages/mydoc/Rgraphics.html"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#extensões-do-ggplot2",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#extensões-do-ggplot2",
    "title": "8. Visualização de dados",
    "section": "Extensões do ggplot2",
    "text": "Extensões do ggplot2\n\nhttp://www.ggplot2-exts.org/gallery/\nhttps://mode.com/blog/r-ggplot-extension-packages"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#tutoriais-em-português",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#tutoriais-em-português",
    "title": "8. Visualização de dados",
    "section": "Tutoriais em português",
    "text": "Tutoriais em português\n\nhttps://rpubs.com/mnunes/ggplot2\nhttps://analisereal.com/2015/09/19/introducao-ao-ggplot2/\nhttps://timogrossenbacher.ch/2016/12/beautiful-thematic-maps-with-ggplot2-only/\nhttp://recologia.com.br/tag/graficos/\nhttp://rstudio-pubs-static.s3.amazonaws.com/24563_3b7b0a6414824e3b91769a95309380f1.html\nhttp://eduardogutierres.com/inteligencia-geografica-gerando-mapas-em-r/\nhttps://pt.stackoverflow.com/questions/332053/r-mapa-de-cidades-brasileiras"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#meu-primeiro-gráfico-em-ggplot2",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#meu-primeiro-gráfico-em-ggplot2",
    "title": "8. Visualização de dados",
    "section": "Meu primeiro gráfico em ggplot2",
    "text": "Meu primeiro gráfico em ggplot2\nA seguir, vamos discutir os aspcetos básicos para a construção de gráficos utilizando o pacote ggplot2. A função arrange_ggplot() do pacote metan é utilizada aqui para organizar os gráficos em forma de painéis."
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#as-camadas-de-um-gráfico-ggplot2",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#as-camadas-de-um-gráfico-ggplot2",
    "title": "8. Visualização de dados",
    "section": "As camadas de um gráfico ggplot2",
    "text": "As camadas de um gráfico ggplot2\nNo ggplot2, os gráficos são construídos camada por camada (ou, layers, em inglês). Neste exemplo, vamos confeccionar um gráfico mostrando a distribuição do comprimento da folha (eixo x) e largura da folha (eixo y).\n\np1 <- \n  ggplot(df, aes(x = comprimento, y = largura)) +\n  geom_point()\np1\n\n\n\n\nEste comando criou um gráfico e armazenou no objeto p1, que será plotado posteriormente. Observe que o primeiro argumento da função é o data frame onde nossos dados foram armazenados. A função aes() descreve como as variáveis são mapeadas (neste caso comprimento no eixo x e largura no eixo y). A função geom_point() definiu que a forma geométrica a ser utilizada é baseada em pontos, gerando, assim, um gráfico de dispersão. Isto é tudo que precisa ser feito para a confecção de um gráfico simples."
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#aesthetics-estética",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#aesthetics-estética",
    "title": "8. Visualização de dados",
    "section": "Aesthetics (estética)",
    "text": "Aesthetics (estética)\n\n“O maior valor de uma imagem é quando ela nos obriga a perceber o que nunca esperamos ver.” — John Tukey\n\nAlterar a estética dos gráficos ggplot2 é uma tarefa relativamente simples. No gráfico anterior, os valores do comprimento e largura foram plotados sem nenhum tipo de mapeamento estético. Digamos que marcadores com diferentes cores para cada nível do fator cor poderia nos ajudar a compreender melhor o padrão presente em nossos dados. Vamos confeccionar este gráfico.\n\np2 <- \n  ggplot(df, aes(x = comprimento,\n                 y = largura,\n                 colour = cor)) +\n  geom_point()\np2\n\n\n\n\nAo incluirmos colour = cor dentro da função aes, dizemos ao ggplot que os pontos devem ser mapeados esteticamente (neste caso utilizando cores) para cada nível do fator cor presente em nossos dados. Digamos que em vez de utilizar diferentes cores, a cor do grão do café deveria ser representada por diferentes tipos de marcadores (quadrados, triângulo, etc.) Neste caso, o argumento colour = cor é substituído por shape = cor.\n\np3 <- \n  ggplot(df, aes(x = comprimento, \n                 y = largura,\n                 shape = cor,\n                 color = cor)) +\n  geom_point()\n\n# organizar os gráficos\narrange_ggplot(p1, p2, p3,\n               ncol = 3,\n               tag_levels = list(c(\"p1\", \"p2\", \"p3\")))"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#salvar-gráficos",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#salvar-gráficos",
    "title": "8. Visualização de dados",
    "section": "Salvar gráficos",
    "text": "Salvar gráficos\nA função ggsave() é uma função conveniente para salvar um gráfico. O padrão é salvar a última plotagem exibida, usando o tamanho do dispositivo gráfico atual. Também é possível informar a altura (height) e largura (width). Ele também adivinha o tipo de dispositivo gráfico da extensão. No seguinte exemplo, o gráfico acima é salvo no diretório de trabalho atual com o nome pontos.png, com 5 polegadas de altura e 10 de largura.\n\nggsave(\"pontos.png\",\n       height = 5,\n       width = 10)"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#facet-facetas",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#facet-facetas",
    "title": "8. Visualização de dados",
    "section": "Facet (facetas)",
    "text": "Facet (facetas)\nMapeando os diferentes níveis de cor para diferentes cores, incluímos em um único gráfico os dados de todos osgrupos. Mas, e se nosso objetivo fosse realizar um gráfico para cada grupo? O ggplot2 tem uma poderosa ferramenta para isto: as funções facet_. Ao utilizar estas funções, o conjunto de dados é subdividido e um gráfico é construído para cada um destes subconjuntos. Vamos ver como elas podem nos ajudar em nosso problema.\n\nfac1 <- \n  ggplot(df, aes(x = comprimento,\n                 y = largura,\n                 color = cor)) +\n  geom_point() +\n  facet_wrap(~ grupo)\nfac1\n\n\n\n\nUm painel para cada nível da variável grupo.\n\n\n\n\nNeste exemplo, um gráfico completamente diferente do anterior é gerado com apenas uma simples adição: incluímos uma nova função, facet_wrap(~ grupo). Neste caso, informamos que um gráfico deveria ser realizado para cada grupo."
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#theme-temas",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#theme-temas",
    "title": "8. Visualização de dados",
    "section": "Theme (temas)",
    "text": "Theme (temas)\nCada gráfico criado com a função ggplot() tem um tema padrão. Tema, aqui, é toda propriedade relacionada ao aspecto visual do gráfico, que não foi definida na função aes() e que pode ser modificada utilizando a função theme() (veja ?theme). O ggplot2 já conta com alguns temas personalizados para facilitar nosso trabalho. Considerando o exemplo anterior, vamos utilizar a função theme_bw() (preto e branco) e a função theme() para modificar as propriedades visuais do gráfico.\n\nfac2 <- \n  ggplot(df, aes(x = comprimento, y = largura, color = cor)) +\n  geom_point() +\n  facet_wrap(~ grupo) +\n  theme_light() +\n  theme(panel.grid.minor = element_blank(), # remove as linhas do corpo do gráfico\n        # sem bordas entre os painéis\n        panel.spacing = unit(0, \"cm\"),\n        # legenda abaixo do gráfico\n        legend.position = \"bottom\",\n        # modifica o texto dos eixos\n        axis.text = element_text(size = 12, colour = \"black\"),\n        # cor dos marcadores\n        axis.ticks = element_line(colour = \"black\"),\n        # tamanho dos marcadores\n        axis.ticks.length = unit(.2, \"cm\"), \n        #cor da borda\n        panel.border = element_rect(colour = \"black\", fill = NA, size = 0.5))+\n  # título dos eixos\n  labs(x = \"Comprimento do grão (mm)\", # título do eixo x\n       y = \"Largura do grão (mm)\", # título do eixo y\n       color = \"\") # título da legenda\n\narrange_ggplot(fac1, fac2,\n               ncol = 1,\n               tag_levels = list(c(\"f1\", \"f2\")))\n\n\n\n\nGráfico de dispersão considerando a confecção de um gráfico para cada nível de um fator(f1) e modificações na propriedades do tema de um gráfico ggplot2 (f2)\n\n\n\n\nOs argumentos inseridos dentro das função theme() modificaram a aparência do nosso gráfico. Inúmeros outros argumentos são disponíveis, fazendo com que os gráficos originados sejam completamente personalizáveis. Digamos que precisamos confeccionar diversos gráficos e gostaríamos de manter o mesmo tema do gráfico acima. Seria exaustivo e desinteressante informar cada vez estes argumentos para cada gráfico, não? Felizmente, outra poderosa ferramenta proporcionada pelo ggplot2 é a possibilidade de confeccionarmos nossos próprios temas. Para isto, vamos executar o seguinte comando para criar um tema personalizado (my_theme()). Este tema pode então ser aplicado como uma camada adicional a cada gráfico que confecionarmos. Para evitar a necessidade da inclusão deste tema em cada gráfico gerado, iremos definir este tema como padrão utilizando a função theme_set().\n\nmy_theme <- function () {\n  theme_light() %+replace% # permite que os valores informados possam ser sobescritos\n    theme(axis.ticks.length = unit(.2, \"cm\"),\n          axis.text = element_text(size = 12, colour = \"black\"),\n          axis.title = element_text(size = 12, colour = \"black\"),\n          axis.ticks = element_line(colour = \"black\"),\n          panel.border = element_rect(colour = \"black\", fill = NA, size = 0.5),\n          panel.grid.minor =  element_blank())\n}\ntheme_set(my_theme())"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#geoms-geometria",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#geoms-geometria",
    "title": "8. Visualização de dados",
    "section": "Geoms (geometria)",
    "text": "Geoms (geometria)\nAs funções geom_ definem qual forma geométrica será utilizada para a visualização dos dados no gráfico. Até agora, utilizamos a função geom_point()para construir gráficos de dispersão. Basicamente, qualquer outro tipo de gráfico pode ser criado dependendo da função geom_ utilizada. Dentre as diversas disponíveis no pacote ggplot2 as funções geom_ mais utilizadas são:\n\ngeom_abline(): para retas definidas por um intercepto e uma inclinação;\ngeom_hline(): para retas horizontais definidas por um intercept y;\ngeom_vline(): para retas verticais definidas por um intercept x;\ngeom_boxplot(): para boxplots;\ngeom_histogram(): para histogramas de frequência;\ngeom_smooth(): ajusta uma função para o conjunto de dados e mostra uma banda de confiança;\ngeom_density(): para densidades;\ngeom_area(): para áreas;\ngeom_bar(): para barras;\ngeom_errorbar() para barras de erro;\n\nDeste ponto em diante, vamos confeccionar alguns exemplos utilizando algumas destas funções (ou combinações destas funções) incluindo argumentos de mapeamento de estética e temas vistos até agora.\n\nLinhas horizontais, verticais e diagonais\nTrês importantes geometrias são apresentadas a seguir:\n\ngeom_hline() adiciona uma linha horizontal definida por um intercepto em y\ngeom_vline() adiciona uma linha vertical definida por um intercepto em x.\ngeom_abline() adiciona uma linha diagonal definida por um intercepto e uma inclinação.\n\n\ng1 <- \n  ggplot(df, aes(comprimento, largura)) +\n  geom_point()\n\n\n# adiciona linhas horizontais e verticais\ng2 <- \n  g1 +\n  geom_hline(yintercept = mean(df$largura), color = \"blue\") +\n  geom_vline(xintercept = mean(df$comprimento), color = \"red\")\n\narrange_ggplot(g1, g2,\n               ncol = 1,\n               tag_levels = list(c(\"g1\", \"g2\")))\n\n\n\n\n\n\nGráficos do tipo boxplot\n\nbox1 <- \n  ggplot(df, aes(grupo, comprimento)) +\n  geom_boxplot()\n\nbox2 <- \n  ggplot(df, aes(grupo, comprimento)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.1, color = \"salmon\")\n\nbox3 <- \n  ggplot(df, aes(grupo, comprimento, fill = cor)) +\n  geom_boxplot(width = 0.3) + \n  labs(x = \"Grupo\",\n       y = \"Comprimento do grão (mm)\") +\n  theme(legend.position = \"bottom\") +\n  scale_fill_manual(values = c(\"green\", \"red\"))\n\narrange_ggplot((box1 + box2) / box3,\n               tag_levels = list(c(\"b1\", \"b2\", \"b3\")))\n\n\n\n\nGráfico do tipo boxplot combinando mapeamentos estéticos.\n\n\n\n\nCinco estatísticas são mostradas neste boxplot. A mediana (linha horizontal), as caixas inferior e superior (primeiro e terceiro quartil (percentis 25 e 75, respectivamente)). A linha vertical superior se estende da caixa até o maior valor, não maior que $1,5 $ (onde IQR é a amplitude interquartílica). A linha vertical inferior se estende da caixa até o menor valor, de no máximo, $1,5 $. Dados além das linhas horizontais podem ser considerados outliers.\n\n\nGráficos do tipo barra\nNo seguinte exemplo, os dados do comprimento do grão de café disponíveis em df são utilizados.\n\nbar1 <- \n  ggplot(df, aes(x = grupo, y = comprimento)) +\n  geom_bar(stat = \"summary\", fun = \"mean\")\n\nbar2 <- \n  ggplot(df, aes(x = grupo, y = comprimento, fill = cor)) +\n  stat_summary(fun = mean,\n               geom = \"bar\",\n               col = \"black\",\n               width = 0.8,\n               position = position_dodge(0.8)) + \n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.2,\n               position = position_dodge(0.8))\n\n\narrange_ggplot(bar1, bar2,\n               widths = c(0.6, 1.2),\n               tag_levels = list(c(\"bar1\", \"bar2\")))\n\n\n\n\nGráfico do tipo barras, com mapeamento estético e barras de erro.\n\n\n\n\nA afirmação de que um gráfico ggplot2 é feito em camadas fica mais evidente aqui. No gráfico bar1, as barras representam as médias geral do comprimento para cada grupo. No segundo gráfico, ao usar fill = cor informamos que as barras devem ser coloridas para cada nível do fator cor. A função stat_summary(), é vista pela primeira vez aqui, foi utilizada no segundo gráfico para substituir a função geom_bar(). Com isto, foi possível incluir as médias (fun = mean e geom = \"bar), bem como as barras de erro (fun.data = mean_se e geom = \"errorbar\").\nUtilizando a função plot_factbars() do pacote metan, um gráfico semelhante pode ser criado com as funções plot_bars() e plot_factbars()\n\nmetan1 <- \n  plot_bars(df,\n            x = grupo,\n            y = comprimento)\nmetan2 <- \n  plot_factbars(df, # dados\n                grupo, cor, # dois fatores\n                resp = comprimento) # eixo y\n\narrange_ggplot(metan1, metan2,\n               widths = c(0.6, 1.2),\n               tag_levels = list(c(\"metan1\", \"metan2\")))\n\n\n\n\n\n\n\n\n\nGráficos do tipo histograma\nNeste exemplo, utilizaremos os dados de temperatura média da estação meteorológica, disponível no data frame df_estacao. O primeiro histograma (p1) mostra os dados gerais desde 01/01/2022. No segundo, um histograma é gerado para cada mês.\n\nh1 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_histogram()\n\nh2 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_histogram(fill = \"skyblue\") +\n  facet_wrap(~m) +\n  labs(x = \"Temperatura média (ºC)\",\n       y = \"Número de horas\")\n\narrange_ggplot(h1, h2,\n               widths = c(1, 1.4),\n               tag_levels = list(c(\"h1\", \"h2\")))\n\n\n\n\nGráfico do tipo histograma\n\n\n\n\n\n\nGráficos de densidade\nOs gráficos de densidade, têm a mesma interpretação que histogramas, no então são esteticamente mais atraente. Os primeiros dois exemplos nada mais são que a versão densidade dos histogramas apresentados anteriormente.\nNo terceiro exemplo (d3), é mostrado como é possível construir um gráfico de densidade ridges. Gráficos ridges são gráficos de linha parcialmente sobrepostos que criam a impressão de uma cordilheira. Eles podem ser bastante úteis para visualizar mudanças nas distribuições ao longo do tempo ou espaço2.\n\nd1 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_density()\n\nd2 <- \n  ggplot(df_estacao, aes(x = tmed)) +\n  geom_density(color = \"black\",\n               fill = \"skyblue\") +\n  facet_wrap(~m, ncol = 6) +\n  labs(x = \"Temperatura média (ºC)\",\n       y = \"Densidade\")\n\nd3 <- \n  ggplot(df_estacao, aes(x = tmed, y = m, fill = stat(x))) +\n  geom_density_ridges_gradient() +\n  scale_fill_viridis_c() +\n  labs(x = \"Temperatura média (ºC)\",\n       y = \"Meses do ano\",\n       fill = \"Temperatura\\nmédia (ºC)\")\n\n# agrupa os gráficos\narrange_ggplot(d1 + d2,\n               d3,\n               nrow = 2,\n               heights = c(0.3, 0.7), # maior altura do gráfico d3\n               tag_levels = list(c(\"d1\", \"d2\", \"d3\")))\n\n\n\n\nGráfico do tipo densidade\n\n\n\n\n\n\nGráficos de linhas\nO seguinte exemplo mostra a temperatura mínima, média e máxima ao longo dos dias desde 01/01/2022. Primeiro, é preciso obter as temperaturas mínimas, máximas e médias de cada dia. Fazemos isso com a função summarise().\n\nclima_max_min <-\n  df_estacao %>%\n  group_by(dia) %>% \n  summarise(max = max(tmax),\n            min = min(tmin),\n            mean = mean(tmed),\n            precip = sum(prec)) %>% \n  pivot_longer(-dia)\nclima_max_min\n\n# A tibble: 1,328 × 3\n   dia        name   value\n   <date>     <chr>  <dbl>\n 1 2022-01-01 max     28.7\n 2 2022-01-01 min      0  \n 3 2022-01-01 mean    24.0\n 4 2022-01-01 precip   0  \n 5 2022-01-02 max     31.8\n 6 2022-01-02 min     23.4\n 7 2022-01-02 mean    27.1\n 8 2022-01-02 precip   0  \n 9 2022-01-03 max     32.4\n10 2022-01-03 min     24.3\n# … with 1,318 more rows\n\n\n\n# realiza um subset para remover a precipitação\ndf_temp <-  \n  clima_max_min |>  \n  subset(name != \"precip\")\n\n# faz o gráfico de linhas\nggplot(df_temp, aes(dia, value, color = name, group = name)) +\n  geom_point() + \n  geom_line() + \n  scale_color_manual(values = c(\"red\", \"green\", \"blue\"),\n                     labels = c(\"Temperatura máxima (ºC)\",\n                                \"Temperatura média (ºC)\",\n                                \"Temperatura mínima (ºC)\"),\n                     guide = \"legend\") + \n  scale_x_date(date_breaks = \"3 week\", # marcação a cada duas semanas\n               date_labels = \"%d/%m/%y\") + # formato dd/mm/aa\n  theme(legend.position = \"bottom\",\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) + \n  labs(title = \"Temperaturas máximas, médias e mínimas em 2022\",\n       subtitle = \"Estação - Fazenda Ressacada\",\n       caption = \"Elaboração: Prof. Olivoto\",\n       x = \"Dia do ano\",\n       y = \"Temperatura (ºC)\",\n       color = NULL) # remove o título da legenda\n\n\n\n\n\n\n\n\n\nLinha de regressão (linear)\n\nl1 <-\n  ggplot(df, aes(x = comprimento, y = largura)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) + # estima uma regressão linear\n  labs(x = \"Comprimento do grão\",\n       y = \"Largura do grão\")\n\nl2 <-\n  ggplot(df, aes(x = comprimento, y = largura, color = grupo)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F)+\n  labs(x = \"Comprimento do grão\",\n       y = \"Largura do grão\")\n\narrange_ggplot(l1, l2,\n               tag_levels = list(c(\"s1\", \"s2\")),\n               widths = c(1, 1.2))\n\n\n\n\nGráfico de dispersão, combinando pontos e linhas de regressão.\n\n\n\n\n\n\nLinha de regressão (polinomial)\nPara confeccionar um gráfico de regressão polinomial, além do argumento method = \"lm\" (linear model), precisa-se incluir no argumento formula a formula utilizada, neste caso, definida utilizando poly() (polinomial).\n\n#### Polinômio de segundo grau\n\ndado_reg <- tibble(dose = c(15,20,25,30,35,40),\n                   prod = c(65,70,73,75,69,62))\n\nq1 <-\n  ggplot(dado_reg, aes(dose, prod))+\n  geom_point()+\n  stat_smooth(method = \"lm\",\n              formula = \"y ~ poly(x, 1)\",\n              se = FALSE)\n\nq2 <-\n  q1 +\n  stat_smooth(method = \"lm\",\n              formula = \"y ~ poly(x, 2)\",\n              linetype = \"dashed\",\n              color = \"red\",\n              se = FALSE)\n\narrange_ggplot(q1, q2, tag_levels = list(c(\"l1\", \"l2\")))\n\n\n\n\nGráfico de dispersão combinado com inclusão de curvas ajustadas.\n\n\n\n\nUtilizando a função plot_lines() do pacote metan, um gráfico semelhante pode ser criado com\n\nplot_lines(dado_reg,\n           x = dose,\n           y = prod,\n           fit = 2)"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#sec-dados-da-estação",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#sec-dados-da-estação",
    "title": "8. Visualização de dados",
    "section": "Dados da estação",
    "text": "Dados da estação\n\nExploração dos dados\n\nplot_intro(df_estacao)\n\n\n\n# Colunas numéricas\nplot_histogram(df_estacao, ncol = 5)\n\n\n\n\n\n\nGráfico da precipitação e temperatura\n\n#| out-width: \"100%\"\n\ndf_prec <- \n  clima_max_min |> \n  pivot_wider(names_from = \"name\",\n              values_from = \"value\")\n\nggplot() +\n  geom_bar(df_prec,\n           mapping = aes(x = dia, y = precip * 30 / 100),\n           stat = \"identity\",\n           fill = \"skyblue\") +\n  geom_line(df_prec,\n            mapping = aes(x = dia, y = max, colour = \"red\"),\n            size = 1) +\n  geom_line(df_prec, \n            mapping = aes(x = dia, y = min, colour = \"blue\"),\n            size = 1) +\n  scale_x_date(date_breaks = \"15 days\", date_labels =  \"%d/%m\",\n               expand = expansion(c(0, 0)))+\n  scale_y_continuous(name = expression(\"Temperatura (\"~degree~\"C)\"),\n                     sec.axis = sec_axis(~ . * 100 / 30 , name = \"Precipitação (mm)\")) +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +\n  scale_color_identity(breaks = c(\"red\", \"blue\"),\n                       labels = c(\"Temperatura máxima (ºC)\",\n                                  \"Temperatura mínima (ºC)\"),\n                       guide = \"legend\") +\n  labs(x = \"Dia do ano\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nTemperaturas máximas e mínimas e precipitação observada ao longo dos dias.\n\n\n\n\n\n\nVelocidade média do vento\n\nvento_long <-\n  df_estacao %>%\n  select(m, hora, velvent) %>% \n  pivot_longer(-c(m, hora))\n\n\n\n# confeccionar gráfico\nggplot(vento_long, aes(m, value, color = name, group = name )) +\n  stat_summary(geom = \"point\", \n               fun = mean) +\n  stat_summary(geom = \"line\") + \n  stat_summary(geom = \"errorbar\", width = 0.1) +\n  scale_color_manual(values = c(\"red\", \"blue\"),\n                     labels = c(\"Rajada (m/s)\",\n                                \"Velocidade do vento (m/s)\"),\n                     guide = \"legend\") +\n  theme(panel.grid.minor = element_blank(),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 12)) + \n  labs(title = \"Velocidade média mensal do vento em 2022\",\n       subtitle = \"Estação UFSC - Ressacada\",\n       caption = \"Elaboração: Prof. Tiago Olivoto\",\n       x = \"Mês do ano\",\n       y = \"Velocidade (m/s)\")\n\n\n\n\n\n\nDireção do vento\n\n\n# cria uma tabela de frequência transformando a variável quantitativa direção do vento\n# em uma qualitativa usando a função cut()\n\nfreq <- \ndf_estacao %>% \n  group_by(m) %>% \n  mutate(quadrante = cut(dirvent, \n                         breaks = seq(0, 360, by = 45),\n                         right = FALSE)) |> \n  group_by(m, quadrante) |> # conta as horas por mes e por quadrante\n  count() |> # conta as horas por mes e por quadrante\n  group_by(m) |> # agrupa por mes\n  mutate(percent = n / sum(n)) |> # converte em percentagem\n  select(m, quadrante, percent) |> \n  pivot_wider(names_from = quadrante, values_from = percent) |> \n  set_names(c(\"mes\", paste0(seq(0, 315, by = 45)))) |> \n  column_to_rownames(\"mes\") |> \n  slice(2, 11)\n\n# altera o nome das colunas para pontos cardeais\nnames(freq) <- c(\"N\", \"NE\", \"L\", \"SE\", \"S\", \"SO\", \"O\", \"NO\")\nfreq\n##            N         NE          L         SE         S         SO          O\n## 2  0.2098214 0.08779762 0.04613095 0.04464286 0.1577381 0.07142857 0.09970238\n## 11 0.1437216 0.04689864 0.09531014 0.21482602 0.2042360 0.04992436 0.07866868\n##           NO\n## 2  0.2827381\n## 11 0.1664145\n\n# define o máximo da frequência e o mínimo da frequência\n# isso vai definir o quao expandido e contraído ficará o radar\nmaxmim <- data.frame(rbind(rep(0.4, 8), rep(0, 8)))\nnames(maxmim) <- c(\"N\", \"NE\", \"L\", \"SE\", \"S\", \"SO\", \"O\", \"NO\")\n\n# junta as frequências com os máximos e mínimos\nfreqrad <- rbind(maxmim, freq)\n# inverte a ordem das colunas para ficar certo na rosa dos ventos\nfreqrad <- freqrad[,c(1, seq(8, 2))]\n\nlibrary(fmsb) # pacote para criar o radar\n# https://r-charts.com/ranking/radar-chart/\nareas <- c(rgb(1, 0, 0, 0.3),\n           rgb(0, 1, 0, 0.3))\nradarchart(freqrad,\n           seg = 3,\n           axistype = 4,\n           caxislabels = paste0(c(0, 10, 20, 30), \"%\"),\n           pcol = c(\"red\", \"green\"),\n           pfcol = areas)\nlegend(\"topright\",\n       legend = c(\"Junho\", \"Novembro\"),\n       bty = \"n\",\n       pch = 20,\n       col = areas,\n       text.col = \"grey25\",\n       pt.cex = 2)"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#mapas",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#mapas",
    "title": "8. Visualização de dados",
    "section": "Mapas",
    "text": "Mapas\n\nMapa da américa do sul e Brasil\nO pacote rnaturalearth é uma excelente ferramenta para manter e facilitar a interação com os dados do mapa Natural Earth. Para produção de mapas com o ggplot2, os seguintes pacotes são necessários.\n\n#| out-width: \"100%\"\n\n\n# américa do sul\nlibrary(rnaturalearth)\nlibrary(tidyverse)\nsam <-\n  ne_countries(continent = \"south america\",\n               returnclass = \"sf\",\n               scale = 50)\n\np1 <- \n  ggplot() +\n  geom_sf(data = sam, fill = \"white\") +\n  theme_light() +\n  xlim(c(-90, -35))\n\n# plotar o brasil e destacar santa catarina\nbrazil <- \n  ne_states(country = \"brazil\", returnclass = \"sf\") |> \n  mutate(scat = ifelse(postal == \"SC\", \"SC\", \"Outros\"))\n\np2 <- \n  p1 + \n  geom_sf(data = brazil, aes(fill = scat))\np2\n\n\n\n\n\n\nMapa do Brasil e SC, com municípios\n\nsc <- \n  read_municipality(code_muni = \"SC\",\n                    simplified = FALSE,\n                    showProgress = FALSE) |> \n  mutate(floripa = ifelse(name_muni == \"Florianópolis\",\n                          \"Florianópolis\",\n                          \"Outro\"))\n\nUsing year 2010\n\np3 <-\n  p1 + \n  geom_sf(data = brazil) +\n  geom_sf(data = sc, aes(fill = floripa)) +\n  xlim(c(-55, -47)) +\n  ylim(c(-30, -25)) +\n  labs(title = \"Mapa do brasil destacando o estado de SC\",\n       caption = \"Produzido com os pkgs geobr e rnaturalearth\",\n       fill = \"\") +\n  theme(legend.position = \"bottom\")\n\nScale for x is already present.\nAdding another scale for x, which will replace the existing scale.\n\np3"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#o-pacote-esquisse",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#o-pacote-esquisse",
    "title": "8. Visualização de dados",
    "section": "O pacote esquisse",
    "text": "O pacote esquisse\nO pacote esquisse ajuda a explorar e visualizar dados de forma interativa. Ele é uma interface Shiny para criar gráficos ggplot interativamente usando “arrastar e soltar” para mapear suas variáveis. Pode-se visualizar rapidamente os dados de acordo com seu tipo, exportar para formatos raster (ex., .png, .jpg) ou vetor (ex., .pdf, .eps) e recuperar o código para reproduzir o gráfico.\nPara inciar a criação do gráfico, basta carregar o pacote e executar o comando esquisser(). Uma janela aparecerá, onde será possível importar um conjunto de dados, ou utilizar um conjunto de dados existente no ambiente R.\n\nesquisser()\n\n\nApós selecionar o conjunto de dados, as variáveis existentes ficarão disponíveis para serem mapeadas. Basta clicar e arrastar! Para ter uma maior área de trabalho do pacote, sugere-se definir a opção para que a interface gráfica do pacote seja aberta no navegador. Para isso, rode options(\"esquisse.viewer\" = \"browser\")."
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#motivação",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#motivação",
    "title": "8. Visualização de dados",
    "section": "Motivação",
    "text": "Motivação\nA densidade de fluxo de fótons fotossintéticos (PPFD) em níveis subótimos ou superótimos pode modificar o acúmulo de biomassa, composição bromatológica e aparência das culturas. Para isso, Olivoto et al. (2018)3 investigaram o efeito de níveis de radiação no crescimento da chicória (Cichorium endivia L. var. latifolia). Os dados disponíveis na aba chicoria do conjunto de dados examples_data.xlsx são relativos a duas variáveis, à saber, matéria seca total (MST) e área foliar (AF) de plantas de chicória cultivadas em diferentes níveis de sombreamento (50, 70, e 100), e avaliados aos 21, 28 e 35 dias após o plantio.\n\ndf <-  import(\"examples_data.xlsx\",\n              sheet = \"chicoria\",\n              setclass = \"tbl\")\ndf\n\n# A tibble: 36 × 5\n   DAP   SOM   REP     MST    AF\n   <chr> <chr> <chr> <dbl> <dbl>\n 1 21DAP 50R   B1     4.31  847.\n 2 21DAP 50R   B2     5.25 1607.\n 3 21DAP 50R   B3     4.50 1320.\n 4 21DAP 50R   B4     4.61 1567.\n 5 21DAP 70R   B1     4.12 1206.\n 6 21DAP 70R   B2     5.52 1863.\n 7 21DAP 70R   B3     5.27 1774.\n 8 21DAP 70R   B4     4.26 1307.\n 9 21DAP 100R  B1     5.24 1203.\n10 21DAP 100R  B2     5.70 1299.\n# … with 26 more rows\n\n\nPara lapidar os conhecimentos na construção de gráficos, utilize o pacote ggplot24 e metan5 para solução dos seguintes problemas."
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#problema-1---associação-entre-variáveis",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#problema-1---associação-entre-variáveis",
    "title": "8. Visualização de dados",
    "section": "Problema 1 - Associação entre variáveis",
    "text": "Problema 1 - Associação entre variáveis\n\nConsiderando os dados, construa um gráfico de dispersão com a variável AF no eixo x e a variável MST no eixo y, salve o gráfico em um objeto chamado p1.\n\n\np1 <- \n  ggplot(df, aes(AF, MST)) +\n  geom_point()\n\n\nPara melhor compreender a distribuição dos pontos, realize o mapeamento da variável DAP com diferentes cores.\nAltere a legenda do eixo x e y para ‘Área foliar (cm2)’ e ‘Matéria seca (g)’, respectivamente.\nAplique um tema de sua preferência ao tema utilizando qualquer tema definido por theme_*()6.\nArmazene o gráfico em um objeto chamado p2.\n\n\np2 <- \n  ggplot(df, aes(AF, MST, color = DAP)) +\n  geom_point() +\n  labs(x = \"Área foliar (cm2)\",\n       y = \"Matéria seca (g)\")\n\n\nOrganize os gráficos p1 e p2 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p1, p2)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à associação entre AF e MST.\n\n\nA área foliar e a matéria seca estão positivamente relacionadas, ou seja, há a tendêncida de que o aumento na área foliar venha acompanhado do aumento na matéria seca. No segundo gráfico, é possível identificar que os maiores valores de matéria seca e área foliar foram observados nos 35DAP, e o menores, aos 21DAP.\n\n\nSalve os gráficos em um arquivo chamado dispersão.png, com 3 polegadas de altura e 8 de largura\n\n\nggsave(\"dispersão.png\", width = 8, height = 3)"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#problema-2---variação-dos-dados",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#problema-2---variação-dos-dados",
    "title": "8. Visualização de dados",
    "section": "Problema 2 - Variação dos dados",
    "text": "Problema 2 - Variação dos dados\n\nConfeccione um gráfico do tipo boxplot contendo a variável DAP no eixo x e MST no eixo y. Salve o gráfico em um objeto chamado p3.\n\n\np3 <- \n  ggplot(df, aes(DAP, MST)) +\n  geom_boxplot()\n\n\nPara fazer inferências sobre o fator sombreamento, construa um boxplot semelhante, mas agora mapeando a variável SOM com diferentes cores de preenchimento do boxplot. * Inclua uma linha horizontal que represente a média geral da matéria seca.\nSalve o gráfico em um objeto chamado p4.\n\n\np4 <- \n  ggplot(df, aes(DAP, MST, fill = SOM)) +\n  geom_boxplot() +\n  geom_hline(yintercept = mean(df$MST))\n\n\nOrganize os gráficos p3 e p4 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p3, p4)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à variação da matéria seca total entre os diferentes níveis de radiação dentro de cada dia após o plantio.\n\n\nAos 21DAP foi observada a menor variação entre os níveis de SOM. Aos 28DAP, a diferença entre os níveis de SOM foi mais evidente, onde plantas crescendo em 100R apresentaram um valor mediano de MST maior, mas também a maior variação entre as repetições (comprimento da caixa). Aos 35DAP, a diferença entre as radiações torna-se mais evidente. Também, pode-se observar que as variações entre as repetições do 100R e 50R foram menores se comparado aos 28DAP (menor comprimento da caixa).\n\n\nSalve os boxplots em um arquivo chamado boxplot.png.\n\n\nggsave(\"boxplot.png\")"
  },
  {
    "objectID": "RGV410046/RGV410046_08_DATAVIZ.html#problema-3---médias",
    "href": "RGV410046/RGV410046_08_DATAVIZ.html#problema-3---médias",
    "title": "8. Visualização de dados",
    "section": "Problema 3 - Médias",
    "text": "Problema 3 - Médias\n\nConfeccione um gráfico de barras mostrando a média da variável AF no eixo y para cada dia após o plantio (DAP) no eixo x.\nDefina os limites do eixo y de 0 até 6000.\nSalve o gráfico em um objeto chamado p5.\n\n\nDica: a função plot_bars() do pacote metan pode ser útil.\n\n\np5 <- \n  plot_bars(df,\n            x = DAP,\n            y = AF,\n            y.lim = c(0, 6000))\n\n# versão ggplot2\np5.2 <- \n  ggplot(df, aes(DAP, AF)) +\n  geom_bar(stat = \"summary\") +\n  ylim(c(0, 6000))\n\n\nAssumindo que as médias da AF precisam ser apresentadas para cada combinação de DAP e SOM, mapeie a variável SOM com diferentes cores de preenchimento no gráfico de barras.\nMude os títulos dos eixos x e y para “Dias após o plantio (DAP)” e “Área foliar (cm2)”, respectivamente.\nDefina os limites do eixo y de 0 até 6000.\nArmazene o gráfico em um objeto chamado p6.\nOrganize os gráficos p5 e p6 em um único painel\nSalve os gráficos de barra em uma imagem chamada barras.png.\n\n\nDica: a função plot_factbars() do pacote metan pode ser útil.\n\n\np6 <- \n  plot_factbars(df, DAP, SOM,\n                resp = AF,\n                y.lim = c(0, 6000),\n                xlab = \"Dias após o plantio (DAP)\",\n                ylab = \"Área foliar (cm2)\")\n\n# versão ggplot2\np6.2 <- \n  ggplot(df, aes(DAP, AF, fill = SOM)) +\n  geom_bar(stat = \"summary\",\n           fun = \"mean\",\n           width = 0.7,\n           position = position_dodge()) +\n  stat_summary(fun.data = mean_se,\n               geom = \"errorbar\",\n               width = 0.2,\n               position = position_dodge( width = 0.7)) +\n  labs(x = \"Dias após o plantio (DAP)\",\n       y = \"Área foliar (cm2)\") +\n  ylim(c(0, 6000))\n\n\nOrganize os gráficos p5 e p6 em um mesmo painel, um ao lado do outro.\n\n\narrange_ggplot(p5, p6)\n\n\n\n\n\nRealize a interpretação do gráfico com relação à área foliar nos diferentes níveis de radiação ao longo dos dias após o plantio.\n\n\nA média da área foliar foi mais semelhante entre os níveis de radiação aos 21DAP. Considerando o erro padrão da média como uma medida de significância, pode-se afirmar que aos 21DAP as médias do 50R e 70R foram estatisticamente iguais. Aos 35DAP, a área foliar das plantas crescendo com 50% de radiação foi menor que àquelas crescendo em pleno sol (100R) e com 70% de radiação (70R).\n\n\nSalve os boxplots em um arquivo chamado barras.png.\n\n\nggsave(\"barras.png\")"
  }
]